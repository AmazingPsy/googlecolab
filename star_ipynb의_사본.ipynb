{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "star.ipynb의 사본",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AmazingPsy/googlecolab/blob/master/star_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--iqy2YVhDbJ",
        "colab_type": "code",
        "outputId": "253e3e0a-cc4b-4244-a7c5-c77f45100acc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!git clone https://github.com/sherjilozair/char-rnn-tensorflow.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'char-rnn-tensorflow'...\n",
            "remote: Enumerating objects: 404, done.\u001b[K\n",
            "remote: Total 404 (delta 0), reused 0 (delta 0), pack-reused 404\u001b[K\n",
            "Receiving objects: 100% (404/404), 508.45 KiB | 1.93 MiB/s, done.\n",
            "Resolving deltas: 100% (238/238), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcjn2z1whRus",
        "colab_type": "code",
        "outputId": "7e6c590a-37b9-46e3-8e42-ee094b3e78b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvko_JvNhbWd",
        "colab_type": "code",
        "outputId": "4b9ddbb0-761d-4d68-ef4e-900443620c1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cp input.txt /content/char-rnn-tensorflow/data/star"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cp: cannot stat 'input.txt': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhlFDXrDiTy6",
        "colab_type": "code",
        "outputId": "beb5e75e-661d-4a51-e035-9509895b95c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "filepath=\"/content/gdrive/My Drive/MyCNN/epochs:{epoch:03d}-val_acc:{val_acc:.3f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-299207f3dcf4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/content/gdrive/My Drive/MyCNN/epochs:{epoch:03d}-val_acc:{val_acc:.3f}.hdf5\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'max'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcallbacks_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ModelCheckpoint' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtExPUYHidGe",
        "colab_type": "code",
        "outputId": "72298dfc-2e2f-4510-cc86-9bfd2b9cdd2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python train.py --data_dir=./data/star/ --log_dir=./logs_star --save_dir=./save_star"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "reading text file\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0828 01:14:01.099411 140429351114624 deprecation.py:323] From /content/char-rnn-tensorflow/model.py:30: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "W0828 01:14:01.106169 140429351114624 deprecation.py:323] From /content/char-rnn-tensorflow/model.py:36: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
            "W0828 01:14:01.106772 140429351114624 deprecation_wrapper.py:119] From /content/char-rnn-tensorflow/model.py:39: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0828 01:14:01.152246 140429351114624 deprecation_wrapper.py:119] From /content/char-rnn-tensorflow/model.py:46: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0828 01:14:01.152685 140429351114624 deprecation_wrapper.py:119] From /content/char-rnn-tensorflow/model.py:47: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "W0828 01:14:01.153171 140429351114624 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0828 01:14:01.180088 140429351114624 deprecation.py:506] From /content/char-rnn-tensorflow/model.py:57: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0828 01:14:01.568194 140429351114624 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn_cell_impl.py:961: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0828 01:14:03.711559 140429351114624 deprecation_wrapper.py:119] From /content/char-rnn-tensorflow/model.py:86: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "W0828 01:14:06.543206 140429351114624 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/clip_ops.py:286: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0828 01:14:06.554431 140429351114624 deprecation_wrapper.py:119] From /content/char-rnn-tensorflow/model.py:92: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "W0828 01:14:06.681123 140429351114624 deprecation_wrapper.py:119] From /content/char-rnn-tensorflow/model.py:98: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n",
            "\n",
            "W0828 01:14:06.683911 140429351114624 deprecation_wrapper.py:119] From /content/char-rnn-tensorflow/model.py:100: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "W0828 01:14:06.685509 140429351114624 deprecation_wrapper.py:119] From train.py:99: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2019-08-28 01:14:06.686965: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
            "2019-08-28 01:14:06.749731: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-28 01:14:06.750525: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-08-28 01:14:06.766003: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-08-28 01:14:06.953989: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-08-28 01:14:07.029949: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-08-28 01:14:07.051720: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-08-28 01:14:07.274117: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-08-28 01:14:07.403470: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-08-28 01:14:07.784646: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-08-28 01:14:07.784867: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-28 01:14:07.785718: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-28 01:14:07.786413: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-08-28 01:14:07.802904: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
            "2019-08-28 01:14:07.805992: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x25ed2c0 executing computations on platform Host. Devices:\n",
            "2019-08-28 01:14:07.806027: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-08-28 01:14:07.880757: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-28 01:14:07.881615: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x25ed480 executing computations on platform CUDA. Devices:\n",
            "2019-08-28 01:14:07.881646: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2019-08-28 01:14:07.884675: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-28 01:14:07.885434: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-08-28 01:14:07.885509: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-08-28 01:14:07.885540: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-08-28 01:14:07.885566: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-08-28 01:14:07.885590: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-08-28 01:14:07.885615: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-08-28 01:14:07.885638: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-08-28 01:14:07.885664: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-08-28 01:14:07.885731: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-28 01:14:07.886716: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-28 01:14:07.887370: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-08-28 01:14:07.890269: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-08-28 01:14:07.891860: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-08-28 01:14:07.891893: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2019-08-28 01:14:07.891911: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2019-08-28 01:14:07.893612: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-28 01:14:07.894348: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-28 01:14:07.895032: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:40] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-08-28 01:14:07.895080: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "W0828 01:14:07.896013 140429351114624 deprecation_wrapper.py:119] From train.py:101: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "W0828 01:14:07.897418 140429351114624 deprecation_wrapper.py:119] From train.py:102: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "W0828 01:14:10.340761 140429351114624 deprecation_wrapper.py:119] From train.py:107: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "2019-08-28 01:14:11.450104: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "0/15750 (epoch 0), train_loss = 7.323, time/batch = 1.760\n",
            "model saved to ./save_star/model.ckpt\n",
            "1/15750 (epoch 0), train_loss = 7.315, time/batch = 0.225\n",
            "2/15750 (epoch 0), train_loss = 7.295, time/batch = 0.239\n",
            "3/15750 (epoch 0), train_loss = 7.231, time/batch = 0.221\n",
            "4/15750 (epoch 0), train_loss = 6.992, time/batch = 0.212\n",
            "5/15750 (epoch 0), train_loss = 6.613, time/batch = 0.204\n",
            "6/15750 (epoch 0), train_loss = 6.320, time/batch = 0.195\n",
            "7/15750 (epoch 0), train_loss = 6.039, time/batch = 0.189\n",
            "8/15750 (epoch 0), train_loss = 5.766, time/batch = 0.189\n",
            "9/15750 (epoch 0), train_loss = 5.514, time/batch = 0.186\n",
            "10/15750 (epoch 0), train_loss = 5.312, time/batch = 0.178\n",
            "11/15750 (epoch 0), train_loss = 5.134, time/batch = 0.180\n",
            "12/15750 (epoch 0), train_loss = 5.041, time/batch = 0.181\n",
            "13/15750 (epoch 0), train_loss = 4.957, time/batch = 0.170\n",
            "14/15750 (epoch 0), train_loss = 4.918, time/batch = 0.176\n",
            "15/15750 (epoch 0), train_loss = 4.862, time/batch = 0.167\n",
            "16/15750 (epoch 0), train_loss = 4.939, time/batch = 0.173\n",
            "17/15750 (epoch 0), train_loss = 4.939, time/batch = 0.171\n",
            "18/15750 (epoch 0), train_loss = 4.989, time/batch = 0.179\n",
            "19/15750 (epoch 0), train_loss = 4.954, time/batch = 0.177\n",
            "20/15750 (epoch 0), train_loss = 5.007, time/batch = 0.173\n",
            "21/15750 (epoch 0), train_loss = 4.996, time/batch = 0.170\n",
            "22/15750 (epoch 0), train_loss = 4.888, time/batch = 0.175\n",
            "23/15750 (epoch 0), train_loss = 4.971, time/batch = 0.177\n",
            "24/15750 (epoch 0), train_loss = 4.961, time/batch = 0.173\n",
            "25/15750 (epoch 0), train_loss = 4.960, time/batch = 0.174\n",
            "26/15750 (epoch 0), train_loss = 4.862, time/batch = 0.171\n",
            "27/15750 (epoch 0), train_loss = 4.855, time/batch = 0.174\n",
            "28/15750 (epoch 0), train_loss = 4.888, time/batch = 0.172\n",
            "29/15750 (epoch 0), train_loss = 4.894, time/batch = 0.175\n",
            "30/15750 (epoch 0), train_loss = 4.942, time/batch = 0.186\n",
            "31/15750 (epoch 0), train_loss = 4.839, time/batch = 0.175\n",
            "32/15750 (epoch 0), train_loss = 4.854, time/batch = 0.173\n",
            "33/15750 (epoch 0), train_loss = 4.859, time/batch = 0.171\n",
            "34/15750 (epoch 0), train_loss = 4.829, time/batch = 0.177\n",
            "35/15750 (epoch 0), train_loss = 4.822, time/batch = 0.173\n",
            "36/15750 (epoch 0), train_loss = 4.827, time/batch = 0.183\n",
            "37/15750 (epoch 0), train_loss = 4.825, time/batch = 0.173\n",
            "38/15750 (epoch 0), train_loss = 4.812, time/batch = 0.174\n",
            "39/15750 (epoch 0), train_loss = 4.827, time/batch = 0.179\n",
            "40/15750 (epoch 0), train_loss = 4.891, time/batch = 0.175\n",
            "41/15750 (epoch 0), train_loss = 4.887, time/batch = 0.175\n",
            "42/15750 (epoch 0), train_loss = 4.829, time/batch = 0.172\n",
            "43/15750 (epoch 0), train_loss = 4.777, time/batch = 0.175\n",
            "44/15750 (epoch 0), train_loss = 4.791, time/batch = 0.178\n",
            "45/15750 (epoch 0), train_loss = 4.840, time/batch = 0.174\n",
            "46/15750 (epoch 0), train_loss = 4.789, time/batch = 0.182\n",
            "47/15750 (epoch 0), train_loss = 4.841, time/batch = 0.186\n",
            "48/15750 (epoch 0), train_loss = 4.799, time/batch = 0.179\n",
            "49/15750 (epoch 0), train_loss = 4.806, time/batch = 0.177\n",
            "50/15750 (epoch 0), train_loss = 4.780, time/batch = 0.180\n",
            "51/15750 (epoch 0), train_loss = 4.827, time/batch = 0.179\n",
            "52/15750 (epoch 0), train_loss = 4.864, time/batch = 0.176\n",
            "53/15750 (epoch 0), train_loss = 4.836, time/batch = 0.182\n",
            "54/15750 (epoch 0), train_loss = 4.814, time/batch = 0.179\n",
            "55/15750 (epoch 0), train_loss = 4.803, time/batch = 0.191\n",
            "56/15750 (epoch 0), train_loss = 4.809, time/batch = 0.182\n",
            "57/15750 (epoch 0), train_loss = 4.778, time/batch = 0.178\n",
            "58/15750 (epoch 0), train_loss = 4.759, time/batch = 0.172\n",
            "59/15750 (epoch 0), train_loss = 4.756, time/batch = 0.187\n",
            "60/15750 (epoch 0), train_loss = 4.793, time/batch = 0.179\n",
            "61/15750 (epoch 0), train_loss = 4.767, time/batch = 0.174\n",
            "62/15750 (epoch 0), train_loss = 4.798, time/batch = 0.176\n",
            "63/15750 (epoch 0), train_loss = 4.808, time/batch = 0.178\n",
            "64/15750 (epoch 0), train_loss = 4.791, time/batch = 0.180\n",
            "65/15750 (epoch 0), train_loss = 4.776, time/batch = 0.172\n",
            "66/15750 (epoch 0), train_loss = 4.781, time/batch = 0.175\n",
            "67/15750 (epoch 0), train_loss = 4.751, time/batch = 0.177\n",
            "68/15750 (epoch 0), train_loss = 4.789, time/batch = 0.178\n",
            "69/15750 (epoch 0), train_loss = 4.785, time/batch = 0.170\n",
            "70/15750 (epoch 0), train_loss = 4.754, time/batch = 0.188\n",
            "71/15750 (epoch 0), train_loss = 4.742, time/batch = 0.177\n",
            "72/15750 (epoch 0), train_loss = 4.745, time/batch = 0.180\n",
            "73/15750 (epoch 0), train_loss = 4.757, time/batch = 0.176\n",
            "74/15750 (epoch 0), train_loss = 4.845, time/batch = 0.177\n",
            "75/15750 (epoch 0), train_loss = 4.800, time/batch = 0.176\n",
            "76/15750 (epoch 0), train_loss = 4.762, time/batch = 0.181\n",
            "77/15750 (epoch 0), train_loss = 4.801, time/batch = 0.177\n",
            "78/15750 (epoch 0), train_loss = 4.822, time/batch = 0.181\n",
            "79/15750 (epoch 0), train_loss = 4.849, time/batch = 0.177\n",
            "80/15750 (epoch 0), train_loss = 4.751, time/batch = 0.179\n",
            "81/15750 (epoch 0), train_loss = 4.800, time/batch = 0.177\n",
            "82/15750 (epoch 0), train_loss = 4.788, time/batch = 0.179\n",
            "83/15750 (epoch 0), train_loss = 4.824, time/batch = 0.177\n",
            "84/15750 (epoch 0), train_loss = 4.800, time/batch = 0.180\n",
            "85/15750 (epoch 0), train_loss = 4.799, time/batch = 0.178\n",
            "86/15750 (epoch 0), train_loss = 4.794, time/batch = 0.177\n",
            "87/15750 (epoch 0), train_loss = 4.848, time/batch = 0.175\n",
            "88/15750 (epoch 0), train_loss = 4.832, time/batch = 0.174\n",
            "89/15750 (epoch 0), train_loss = 4.773, time/batch = 0.180\n",
            "90/15750 (epoch 0), train_loss = 4.885, time/batch = 0.178\n",
            "91/15750 (epoch 0), train_loss = 4.780, time/batch = 0.179\n",
            "92/15750 (epoch 0), train_loss = 4.795, time/batch = 0.178\n",
            "93/15750 (epoch 0), train_loss = 4.807, time/batch = 0.177\n",
            "94/15750 (epoch 0), train_loss = 4.813, time/batch = 0.183\n",
            "95/15750 (epoch 0), train_loss = 4.806, time/batch = 0.178\n",
            "96/15750 (epoch 0), train_loss = 4.812, time/batch = 0.177\n",
            "97/15750 (epoch 0), train_loss = 4.809, time/batch = 0.177\n",
            "98/15750 (epoch 0), train_loss = 4.840, time/batch = 0.180\n",
            "99/15750 (epoch 0), train_loss = 4.783, time/batch = 0.179\n",
            "100/15750 (epoch 0), train_loss = 4.752, time/batch = 0.180\n",
            "101/15750 (epoch 0), train_loss = 4.730, time/batch = 0.180\n",
            "102/15750 (epoch 0), train_loss = 4.723, time/batch = 0.177\n",
            "103/15750 (epoch 0), train_loss = 4.799, time/batch = 0.182\n",
            "104/15750 (epoch 0), train_loss = 4.811, time/batch = 0.176\n",
            "105/15750 (epoch 0), train_loss = 4.761, time/batch = 0.179\n",
            "106/15750 (epoch 0), train_loss = 4.791, time/batch = 0.183\n",
            "107/15750 (epoch 0), train_loss = 4.802, time/batch = 0.183\n",
            "108/15750 (epoch 0), train_loss = 4.835, time/batch = 0.178\n",
            "109/15750 (epoch 0), train_loss = 4.808, time/batch = 0.179\n",
            "110/15750 (epoch 0), train_loss = 4.786, time/batch = 0.196\n",
            "111/15750 (epoch 0), train_loss = 4.790, time/batch = 0.177\n",
            "112/15750 (epoch 0), train_loss = 4.789, time/batch = 0.176\n",
            "113/15750 (epoch 0), train_loss = 4.861, time/batch = 0.179\n",
            "114/15750 (epoch 0), train_loss = 4.893, time/batch = 0.170\n",
            "115/15750 (epoch 0), train_loss = 4.840, time/batch = 0.184\n",
            "116/15750 (epoch 0), train_loss = 4.786, time/batch = 0.186\n",
            "117/15750 (epoch 0), train_loss = 4.877, time/batch = 0.177\n",
            "118/15750 (epoch 0), train_loss = 4.860, time/batch = 0.179\n",
            "119/15750 (epoch 0), train_loss = 4.762, time/batch = 0.174\n",
            "120/15750 (epoch 0), train_loss = 4.779, time/batch = 0.182\n",
            "121/15750 (epoch 0), train_loss = 4.793, time/batch = 0.182\n",
            "122/15750 (epoch 0), train_loss = 4.819, time/batch = 0.182\n",
            "123/15750 (epoch 0), train_loss = 4.793, time/batch = 0.182\n",
            "124/15750 (epoch 0), train_loss = 4.852, time/batch = 0.184\n",
            "125/15750 (epoch 0), train_loss = 4.812, time/batch = 0.178\n",
            "126/15750 (epoch 0), train_loss = 4.867, time/batch = 0.181\n",
            "127/15750 (epoch 0), train_loss = 4.729, time/batch = 0.183\n",
            "128/15750 (epoch 0), train_loss = 4.774, time/batch = 0.178\n",
            "129/15750 (epoch 0), train_loss = 4.773, time/batch = 0.184\n",
            "130/15750 (epoch 0), train_loss = 4.776, time/batch = 0.177\n",
            "131/15750 (epoch 0), train_loss = 4.793, time/batch = 0.177\n",
            "132/15750 (epoch 0), train_loss = 4.783, time/batch = 0.181\n",
            "133/15750 (epoch 0), train_loss = 4.779, time/batch = 0.182\n",
            "134/15750 (epoch 0), train_loss = 4.752, time/batch = 0.181\n",
            "135/15750 (epoch 0), train_loss = 4.777, time/batch = 0.180\n",
            "136/15750 (epoch 0), train_loss = 4.870, time/batch = 0.177\n",
            "137/15750 (epoch 0), train_loss = 4.814, time/batch = 0.178\n",
            "138/15750 (epoch 0), train_loss = 4.835, time/batch = 0.183\n",
            "139/15750 (epoch 0), train_loss = 4.867, time/batch = 0.190\n",
            "140/15750 (epoch 0), train_loss = 4.761, time/batch = 0.175\n",
            "141/15750 (epoch 0), train_loss = 4.852, time/batch = 0.188\n",
            "142/15750 (epoch 0), train_loss = 4.757, time/batch = 0.180\n",
            "143/15750 (epoch 0), train_loss = 4.758, time/batch = 0.185\n",
            "144/15750 (epoch 0), train_loss = 4.769, time/batch = 0.183\n",
            "145/15750 (epoch 0), train_loss = 4.763, time/batch = 0.176\n",
            "146/15750 (epoch 0), train_loss = 4.844, time/batch = 0.181\n",
            "147/15750 (epoch 0), train_loss = 4.728, time/batch = 0.182\n",
            "148/15750 (epoch 0), train_loss = 4.813, time/batch = 0.181\n",
            "149/15750 (epoch 0), train_loss = 4.827, time/batch = 0.177\n",
            "150/15750 (epoch 0), train_loss = 4.873, time/batch = 0.184\n",
            "151/15750 (epoch 0), train_loss = 4.824, time/batch = 0.180\n",
            "152/15750 (epoch 0), train_loss = 4.900, time/batch = 0.183\n",
            "153/15750 (epoch 0), train_loss = 4.822, time/batch = 0.178\n",
            "154/15750 (epoch 0), train_loss = 4.808, time/batch = 0.179\n",
            "155/15750 (epoch 0), train_loss = 4.805, time/batch = 0.182\n",
            "156/15750 (epoch 0), train_loss = 4.833, time/batch = 0.184\n",
            "157/15750 (epoch 0), train_loss = 4.858, time/batch = 0.178\n",
            "158/15750 (epoch 0), train_loss = 4.819, time/batch = 0.181\n",
            "159/15750 (epoch 0), train_loss = 4.830, time/batch = 0.182\n",
            "160/15750 (epoch 0), train_loss = 4.834, time/batch = 0.179\n",
            "161/15750 (epoch 0), train_loss = 4.864, time/batch = 0.184\n",
            "162/15750 (epoch 0), train_loss = 4.858, time/batch = 0.180\n",
            "163/15750 (epoch 0), train_loss = 4.878, time/batch = 0.182\n",
            "164/15750 (epoch 0), train_loss = 4.912, time/batch = 0.182\n",
            "165/15750 (epoch 0), train_loss = 4.867, time/batch = 0.180\n",
            "166/15750 (epoch 0), train_loss = 4.871, time/batch = 0.181\n",
            "167/15750 (epoch 0), train_loss = 4.850, time/batch = 0.185\n",
            "168/15750 (epoch 0), train_loss = 4.847, time/batch = 0.187\n",
            "169/15750 (epoch 0), train_loss = 4.854, time/batch = 0.185\n",
            "170/15750 (epoch 0), train_loss = 4.857, time/batch = 0.184\n",
            "171/15750 (epoch 0), train_loss = 4.870, time/batch = 0.181\n",
            "172/15750 (epoch 0), train_loss = 4.861, time/batch = 0.183\n",
            "173/15750 (epoch 0), train_loss = 4.861, time/batch = 0.182\n",
            "174/15750 (epoch 0), train_loss = 4.823, time/batch = 0.184\n",
            "175/15750 (epoch 0), train_loss = 4.831, time/batch = 0.179\n",
            "176/15750 (epoch 0), train_loss = 4.840, time/batch = 0.185\n",
            "177/15750 (epoch 0), train_loss = 4.846, time/batch = 0.179\n",
            "178/15750 (epoch 0), train_loss = 4.837, time/batch = 0.189\n",
            "179/15750 (epoch 0), train_loss = 4.887, time/batch = 0.182\n",
            "180/15750 (epoch 0), train_loss = 4.813, time/batch = 0.181\n",
            "181/15750 (epoch 0), train_loss = 4.829, time/batch = 0.180\n",
            "182/15750 (epoch 0), train_loss = 4.767, time/batch = 0.180\n",
            "183/15750 (epoch 0), train_loss = 4.843, time/batch = 0.180\n",
            "184/15750 (epoch 0), train_loss = 4.888, time/batch = 0.183\n",
            "185/15750 (epoch 0), train_loss = 4.785, time/batch = 0.181\n",
            "186/15750 (epoch 0), train_loss = 4.819, time/batch = 0.180\n",
            "187/15750 (epoch 0), train_loss = 4.824, time/batch = 0.179\n",
            "188/15750 (epoch 0), train_loss = 4.865, time/batch = 0.180\n",
            "189/15750 (epoch 0), train_loss = 4.877, time/batch = 0.185\n",
            "190/15750 (epoch 0), train_loss = 4.818, time/batch = 0.178\n",
            "191/15750 (epoch 0), train_loss = 4.795, time/batch = 0.182\n",
            "192/15750 (epoch 0), train_loss = 4.781, time/batch = 0.180\n",
            "193/15750 (epoch 0), train_loss = 4.781, time/batch = 0.180\n",
            "194/15750 (epoch 0), train_loss = 4.821, time/batch = 0.180\n",
            "195/15750 (epoch 0), train_loss = 4.829, time/batch = 0.186\n",
            "196/15750 (epoch 0), train_loss = 4.771, time/batch = 0.182\n",
            "197/15750 (epoch 0), train_loss = 4.804, time/batch = 0.181\n",
            "198/15750 (epoch 0), train_loss = 4.768, time/batch = 0.181\n",
            "199/15750 (epoch 0), train_loss = 4.762, time/batch = 0.177\n",
            "200/15750 (epoch 0), train_loss = 4.830, time/batch = 0.182\n",
            "201/15750 (epoch 0), train_loss = 4.858, time/batch = 0.183\n",
            "202/15750 (epoch 0), train_loss = 4.885, time/batch = 0.184\n",
            "203/15750 (epoch 0), train_loss = 4.921, time/batch = 0.185\n",
            "204/15750 (epoch 0), train_loss = 4.896, time/batch = 0.182\n",
            "205/15750 (epoch 0), train_loss = 4.869, time/batch = 0.179\n",
            "206/15750 (epoch 0), train_loss = 4.872, time/batch = 0.182\n",
            "207/15750 (epoch 0), train_loss = 4.846, time/batch = 0.178\n",
            "208/15750 (epoch 0), train_loss = 4.760, time/batch = 0.184\n",
            "209/15750 (epoch 0), train_loss = 4.756, time/batch = 0.185\n",
            "210/15750 (epoch 0), train_loss = 4.770, time/batch = 0.177\n",
            "211/15750 (epoch 0), train_loss = 4.738, time/batch = 0.181\n",
            "212/15750 (epoch 0), train_loss = 4.759, time/batch = 0.183\n",
            "213/15750 (epoch 0), train_loss = 4.803, time/batch = 0.185\n",
            "214/15750 (epoch 0), train_loss = 4.765, time/batch = 0.182\n",
            "215/15750 (epoch 0), train_loss = 4.816, time/batch = 0.173\n",
            "216/15750 (epoch 0), train_loss = 4.822, time/batch = 0.178\n",
            "217/15750 (epoch 0), train_loss = 4.795, time/batch = 0.173\n",
            "218/15750 (epoch 0), train_loss = 4.830, time/batch = 0.182\n",
            "219/15750 (epoch 0), train_loss = 4.770, time/batch = 0.178\n",
            "220/15750 (epoch 0), train_loss = 4.768, time/batch = 0.183\n",
            "221/15750 (epoch 0), train_loss = 4.797, time/batch = 0.174\n",
            "222/15750 (epoch 0), train_loss = 4.796, time/batch = 0.184\n",
            "223/15750 (epoch 0), train_loss = 4.773, time/batch = 0.185\n",
            "224/15750 (epoch 0), train_loss = 4.772, time/batch = 0.187\n",
            "225/15750 (epoch 0), train_loss = 4.811, time/batch = 0.179\n",
            "226/15750 (epoch 0), train_loss = 4.813, time/batch = 0.176\n",
            "227/15750 (epoch 0), train_loss = 4.812, time/batch = 0.188\n",
            "228/15750 (epoch 0), train_loss = 4.847, time/batch = 0.181\n",
            "229/15750 (epoch 0), train_loss = 4.756, time/batch = 0.187\n",
            "230/15750 (epoch 0), train_loss = 4.801, time/batch = 0.183\n",
            "231/15750 (epoch 0), train_loss = 4.825, time/batch = 0.175\n",
            "232/15750 (epoch 0), train_loss = 4.835, time/batch = 0.184\n",
            "233/15750 (epoch 0), train_loss = 4.814, time/batch = 0.183\n",
            "234/15750 (epoch 0), train_loss = 4.817, time/batch = 0.183\n",
            "235/15750 (epoch 0), train_loss = 4.856, time/batch = 0.170\n",
            "236/15750 (epoch 0), train_loss = 4.791, time/batch = 0.191\n",
            "237/15750 (epoch 0), train_loss = 4.803, time/batch = 0.182\n",
            "238/15750 (epoch 0), train_loss = 4.844, time/batch = 0.177\n",
            "239/15750 (epoch 0), train_loss = 4.791, time/batch = 0.183\n",
            "240/15750 (epoch 0), train_loss = 4.834, time/batch = 0.183\n",
            "241/15750 (epoch 0), train_loss = 4.751, time/batch = 0.177\n",
            "242/15750 (epoch 0), train_loss = 4.786, time/batch = 0.184\n",
            "243/15750 (epoch 0), train_loss = 4.830, time/batch = 0.182\n",
            "244/15750 (epoch 0), train_loss = 4.859, time/batch = 0.178\n",
            "245/15750 (epoch 0), train_loss = 4.834, time/batch = 0.174\n",
            "246/15750 (epoch 0), train_loss = 4.849, time/batch = 0.198\n",
            "247/15750 (epoch 0), train_loss = 4.890, time/batch = 0.182\n",
            "248/15750 (epoch 0), train_loss = 4.874, time/batch = 0.177\n",
            "249/15750 (epoch 0), train_loss = 4.861, time/batch = 0.182\n",
            "250/15750 (epoch 0), train_loss = 4.850, time/batch = 0.178\n",
            "251/15750 (epoch 0), train_loss = 4.822, time/batch = 0.180\n",
            "252/15750 (epoch 0), train_loss = 4.839, time/batch = 0.180\n",
            "253/15750 (epoch 0), train_loss = 4.768, time/batch = 0.182\n",
            "254/15750 (epoch 0), train_loss = 4.854, time/batch = 0.184\n",
            "255/15750 (epoch 0), train_loss = 4.776, time/batch = 0.178\n",
            "256/15750 (epoch 0), train_loss = 4.779, time/batch = 0.185\n",
            "257/15750 (epoch 0), train_loss = 4.764, time/batch = 0.183\n",
            "258/15750 (epoch 0), train_loss = 4.871, time/batch = 0.177\n",
            "259/15750 (epoch 0), train_loss = 4.794, time/batch = 0.181\n",
            "260/15750 (epoch 0), train_loss = 4.784, time/batch = 0.177\n",
            "261/15750 (epoch 0), train_loss = 4.829, time/batch = 0.177\n",
            "262/15750 (epoch 0), train_loss = 4.870, time/batch = 0.184\n",
            "263/15750 (epoch 0), train_loss = 4.878, time/batch = 0.192\n",
            "264/15750 (epoch 0), train_loss = 4.946, time/batch = 0.183\n",
            "265/15750 (epoch 0), train_loss = 4.956, time/batch = 0.179\n",
            "266/15750 (epoch 0), train_loss = 4.962, time/batch = 0.176\n",
            "267/15750 (epoch 0), train_loss = 4.890, time/batch = 0.183\n",
            "268/15750 (epoch 0), train_loss = 4.901, time/batch = 0.181\n",
            "269/15750 (epoch 0), train_loss = 4.877, time/batch = 0.172\n",
            "270/15750 (epoch 0), train_loss = 4.857, time/batch = 0.189\n",
            "271/15750 (epoch 0), train_loss = 4.816, time/batch = 0.178\n",
            "272/15750 (epoch 0), train_loss = 4.819, time/batch = 0.177\n",
            "273/15750 (epoch 0), train_loss = 4.847, time/batch = 0.189\n",
            "274/15750 (epoch 0), train_loss = 4.859, time/batch = 0.184\n",
            "275/15750 (epoch 0), train_loss = 4.865, time/batch = 0.184\n",
            "276/15750 (epoch 0), train_loss = 4.910, time/batch = 0.188\n",
            "277/15750 (epoch 0), train_loss = 4.866, time/batch = 0.179\n",
            "278/15750 (epoch 0), train_loss = 4.834, time/batch = 0.176\n",
            "279/15750 (epoch 0), train_loss = 4.799, time/batch = 0.180\n",
            "280/15750 (epoch 0), train_loss = 4.946, time/batch = 0.181\n",
            "281/15750 (epoch 0), train_loss = 4.815, time/batch = 0.176\n",
            "282/15750 (epoch 0), train_loss = 4.852, time/batch = 0.180\n",
            "283/15750 (epoch 0), train_loss = 4.871, time/batch = 0.178\n",
            "284/15750 (epoch 0), train_loss = 4.825, time/batch = 0.175\n",
            "285/15750 (epoch 0), train_loss = 4.900, time/batch = 0.182\n",
            "286/15750 (epoch 0), train_loss = 4.830, time/batch = 0.176\n",
            "287/15750 (epoch 0), train_loss = 4.852, time/batch = 0.179\n",
            "288/15750 (epoch 0), train_loss = 4.823, time/batch = 0.176\n",
            "289/15750 (epoch 0), train_loss = 4.803, time/batch = 0.183\n",
            "290/15750 (epoch 0), train_loss = 4.768, time/batch = 0.180\n",
            "291/15750 (epoch 0), train_loss = 4.828, time/batch = 0.188\n",
            "292/15750 (epoch 0), train_loss = 4.822, time/batch = 0.183\n",
            "293/15750 (epoch 0), train_loss = 4.819, time/batch = 0.181\n",
            "294/15750 (epoch 0), train_loss = 4.811, time/batch = 0.180\n",
            "295/15750 (epoch 0), train_loss = 4.850, time/batch = 0.173\n",
            "296/15750 (epoch 0), train_loss = 4.837, time/batch = 0.179\n",
            "297/15750 (epoch 0), train_loss = 4.855, time/batch = 0.192\n",
            "298/15750 (epoch 0), train_loss = 4.767, time/batch = 0.176\n",
            "299/15750 (epoch 0), train_loss = 4.833, time/batch = 0.182\n",
            "300/15750 (epoch 0), train_loss = 4.888, time/batch = 0.179\n",
            "301/15750 (epoch 0), train_loss = 4.802, time/batch = 0.179\n",
            "302/15750 (epoch 0), train_loss = 4.818, time/batch = 0.184\n",
            "303/15750 (epoch 0), train_loss = 4.803, time/batch = 0.184\n",
            "304/15750 (epoch 0), train_loss = 4.840, time/batch = 0.182\n",
            "305/15750 (epoch 0), train_loss = 4.850, time/batch = 0.182\n",
            "306/15750 (epoch 0), train_loss = 4.834, time/batch = 0.182\n",
            "307/15750 (epoch 0), train_loss = 4.867, time/batch = 0.179\n",
            "308/15750 (epoch 0), train_loss = 4.819, time/batch = 0.186\n",
            "309/15750 (epoch 0), train_loss = 4.846, time/batch = 0.184\n",
            "310/15750 (epoch 0), train_loss = 4.776, time/batch = 0.182\n",
            "311/15750 (epoch 0), train_loss = 4.688, time/batch = 0.179\n",
            "312/15750 (epoch 0), train_loss = 4.792, time/batch = 0.182\n",
            "313/15750 (epoch 0), train_loss = 4.802, time/batch = 0.178\n",
            "314/15750 (epoch 0), train_loss = 4.890, time/batch = 0.183\n",
            "315/15750 (epoch 1), train_loss = 4.878, time/batch = 0.181\n",
            "316/15750 (epoch 1), train_loss = 4.835, time/batch = 0.175\n",
            "317/15750 (epoch 1), train_loss = 4.822, time/batch = 0.180\n",
            "318/15750 (epoch 1), train_loss = 4.957, time/batch = 0.186\n",
            "319/15750 (epoch 1), train_loss = 4.818, time/batch = 0.176\n",
            "320/15750 (epoch 1), train_loss = 4.792, time/batch = 0.184\n",
            "321/15750 (epoch 1), train_loss = 4.876, time/batch = 0.180\n",
            "322/15750 (epoch 1), train_loss = 4.828, time/batch = 0.178\n",
            "323/15750 (epoch 1), train_loss = 4.815, time/batch = 0.179\n",
            "324/15750 (epoch 1), train_loss = 4.802, time/batch = 0.180\n",
            "325/15750 (epoch 1), train_loss = 4.826, time/batch = 0.179\n",
            "326/15750 (epoch 1), train_loss = 4.792, time/batch = 0.179\n",
            "327/15750 (epoch 1), train_loss = 4.830, time/batch = 0.179\n",
            "328/15750 (epoch 1), train_loss = 4.825, time/batch = 0.179\n",
            "329/15750 (epoch 1), train_loss = 4.805, time/batch = 0.182\n",
            "330/15750 (epoch 1), train_loss = 4.812, time/batch = 0.183\n",
            "331/15750 (epoch 1), train_loss = 4.878, time/batch = 0.177\n",
            "332/15750 (epoch 1), train_loss = 4.891, time/batch = 0.178\n",
            "333/15750 (epoch 1), train_loss = 4.921, time/batch = 0.172\n",
            "334/15750 (epoch 1), train_loss = 4.880, time/batch = 0.176\n",
            "335/15750 (epoch 1), train_loss = 4.901, time/batch = 0.183\n",
            "336/15750 (epoch 1), train_loss = 4.897, time/batch = 0.180\n",
            "337/15750 (epoch 1), train_loss = 4.798, time/batch = 0.177\n",
            "338/15750 (epoch 1), train_loss = 4.874, time/batch = 0.178\n",
            "339/15750 (epoch 1), train_loss = 4.890, time/batch = 0.178\n",
            "340/15750 (epoch 1), train_loss = 4.894, time/batch = 0.175\n",
            "341/15750 (epoch 1), train_loss = 4.817, time/batch = 0.189\n",
            "342/15750 (epoch 1), train_loss = 4.833, time/batch = 0.180\n",
            "343/15750 (epoch 1), train_loss = 4.858, time/batch = 0.182\n",
            "344/15750 (epoch 1), train_loss = 4.880, time/batch = 0.183\n",
            "345/15750 (epoch 1), train_loss = 4.906, time/batch = 0.185\n",
            "346/15750 (epoch 1), train_loss = 4.822, time/batch = 0.182\n",
            "347/15750 (epoch 1), train_loss = 4.829, time/batch = 0.190\n",
            "348/15750 (epoch 1), train_loss = 4.832, time/batch = 0.177\n",
            "349/15750 (epoch 1), train_loss = 4.798, time/batch = 0.178\n",
            "350/15750 (epoch 1), train_loss = 4.788, time/batch = 0.181\n",
            "351/15750 (epoch 1), train_loss = 4.811, time/batch = 0.174\n",
            "352/15750 (epoch 1), train_loss = 4.804, time/batch = 0.183\n",
            "353/15750 (epoch 1), train_loss = 4.795, time/batch = 0.175\n",
            "354/15750 (epoch 1), train_loss = 4.820, time/batch = 0.184\n",
            "355/15750 (epoch 1), train_loss = 4.882, time/batch = 0.179\n",
            "356/15750 (epoch 1), train_loss = 4.880, time/batch = 0.176\n",
            "357/15750 (epoch 1), train_loss = 4.827, time/batch = 0.184\n",
            "358/15750 (epoch 1), train_loss = 4.770, time/batch = 0.183\n",
            "359/15750 (epoch 1), train_loss = 4.778, time/batch = 0.186\n",
            "360/15750 (epoch 1), train_loss = 4.835, time/batch = 0.187\n",
            "361/15750 (epoch 1), train_loss = 4.779, time/batch = 0.179\n",
            "362/15750 (epoch 1), train_loss = 4.834, time/batch = 0.185\n",
            "363/15750 (epoch 1), train_loss = 4.796, time/batch = 0.179\n",
            "364/15750 (epoch 1), train_loss = 4.801, time/batch = 0.193\n",
            "365/15750 (epoch 1), train_loss = 4.777, time/batch = 0.184\n",
            "366/15750 (epoch 1), train_loss = 4.815, time/batch = 0.180\n",
            "367/15750 (epoch 1), train_loss = 4.859, time/batch = 0.179\n",
            "368/15750 (epoch 1), train_loss = 4.830, time/batch = 0.176\n",
            "369/15750 (epoch 1), train_loss = 4.807, time/batch = 0.192\n",
            "370/15750 (epoch 1), train_loss = 4.798, time/batch = 0.185\n",
            "371/15750 (epoch 1), train_loss = 4.804, time/batch = 0.174\n",
            "372/15750 (epoch 1), train_loss = 4.773, time/batch = 0.179\n",
            "373/15750 (epoch 1), train_loss = 4.751, time/batch = 0.177\n",
            "374/15750 (epoch 1), train_loss = 4.755, time/batch = 0.184\n",
            "375/15750 (epoch 1), train_loss = 4.791, time/batch = 0.187\n",
            "376/15750 (epoch 1), train_loss = 4.761, time/batch = 0.175\n",
            "377/15750 (epoch 1), train_loss = 4.793, time/batch = 0.181\n",
            "378/15750 (epoch 1), train_loss = 4.805, time/batch = 0.179\n",
            "379/15750 (epoch 1), train_loss = 4.789, time/batch = 0.183\n",
            "380/15750 (epoch 1), train_loss = 4.775, time/batch = 0.183\n",
            "381/15750 (epoch 1), train_loss = 4.780, time/batch = 0.172\n",
            "382/15750 (epoch 1), train_loss = 4.749, time/batch = 0.181\n",
            "383/15750 (epoch 1), train_loss = 4.788, time/batch = 0.179\n",
            "384/15750 (epoch 1), train_loss = 4.781, time/batch = 0.182\n",
            "385/15750 (epoch 1), train_loss = 4.752, time/batch = 0.176\n",
            "386/15750 (epoch 1), train_loss = 4.742, time/batch = 0.181\n",
            "387/15750 (epoch 1), train_loss = 4.743, time/batch = 0.184\n",
            "388/15750 (epoch 1), train_loss = 4.755, time/batch = 0.181\n",
            "389/15750 (epoch 1), train_loss = 4.842, time/batch = 0.181\n",
            "390/15750 (epoch 1), train_loss = 4.799, time/batch = 0.185\n",
            "391/15750 (epoch 1), train_loss = 4.760, time/batch = 0.180\n",
            "392/15750 (epoch 1), train_loss = 4.799, time/batch = 0.184\n",
            "393/15750 (epoch 1), train_loss = 4.819, time/batch = 0.179\n",
            "394/15750 (epoch 1), train_loss = 4.847, time/batch = 0.185\n",
            "395/15750 (epoch 1), train_loss = 4.752, time/batch = 0.183\n",
            "396/15750 (epoch 1), train_loss = 4.802, time/batch = 0.178\n",
            "397/15750 (epoch 1), train_loss = 4.786, time/batch = 0.178\n",
            "398/15750 (epoch 1), train_loss = 4.823, time/batch = 0.182\n",
            "399/15750 (epoch 1), train_loss = 4.799, time/batch = 0.182\n",
            "400/15750 (epoch 1), train_loss = 4.797, time/batch = 0.180\n",
            "401/15750 (epoch 1), train_loss = 4.792, time/batch = 0.178\n",
            "402/15750 (epoch 1), train_loss = 4.843, time/batch = 0.181\n",
            "403/15750 (epoch 1), train_loss = 4.826, time/batch = 0.186\n",
            "404/15750 (epoch 1), train_loss = 4.773, time/batch = 0.178\n",
            "405/15750 (epoch 1), train_loss = 4.884, time/batch = 0.177\n",
            "406/15750 (epoch 1), train_loss = 4.779, time/batch = 0.180\n",
            "407/15750 (epoch 1), train_loss = 4.793, time/batch = 0.175\n",
            "408/15750 (epoch 1), train_loss = 4.806, time/batch = 0.181\n",
            "409/15750 (epoch 1), train_loss = 4.810, time/batch = 0.186\n",
            "410/15750 (epoch 1), train_loss = 4.805, time/batch = 0.179\n",
            "411/15750 (epoch 1), train_loss = 4.811, time/batch = 0.182\n",
            "412/15750 (epoch 1), train_loss = 4.805, time/batch = 0.177\n",
            "413/15750 (epoch 1), train_loss = 4.837, time/batch = 0.181\n",
            "414/15750 (epoch 1), train_loss = 4.782, time/batch = 0.184\n",
            "415/15750 (epoch 1), train_loss = 4.749, time/batch = 0.176\n",
            "416/15750 (epoch 1), train_loss = 4.724, time/batch = 0.184\n",
            "417/15750 (epoch 1), train_loss = 4.721, time/batch = 0.188\n",
            "418/15750 (epoch 1), train_loss = 4.797, time/batch = 0.177\n",
            "419/15750 (epoch 1), train_loss = 4.810, time/batch = 0.181\n",
            "420/15750 (epoch 1), train_loss = 4.759, time/batch = 0.179\n",
            "421/15750 (epoch 1), train_loss = 4.788, time/batch = 0.175\n",
            "422/15750 (epoch 1), train_loss = 4.797, time/batch = 0.182\n",
            "423/15750 (epoch 1), train_loss = 4.832, time/batch = 0.184\n",
            "424/15750 (epoch 1), train_loss = 4.801, time/batch = 0.177\n",
            "425/15750 (epoch 1), train_loss = 4.781, time/batch = 0.186\n",
            "426/15750 (epoch 1), train_loss = 4.787, time/batch = 0.185\n",
            "427/15750 (epoch 1), train_loss = 4.786, time/batch = 0.189\n",
            "428/15750 (epoch 1), train_loss = 4.856, time/batch = 0.186\n",
            "429/15750 (epoch 1), train_loss = 4.889, time/batch = 0.179\n",
            "430/15750 (epoch 1), train_loss = 4.835, time/batch = 0.184\n",
            "431/15750 (epoch 1), train_loss = 4.779, time/batch = 0.186\n",
            "432/15750 (epoch 1), train_loss = 4.870, time/batch = 0.188\n",
            "433/15750 (epoch 1), train_loss = 4.850, time/batch = 0.185\n",
            "434/15750 (epoch 1), train_loss = 4.751, time/batch = 0.181\n",
            "435/15750 (epoch 1), train_loss = 4.769, time/batch = 0.183\n",
            "436/15750 (epoch 1), train_loss = 4.782, time/batch = 0.180\n",
            "437/15750 (epoch 1), train_loss = 4.809, time/batch = 0.191\n",
            "438/15750 (epoch 1), train_loss = 4.781, time/batch = 0.194\n",
            "439/15750 (epoch 1), train_loss = 4.842, time/batch = 0.184\n",
            "440/15750 (epoch 1), train_loss = 4.798, time/batch = 0.187\n",
            "441/15750 (epoch 1), train_loss = 4.853, time/batch = 0.194\n",
            "442/15750 (epoch 1), train_loss = 4.714, time/batch = 0.191\n",
            "443/15750 (epoch 1), train_loss = 4.755, time/batch = 0.187\n",
            "444/15750 (epoch 1), train_loss = 4.754, time/batch = 0.183\n",
            "445/15750 (epoch 1), train_loss = 4.757, time/batch = 0.182\n",
            "446/15750 (epoch 1), train_loss = 4.771, time/batch = 0.182\n",
            "447/15750 (epoch 1), train_loss = 4.758, time/batch = 0.186\n",
            "448/15750 (epoch 1), train_loss = 4.754, time/batch = 0.193\n",
            "449/15750 (epoch 1), train_loss = 4.725, time/batch = 0.188\n",
            "450/15750 (epoch 1), train_loss = 4.749, time/batch = 0.185\n",
            "451/15750 (epoch 1), train_loss = 4.838, time/batch = 0.186\n",
            "452/15750 (epoch 1), train_loss = 4.783, time/batch = 0.184\n",
            "453/15750 (epoch 1), train_loss = 4.799, time/batch = 0.193\n",
            "454/15750 (epoch 1), train_loss = 4.826, time/batch = 0.187\n",
            "455/15750 (epoch 1), train_loss = 4.717, time/batch = 0.186\n",
            "456/15750 (epoch 1), train_loss = 4.805, time/batch = 0.187\n",
            "457/15750 (epoch 1), train_loss = 4.710, time/batch = 0.187\n",
            "458/15750 (epoch 1), train_loss = 4.705, time/batch = 0.183\n",
            "459/15750 (epoch 1), train_loss = 4.713, time/batch = 0.202\n",
            "460/15750 (epoch 1), train_loss = 4.702, time/batch = 0.189\n",
            "461/15750 (epoch 1), train_loss = 4.784, time/batch = 0.181\n",
            "462/15750 (epoch 1), train_loss = 4.667, time/batch = 0.186\n",
            "463/15750 (epoch 1), train_loss = 4.744, time/batch = 0.182\n",
            "464/15750 (epoch 1), train_loss = 4.758, time/batch = 0.182\n",
            "465/15750 (epoch 1), train_loss = 4.796, time/batch = 0.183\n",
            "466/15750 (epoch 1), train_loss = 4.742, time/batch = 0.187\n",
            "467/15750 (epoch 1), train_loss = 4.825, time/batch = 0.185\n",
            "468/15750 (epoch 1), train_loss = 4.735, time/batch = 0.188\n",
            "469/15750 (epoch 1), train_loss = 4.712, time/batch = 0.185\n",
            "470/15750 (epoch 1), train_loss = 4.717, time/batch = 0.185\n",
            "471/15750 (epoch 1), train_loss = 4.738, time/batch = 0.182\n",
            "472/15750 (epoch 1), train_loss = 4.757, time/batch = 0.182\n",
            "473/15750 (epoch 1), train_loss = 4.716, time/batch = 0.181\n",
            "474/15750 (epoch 1), train_loss = 4.721, time/batch = 0.186\n",
            "475/15750 (epoch 1), train_loss = 4.726, time/batch = 0.189\n",
            "476/15750 (epoch 1), train_loss = 4.744, time/batch = 0.182\n",
            "477/15750 (epoch 1), train_loss = 4.742, time/batch = 0.186\n",
            "478/15750 (epoch 1), train_loss = 4.762, time/batch = 0.193\n",
            "479/15750 (epoch 1), train_loss = 4.789, time/batch = 0.184\n",
            "480/15750 (epoch 1), train_loss = 4.738, time/batch = 0.184\n",
            "481/15750 (epoch 1), train_loss = 4.753, time/batch = 0.195\n",
            "482/15750 (epoch 1), train_loss = 4.713, time/batch = 0.186\n",
            "483/15750 (epoch 1), train_loss = 4.707, time/batch = 0.185\n",
            "484/15750 (epoch 1), train_loss = 4.722, time/batch = 0.193\n",
            "485/15750 (epoch 1), train_loss = 4.709, time/batch = 0.191\n",
            "486/15750 (epoch 1), train_loss = 4.726, time/batch = 0.193\n",
            "487/15750 (epoch 1), train_loss = 4.712, time/batch = 0.195\n",
            "488/15750 (epoch 1), train_loss = 4.707, time/batch = 0.192\n",
            "489/15750 (epoch 1), train_loss = 4.668, time/batch = 0.193\n",
            "490/15750 (epoch 1), train_loss = 4.667, time/batch = 0.198\n",
            "491/15750 (epoch 1), train_loss = 4.684, time/batch = 0.193\n",
            "492/15750 (epoch 1), train_loss = 4.683, time/batch = 0.187\n",
            "493/15750 (epoch 1), train_loss = 4.654, time/batch = 0.190\n",
            "494/15750 (epoch 1), train_loss = 4.699, time/batch = 0.188\n",
            "495/15750 (epoch 1), train_loss = 4.613, time/batch = 0.195\n",
            "496/15750 (epoch 1), train_loss = 4.636, time/batch = 0.192\n",
            "497/15750 (epoch 1), train_loss = 4.570, time/batch = 0.192\n",
            "498/15750 (epoch 1), train_loss = 4.653, time/batch = 0.188\n",
            "499/15750 (epoch 1), train_loss = 4.700, time/batch = 0.194\n",
            "500/15750 (epoch 1), train_loss = 4.571, time/batch = 0.194\n",
            "501/15750 (epoch 1), train_loss = 4.615, time/batch = 0.194\n",
            "502/15750 (epoch 1), train_loss = 4.622, time/batch = 0.195\n",
            "503/15750 (epoch 1), train_loss = 4.654, time/batch = 0.187\n",
            "504/15750 (epoch 1), train_loss = 4.668, time/batch = 0.190\n",
            "505/15750 (epoch 1), train_loss = 4.594, time/batch = 0.188\n",
            "506/15750 (epoch 1), train_loss = 4.557, time/batch = 0.190\n",
            "507/15750 (epoch 1), train_loss = 4.547, time/batch = 0.199\n",
            "508/15750 (epoch 1), train_loss = 4.532, time/batch = 0.193\n",
            "509/15750 (epoch 1), train_loss = 4.586, time/batch = 0.193\n",
            "510/15750 (epoch 1), train_loss = 4.579, time/batch = 0.191\n",
            "511/15750 (epoch 1), train_loss = 4.518, time/batch = 0.186\n",
            "512/15750 (epoch 1), train_loss = 4.543, time/batch = 0.185\n",
            "513/15750 (epoch 1), train_loss = 4.500, time/batch = 0.190\n",
            "514/15750 (epoch 1), train_loss = 4.473, time/batch = 0.190\n",
            "515/15750 (epoch 1), train_loss = 4.548, time/batch = 0.187\n",
            "516/15750 (epoch 1), train_loss = 4.567, time/batch = 0.182\n",
            "517/15750 (epoch 1), train_loss = 4.603, time/batch = 0.189\n",
            "518/15750 (epoch 1), train_loss = 4.613, time/batch = 0.193\n",
            "519/15750 (epoch 1), train_loss = 4.590, time/batch = 0.190\n",
            "520/15750 (epoch 1), train_loss = 4.568, time/batch = 0.181\n",
            "521/15750 (epoch 1), train_loss = 4.565, time/batch = 0.193\n",
            "522/15750 (epoch 1), train_loss = 4.544, time/batch = 0.195\n",
            "523/15750 (epoch 1), train_loss = 4.434, time/batch = 0.197\n",
            "524/15750 (epoch 1), train_loss = 4.441, time/batch = 0.182\n",
            "525/15750 (epoch 1), train_loss = 4.425, time/batch = 0.193\n",
            "526/15750 (epoch 1), train_loss = 4.403, time/batch = 0.191\n",
            "527/15750 (epoch 1), train_loss = 4.429, time/batch = 0.185\n",
            "528/15750 (epoch 1), train_loss = 4.458, time/batch = 0.192\n",
            "529/15750 (epoch 1), train_loss = 4.407, time/batch = 0.199\n",
            "530/15750 (epoch 1), train_loss = 4.469, time/batch = 0.190\n",
            "531/15750 (epoch 1), train_loss = 4.482, time/batch = 0.188\n",
            "532/15750 (epoch 1), train_loss = 4.443, time/batch = 0.184\n",
            "533/15750 (epoch 1), train_loss = 4.492, time/batch = 0.188\n",
            "534/15750 (epoch 1), train_loss = 4.418, time/batch = 0.192\n",
            "535/15750 (epoch 1), train_loss = 4.397, time/batch = 0.186\n",
            "536/15750 (epoch 1), train_loss = 4.414, time/batch = 0.188\n",
            "537/15750 (epoch 1), train_loss = 4.424, time/batch = 0.186\n",
            "538/15750 (epoch 1), train_loss = 4.392, time/batch = 0.190\n",
            "539/15750 (epoch 1), train_loss = 4.379, time/batch = 0.191\n",
            "540/15750 (epoch 1), train_loss = 4.430, time/batch = 0.193\n",
            "541/15750 (epoch 1), train_loss = 4.419, time/batch = 0.191\n",
            "542/15750 (epoch 1), train_loss = 4.411, time/batch = 0.190\n",
            "543/15750 (epoch 1), train_loss = 4.434, time/batch = 0.187\n",
            "544/15750 (epoch 1), train_loss = 4.339, time/batch = 0.185\n",
            "545/15750 (epoch 1), train_loss = 4.378, time/batch = 0.191\n",
            "546/15750 (epoch 1), train_loss = 4.423, time/batch = 0.189\n",
            "547/15750 (epoch 1), train_loss = 4.410, time/batch = 0.190\n",
            "548/15750 (epoch 1), train_loss = 4.389, time/batch = 0.189\n",
            "549/15750 (epoch 1), train_loss = 4.385, time/batch = 0.191\n",
            "550/15750 (epoch 1), train_loss = 4.457, time/batch = 0.193\n",
            "551/15750 (epoch 1), train_loss = 4.359, time/batch = 0.188\n",
            "552/15750 (epoch 1), train_loss = 4.370, time/batch = 0.188\n",
            "553/15750 (epoch 1), train_loss = 4.436, time/batch = 0.190\n",
            "554/15750 (epoch 1), train_loss = 4.341, time/batch = 0.194\n",
            "555/15750 (epoch 1), train_loss = 4.412, time/batch = 0.187\n",
            "556/15750 (epoch 1), train_loss = 4.306, time/batch = 0.193\n",
            "557/15750 (epoch 1), train_loss = 4.352, time/batch = 0.199\n",
            "558/15750 (epoch 1), train_loss = 4.397, time/batch = 0.189\n",
            "559/15750 (epoch 1), train_loss = 4.428, time/batch = 0.191\n",
            "560/15750 (epoch 1), train_loss = 4.386, time/batch = 0.186\n",
            "561/15750 (epoch 1), train_loss = 4.413, time/batch = 0.194\n",
            "562/15750 (epoch 1), train_loss = 4.436, time/batch = 0.194\n",
            "563/15750 (epoch 1), train_loss = 4.406, time/batch = 0.185\n",
            "564/15750 (epoch 1), train_loss = 4.396, time/batch = 0.188\n",
            "565/15750 (epoch 1), train_loss = 4.358, time/batch = 0.192\n",
            "566/15750 (epoch 1), train_loss = 4.327, time/batch = 0.189\n",
            "567/15750 (epoch 1), train_loss = 4.346, time/batch = 0.190\n",
            "568/15750 (epoch 1), train_loss = 4.299, time/batch = 0.184\n",
            "569/15750 (epoch 1), train_loss = 4.387, time/batch = 0.188\n",
            "570/15750 (epoch 1), train_loss = 4.298, time/batch = 0.189\n",
            "571/15750 (epoch 1), train_loss = 4.267, time/batch = 0.186\n",
            "572/15750 (epoch 1), train_loss = 4.255, time/batch = 0.197\n",
            "573/15750 (epoch 1), train_loss = 4.419, time/batch = 0.193\n",
            "574/15750 (epoch 1), train_loss = 4.282, time/batch = 0.187\n",
            "575/15750 (epoch 1), train_loss = 4.301, time/batch = 0.192\n",
            "576/15750 (epoch 1), train_loss = 4.317, time/batch = 0.186\n",
            "577/15750 (epoch 1), train_loss = 4.356, time/batch = 0.192\n",
            "578/15750 (epoch 1), train_loss = 4.343, time/batch = 0.193\n",
            "579/15750 (epoch 1), train_loss = 4.450, time/batch = 0.188\n",
            "580/15750 (epoch 1), train_loss = 4.453, time/batch = 0.184\n",
            "581/15750 (epoch 1), train_loss = 4.428, time/batch = 0.194\n",
            "582/15750 (epoch 1), train_loss = 4.365, time/batch = 0.195\n",
            "583/15750 (epoch 1), train_loss = 4.353, time/batch = 0.189\n",
            "584/15750 (epoch 1), train_loss = 4.362, time/batch = 0.191\n",
            "585/15750 (epoch 1), train_loss = 4.344, time/batch = 0.194\n",
            "586/15750 (epoch 1), train_loss = 4.260, time/batch = 0.183\n",
            "587/15750 (epoch 1), train_loss = 4.252, time/batch = 0.192\n",
            "588/15750 (epoch 1), train_loss = 4.306, time/batch = 0.189\n",
            "589/15750 (epoch 1), train_loss = 4.293, time/batch = 0.188\n",
            "590/15750 (epoch 1), train_loss = 4.291, time/batch = 0.191\n",
            "591/15750 (epoch 1), train_loss = 4.351, time/batch = 0.189\n",
            "592/15750 (epoch 1), train_loss = 4.272, time/batch = 0.187\n",
            "593/15750 (epoch 1), train_loss = 4.274, time/batch = 0.194\n",
            "594/15750 (epoch 1), train_loss = 4.190, time/batch = 0.191\n",
            "595/15750 (epoch 1), train_loss = 4.396, time/batch = 0.190\n",
            "596/15750 (epoch 1), train_loss = 4.204, time/batch = 0.197\n",
            "597/15750 (epoch 1), train_loss = 4.227, time/batch = 0.187\n",
            "598/15750 (epoch 1), train_loss = 4.296, time/batch = 0.192\n",
            "599/15750 (epoch 1), train_loss = 4.193, time/batch = 0.202\n",
            "600/15750 (epoch 1), train_loss = 4.294, time/batch = 0.189\n",
            "601/15750 (epoch 1), train_loss = 4.208, time/batch = 0.196\n",
            "602/15750 (epoch 1), train_loss = 4.248, time/batch = 0.193\n",
            "603/15750 (epoch 1), train_loss = 4.193, time/batch = 0.193\n",
            "604/15750 (epoch 1), train_loss = 4.165, time/batch = 0.201\n",
            "605/15750 (epoch 1), train_loss = 4.133, time/batch = 0.191\n",
            "606/15750 (epoch 1), train_loss = 4.208, time/batch = 0.191\n",
            "607/15750 (epoch 1), train_loss = 4.169, time/batch = 0.184\n",
            "608/15750 (epoch 1), train_loss = 4.148, time/batch = 0.188\n",
            "609/15750 (epoch 1), train_loss = 4.158, time/batch = 0.187\n",
            "610/15750 (epoch 1), train_loss = 4.191, time/batch = 0.188\n",
            "611/15750 (epoch 1), train_loss = 4.175, time/batch = 0.192\n",
            "612/15750 (epoch 1), train_loss = 4.192, time/batch = 0.192\n",
            "613/15750 (epoch 1), train_loss = 4.082, time/batch = 0.192\n",
            "614/15750 (epoch 1), train_loss = 4.169, time/batch = 0.191\n",
            "615/15750 (epoch 1), train_loss = 4.205, time/batch = 0.193\n",
            "616/15750 (epoch 1), train_loss = 4.099, time/batch = 0.185\n",
            "617/15750 (epoch 1), train_loss = 4.136, time/batch = 0.186\n",
            "618/15750 (epoch 1), train_loss = 4.073, time/batch = 0.187\n",
            "619/15750 (epoch 1), train_loss = 4.167, time/batch = 0.186\n",
            "620/15750 (epoch 1), train_loss = 4.144, time/batch = 0.191\n",
            "621/15750 (epoch 1), train_loss = 4.139, time/batch = 0.189\n",
            "622/15750 (epoch 1), train_loss = 4.125, time/batch = 0.187\n",
            "623/15750 (epoch 1), train_loss = 4.105, time/batch = 0.188\n",
            "624/15750 (epoch 1), train_loss = 4.172, time/batch = 0.181\n",
            "625/15750 (epoch 1), train_loss = 4.037, time/batch = 0.187\n",
            "626/15750 (epoch 1), train_loss = 3.970, time/batch = 0.196\n",
            "627/15750 (epoch 1), train_loss = 4.038, time/batch = 0.190\n",
            "628/15750 (epoch 1), train_loss = 4.074, time/batch = 0.194\n",
            "629/15750 (epoch 1), train_loss = 4.141, time/batch = 0.193\n",
            "630/15750 (epoch 2), train_loss = 4.168, time/batch = 0.189\n",
            "631/15750 (epoch 2), train_loss = 4.099, time/batch = 0.187\n",
            "632/15750 (epoch 2), train_loss = 4.083, time/batch = 0.199\n",
            "633/15750 (epoch 2), train_loss = 4.220, time/batch = 0.193\n",
            "634/15750 (epoch 2), train_loss = 4.079, time/batch = 0.188\n",
            "635/15750 (epoch 2), train_loss = 4.016, time/batch = 0.187\n",
            "636/15750 (epoch 2), train_loss = 4.136, time/batch = 0.194\n",
            "637/15750 (epoch 2), train_loss = 4.115, time/batch = 0.190\n",
            "638/15750 (epoch 2), train_loss = 4.095, time/batch = 0.193\n",
            "639/15750 (epoch 2), train_loss = 4.040, time/batch = 0.191\n",
            "640/15750 (epoch 2), train_loss = 4.032, time/batch = 0.188\n",
            "641/15750 (epoch 2), train_loss = 3.981, time/batch = 0.195\n",
            "642/15750 (epoch 2), train_loss = 4.070, time/batch = 0.183\n",
            "643/15750 (epoch 2), train_loss = 4.004, time/batch = 0.193\n",
            "644/15750 (epoch 2), train_loss = 4.016, time/batch = 0.191\n",
            "645/15750 (epoch 2), train_loss = 4.022, time/batch = 0.186\n",
            "646/15750 (epoch 2), train_loss = 4.089, time/batch = 0.193\n",
            "647/15750 (epoch 2), train_loss = 4.096, time/batch = 0.190\n",
            "648/15750 (epoch 2), train_loss = 4.108, time/batch = 0.190\n",
            "649/15750 (epoch 2), train_loss = 4.067, time/batch = 0.193\n",
            "650/15750 (epoch 2), train_loss = 4.084, time/batch = 0.189\n",
            "651/15750 (epoch 2), train_loss = 4.089, time/batch = 0.188\n",
            "652/15750 (epoch 2), train_loss = 3.991, time/batch = 0.203\n",
            "653/15750 (epoch 2), train_loss = 4.057, time/batch = 0.189\n",
            "654/15750 (epoch 2), train_loss = 4.071, time/batch = 0.189\n",
            "655/15750 (epoch 2), train_loss = 4.079, time/batch = 0.190\n",
            "656/15750 (epoch 2), train_loss = 3.994, time/batch = 0.201\n",
            "657/15750 (epoch 2), train_loss = 3.994, time/batch = 0.195\n",
            "658/15750 (epoch 2), train_loss = 4.089, time/batch = 0.194\n",
            "659/15750 (epoch 2), train_loss = 4.017, time/batch = 0.186\n",
            "660/15750 (epoch 2), train_loss = 4.043, time/batch = 0.192\n",
            "661/15750 (epoch 2), train_loss = 3.990, time/batch = 0.195\n",
            "662/15750 (epoch 2), train_loss = 3.923, time/batch = 0.199\n",
            "663/15750 (epoch 2), train_loss = 3.957, time/batch = 0.192\n",
            "664/15750 (epoch 2), train_loss = 3.928, time/batch = 0.190\n",
            "665/15750 (epoch 2), train_loss = 3.916, time/batch = 0.187\n",
            "666/15750 (epoch 2), train_loss = 3.917, time/batch = 0.190\n",
            "667/15750 (epoch 2), train_loss = 3.932, time/batch = 0.189\n",
            "668/15750 (epoch 2), train_loss = 3.900, time/batch = 0.193\n",
            "669/15750 (epoch 2), train_loss = 3.935, time/batch = 0.188\n",
            "670/15750 (epoch 2), train_loss = 3.973, time/batch = 0.189\n",
            "671/15750 (epoch 2), train_loss = 4.020, time/batch = 0.191\n",
            "672/15750 (epoch 2), train_loss = 3.954, time/batch = 0.186\n",
            "673/15750 (epoch 2), train_loss = 3.886, time/batch = 0.191\n",
            "674/15750 (epoch 2), train_loss = 3.932, time/batch = 0.191\n",
            "675/15750 (epoch 2), train_loss = 3.892, time/batch = 0.185\n",
            "676/15750 (epoch 2), train_loss = 3.891, time/batch = 0.187\n",
            "677/15750 (epoch 2), train_loss = 3.928, time/batch = 0.196\n",
            "678/15750 (epoch 2), train_loss = 3.868, time/batch = 0.197\n",
            "679/15750 (epoch 2), train_loss = 3.875, time/batch = 0.194\n",
            "680/15750 (epoch 2), train_loss = 3.820, time/batch = 0.192\n",
            "681/15750 (epoch 2), train_loss = 3.883, time/batch = 0.189\n",
            "682/15750 (epoch 2), train_loss = 3.943, time/batch = 0.191\n",
            "683/15750 (epoch 2), train_loss = 3.923, time/batch = 0.190\n",
            "684/15750 (epoch 2), train_loss = 3.904, time/batch = 0.197\n",
            "685/15750 (epoch 2), train_loss = 3.899, time/batch = 0.190\n",
            "686/15750 (epoch 2), train_loss = 3.844, time/batch = 0.193\n",
            "687/15750 (epoch 2), train_loss = 3.819, time/batch = 0.190\n",
            "688/15750 (epoch 2), train_loss = 3.828, time/batch = 0.190\n",
            "689/15750 (epoch 2), train_loss = 3.803, time/batch = 0.201\n",
            "690/15750 (epoch 2), train_loss = 3.830, time/batch = 0.195\n",
            "691/15750 (epoch 2), train_loss = 3.809, time/batch = 0.189\n",
            "692/15750 (epoch 2), train_loss = 3.831, time/batch = 0.198\n",
            "693/15750 (epoch 2), train_loss = 3.826, time/batch = 0.189\n",
            "694/15750 (epoch 2), train_loss = 3.827, time/batch = 0.199\n",
            "695/15750 (epoch 2), train_loss = 3.796, time/batch = 0.187\n",
            "696/15750 (epoch 2), train_loss = 3.775, time/batch = 0.187\n",
            "697/15750 (epoch 2), train_loss = 3.797, time/batch = 0.188\n",
            "698/15750 (epoch 2), train_loss = 3.802, time/batch = 0.191\n",
            "699/15750 (epoch 2), train_loss = 3.872, time/batch = 0.190\n",
            "700/15750 (epoch 2), train_loss = 3.794, time/batch = 0.207\n",
            "701/15750 (epoch 2), train_loss = 3.792, time/batch = 0.199\n",
            "702/15750 (epoch 2), train_loss = 3.676, time/batch = 0.190\n",
            "703/15750 (epoch 2), train_loss = 3.788, time/batch = 0.186\n",
            "704/15750 (epoch 2), train_loss = 3.900, time/batch = 0.188\n",
            "705/15750 (epoch 2), train_loss = 3.812, time/batch = 0.194\n",
            "706/15750 (epoch 2), train_loss = 3.806, time/batch = 0.192\n",
            "707/15750 (epoch 2), train_loss = 3.826, time/batch = 0.196\n",
            "708/15750 (epoch 2), train_loss = 3.840, time/batch = 0.191\n",
            "709/15750 (epoch 2), train_loss = 3.857, time/batch = 0.194\n",
            "710/15750 (epoch 2), train_loss = 3.761, time/batch = 0.198\n",
            "711/15750 (epoch 2), train_loss = 3.788, time/batch = 0.187\n",
            "712/15750 (epoch 2), train_loss = 3.732, time/batch = 0.196\n",
            "713/15750 (epoch 2), train_loss = 3.832, time/batch = 0.197\n",
            "714/15750 (epoch 2), train_loss = 3.850, time/batch = 0.190\n",
            "715/15750 (epoch 2), train_loss = 3.861, time/batch = 0.190\n",
            "716/15750 (epoch 2), train_loss = 3.782, time/batch = 0.188\n",
            "717/15750 (epoch 2), train_loss = 3.839, time/batch = 0.193\n",
            "718/15750 (epoch 2), train_loss = 3.846, time/batch = 0.196\n",
            "719/15750 (epoch 2), train_loss = 3.744, time/batch = 0.192\n",
            "720/15750 (epoch 2), train_loss = 3.871, time/batch = 0.195\n",
            "721/15750 (epoch 2), train_loss = 3.796, time/batch = 0.200\n",
            "722/15750 (epoch 2), train_loss = 3.800, time/batch = 0.194\n",
            "723/15750 (epoch 2), train_loss = 3.815, time/batch = 0.189\n",
            "724/15750 (epoch 2), train_loss = 3.826, time/batch = 0.190\n",
            "725/15750 (epoch 2), train_loss = 3.810, time/batch = 0.189\n",
            "726/15750 (epoch 2), train_loss = 3.765, time/batch = 0.198\n",
            "727/15750 (epoch 2), train_loss = 3.766, time/batch = 0.193\n",
            "728/15750 (epoch 2), train_loss = 3.836, time/batch = 0.188\n",
            "729/15750 (epoch 2), train_loss = 3.756, time/batch = 0.193\n",
            "730/15750 (epoch 2), train_loss = 3.754, time/batch = 0.190\n",
            "731/15750 (epoch 2), train_loss = 3.692, time/batch = 0.195\n",
            "732/15750 (epoch 2), train_loss = 3.702, time/batch = 0.183\n",
            "733/15750 (epoch 2), train_loss = 3.796, time/batch = 0.187\n",
            "734/15750 (epoch 2), train_loss = 3.774, time/batch = 0.191\n",
            "735/15750 (epoch 2), train_loss = 3.732, time/batch = 0.193\n",
            "736/15750 (epoch 2), train_loss = 3.794, time/batch = 0.187\n",
            "737/15750 (epoch 2), train_loss = 3.756, time/batch = 0.196\n",
            "738/15750 (epoch 2), train_loss = 3.830, time/batch = 0.189\n",
            "739/15750 (epoch 2), train_loss = 3.805, time/batch = 0.198\n",
            "740/15750 (epoch 2), train_loss = 3.792, time/batch = 0.194\n",
            "741/15750 (epoch 2), train_loss = 3.743, time/batch = 0.196\n",
            "742/15750 (epoch 2), train_loss = 3.750, time/batch = 0.201\n",
            "743/15750 (epoch 2), train_loss = 3.776, time/batch = 0.192\n",
            "744/15750 (epoch 2), train_loss = 3.798, time/batch = 0.196\n",
            "745/15750 (epoch 2), train_loss = 3.830, time/batch = 0.199\n",
            "746/15750 (epoch 2), train_loss = 3.724, time/batch = 0.188\n",
            "747/15750 (epoch 2), train_loss = 3.867, time/batch = 0.202\n",
            "748/15750 (epoch 2), train_loss = 3.797, time/batch = 0.193\n",
            "749/15750 (epoch 2), train_loss = 3.690, time/batch = 0.189\n",
            "750/15750 (epoch 2), train_loss = 3.691, time/batch = 0.185\n",
            "751/15750 (epoch 2), train_loss = 3.709, time/batch = 0.189\n",
            "752/15750 (epoch 2), train_loss = 3.729, time/batch = 0.196\n",
            "753/15750 (epoch 2), train_loss = 3.730, time/batch = 0.208\n",
            "754/15750 (epoch 2), train_loss = 3.773, time/batch = 0.197\n",
            "755/15750 (epoch 2), train_loss = 3.731, time/batch = 0.200\n",
            "756/15750 (epoch 2), train_loss = 3.822, time/batch = 0.196\n",
            "757/15750 (epoch 2), train_loss = 3.674, time/batch = 0.198\n",
            "758/15750 (epoch 2), train_loss = 3.654, time/batch = 0.200\n",
            "759/15750 (epoch 2), train_loss = 3.663, time/batch = 0.197\n",
            "760/15750 (epoch 2), train_loss = 3.639, time/batch = 0.202\n",
            "761/15750 (epoch 2), train_loss = 3.692, time/batch = 0.197\n",
            "762/15750 (epoch 2), train_loss = 3.714, time/batch = 0.196\n",
            "763/15750 (epoch 2), train_loss = 3.668, time/batch = 0.203\n",
            "764/15750 (epoch 2), train_loss = 3.703, time/batch = 0.198\n",
            "765/15750 (epoch 2), train_loss = 3.713, time/batch = 0.193\n",
            "766/15750 (epoch 2), train_loss = 3.782, time/batch = 0.192\n",
            "767/15750 (epoch 2), train_loss = 3.781, time/batch = 0.194\n",
            "768/15750 (epoch 2), train_loss = 3.755, time/batch = 0.200\n",
            "769/15750 (epoch 2), train_loss = 3.776, time/batch = 0.198\n",
            "770/15750 (epoch 2), train_loss = 3.668, time/batch = 0.192\n",
            "771/15750 (epoch 2), train_loss = 3.741, time/batch = 0.191\n",
            "772/15750 (epoch 2), train_loss = 3.730, time/batch = 0.188\n",
            "773/15750 (epoch 2), train_loss = 3.708, time/batch = 0.197\n",
            "774/15750 (epoch 2), train_loss = 3.654, time/batch = 0.189\n",
            "775/15750 (epoch 2), train_loss = 3.651, time/batch = 0.189\n",
            "776/15750 (epoch 2), train_loss = 3.720, time/batch = 0.195\n",
            "777/15750 (epoch 2), train_loss = 3.664, time/batch = 0.193\n",
            "778/15750 (epoch 2), train_loss = 3.710, time/batch = 0.190\n",
            "779/15750 (epoch 2), train_loss = 3.717, time/batch = 0.202\n",
            "780/15750 (epoch 2), train_loss = 3.726, time/batch = 0.196\n",
            "781/15750 (epoch 2), train_loss = 3.714, time/batch = 0.198\n",
            "782/15750 (epoch 2), train_loss = 3.835, time/batch = 0.199\n",
            "783/15750 (epoch 2), train_loss = 3.735, time/batch = 0.190\n",
            "784/15750 (epoch 2), train_loss = 3.679, time/batch = 0.205\n",
            "785/15750 (epoch 2), train_loss = 3.745, time/batch = 0.191\n",
            "786/15750 (epoch 2), train_loss = 3.777, time/batch = 0.188\n",
            "787/15750 (epoch 2), train_loss = 3.751, time/batch = 0.198\n",
            "788/15750 (epoch 2), train_loss = 3.756, time/batch = 0.196\n",
            "789/15750 (epoch 2), train_loss = 3.732, time/batch = 0.195\n",
            "790/15750 (epoch 2), train_loss = 3.743, time/batch = 0.198\n",
            "791/15750 (epoch 2), train_loss = 3.745, time/batch = 0.191\n",
            "792/15750 (epoch 2), train_loss = 3.792, time/batch = 0.195\n",
            "793/15750 (epoch 2), train_loss = 3.818, time/batch = 0.198\n",
            "794/15750 (epoch 2), train_loss = 3.818, time/batch = 0.197\n",
            "795/15750 (epoch 2), train_loss = 3.768, time/batch = 0.193\n",
            "796/15750 (epoch 2), train_loss = 3.841, time/batch = 0.200\n",
            "797/15750 (epoch 2), train_loss = 3.751, time/batch = 0.192\n",
            "798/15750 (epoch 2), train_loss = 3.706, time/batch = 0.194\n",
            "799/15750 (epoch 2), train_loss = 3.756, time/batch = 0.195\n",
            "800/15750 (epoch 2), train_loss = 3.740, time/batch = 0.196\n",
            "801/15750 (epoch 2), train_loss = 3.805, time/batch = 0.188\n",
            "802/15750 (epoch 2), train_loss = 3.754, time/batch = 0.194\n",
            "803/15750 (epoch 2), train_loss = 3.754, time/batch = 0.199\n",
            "804/15750 (epoch 2), train_loss = 3.749, time/batch = 0.198\n",
            "805/15750 (epoch 2), train_loss = 3.655, time/batch = 0.201\n",
            "806/15750 (epoch 2), train_loss = 3.736, time/batch = 0.200\n",
            "807/15750 (epoch 2), train_loss = 3.743, time/batch = 0.195\n",
            "808/15750 (epoch 2), train_loss = 3.689, time/batch = 0.202\n",
            "809/15750 (epoch 2), train_loss = 3.707, time/batch = 0.194\n",
            "810/15750 (epoch 2), train_loss = 3.605, time/batch = 0.193\n",
            "811/15750 (epoch 2), train_loss = 3.712, time/batch = 0.204\n",
            "812/15750 (epoch 2), train_loss = 3.605, time/batch = 0.198\n",
            "813/15750 (epoch 2), train_loss = 3.723, time/batch = 0.198\n",
            "814/15750 (epoch 2), train_loss = 3.752, time/batch = 0.191\n",
            "815/15750 (epoch 2), train_loss = 3.624, time/batch = 0.203\n",
            "816/15750 (epoch 2), train_loss = 3.693, time/batch = 0.194\n",
            "817/15750 (epoch 2), train_loss = 3.693, time/batch = 0.195\n",
            "818/15750 (epoch 2), train_loss = 3.760, time/batch = 0.196\n",
            "819/15750 (epoch 2), train_loss = 3.796, time/batch = 0.186\n",
            "820/15750 (epoch 2), train_loss = 3.695, time/batch = 0.199\n",
            "821/15750 (epoch 2), train_loss = 3.658, time/batch = 0.189\n",
            "822/15750 (epoch 2), train_loss = 3.677, time/batch = 0.195\n",
            "823/15750 (epoch 2), train_loss = 3.665, time/batch = 0.195\n",
            "824/15750 (epoch 2), train_loss = 3.698, time/batch = 0.192\n",
            "825/15750 (epoch 2), train_loss = 3.699, time/batch = 0.192\n",
            "826/15750 (epoch 2), train_loss = 3.618, time/batch = 0.197\n",
            "827/15750 (epoch 2), train_loss = 3.627, time/batch = 0.197\n",
            "828/15750 (epoch 2), train_loss = 3.634, time/batch = 0.195\n",
            "829/15750 (epoch 2), train_loss = 3.550, time/batch = 0.194\n",
            "830/15750 (epoch 2), train_loss = 3.632, time/batch = 0.192\n",
            "831/15750 (epoch 2), train_loss = 3.651, time/batch = 0.195\n",
            "832/15750 (epoch 2), train_loss = 3.699, time/batch = 0.182\n",
            "833/15750 (epoch 2), train_loss = 3.696, time/batch = 0.200\n",
            "834/15750 (epoch 2), train_loss = 3.663, time/batch = 0.204\n",
            "835/15750 (epoch 2), train_loss = 3.681, time/batch = 0.198\n",
            "836/15750 (epoch 2), train_loss = 3.641, time/batch = 0.205\n",
            "837/15750 (epoch 2), train_loss = 3.648, time/batch = 0.199\n",
            "838/15750 (epoch 2), train_loss = 3.597, time/batch = 0.199\n",
            "839/15750 (epoch 2), train_loss = 3.612, time/batch = 0.189\n",
            "840/15750 (epoch 2), train_loss = 3.531, time/batch = 0.193\n",
            "841/15750 (epoch 2), train_loss = 3.572, time/batch = 0.201\n",
            "842/15750 (epoch 2), train_loss = 3.535, time/batch = 0.192\n",
            "843/15750 (epoch 2), train_loss = 3.614, time/batch = 0.192\n",
            "844/15750 (epoch 2), train_loss = 3.529, time/batch = 0.196\n",
            "845/15750 (epoch 2), train_loss = 3.606, time/batch = 0.194\n",
            "846/15750 (epoch 2), train_loss = 3.676, time/batch = 0.200\n",
            "847/15750 (epoch 2), train_loss = 3.581, time/batch = 0.211\n",
            "848/15750 (epoch 2), train_loss = 3.663, time/batch = 0.196\n",
            "849/15750 (epoch 2), train_loss = 3.604, time/batch = 0.196\n",
            "850/15750 (epoch 2), train_loss = 3.534, time/batch = 0.193\n",
            "851/15750 (epoch 2), train_loss = 3.575, time/batch = 0.201\n",
            "852/15750 (epoch 2), train_loss = 3.601, time/batch = 0.200\n",
            "853/15750 (epoch 2), train_loss = 3.593, time/batch = 0.185\n",
            "854/15750 (epoch 2), train_loss = 3.544, time/batch = 0.199\n",
            "855/15750 (epoch 2), train_loss = 3.588, time/batch = 0.196\n",
            "856/15750 (epoch 2), train_loss = 3.615, time/batch = 0.190\n",
            "857/15750 (epoch 2), train_loss = 3.542, time/batch = 0.196\n",
            "858/15750 (epoch 2), train_loss = 3.594, time/batch = 0.193\n",
            "859/15750 (epoch 2), train_loss = 3.567, time/batch = 0.199\n",
            "860/15750 (epoch 2), train_loss = 3.530, time/batch = 0.200\n",
            "861/15750 (epoch 2), train_loss = 3.598, time/batch = 0.191\n",
            "862/15750 (epoch 2), train_loss = 3.565, time/batch = 0.201\n",
            "863/15750 (epoch 2), train_loss = 3.599, time/batch = 0.194\n",
            "864/15750 (epoch 2), train_loss = 3.562, time/batch = 0.195\n",
            "865/15750 (epoch 2), train_loss = 3.666, time/batch = 0.201\n",
            "866/15750 (epoch 2), train_loss = 3.544, time/batch = 0.195\n",
            "867/15750 (epoch 2), train_loss = 3.598, time/batch = 0.197\n",
            "868/15750 (epoch 2), train_loss = 3.720, time/batch = 0.188\n",
            "869/15750 (epoch 2), train_loss = 3.587, time/batch = 0.194\n",
            "870/15750 (epoch 2), train_loss = 3.664, time/batch = 0.190\n",
            "871/15750 (epoch 2), train_loss = 3.555, time/batch = 0.196\n",
            "872/15750 (epoch 2), train_loss = 3.626, time/batch = 0.198\n",
            "873/15750 (epoch 2), train_loss = 3.619, time/batch = 0.205\n",
            "874/15750 (epoch 2), train_loss = 3.660, time/batch = 0.192\n",
            "875/15750 (epoch 2), train_loss = 3.628, time/batch = 0.198\n",
            "876/15750 (epoch 2), train_loss = 3.671, time/batch = 0.198\n",
            "877/15750 (epoch 2), train_loss = 3.651, time/batch = 0.193\n",
            "878/15750 (epoch 2), train_loss = 3.589, time/batch = 0.197\n",
            "879/15750 (epoch 2), train_loss = 3.621, time/batch = 0.197\n",
            "880/15750 (epoch 2), train_loss = 3.586, time/batch = 0.192\n",
            "881/15750 (epoch 2), train_loss = 3.540, time/batch = 0.197\n",
            "882/15750 (epoch 2), train_loss = 3.629, time/batch = 0.197\n",
            "883/15750 (epoch 2), train_loss = 3.570, time/batch = 0.198\n",
            "884/15750 (epoch 2), train_loss = 3.621, time/batch = 0.194\n",
            "885/15750 (epoch 2), train_loss = 3.587, time/batch = 0.195\n",
            "886/15750 (epoch 2), train_loss = 3.481, time/batch = 0.188\n",
            "887/15750 (epoch 2), train_loss = 3.500, time/batch = 0.193\n",
            "888/15750 (epoch 2), train_loss = 3.673, time/batch = 0.196\n",
            "889/15750 (epoch 2), train_loss = 3.588, time/batch = 0.192\n",
            "890/15750 (epoch 2), train_loss = 3.600, time/batch = 0.199\n",
            "891/15750 (epoch 2), train_loss = 3.601, time/batch = 0.193\n",
            "892/15750 (epoch 2), train_loss = 3.622, time/batch = 0.196\n",
            "893/15750 (epoch 2), train_loss = 3.547, time/batch = 0.200\n",
            "894/15750 (epoch 2), train_loss = 3.715, time/batch = 0.196\n",
            "895/15750 (epoch 2), train_loss = 3.699, time/batch = 0.197\n",
            "896/15750 (epoch 2), train_loss = 3.715, time/batch = 0.197\n",
            "897/15750 (epoch 2), train_loss = 3.633, time/batch = 0.198\n",
            "898/15750 (epoch 2), train_loss = 3.645, time/batch = 0.192\n",
            "899/15750 (epoch 2), train_loss = 3.677, time/batch = 0.202\n",
            "900/15750 (epoch 2), train_loss = 3.642, time/batch = 0.203\n",
            "901/15750 (epoch 2), train_loss = 3.510, time/batch = 0.198\n",
            "902/15750 (epoch 2), train_loss = 3.554, time/batch = 0.198\n",
            "903/15750 (epoch 2), train_loss = 3.605, time/batch = 0.193\n",
            "904/15750 (epoch 2), train_loss = 3.596, time/batch = 0.197\n",
            "905/15750 (epoch 2), train_loss = 3.595, time/batch = 0.197\n",
            "906/15750 (epoch 2), train_loss = 3.625, time/batch = 0.191\n",
            "907/15750 (epoch 2), train_loss = 3.549, time/batch = 0.197\n",
            "908/15750 (epoch 2), train_loss = 3.576, time/batch = 0.196\n",
            "909/15750 (epoch 2), train_loss = 3.499, time/batch = 0.211\n",
            "910/15750 (epoch 2), train_loss = 3.708, time/batch = 0.199\n",
            "911/15750 (epoch 2), train_loss = 3.514, time/batch = 0.193\n",
            "912/15750 (epoch 2), train_loss = 3.548, time/batch = 0.200\n",
            "913/15750 (epoch 2), train_loss = 3.628, time/batch = 0.198\n",
            "914/15750 (epoch 2), train_loss = 3.529, time/batch = 0.198\n",
            "915/15750 (epoch 2), train_loss = 3.653, time/batch = 0.196\n",
            "916/15750 (epoch 2), train_loss = 3.536, time/batch = 0.191\n",
            "917/15750 (epoch 2), train_loss = 3.572, time/batch = 0.198\n",
            "918/15750 (epoch 2), train_loss = 3.516, time/batch = 0.199\n",
            "919/15750 (epoch 2), train_loss = 3.540, time/batch = 0.191\n",
            "920/15750 (epoch 2), train_loss = 3.485, time/batch = 0.203\n",
            "921/15750 (epoch 2), train_loss = 3.586, time/batch = 0.198\n",
            "922/15750 (epoch 2), train_loss = 3.543, time/batch = 0.193\n",
            "923/15750 (epoch 2), train_loss = 3.524, time/batch = 0.191\n",
            "924/15750 (epoch 2), train_loss = 3.572, time/batch = 0.194\n",
            "925/15750 (epoch 2), train_loss = 3.614, time/batch = 0.198\n",
            "926/15750 (epoch 2), train_loss = 3.606, time/batch = 0.192\n",
            "927/15750 (epoch 2), train_loss = 3.606, time/batch = 0.192\n",
            "928/15750 (epoch 2), train_loss = 3.468, time/batch = 0.188\n",
            "929/15750 (epoch 2), train_loss = 3.588, time/batch = 0.187\n",
            "930/15750 (epoch 2), train_loss = 3.594, time/batch = 0.205\n",
            "931/15750 (epoch 2), train_loss = 3.468, time/batch = 0.195\n",
            "932/15750 (epoch 2), train_loss = 3.577, time/batch = 0.197\n",
            "933/15750 (epoch 2), train_loss = 3.459, time/batch = 0.197\n",
            "934/15750 (epoch 2), train_loss = 3.577, time/batch = 0.196\n",
            "935/15750 (epoch 2), train_loss = 3.564, time/batch = 0.196\n",
            "936/15750 (epoch 2), train_loss = 3.577, time/batch = 0.197\n",
            "937/15750 (epoch 2), train_loss = 3.531, time/batch = 0.204\n",
            "938/15750 (epoch 2), train_loss = 3.507, time/batch = 0.198\n",
            "939/15750 (epoch 2), train_loss = 3.623, time/batch = 0.193\n",
            "940/15750 (epoch 2), train_loss = 3.475, time/batch = 0.194\n",
            "941/15750 (epoch 2), train_loss = 3.399, time/batch = 0.188\n",
            "942/15750 (epoch 2), train_loss = 3.482, time/batch = 0.189\n",
            "943/15750 (epoch 2), train_loss = 3.540, time/batch = 0.199\n",
            "944/15750 (epoch 2), train_loss = 3.594, time/batch = 0.194\n",
            "945/15750 (epoch 3), train_loss = 3.653, time/batch = 0.199\n",
            "946/15750 (epoch 3), train_loss = 3.572, time/batch = 0.193\n",
            "947/15750 (epoch 3), train_loss = 3.541, time/batch = 0.201\n",
            "948/15750 (epoch 3), train_loss = 3.656, time/batch = 0.202\n",
            "949/15750 (epoch 3), train_loss = 3.570, time/batch = 0.195\n",
            "950/15750 (epoch 3), train_loss = 3.497, time/batch = 0.198\n",
            "951/15750 (epoch 3), train_loss = 3.610, time/batch = 0.192\n",
            "952/15750 (epoch 3), train_loss = 3.620, time/batch = 0.192\n",
            "953/15750 (epoch 3), train_loss = 3.595, time/batch = 0.195\n",
            "954/15750 (epoch 3), train_loss = 3.527, time/batch = 0.198\n",
            "955/15750 (epoch 3), train_loss = 3.494, time/batch = 0.203\n",
            "956/15750 (epoch 3), train_loss = 3.462, time/batch = 0.196\n",
            "957/15750 (epoch 3), train_loss = 3.574, time/batch = 0.197\n",
            "958/15750 (epoch 3), train_loss = 3.486, time/batch = 0.192\n",
            "959/15750 (epoch 3), train_loss = 3.536, time/batch = 0.197\n",
            "960/15750 (epoch 3), train_loss = 3.514, time/batch = 0.198\n",
            "961/15750 (epoch 3), train_loss = 3.578, time/batch = 0.196\n",
            "962/15750 (epoch 3), train_loss = 3.590, time/batch = 0.198\n",
            "963/15750 (epoch 3), train_loss = 3.599, time/batch = 0.201\n",
            "964/15750 (epoch 3), train_loss = 3.546, time/batch = 0.196\n",
            "965/15750 (epoch 3), train_loss = 3.581, time/batch = 0.201\n",
            "966/15750 (epoch 3), train_loss = 3.568, time/batch = 0.200\n",
            "967/15750 (epoch 3), train_loss = 3.486, time/batch = 0.195\n",
            "968/15750 (epoch 3), train_loss = 3.556, time/batch = 0.189\n",
            "969/15750 (epoch 3), train_loss = 3.569, time/batch = 0.195\n",
            "970/15750 (epoch 3), train_loss = 3.614, time/batch = 0.194\n",
            "971/15750 (epoch 3), train_loss = 3.525, time/batch = 0.206\n",
            "972/15750 (epoch 3), train_loss = 3.544, time/batch = 0.195\n",
            "973/15750 (epoch 3), train_loss = 3.654, time/batch = 0.191\n",
            "974/15750 (epoch 3), train_loss = 3.548, time/batch = 0.200\n",
            "975/15750 (epoch 3), train_loss = 3.550, time/batch = 0.193\n",
            "976/15750 (epoch 3), train_loss = 3.537, time/batch = 0.197\n",
            "977/15750 (epoch 3), train_loss = 3.460, time/batch = 0.194\n",
            "978/15750 (epoch 3), train_loss = 3.489, time/batch = 0.191\n",
            "979/15750 (epoch 3), train_loss = 3.471, time/batch = 0.194\n",
            "980/15750 (epoch 3), train_loss = 3.458, time/batch = 0.198\n",
            "981/15750 (epoch 3), train_loss = 3.439, time/batch = 0.198\n",
            "982/15750 (epoch 3), train_loss = 3.473, time/batch = 0.190\n",
            "983/15750 (epoch 3), train_loss = 3.454, time/batch = 0.196\n",
            "984/15750 (epoch 3), train_loss = 3.489, time/batch = 0.195\n",
            "985/15750 (epoch 3), train_loss = 3.504, time/batch = 0.190\n",
            "986/15750 (epoch 3), train_loss = 3.575, time/batch = 0.198\n",
            "987/15750 (epoch 3), train_loss = 3.527, time/batch = 0.202\n",
            "988/15750 (epoch 3), train_loss = 3.453, time/batch = 0.196\n",
            "989/15750 (epoch 3), train_loss = 3.497, time/batch = 0.205\n",
            "990/15750 (epoch 3), train_loss = 3.448, time/batch = 0.191\n",
            "991/15750 (epoch 3), train_loss = 3.450, time/batch = 0.192\n",
            "992/15750 (epoch 3), train_loss = 3.501, time/batch = 0.203\n",
            "993/15750 (epoch 3), train_loss = 3.440, time/batch = 0.192\n",
            "994/15750 (epoch 3), train_loss = 3.442, time/batch = 0.195\n",
            "995/15750 (epoch 3), train_loss = 3.394, time/batch = 0.194\n",
            "996/15750 (epoch 3), train_loss = 3.440, time/batch = 0.197\n",
            "997/15750 (epoch 3), train_loss = 3.510, time/batch = 0.195\n",
            "998/15750 (epoch 3), train_loss = 3.501, time/batch = 0.195\n",
            "999/15750 (epoch 3), train_loss = 3.478, time/batch = 0.198\n",
            "1000/15750 (epoch 3), train_loss = 3.489, time/batch = 0.197\n",
            "model saved to ./save_star/model.ckpt\n",
            "1001/15750 (epoch 3), train_loss = 3.393, time/batch = 0.198\n",
            "1002/15750 (epoch 3), train_loss = 3.395, time/batch = 0.203\n",
            "1003/15750 (epoch 3), train_loss = 3.430, time/batch = 0.200\n",
            "1004/15750 (epoch 3), train_loss = 3.354, time/batch = 0.195\n",
            "1005/15750 (epoch 3), train_loss = 3.407, time/batch = 0.199\n",
            "1006/15750 (epoch 3), train_loss = 3.400, time/batch = 0.195\n",
            "1007/15750 (epoch 3), train_loss = 3.405, time/batch = 0.196\n",
            "1008/15750 (epoch 3), train_loss = 3.396, time/batch = 0.189\n",
            "1009/15750 (epoch 3), train_loss = 3.404, time/batch = 0.201\n",
            "1010/15750 (epoch 3), train_loss = 3.365, time/batch = 0.194\n",
            "1011/15750 (epoch 3), train_loss = 3.340, time/batch = 0.204\n",
            "1012/15750 (epoch 3), train_loss = 3.376, time/batch = 0.202\n",
            "1013/15750 (epoch 3), train_loss = 3.397, time/batch = 0.196\n",
            "1014/15750 (epoch 3), train_loss = 3.473, time/batch = 0.201\n",
            "1015/15750 (epoch 3), train_loss = 3.376, time/batch = 0.200\n",
            "1016/15750 (epoch 3), train_loss = 3.403, time/batch = 0.205\n",
            "1017/15750 (epoch 3), train_loss = 3.228, time/batch = 0.200\n",
            "1018/15750 (epoch 3), train_loss = 3.387, time/batch = 0.192\n",
            "1019/15750 (epoch 3), train_loss = 3.486, time/batch = 0.193\n",
            "1020/15750 (epoch 3), train_loss = 3.410, time/batch = 0.195\n",
            "1021/15750 (epoch 3), train_loss = 3.432, time/batch = 0.191\n",
            "1022/15750 (epoch 3), train_loss = 3.395, time/batch = 0.193\n",
            "1023/15750 (epoch 3), train_loss = 3.441, time/batch = 0.193\n",
            "1024/15750 (epoch 3), train_loss = 3.463, time/batch = 0.194\n",
            "1025/15750 (epoch 3), train_loss = 3.368, time/batch = 0.197\n",
            "1026/15750 (epoch 3), train_loss = 3.415, time/batch = 0.194\n",
            "1027/15750 (epoch 3), train_loss = 3.329, time/batch = 0.199\n",
            "1028/15750 (epoch 3), train_loss = 3.441, time/batch = 0.199\n",
            "1029/15750 (epoch 3), train_loss = 3.477, time/batch = 0.194\n",
            "1030/15750 (epoch 3), train_loss = 3.491, time/batch = 0.194\n",
            "1031/15750 (epoch 3), train_loss = 3.369, time/batch = 0.195\n",
            "1032/15750 (epoch 3), train_loss = 3.432, time/batch = 0.201\n",
            "1033/15750 (epoch 3), train_loss = 3.461, time/batch = 0.199\n",
            "1034/15750 (epoch 3), train_loss = 3.346, time/batch = 0.194\n",
            "1035/15750 (epoch 3), train_loss = 3.462, time/batch = 0.199\n",
            "1036/15750 (epoch 3), train_loss = 3.421, time/batch = 0.192\n",
            "1037/15750 (epoch 3), train_loss = 3.434, time/batch = 0.198\n",
            "1038/15750 (epoch 3), train_loss = 3.450, time/batch = 0.195\n",
            "1039/15750 (epoch 3), train_loss = 3.458, time/batch = 0.191\n",
            "1040/15750 (epoch 3), train_loss = 3.423, time/batch = 0.200\n",
            "1041/15750 (epoch 3), train_loss = 3.384, time/batch = 0.198\n",
            "1042/15750 (epoch 3), train_loss = 3.373, time/batch = 0.209\n",
            "1043/15750 (epoch 3), train_loss = 3.471, time/batch = 0.202\n",
            "1044/15750 (epoch 3), train_loss = 3.384, time/batch = 0.200\n",
            "1045/15750 (epoch 3), train_loss = 3.371, time/batch = 0.194\n",
            "1046/15750 (epoch 3), train_loss = 3.319, time/batch = 0.192\n",
            "1047/15750 (epoch 3), train_loss = 3.340, time/batch = 0.194\n",
            "1048/15750 (epoch 3), train_loss = 3.454, time/batch = 0.197\n",
            "1049/15750 (epoch 3), train_loss = 3.403, time/batch = 0.197\n",
            "1050/15750 (epoch 3), train_loss = 3.349, time/batch = 0.203\n",
            "1051/15750 (epoch 3), train_loss = 3.427, time/batch = 0.198\n",
            "1052/15750 (epoch 3), train_loss = 3.383, time/batch = 0.197\n",
            "1053/15750 (epoch 3), train_loss = 3.472, time/batch = 0.204\n",
            "1054/15750 (epoch 3), train_loss = 3.472, time/batch = 0.198\n",
            "1055/15750 (epoch 3), train_loss = 3.470, time/batch = 0.202\n",
            "1056/15750 (epoch 3), train_loss = 3.381, time/batch = 0.202\n",
            "1057/15750 (epoch 3), train_loss = 3.401, time/batch = 0.204\n",
            "1058/15750 (epoch 3), train_loss = 3.397, time/batch = 0.204\n",
            "1059/15750 (epoch 3), train_loss = 3.407, time/batch = 0.204\n",
            "1060/15750 (epoch 3), train_loss = 3.474, time/batch = 0.204\n",
            "1061/15750 (epoch 3), train_loss = 3.372, time/batch = 0.197\n",
            "1062/15750 (epoch 3), train_loss = 3.521, time/batch = 0.199\n",
            "1063/15750 (epoch 3), train_loss = 3.418, time/batch = 0.202\n",
            "1064/15750 (epoch 3), train_loss = 3.330, time/batch = 0.193\n",
            "1065/15750 (epoch 3), train_loss = 3.335, time/batch = 0.203\n",
            "1066/15750 (epoch 3), train_loss = 3.331, time/batch = 0.194\n",
            "1067/15750 (epoch 3), train_loss = 3.374, time/batch = 0.198\n",
            "1068/15750 (epoch 3), train_loss = 3.361, time/batch = 0.208\n",
            "1069/15750 (epoch 3), train_loss = 3.399, time/batch = 0.191\n",
            "1070/15750 (epoch 3), train_loss = 3.380, time/batch = 0.202\n",
            "1071/15750 (epoch 3), train_loss = 3.474, time/batch = 0.199\n",
            "1072/15750 (epoch 3), train_loss = 3.311, time/batch = 0.188\n",
            "1073/15750 (epoch 3), train_loss = 3.280, time/batch = 0.202\n",
            "1074/15750 (epoch 3), train_loss = 3.317, time/batch = 0.196\n",
            "1075/15750 (epoch 3), train_loss = 3.281, time/batch = 0.200\n",
            "1076/15750 (epoch 3), train_loss = 3.322, time/batch = 0.196\n",
            "1077/15750 (epoch 3), train_loss = 3.366, time/batch = 0.198\n",
            "1078/15750 (epoch 3), train_loss = 3.299, time/batch = 0.201\n",
            "1079/15750 (epoch 3), train_loss = 3.368, time/batch = 0.200\n",
            "1080/15750 (epoch 3), train_loss = 3.387, time/batch = 0.197\n",
            "1081/15750 (epoch 3), train_loss = 3.412, time/batch = 0.191\n",
            "1082/15750 (epoch 3), train_loss = 3.444, time/batch = 0.193\n",
            "1083/15750 (epoch 3), train_loss = 3.398, time/batch = 0.208\n",
            "1084/15750 (epoch 3), train_loss = 3.392, time/batch = 0.196\n",
            "1085/15750 (epoch 3), train_loss = 3.326, time/batch = 0.201\n",
            "1086/15750 (epoch 3), train_loss = 3.408, time/batch = 0.198\n",
            "1087/15750 (epoch 3), train_loss = 3.413, time/batch = 0.198\n",
            "1088/15750 (epoch 3), train_loss = 3.381, time/batch = 0.201\n",
            "1089/15750 (epoch 3), train_loss = 3.341, time/batch = 0.205\n",
            "1090/15750 (epoch 3), train_loss = 3.306, time/batch = 0.203\n",
            "1091/15750 (epoch 3), train_loss = 3.335, time/batch = 0.204\n",
            "1092/15750 (epoch 3), train_loss = 3.339, time/batch = 0.198\n",
            "1093/15750 (epoch 3), train_loss = 3.377, time/batch = 0.198\n",
            "1094/15750 (epoch 3), train_loss = 3.352, time/batch = 0.202\n",
            "1095/15750 (epoch 3), train_loss = 3.354, time/batch = 0.199\n",
            "1096/15750 (epoch 3), train_loss = 3.370, time/batch = 0.195\n",
            "1097/15750 (epoch 3), train_loss = 3.469, time/batch = 0.194\n",
            "1098/15750 (epoch 3), train_loss = 3.397, time/batch = 0.199\n",
            "1099/15750 (epoch 3), train_loss = 3.343, time/batch = 0.206\n",
            "1100/15750 (epoch 3), train_loss = 3.425, time/batch = 0.199\n",
            "1101/15750 (epoch 3), train_loss = 3.447, time/batch = 0.202\n",
            "1102/15750 (epoch 3), train_loss = 3.403, time/batch = 0.198\n",
            "1103/15750 (epoch 3), train_loss = 3.447, time/batch = 0.193\n",
            "1104/15750 (epoch 3), train_loss = 3.386, time/batch = 0.202\n",
            "1105/15750 (epoch 3), train_loss = 3.411, time/batch = 0.192\n",
            "1106/15750 (epoch 3), train_loss = 3.387, time/batch = 0.195\n",
            "1107/15750 (epoch 3), train_loss = 3.464, time/batch = 0.201\n",
            "1108/15750 (epoch 3), train_loss = 3.496, time/batch = 0.196\n",
            "1109/15750 (epoch 3), train_loss = 3.476, time/batch = 0.202\n",
            "1110/15750 (epoch 3), train_loss = 3.413, time/batch = 0.202\n",
            "1111/15750 (epoch 3), train_loss = 3.488, time/batch = 0.204\n",
            "1112/15750 (epoch 3), train_loss = 3.387, time/batch = 0.199\n",
            "1113/15750 (epoch 3), train_loss = 3.344, time/batch = 0.196\n",
            "1114/15750 (epoch 3), train_loss = 3.388, time/batch = 0.192\n",
            "1115/15750 (epoch 3), train_loss = 3.405, time/batch = 0.207\n",
            "1116/15750 (epoch 3), train_loss = 3.473, time/batch = 0.198\n",
            "1117/15750 (epoch 3), train_loss = 3.386, time/batch = 0.194\n",
            "1118/15750 (epoch 3), train_loss = 3.416, time/batch = 0.199\n",
            "1119/15750 (epoch 3), train_loss = 3.419, time/batch = 0.208\n",
            "1120/15750 (epoch 3), train_loss = 3.291, time/batch = 0.202\n",
            "1121/15750 (epoch 3), train_loss = 3.387, time/batch = 0.205\n",
            "1122/15750 (epoch 3), train_loss = 3.394, time/batch = 0.204\n",
            "1123/15750 (epoch 3), train_loss = 3.347, time/batch = 0.200\n",
            "1124/15750 (epoch 3), train_loss = 3.337, time/batch = 0.202\n",
            "1125/15750 (epoch 3), train_loss = 3.265, time/batch = 0.197\n",
            "1126/15750 (epoch 3), train_loss = 3.393, time/batch = 0.192\n",
            "1127/15750 (epoch 3), train_loss = 3.287, time/batch = 0.194\n",
            "1128/15750 (epoch 3), train_loss = 3.399, time/batch = 0.196\n",
            "1129/15750 (epoch 3), train_loss = 3.404, time/batch = 0.191\n",
            "1130/15750 (epoch 3), train_loss = 3.293, time/batch = 0.199\n",
            "1131/15750 (epoch 3), train_loss = 3.347, time/batch = 0.195\n",
            "1132/15750 (epoch 3), train_loss = 3.358, time/batch = 0.199\n",
            "1133/15750 (epoch 3), train_loss = 3.436, time/batch = 0.202\n",
            "1134/15750 (epoch 3), train_loss = 3.476, time/batch = 0.195\n",
            "1135/15750 (epoch 3), train_loss = 3.377, time/batch = 0.208\n",
            "1136/15750 (epoch 3), train_loss = 3.339, time/batch = 0.200\n",
            "1137/15750 (epoch 3), train_loss = 3.356, time/batch = 0.200\n",
            "1138/15750 (epoch 3), train_loss = 3.335, time/batch = 0.203\n",
            "1139/15750 (epoch 3), train_loss = 3.377, time/batch = 0.201\n",
            "1140/15750 (epoch 3), train_loss = 3.389, time/batch = 0.204\n",
            "1141/15750 (epoch 3), train_loss = 3.285, time/batch = 0.196\n",
            "1142/15750 (epoch 3), train_loss = 3.293, time/batch = 0.193\n",
            "1143/15750 (epoch 3), train_loss = 3.327, time/batch = 0.201\n",
            "1144/15750 (epoch 3), train_loss = 3.238, time/batch = 0.195\n",
            "1145/15750 (epoch 3), train_loss = 3.300, time/batch = 0.203\n",
            "1146/15750 (epoch 3), train_loss = 3.298, time/batch = 0.195\n",
            "1147/15750 (epoch 3), train_loss = 3.366, time/batch = 0.201\n",
            "1148/15750 (epoch 3), train_loss = 3.340, time/batch = 0.201\n",
            "1149/15750 (epoch 3), train_loss = 3.341, time/batch = 0.194\n",
            "1150/15750 (epoch 3), train_loss = 3.333, time/batch = 0.203\n",
            "1151/15750 (epoch 3), train_loss = 3.281, time/batch = 0.202\n",
            "1152/15750 (epoch 3), train_loss = 3.295, time/batch = 0.199\n",
            "1153/15750 (epoch 3), train_loss = 3.270, time/batch = 0.197\n",
            "1154/15750 (epoch 3), train_loss = 3.299, time/batch = 0.198\n",
            "1155/15750 (epoch 3), train_loss = 3.181, time/batch = 0.201\n",
            "1156/15750 (epoch 3), train_loss = 3.257, time/batch = 0.194\n",
            "1157/15750 (epoch 3), train_loss = 3.195, time/batch = 0.201\n",
            "1158/15750 (epoch 3), train_loss = 3.266, time/batch = 0.197\n",
            "1159/15750 (epoch 3), train_loss = 3.194, time/batch = 0.197\n",
            "1160/15750 (epoch 3), train_loss = 3.269, time/batch = 0.206\n",
            "1161/15750 (epoch 3), train_loss = 3.374, time/batch = 0.195\n",
            "1162/15750 (epoch 3), train_loss = 3.243, time/batch = 0.197\n",
            "1163/15750 (epoch 3), train_loss = 3.382, time/batch = 0.204\n",
            "1164/15750 (epoch 3), train_loss = 3.286, time/batch = 0.199\n",
            "1165/15750 (epoch 3), train_loss = 3.185, time/batch = 0.203\n",
            "1166/15750 (epoch 3), train_loss = 3.241, time/batch = 0.199\n",
            "1167/15750 (epoch 3), train_loss = 3.296, time/batch = 0.201\n",
            "1168/15750 (epoch 3), train_loss = 3.278, time/batch = 0.207\n",
            "1169/15750 (epoch 3), train_loss = 3.227, time/batch = 0.194\n",
            "1170/15750 (epoch 3), train_loss = 3.278, time/batch = 0.199\n",
            "1171/15750 (epoch 3), train_loss = 3.315, time/batch = 0.201\n",
            "1172/15750 (epoch 3), train_loss = 3.222, time/batch = 0.195\n",
            "1173/15750 (epoch 3), train_loss = 3.285, time/batch = 0.204\n",
            "1174/15750 (epoch 3), train_loss = 3.277, time/batch = 0.198\n",
            "1175/15750 (epoch 3), train_loss = 3.201, time/batch = 0.194\n",
            "1176/15750 (epoch 3), train_loss = 3.265, time/batch = 0.207\n",
            "1177/15750 (epoch 3), train_loss = 3.235, time/batch = 0.199\n",
            "1178/15750 (epoch 3), train_loss = 3.275, time/batch = 0.196\n",
            "1179/15750 (epoch 3), train_loss = 3.233, time/batch = 0.200\n",
            "1180/15750 (epoch 3), train_loss = 3.314, time/batch = 0.197\n",
            "1181/15750 (epoch 3), train_loss = 3.206, time/batch = 0.201\n",
            "1182/15750 (epoch 3), train_loss = 3.277, time/batch = 0.200\n",
            "1183/15750 (epoch 3), train_loss = 3.431, time/batch = 0.197\n",
            "1184/15750 (epoch 3), train_loss = 3.258, time/batch = 0.199\n",
            "1185/15750 (epoch 3), train_loss = 3.348, time/batch = 0.188\n",
            "1186/15750 (epoch 3), train_loss = 3.236, time/batch = 0.203\n",
            "1187/15750 (epoch 3), train_loss = 3.323, time/batch = 0.198\n",
            "1188/15750 (epoch 3), train_loss = 3.302, time/batch = 0.197\n",
            "1189/15750 (epoch 3), train_loss = 3.331, time/batch = 0.204\n",
            "1190/15750 (epoch 3), train_loss = 3.325, time/batch = 0.193\n",
            "1191/15750 (epoch 3), train_loss = 3.342, time/batch = 0.204\n",
            "1192/15750 (epoch 3), train_loss = 3.340, time/batch = 0.201\n",
            "1193/15750 (epoch 3), train_loss = 3.277, time/batch = 0.202\n",
            "1194/15750 (epoch 3), train_loss = 3.297, time/batch = 0.199\n",
            "1195/15750 (epoch 3), train_loss = 3.256, time/batch = 0.204\n",
            "1196/15750 (epoch 3), train_loss = 3.229, time/batch = 0.214\n",
            "1197/15750 (epoch 3), train_loss = 3.328, time/batch = 0.198\n",
            "1198/15750 (epoch 3), train_loss = 3.273, time/batch = 0.198\n",
            "1199/15750 (epoch 3), train_loss = 3.281, time/batch = 0.199\n",
            "1200/15750 (epoch 3), train_loss = 3.283, time/batch = 0.208\n",
            "1201/15750 (epoch 3), train_loss = 3.170, time/batch = 0.199\n",
            "1202/15750 (epoch 3), train_loss = 3.197, time/batch = 0.201\n",
            "1203/15750 (epoch 3), train_loss = 3.383, time/batch = 0.201\n",
            "1204/15750 (epoch 3), train_loss = 3.295, time/batch = 0.198\n",
            "1205/15750 (epoch 3), train_loss = 3.303, time/batch = 0.210\n",
            "1206/15750 (epoch 3), train_loss = 3.276, time/batch = 0.198\n",
            "1207/15750 (epoch 3), train_loss = 3.327, time/batch = 0.199\n",
            "1208/15750 (epoch 3), train_loss = 3.227, time/batch = 0.195\n",
            "1209/15750 (epoch 3), train_loss = 3.389, time/batch = 0.195\n",
            "1210/15750 (epoch 3), train_loss = 3.371, time/batch = 0.212\n",
            "1211/15750 (epoch 3), train_loss = 3.391, time/batch = 0.204\n",
            "1212/15750 (epoch 3), train_loss = 3.310, time/batch = 0.208\n",
            "1213/15750 (epoch 3), train_loss = 3.327, time/batch = 0.198\n",
            "1214/15750 (epoch 3), train_loss = 3.362, time/batch = 0.196\n",
            "1215/15750 (epoch 3), train_loss = 3.317, time/batch = 0.214\n",
            "1216/15750 (epoch 3), train_loss = 3.182, time/batch = 0.200\n",
            "1217/15750 (epoch 3), train_loss = 3.243, time/batch = 0.200\n",
            "1218/15750 (epoch 3), train_loss = 3.304, time/batch = 0.198\n",
            "1219/15750 (epoch 3), train_loss = 3.301, time/batch = 0.196\n",
            "1220/15750 (epoch 3), train_loss = 3.293, time/batch = 0.201\n",
            "1221/15750 (epoch 3), train_loss = 3.328, time/batch = 0.199\n",
            "1222/15750 (epoch 3), train_loss = 3.234, time/batch = 0.203\n",
            "1223/15750 (epoch 3), train_loss = 3.255, time/batch = 0.206\n",
            "1224/15750 (epoch 3), train_loss = 3.198, time/batch = 0.198\n",
            "1225/15750 (epoch 3), train_loss = 3.429, time/batch = 0.202\n",
            "1226/15750 (epoch 3), train_loss = 3.217, time/batch = 0.199\n",
            "1227/15750 (epoch 3), train_loss = 3.235, time/batch = 0.200\n",
            "1228/15750 (epoch 3), train_loss = 3.328, time/batch = 0.200\n",
            "1229/15750 (epoch 3), train_loss = 3.219, time/batch = 0.197\n",
            "1230/15750 (epoch 3), train_loss = 3.362, time/batch = 0.211\n",
            "1231/15750 (epoch 3), train_loss = 3.230, time/batch = 0.197\n",
            "1232/15750 (epoch 3), train_loss = 3.269, time/batch = 0.209\n",
            "1233/15750 (epoch 3), train_loss = 3.195, time/batch = 0.199\n",
            "1234/15750 (epoch 3), train_loss = 3.246, time/batch = 0.200\n",
            "1235/15750 (epoch 3), train_loss = 3.170, time/batch = 0.208\n",
            "1236/15750 (epoch 3), train_loss = 3.284, time/batch = 0.202\n",
            "1237/15750 (epoch 3), train_loss = 3.261, time/batch = 0.203\n",
            "1238/15750 (epoch 3), train_loss = 3.217, time/batch = 0.195\n",
            "1239/15750 (epoch 3), train_loss = 3.301, time/batch = 0.199\n",
            "1240/15750 (epoch 3), train_loss = 3.338, time/batch = 0.203\n",
            "1241/15750 (epoch 3), train_loss = 3.314, time/batch = 0.203\n",
            "1242/15750 (epoch 3), train_loss = 3.324, time/batch = 0.199\n",
            "1243/15750 (epoch 3), train_loss = 3.183, time/batch = 0.204\n",
            "1244/15750 (epoch 3), train_loss = 3.304, time/batch = 0.202\n",
            "1245/15750 (epoch 3), train_loss = 3.272, time/batch = 0.200\n",
            "1246/15750 (epoch 3), train_loss = 3.168, time/batch = 0.200\n",
            "1247/15750 (epoch 3), train_loss = 3.291, time/batch = 0.206\n",
            "1248/15750 (epoch 3), train_loss = 3.167, time/batch = 0.195\n",
            "1249/15750 (epoch 3), train_loss = 3.287, time/batch = 0.203\n",
            "1250/15750 (epoch 3), train_loss = 3.281, time/batch = 0.197\n",
            "1251/15750 (epoch 3), train_loss = 3.265, time/batch = 0.190\n",
            "1252/15750 (epoch 3), train_loss = 3.208, time/batch = 0.208\n",
            "1253/15750 (epoch 3), train_loss = 3.189, time/batch = 0.197\n",
            "1254/15750 (epoch 3), train_loss = 3.346, time/batch = 0.192\n",
            "1255/15750 (epoch 3), train_loss = 3.175, time/batch = 0.206\n",
            "1256/15750 (epoch 3), train_loss = 3.094, time/batch = 0.201\n",
            "1257/15750 (epoch 3), train_loss = 3.203, time/batch = 0.200\n",
            "1258/15750 (epoch 3), train_loss = 3.226, time/batch = 0.196\n",
            "1259/15750 (epoch 3), train_loss = 3.304, time/batch = 0.202\n",
            "1260/15750 (epoch 4), train_loss = 3.370, time/batch = 0.203\n",
            "1261/15750 (epoch 4), train_loss = 3.296, time/batch = 0.198\n",
            "1262/15750 (epoch 4), train_loss = 3.252, time/batch = 0.199\n",
            "1263/15750 (epoch 4), train_loss = 3.369, time/batch = 0.208\n",
            "1264/15750 (epoch 4), train_loss = 3.273, time/batch = 0.201\n",
            "1265/15750 (epoch 4), train_loss = 3.216, time/batch = 0.205\n",
            "1266/15750 (epoch 4), train_loss = 3.337, time/batch = 0.201\n",
            "1267/15750 (epoch 4), train_loss = 3.328, time/batch = 0.206\n",
            "1268/15750 (epoch 4), train_loss = 3.303, time/batch = 0.197\n",
            "1269/15750 (epoch 4), train_loss = 3.262, time/batch = 0.200\n",
            "1270/15750 (epoch 4), train_loss = 3.202, time/batch = 0.201\n",
            "1271/15750 (epoch 4), train_loss = 3.171, time/batch = 0.201\n",
            "1272/15750 (epoch 4), train_loss = 3.296, time/batch = 0.204\n",
            "1273/15750 (epoch 4), train_loss = 3.207, time/batch = 0.197\n",
            "1274/15750 (epoch 4), train_loss = 3.257, time/batch = 0.198\n",
            "1275/15750 (epoch 4), train_loss = 3.224, time/batch = 0.197\n",
            "1276/15750 (epoch 4), train_loss = 3.301, time/batch = 0.198\n",
            "1277/15750 (epoch 4), train_loss = 3.316, time/batch = 0.202\n",
            "1278/15750 (epoch 4), train_loss = 3.316, time/batch = 0.198\n",
            "1279/15750 (epoch 4), train_loss = 3.275, time/batch = 0.201\n",
            "1280/15750 (epoch 4), train_loss = 3.313, time/batch = 0.197\n",
            "1281/15750 (epoch 4), train_loss = 3.283, time/batch = 0.200\n",
            "1282/15750 (epoch 4), train_loss = 3.215, time/batch = 0.211\n",
            "1283/15750 (epoch 4), train_loss = 3.276, time/batch = 0.199\n",
            "1284/15750 (epoch 4), train_loss = 3.281, time/batch = 0.205\n",
            "1285/15750 (epoch 4), train_loss = 3.336, time/batch = 0.199\n",
            "1286/15750 (epoch 4), train_loss = 3.262, time/batch = 0.202\n",
            "1287/15750 (epoch 4), train_loss = 3.270, time/batch = 0.211\n",
            "1288/15750 (epoch 4), train_loss = 3.398, time/batch = 0.203\n",
            "1289/15750 (epoch 4), train_loss = 3.288, time/batch = 0.206\n",
            "1290/15750 (epoch 4), train_loss = 3.269, time/batch = 0.204\n",
            "1291/15750 (epoch 4), train_loss = 3.260, time/batch = 0.199\n",
            "1292/15750 (epoch 4), train_loss = 3.187, time/batch = 0.209\n",
            "1293/15750 (epoch 4), train_loss = 3.193, time/batch = 0.201\n",
            "1294/15750 (epoch 4), train_loss = 3.211, time/batch = 0.199\n",
            "1295/15750 (epoch 4), train_loss = 3.183, time/batch = 0.204\n",
            "1296/15750 (epoch 4), train_loss = 3.139, time/batch = 0.195\n",
            "1297/15750 (epoch 4), train_loss = 3.222, time/batch = 0.210\n",
            "1298/15750 (epoch 4), train_loss = 3.193, time/batch = 0.197\n",
            "1299/15750 (epoch 4), train_loss = 3.218, time/batch = 0.206\n",
            "1300/15750 (epoch 4), train_loss = 3.226, time/batch = 0.198\n",
            "1301/15750 (epoch 4), train_loss = 3.293, time/batch = 0.199\n",
            "1302/15750 (epoch 4), train_loss = 3.259, time/batch = 0.206\n",
            "1303/15750 (epoch 4), train_loss = 3.180, time/batch = 0.203\n",
            "1304/15750 (epoch 4), train_loss = 3.234, time/batch = 0.202\n",
            "1305/15750 (epoch 4), train_loss = 3.163, time/batch = 0.202\n",
            "1306/15750 (epoch 4), train_loss = 3.173, time/batch = 0.195\n",
            "1307/15750 (epoch 4), train_loss = 3.237, time/batch = 0.202\n",
            "1308/15750 (epoch 4), train_loss = 3.208, time/batch = 0.198\n",
            "1309/15750 (epoch 4), train_loss = 3.168, time/batch = 0.194\n",
            "1310/15750 (epoch 4), train_loss = 3.152, time/batch = 0.199\n",
            "1311/15750 (epoch 4), train_loss = 3.187, time/batch = 0.202\n",
            "1312/15750 (epoch 4), train_loss = 3.244, time/batch = 0.201\n",
            "1313/15750 (epoch 4), train_loss = 3.234, time/batch = 0.200\n",
            "1314/15750 (epoch 4), train_loss = 3.212, time/batch = 0.207\n",
            "1315/15750 (epoch 4), train_loss = 3.232, time/batch = 0.199\n",
            "1316/15750 (epoch 4), train_loss = 3.132, time/batch = 0.205\n",
            "1317/15750 (epoch 4), train_loss = 3.135, time/batch = 0.204\n",
            "1318/15750 (epoch 4), train_loss = 3.179, time/batch = 0.198\n",
            "1319/15750 (epoch 4), train_loss = 3.057, time/batch = 0.202\n",
            "1320/15750 (epoch 4), train_loss = 3.159, time/batch = 0.200\n",
            "1321/15750 (epoch 4), train_loss = 3.139, time/batch = 0.197\n",
            "1322/15750 (epoch 4), train_loss = 3.118, time/batch = 0.198\n",
            "1323/15750 (epoch 4), train_loss = 3.124, time/batch = 0.198\n",
            "1324/15750 (epoch 4), train_loss = 3.131, time/batch = 0.197\n",
            "1325/15750 (epoch 4), train_loss = 3.096, time/batch = 0.196\n",
            "1326/15750 (epoch 4), train_loss = 3.061, time/batch = 0.198\n",
            "1327/15750 (epoch 4), train_loss = 3.087, time/batch = 0.197\n",
            "1328/15750 (epoch 4), train_loss = 3.129, time/batch = 0.206\n",
            "1329/15750 (epoch 4), train_loss = 3.205, time/batch = 0.202\n",
            "1330/15750 (epoch 4), train_loss = 3.113, time/batch = 0.198\n",
            "1331/15750 (epoch 4), train_loss = 3.146, time/batch = 0.200\n",
            "1332/15750 (epoch 4), train_loss = 2.959, time/batch = 0.199\n",
            "1333/15750 (epoch 4), train_loss = 3.131, time/batch = 0.205\n",
            "1334/15750 (epoch 4), train_loss = 3.213, time/batch = 0.206\n",
            "1335/15750 (epoch 4), train_loss = 3.161, time/batch = 0.201\n",
            "1336/15750 (epoch 4), train_loss = 3.178, time/batch = 0.195\n",
            "1337/15750 (epoch 4), train_loss = 3.123, time/batch = 0.200\n",
            "1338/15750 (epoch 4), train_loss = 3.178, time/batch = 0.209\n",
            "1339/15750 (epoch 4), train_loss = 3.199, time/batch = 0.205\n",
            "1340/15750 (epoch 4), train_loss = 3.087, time/batch = 0.200\n",
            "1341/15750 (epoch 4), train_loss = 3.176, time/batch = 0.199\n",
            "1342/15750 (epoch 4), train_loss = 3.082, time/batch = 0.203\n",
            "1343/15750 (epoch 4), train_loss = 3.183, time/batch = 0.206\n",
            "1344/15750 (epoch 4), train_loss = 3.230, time/batch = 0.203\n",
            "1345/15750 (epoch 4), train_loss = 3.238, time/batch = 0.200\n",
            "1346/15750 (epoch 4), train_loss = 3.086, time/batch = 0.201\n",
            "1347/15750 (epoch 4), train_loss = 3.177, time/batch = 0.204\n",
            "1348/15750 (epoch 4), train_loss = 3.187, time/batch = 0.204\n",
            "1349/15750 (epoch 4), train_loss = 3.083, time/batch = 0.201\n",
            "1350/15750 (epoch 4), train_loss = 3.185, time/batch = 0.198\n",
            "1351/15750 (epoch 4), train_loss = 3.201, time/batch = 0.200\n",
            "1352/15750 (epoch 4), train_loss = 3.203, time/batch = 0.204\n",
            "1353/15750 (epoch 4), train_loss = 3.202, time/batch = 0.206\n",
            "1354/15750 (epoch 4), train_loss = 3.220, time/batch = 0.204\n",
            "1355/15750 (epoch 4), train_loss = 3.153, time/batch = 0.208\n",
            "1356/15750 (epoch 4), train_loss = 3.132, time/batch = 0.205\n",
            "1357/15750 (epoch 4), train_loss = 3.127, time/batch = 0.196\n",
            "1358/15750 (epoch 4), train_loss = 3.202, time/batch = 0.202\n",
            "1359/15750 (epoch 4), train_loss = 3.132, time/batch = 0.207\n",
            "1360/15750 (epoch 4), train_loss = 3.127, time/batch = 0.200\n",
            "1361/15750 (epoch 4), train_loss = 3.066, time/batch = 0.203\n",
            "1362/15750 (epoch 4), train_loss = 3.081, time/batch = 0.205\n",
            "1363/15750 (epoch 4), train_loss = 3.225, time/batch = 0.207\n",
            "1364/15750 (epoch 4), train_loss = 3.163, time/batch = 0.205\n",
            "1365/15750 (epoch 4), train_loss = 3.091, time/batch = 0.203\n",
            "1366/15750 (epoch 4), train_loss = 3.175, time/batch = 0.199\n",
            "1367/15750 (epoch 4), train_loss = 3.125, time/batch = 0.207\n",
            "1368/15750 (epoch 4), train_loss = 3.240, time/batch = 0.207\n",
            "1369/15750 (epoch 4), train_loss = 3.231, time/batch = 0.199\n",
            "1370/15750 (epoch 4), train_loss = 3.230, time/batch = 0.201\n",
            "1371/15750 (epoch 4), train_loss = 3.140, time/batch = 0.204\n",
            "1372/15750 (epoch 4), train_loss = 3.154, time/batch = 0.197\n",
            "1373/15750 (epoch 4), train_loss = 3.155, time/batch = 0.206\n",
            "1374/15750 (epoch 4), train_loss = 3.147, time/batch = 0.200\n",
            "1375/15750 (epoch 4), train_loss = 3.218, time/batch = 0.201\n",
            "1376/15750 (epoch 4), train_loss = 3.133, time/batch = 0.197\n",
            "1377/15750 (epoch 4), train_loss = 3.292, time/batch = 0.201\n",
            "1378/15750 (epoch 4), train_loss = 3.156, time/batch = 0.206\n",
            "1379/15750 (epoch 4), train_loss = 3.097, time/batch = 0.203\n",
            "1380/15750 (epoch 4), train_loss = 3.093, time/batch = 0.198\n",
            "1381/15750 (epoch 4), train_loss = 3.081, time/batch = 0.199\n",
            "1382/15750 (epoch 4), train_loss = 3.111, time/batch = 0.202\n",
            "1383/15750 (epoch 4), train_loss = 3.106, time/batch = 0.206\n",
            "1384/15750 (epoch 4), train_loss = 3.133, time/batch = 0.199\n",
            "1385/15750 (epoch 4), train_loss = 3.141, time/batch = 0.205\n",
            "1386/15750 (epoch 4), train_loss = 3.232, time/batch = 0.201\n",
            "1387/15750 (epoch 4), train_loss = 3.067, time/batch = 0.200\n",
            "1388/15750 (epoch 4), train_loss = 3.029, time/batch = 0.211\n",
            "1389/15750 (epoch 4), train_loss = 3.081, time/batch = 0.203\n",
            "1390/15750 (epoch 4), train_loss = 3.029, time/batch = 0.201\n",
            "1391/15750 (epoch 4), train_loss = 3.055, time/batch = 0.206\n",
            "1392/15750 (epoch 4), train_loss = 3.107, time/batch = 0.199\n",
            "1393/15750 (epoch 4), train_loss = 3.047, time/batch = 0.202\n",
            "1394/15750 (epoch 4), train_loss = 3.130, time/batch = 0.196\n",
            "1395/15750 (epoch 4), train_loss = 3.153, time/batch = 0.202\n",
            "1396/15750 (epoch 4), train_loss = 3.165, time/batch = 0.198\n",
            "1397/15750 (epoch 4), train_loss = 3.200, time/batch = 0.198\n",
            "1398/15750 (epoch 4), train_loss = 3.157, time/batch = 0.206\n",
            "1399/15750 (epoch 4), train_loss = 3.125, time/batch = 0.202\n",
            "1400/15750 (epoch 4), train_loss = 3.093, time/batch = 0.201\n",
            "1401/15750 (epoch 4), train_loss = 3.163, time/batch = 0.202\n",
            "1402/15750 (epoch 4), train_loss = 3.193, time/batch = 0.202\n",
            "1403/15750 (epoch 4), train_loss = 3.151, time/batch = 0.215\n",
            "1404/15750 (epoch 4), train_loss = 3.114, time/batch = 0.205\n",
            "1405/15750 (epoch 4), train_loss = 3.086, time/batch = 0.199\n",
            "1406/15750 (epoch 4), train_loss = 3.051, time/batch = 0.200\n",
            "1407/15750 (epoch 4), train_loss = 3.108, time/batch = 0.200\n",
            "1408/15750 (epoch 4), train_loss = 3.149, time/batch = 0.204\n",
            "1409/15750 (epoch 4), train_loss = 3.094, time/batch = 0.202\n",
            "1410/15750 (epoch 4), train_loss = 3.104, time/batch = 0.197\n",
            "1411/15750 (epoch 4), train_loss = 3.125, time/batch = 0.197\n",
            "1412/15750 (epoch 4), train_loss = 3.216, time/batch = 0.204\n",
            "1413/15750 (epoch 4), train_loss = 3.163, time/batch = 0.209\n",
            "1414/15750 (epoch 4), train_loss = 3.103, time/batch = 0.201\n",
            "1415/15750 (epoch 4), train_loss = 3.172, time/batch = 0.199\n",
            "1416/15750 (epoch 4), train_loss = 3.195, time/batch = 0.200\n",
            "1417/15750 (epoch 4), train_loss = 3.154, time/batch = 0.197\n",
            "1418/15750 (epoch 4), train_loss = 3.214, time/batch = 0.201\n",
            "1419/15750 (epoch 4), train_loss = 3.120, time/batch = 0.204\n",
            "1420/15750 (epoch 4), train_loss = 3.186, time/batch = 0.197\n",
            "1421/15750 (epoch 4), train_loss = 3.125, time/batch = 0.199\n",
            "1422/15750 (epoch 4), train_loss = 3.235, time/batch = 0.204\n",
            "1423/15750 (epoch 4), train_loss = 3.264, time/batch = 0.200\n",
            "1424/15750 (epoch 4), train_loss = 3.229, time/batch = 0.200\n",
            "1425/15750 (epoch 4), train_loss = 3.182, time/batch = 0.204\n",
            "1426/15750 (epoch 4), train_loss = 3.234, time/batch = 0.200\n",
            "1427/15750 (epoch 4), train_loss = 3.143, time/batch = 0.203\n",
            "1428/15750 (epoch 4), train_loss = 3.102, time/batch = 0.200\n",
            "1429/15750 (epoch 4), train_loss = 3.117, time/batch = 0.206\n",
            "1430/15750 (epoch 4), train_loss = 3.185, time/batch = 0.202\n",
            "1431/15750 (epoch 4), train_loss = 3.227, time/batch = 0.201\n",
            "1432/15750 (epoch 4), train_loss = 3.140, time/batch = 0.195\n",
            "1433/15750 (epoch 4), train_loss = 3.194, time/batch = 0.198\n",
            "1434/15750 (epoch 4), train_loss = 3.180, time/batch = 0.208\n",
            "1435/15750 (epoch 4), train_loss = 3.049, time/batch = 0.200\n",
            "1436/15750 (epoch 4), train_loss = 3.140, time/batch = 0.204\n",
            "1437/15750 (epoch 4), train_loss = 3.163, time/batch = 0.199\n",
            "1438/15750 (epoch 4), train_loss = 3.108, time/batch = 0.210\n",
            "1439/15750 (epoch 4), train_loss = 3.076, time/batch = 0.208\n",
            "1440/15750 (epoch 4), train_loss = 3.041, time/batch = 0.197\n",
            "1441/15750 (epoch 4), train_loss = 3.163, time/batch = 0.207\n",
            "1442/15750 (epoch 4), train_loss = 3.064, time/batch = 0.202\n",
            "1443/15750 (epoch 4), train_loss = 3.165, time/batch = 0.204\n",
            "1444/15750 (epoch 4), train_loss = 3.168, time/batch = 0.205\n",
            "1445/15750 (epoch 4), train_loss = 3.066, time/batch = 0.203\n",
            "1446/15750 (epoch 4), train_loss = 3.095, time/batch = 0.202\n",
            "1447/15750 (epoch 4), train_loss = 3.134, time/batch = 0.200\n",
            "1448/15750 (epoch 4), train_loss = 3.204, time/batch = 0.202\n",
            "1449/15750 (epoch 4), train_loss = 3.250, time/batch = 0.208\n",
            "1450/15750 (epoch 4), train_loss = 3.162, time/batch = 0.201\n",
            "1451/15750 (epoch 4), train_loss = 3.122, time/batch = 0.192\n",
            "1452/15750 (epoch 4), train_loss = 3.132, time/batch = 0.200\n",
            "1453/15750 (epoch 4), train_loss = 3.101, time/batch = 0.198\n",
            "1454/15750 (epoch 4), train_loss = 3.150, time/batch = 0.210\n",
            "1455/15750 (epoch 4), train_loss = 3.170, time/batch = 0.200\n",
            "1456/15750 (epoch 4), train_loss = 3.067, time/batch = 0.200\n",
            "1457/15750 (epoch 4), train_loss = 3.071, time/batch = 0.196\n",
            "1458/15750 (epoch 4), train_loss = 3.116, time/batch = 0.198\n",
            "1459/15750 (epoch 4), train_loss = 3.007, time/batch = 0.209\n",
            "1460/15750 (epoch 4), train_loss = 3.065, time/batch = 0.202\n",
            "1461/15750 (epoch 4), train_loss = 3.055, time/batch = 0.200\n",
            "1462/15750 (epoch 4), train_loss = 3.132, time/batch = 0.202\n",
            "1463/15750 (epoch 4), train_loss = 3.101, time/batch = 0.205\n",
            "1464/15750 (epoch 4), train_loss = 3.118, time/batch = 0.208\n",
            "1465/15750 (epoch 4), train_loss = 3.111, time/batch = 0.202\n",
            "1466/15750 (epoch 4), train_loss = 3.026, time/batch = 0.199\n",
            "1467/15750 (epoch 4), train_loss = 3.054, time/batch = 0.199\n",
            "1468/15750 (epoch 4), train_loss = 3.051, time/batch = 0.203\n",
            "1469/15750 (epoch 4), train_loss = 3.069, time/batch = 0.205\n",
            "1470/15750 (epoch 4), train_loss = 2.954, time/batch = 0.199\n",
            "1471/15750 (epoch 4), train_loss = 3.043, time/batch = 0.198\n",
            "1472/15750 (epoch 4), train_loss = 2.959, time/batch = 0.199\n",
            "1473/15750 (epoch 4), train_loss = 3.020, time/batch = 0.199\n",
            "1474/15750 (epoch 4), train_loss = 2.978, time/batch = 0.204\n",
            "1475/15750 (epoch 4), train_loss = 3.041, time/batch = 0.202\n",
            "1476/15750 (epoch 4), train_loss = 3.153, time/batch = 0.195\n",
            "1477/15750 (epoch 4), train_loss = 3.004, time/batch = 0.204\n",
            "1478/15750 (epoch 4), train_loss = 3.182, time/batch = 0.200\n",
            "1479/15750 (epoch 4), train_loss = 3.056, time/batch = 0.206\n",
            "1480/15750 (epoch 4), train_loss = 2.967, time/batch = 0.199\n",
            "1481/15750 (epoch 4), train_loss = 3.024, time/batch = 0.199\n",
            "1482/15750 (epoch 4), train_loss = 3.087, time/batch = 0.212\n",
            "1483/15750 (epoch 4), train_loss = 3.070, time/batch = 0.201\n",
            "1484/15750 (epoch 4), train_loss = 3.009, time/batch = 0.207\n",
            "1485/15750 (epoch 4), train_loss = 3.058, time/batch = 0.204\n",
            "1486/15750 (epoch 4), train_loss = 3.115, time/batch = 0.201\n",
            "1487/15750 (epoch 4), train_loss = 3.015, time/batch = 0.196\n",
            "1488/15750 (epoch 4), train_loss = 3.070, time/batch = 0.196\n",
            "1489/15750 (epoch 4), train_loss = 3.085, time/batch = 0.203\n",
            "1490/15750 (epoch 4), train_loss = 2.986, time/batch = 0.198\n",
            "1491/15750 (epoch 4), train_loss = 3.051, time/batch = 0.198\n",
            "1492/15750 (epoch 4), train_loss = 3.022, time/batch = 0.201\n",
            "1493/15750 (epoch 4), train_loss = 3.067, time/batch = 0.203\n",
            "1494/15750 (epoch 4), train_loss = 3.002, time/batch = 0.199\n",
            "1495/15750 (epoch 4), train_loss = 3.073, time/batch = 0.196\n",
            "1496/15750 (epoch 4), train_loss = 2.967, time/batch = 0.196\n",
            "1497/15750 (epoch 4), train_loss = 3.053, time/batch = 0.199\n",
            "1498/15750 (epoch 4), train_loss = 3.234, time/batch = 0.206\n",
            "1499/15750 (epoch 4), train_loss = 3.040, time/batch = 0.196\n",
            "1500/15750 (epoch 4), train_loss = 3.133, time/batch = 0.199\n",
            "1501/15750 (epoch 4), train_loss = 3.015, time/batch = 0.199\n",
            "1502/15750 (epoch 4), train_loss = 3.107, time/batch = 0.199\n",
            "1503/15750 (epoch 4), train_loss = 3.083, time/batch = 0.196\n",
            "1504/15750 (epoch 4), train_loss = 3.093, time/batch = 0.198\n",
            "1505/15750 (epoch 4), train_loss = 3.128, time/batch = 0.213\n",
            "1506/15750 (epoch 4), train_loss = 3.113, time/batch = 0.197\n",
            "1507/15750 (epoch 4), train_loss = 3.117, time/batch = 0.201\n",
            "1508/15750 (epoch 4), train_loss = 3.057, time/batch = 0.207\n",
            "1509/15750 (epoch 4), train_loss = 3.084, time/batch = 0.195\n",
            "1510/15750 (epoch 4), train_loss = 3.021, time/batch = 0.208\n",
            "1511/15750 (epoch 4), train_loss = 3.019, time/batch = 0.200\n",
            "1512/15750 (epoch 4), train_loss = 3.114, time/batch = 0.206\n",
            "1513/15750 (epoch 4), train_loss = 3.075, time/batch = 0.198\n",
            "1514/15750 (epoch 4), train_loss = 3.056, time/batch = 0.201\n",
            "1515/15750 (epoch 4), train_loss = 3.058, time/batch = 0.208\n",
            "1516/15750 (epoch 4), train_loss = 2.959, time/batch = 0.200\n",
            "1517/15750 (epoch 4), train_loss = 2.994, time/batch = 0.203\n",
            "1518/15750 (epoch 4), train_loss = 3.183, time/batch = 0.202\n",
            "1519/15750 (epoch 4), train_loss = 3.097, time/batch = 0.197\n",
            "1520/15750 (epoch 4), train_loss = 3.087, time/batch = 0.202\n",
            "1521/15750 (epoch 4), train_loss = 3.052, time/batch = 0.198\n",
            "1522/15750 (epoch 4), train_loss = 3.121, time/batch = 0.199\n",
            "1523/15750 (epoch 4), train_loss = 3.027, time/batch = 0.203\n",
            "1524/15750 (epoch 4), train_loss = 3.169, time/batch = 0.202\n",
            "1525/15750 (epoch 4), train_loss = 3.150, time/batch = 0.204\n",
            "1526/15750 (epoch 4), train_loss = 3.184, time/batch = 0.202\n",
            "1527/15750 (epoch 4), train_loss = 3.089, time/batch = 0.200\n",
            "1528/15750 (epoch 4), train_loss = 3.102, time/batch = 0.204\n",
            "1529/15750 (epoch 4), train_loss = 3.150, time/batch = 0.198\n",
            "1530/15750 (epoch 4), train_loss = 3.101, time/batch = 0.200\n",
            "1531/15750 (epoch 4), train_loss = 2.964, time/batch = 0.208\n",
            "1532/15750 (epoch 4), train_loss = 3.037, time/batch = 0.208\n",
            "1533/15750 (epoch 4), train_loss = 3.093, time/batch = 0.198\n",
            "1534/15750 (epoch 4), train_loss = 3.102, time/batch = 0.203\n",
            "1535/15750 (epoch 4), train_loss = 3.094, time/batch = 0.204\n",
            "1536/15750 (epoch 4), train_loss = 3.128, time/batch = 0.198\n",
            "1537/15750 (epoch 4), train_loss = 3.028, time/batch = 0.202\n",
            "1538/15750 (epoch 4), train_loss = 3.032, time/batch = 0.198\n",
            "1539/15750 (epoch 4), train_loss = 2.987, time/batch = 0.200\n",
            "1540/15750 (epoch 4), train_loss = 3.237, time/batch = 0.208\n",
            "1541/15750 (epoch 4), train_loss = 3.020, time/batch = 0.198\n",
            "1542/15750 (epoch 4), train_loss = 3.019, time/batch = 0.198\n",
            "1543/15750 (epoch 4), train_loss = 3.130, time/batch = 0.200\n",
            "1544/15750 (epoch 4), train_loss = 3.003, time/batch = 0.198\n",
            "1545/15750 (epoch 4), train_loss = 3.159, time/batch = 0.198\n",
            "1546/15750 (epoch 4), train_loss = 3.017, time/batch = 0.199\n",
            "1547/15750 (epoch 4), train_loss = 3.064, time/batch = 0.201\n",
            "1548/15750 (epoch 4), train_loss = 2.974, time/batch = 0.198\n",
            "1549/15750 (epoch 4), train_loss = 3.043, time/batch = 0.199\n",
            "1550/15750 (epoch 4), train_loss = 2.951, time/batch = 0.205\n",
            "1551/15750 (epoch 4), train_loss = 3.084, time/batch = 0.201\n",
            "1552/15750 (epoch 4), train_loss = 3.052, time/batch = 0.204\n",
            "1553/15750 (epoch 4), train_loss = 3.014, time/batch = 0.194\n",
            "1554/15750 (epoch 4), train_loss = 3.108, time/batch = 0.201\n",
            "1555/15750 (epoch 4), train_loss = 3.149, time/batch = 0.202\n",
            "1556/15750 (epoch 4), train_loss = 3.105, time/batch = 0.195\n",
            "1557/15750 (epoch 4), train_loss = 3.140, time/batch = 0.200\n",
            "1558/15750 (epoch 4), train_loss = 2.986, time/batch = 0.199\n",
            "1559/15750 (epoch 4), train_loss = 3.107, time/batch = 0.198\n",
            "1560/15750 (epoch 4), train_loss = 3.061, time/batch = 0.196\n",
            "1561/15750 (epoch 4), train_loss = 2.965, time/batch = 0.193\n",
            "1562/15750 (epoch 4), train_loss = 3.091, time/batch = 0.197\n",
            "1563/15750 (epoch 4), train_loss = 2.961, time/batch = 0.199\n",
            "1564/15750 (epoch 4), train_loss = 3.092, time/batch = 0.198\n",
            "1565/15750 (epoch 4), train_loss = 3.093, time/batch = 0.198\n",
            "1566/15750 (epoch 4), train_loss = 3.048, time/batch = 0.202\n",
            "1567/15750 (epoch 4), train_loss = 2.986, time/batch = 0.198\n",
            "1568/15750 (epoch 4), train_loss = 2.975, time/batch = 0.205\n",
            "1569/15750 (epoch 4), train_loss = 3.148, time/batch = 0.196\n",
            "1570/15750 (epoch 4), train_loss = 2.968, time/batch = 0.204\n",
            "1571/15750 (epoch 4), train_loss = 2.887, time/batch = 0.205\n",
            "1572/15750 (epoch 4), train_loss = 3.005, time/batch = 0.199\n",
            "1573/15750 (epoch 4), train_loss = 3.016, time/batch = 0.197\n",
            "1574/15750 (epoch 4), train_loss = 3.103, time/batch = 0.200\n",
            "1575/15750 (epoch 5), train_loss = 3.178, time/batch = 0.206\n",
            "1576/15750 (epoch 5), train_loss = 3.110, time/batch = 0.198\n",
            "1577/15750 (epoch 5), train_loss = 3.058, time/batch = 0.202\n",
            "1578/15750 (epoch 5), train_loss = 3.162, time/batch = 0.198\n",
            "1579/15750 (epoch 5), train_loss = 3.064, time/batch = 0.199\n",
            "1580/15750 (epoch 5), train_loss = 3.023, time/batch = 0.197\n",
            "1581/15750 (epoch 5), train_loss = 3.164, time/batch = 0.202\n",
            "1582/15750 (epoch 5), train_loss = 3.116, time/batch = 0.191\n",
            "1583/15750 (epoch 5), train_loss = 3.103, time/batch = 0.200\n",
            "1584/15750 (epoch 5), train_loss = 3.076, time/batch = 0.201\n",
            "1585/15750 (epoch 5), train_loss = 3.012, time/batch = 0.202\n",
            "1586/15750 (epoch 5), train_loss = 2.974, time/batch = 0.198\n",
            "1587/15750 (epoch 5), train_loss = 3.115, time/batch = 0.201\n",
            "1588/15750 (epoch 5), train_loss = 3.022, time/batch = 0.203\n",
            "1589/15750 (epoch 5), train_loss = 3.068, time/batch = 0.202\n",
            "1590/15750 (epoch 5), train_loss = 3.027, time/batch = 0.201\n",
            "1591/15750 (epoch 5), train_loss = 3.108, time/batch = 0.202\n",
            "1592/15750 (epoch 5), train_loss = 3.129, time/batch = 0.202\n",
            "1593/15750 (epoch 5), train_loss = 3.125, time/batch = 0.199\n",
            "1594/15750 (epoch 5), train_loss = 3.084, time/batch = 0.195\n",
            "1595/15750 (epoch 5), train_loss = 3.113, time/batch = 0.203\n",
            "1596/15750 (epoch 5), train_loss = 3.079, time/batch = 0.212\n",
            "1597/15750 (epoch 5), train_loss = 3.030, time/batch = 0.206\n",
            "1598/15750 (epoch 5), train_loss = 3.080, time/batch = 0.200\n",
            "1599/15750 (epoch 5), train_loss = 3.077, time/batch = 0.209\n",
            "1600/15750 (epoch 5), train_loss = 3.142, time/batch = 0.211\n",
            "1601/15750 (epoch 5), train_loss = 3.082, time/batch = 0.200\n",
            "1602/15750 (epoch 5), train_loss = 3.090, time/batch = 0.205\n",
            "1603/15750 (epoch 5), train_loss = 3.228, time/batch = 0.200\n",
            "1604/15750 (epoch 5), train_loss = 3.114, time/batch = 0.198\n",
            "1605/15750 (epoch 5), train_loss = 3.077, time/batch = 0.200\n",
            "1606/15750 (epoch 5), train_loss = 3.071, time/batch = 0.208\n",
            "1607/15750 (epoch 5), train_loss = 3.002, time/batch = 0.192\n",
            "1608/15750 (epoch 5), train_loss = 3.000, time/batch = 0.202\n",
            "1609/15750 (epoch 5), train_loss = 3.034, time/batch = 0.201\n",
            "1610/15750 (epoch 5), train_loss = 2.994, time/batch = 0.199\n",
            "1611/15750 (epoch 5), train_loss = 2.958, time/batch = 0.210\n",
            "1612/15750 (epoch 5), train_loss = 3.053, time/batch = 0.204\n",
            "1613/15750 (epoch 5), train_loss = 3.005, time/batch = 0.197\n",
            "1614/15750 (epoch 5), train_loss = 3.043, time/batch = 0.205\n",
            "1615/15750 (epoch 5), train_loss = 3.033, time/batch = 0.199\n",
            "1616/15750 (epoch 5), train_loss = 3.101, time/batch = 0.203\n",
            "1617/15750 (epoch 5), train_loss = 3.074, time/batch = 0.200\n",
            "1618/15750 (epoch 5), train_loss = 2.986, time/batch = 0.201\n",
            "1619/15750 (epoch 5), train_loss = 3.052, time/batch = 0.200\n",
            "1620/15750 (epoch 5), train_loss = 2.957, time/batch = 0.195\n",
            "1621/15750 (epoch 5), train_loss = 2.982, time/batch = 0.207\n",
            "1622/15750 (epoch 5), train_loss = 3.053, time/batch = 0.203\n",
            "1623/15750 (epoch 5), train_loss = 3.051, time/batch = 0.197\n",
            "1624/15750 (epoch 5), train_loss = 2.995, time/batch = 0.200\n",
            "1625/15750 (epoch 5), train_loss = 2.986, time/batch = 0.196\n",
            "1626/15750 (epoch 5), train_loss = 3.012, time/batch = 0.206\n",
            "1627/15750 (epoch 5), train_loss = 3.067, time/batch = 0.196\n",
            "1628/15750 (epoch 5), train_loss = 3.059, time/batch = 0.197\n",
            "1629/15750 (epoch 5), train_loss = 3.039, time/batch = 0.202\n",
            "1630/15750 (epoch 5), train_loss = 3.066, time/batch = 0.201\n",
            "1631/15750 (epoch 5), train_loss = 2.955, time/batch = 0.212\n",
            "1632/15750 (epoch 5), train_loss = 2.965, time/batch = 0.202\n",
            "1633/15750 (epoch 5), train_loss = 3.015, time/batch = 0.201\n",
            "1634/15750 (epoch 5), train_loss = 2.875, time/batch = 0.200\n",
            "1635/15750 (epoch 5), train_loss = 2.990, time/batch = 0.212\n",
            "1636/15750 (epoch 5), train_loss = 2.970, time/batch = 0.203\n",
            "1637/15750 (epoch 5), train_loss = 2.925, time/batch = 0.195\n",
            "1638/15750 (epoch 5), train_loss = 2.944, time/batch = 0.199\n",
            "1639/15750 (epoch 5), train_loss = 2.952, time/batch = 0.197\n",
            "1640/15750 (epoch 5), train_loss = 2.925, time/batch = 0.198\n",
            "1641/15750 (epoch 5), train_loss = 2.883, time/batch = 0.206\n",
            "1642/15750 (epoch 5), train_loss = 2.897, time/batch = 0.202\n",
            "1643/15750 (epoch 5), train_loss = 2.944, time/batch = 0.198\n",
            "1644/15750 (epoch 5), train_loss = 3.027, time/batch = 0.198\n",
            "1645/15750 (epoch 5), train_loss = 2.943, time/batch = 0.198\n",
            "1646/15750 (epoch 5), train_loss = 2.975, time/batch = 0.208\n",
            "1647/15750 (epoch 5), train_loss = 2.793, time/batch = 0.202\n",
            "1648/15750 (epoch 5), train_loss = 2.958, time/batch = 0.198\n",
            "1649/15750 (epoch 5), train_loss = 3.038, time/batch = 0.198\n",
            "1650/15750 (epoch 5), train_loss = 2.985, time/batch = 0.202\n",
            "1651/15750 (epoch 5), train_loss = 3.000, time/batch = 0.202\n",
            "1652/15750 (epoch 5), train_loss = 2.953, time/batch = 0.193\n",
            "1653/15750 (epoch 5), train_loss = 2.998, time/batch = 0.206\n",
            "1654/15750 (epoch 5), train_loss = 3.014, time/batch = 0.206\n",
            "1655/15750 (epoch 5), train_loss = 2.901, time/batch = 0.200\n",
            "1656/15750 (epoch 5), train_loss = 3.009, time/batch = 0.204\n",
            "1657/15750 (epoch 5), train_loss = 2.918, time/batch = 0.197\n",
            "1658/15750 (epoch 5), train_loss = 3.000, time/batch = 0.200\n",
            "1659/15750 (epoch 5), train_loss = 3.061, time/batch = 0.205\n",
            "1660/15750 (epoch 5), train_loss = 3.065, time/batch = 0.197\n",
            "1661/15750 (epoch 5), train_loss = 2.906, time/batch = 0.196\n",
            "1662/15750 (epoch 5), train_loss = 2.999, time/batch = 0.209\n",
            "1663/15750 (epoch 5), train_loss = 3.006, time/batch = 0.200\n",
            "1664/15750 (epoch 5), train_loss = 2.917, time/batch = 0.198\n",
            "1665/15750 (epoch 5), train_loss = 2.999, time/batch = 0.205\n",
            "1666/15750 (epoch 5), train_loss = 3.038, time/batch = 0.199\n",
            "1667/15750 (epoch 5), train_loss = 3.047, time/batch = 0.208\n",
            "1668/15750 (epoch 5), train_loss = 3.032, time/batch = 0.200\n",
            "1669/15750 (epoch 5), train_loss = 3.058, time/batch = 0.201\n",
            "1670/15750 (epoch 5), train_loss = 2.971, time/batch = 0.201\n",
            "1671/15750 (epoch 5), train_loss = 2.968, time/batch = 0.199\n",
            "1672/15750 (epoch 5), train_loss = 2.965, time/batch = 0.206\n",
            "1673/15750 (epoch 5), train_loss = 3.032, time/batch = 0.201\n",
            "1674/15750 (epoch 5), train_loss = 2.968, time/batch = 0.205\n",
            "1675/15750 (epoch 5), train_loss = 2.961, time/batch = 0.199\n",
            "1676/15750 (epoch 5), train_loss = 2.902, time/batch = 0.200\n",
            "1677/15750 (epoch 5), train_loss = 2.912, time/batch = 0.209\n",
            "1678/15750 (epoch 5), train_loss = 3.065, time/batch = 0.199\n",
            "1679/15750 (epoch 5), train_loss = 3.001, time/batch = 0.199\n",
            "1680/15750 (epoch 5), train_loss = 2.925, time/batch = 0.203\n",
            "1681/15750 (epoch 5), train_loss = 3.003, time/batch = 0.199\n",
            "1682/15750 (epoch 5), train_loss = 2.960, time/batch = 0.201\n",
            "1683/15750 (epoch 5), train_loss = 3.074, time/batch = 0.205\n",
            "1684/15750 (epoch 5), train_loss = 3.057, time/batch = 0.197\n",
            "1685/15750 (epoch 5), train_loss = 3.078, time/batch = 0.200\n",
            "1686/15750 (epoch 5), train_loss = 2.981, time/batch = 0.199\n",
            "1687/15750 (epoch 5), train_loss = 2.978, time/batch = 0.207\n",
            "1688/15750 (epoch 5), train_loss = 2.988, time/batch = 0.201\n",
            "1689/15750 (epoch 5), train_loss = 2.983, time/batch = 0.199\n",
            "1690/15750 (epoch 5), train_loss = 3.046, time/batch = 0.202\n",
            "1691/15750 (epoch 5), train_loss = 2.979, time/batch = 0.200\n",
            "1692/15750 (epoch 5), train_loss = 3.131, time/batch = 0.210\n",
            "1693/15750 (epoch 5), train_loss = 2.982, time/batch = 0.205\n",
            "1694/15750 (epoch 5), train_loss = 2.942, time/batch = 0.200\n",
            "1695/15750 (epoch 5), train_loss = 2.934, time/batch = 0.205\n",
            "1696/15750 (epoch 5), train_loss = 2.918, time/batch = 0.201\n",
            "1697/15750 (epoch 5), train_loss = 2.947, time/batch = 0.212\n",
            "1698/15750 (epoch 5), train_loss = 2.942, time/batch = 0.199\n",
            "1699/15750 (epoch 5), train_loss = 2.956, time/batch = 0.198\n",
            "1700/15750 (epoch 5), train_loss = 2.985, time/batch = 0.196\n",
            "1701/15750 (epoch 5), train_loss = 3.079, time/batch = 0.202\n",
            "1702/15750 (epoch 5), train_loss = 2.907, time/batch = 0.204\n",
            "1703/15750 (epoch 5), train_loss = 2.871, time/batch = 0.205\n",
            "1704/15750 (epoch 5), train_loss = 2.925, time/batch = 0.198\n",
            "1705/15750 (epoch 5), train_loss = 2.868, time/batch = 0.201\n",
            "1706/15750 (epoch 5), train_loss = 2.888, time/batch = 0.208\n",
            "1707/15750 (epoch 5), train_loss = 2.937, time/batch = 0.206\n",
            "1708/15750 (epoch 5), train_loss = 2.878, time/batch = 0.199\n",
            "1709/15750 (epoch 5), train_loss = 2.964, time/batch = 0.210\n",
            "1710/15750 (epoch 5), train_loss = 3.008, time/batch = 0.200\n",
            "1711/15750 (epoch 5), train_loss = 3.004, time/batch = 0.197\n",
            "1712/15750 (epoch 5), train_loss = 3.040, time/batch = 0.211\n",
            "1713/15750 (epoch 5), train_loss = 3.002, time/batch = 0.203\n",
            "1714/15750 (epoch 5), train_loss = 2.950, time/batch = 0.200\n",
            "1715/15750 (epoch 5), train_loss = 2.934, time/batch = 0.201\n",
            "1716/15750 (epoch 5), train_loss = 3.013, time/batch = 0.201\n",
            "1717/15750 (epoch 5), train_loss = 3.037, time/batch = 0.203\n",
            "1718/15750 (epoch 5), train_loss = 2.995, time/batch = 0.198\n",
            "1719/15750 (epoch 5), train_loss = 2.954, time/batch = 0.206\n",
            "1720/15750 (epoch 5), train_loss = 2.935, time/batch = 0.202\n",
            "1721/15750 (epoch 5), train_loss = 2.884, time/batch = 0.199\n",
            "1722/15750 (epoch 5), train_loss = 2.959, time/batch = 0.206\n",
            "1723/15750 (epoch 5), train_loss = 2.994, time/batch = 0.200\n",
            "1724/15750 (epoch 5), train_loss = 2.931, time/batch = 0.196\n",
            "1725/15750 (epoch 5), train_loss = 2.947, time/batch = 0.202\n",
            "1726/15750 (epoch 5), train_loss = 2.965, time/batch = 0.200\n",
            "1727/15750 (epoch 5), train_loss = 3.058, time/batch = 0.202\n",
            "1728/15750 (epoch 5), train_loss = 3.007, time/batch = 0.199\n",
            "1729/15750 (epoch 5), train_loss = 2.951, time/batch = 0.200\n",
            "1730/15750 (epoch 5), train_loss = 3.013, time/batch = 0.200\n",
            "1731/15750 (epoch 5), train_loss = 3.030, time/batch = 0.202\n",
            "1732/15750 (epoch 5), train_loss = 2.997, time/batch = 0.205\n",
            "1733/15750 (epoch 5), train_loss = 3.065, time/batch = 0.205\n",
            "1734/15750 (epoch 5), train_loss = 2.945, time/batch = 0.201\n",
            "1735/15750 (epoch 5), train_loss = 3.032, time/batch = 0.207\n",
            "1736/15750 (epoch 5), train_loss = 2.963, time/batch = 0.205\n",
            "1737/15750 (epoch 5), train_loss = 3.082, time/batch = 0.202\n",
            "1738/15750 (epoch 5), train_loss = 3.105, time/batch = 0.203\n",
            "1739/15750 (epoch 5), train_loss = 3.058, time/batch = 0.206\n",
            "1740/15750 (epoch 5), train_loss = 3.029, time/batch = 0.198\n",
            "1741/15750 (epoch 5), train_loss = 3.068, time/batch = 0.205\n",
            "1742/15750 (epoch 5), train_loss = 2.984, time/batch = 0.205\n",
            "1743/15750 (epoch 5), train_loss = 2.943, time/batch = 0.198\n",
            "1744/15750 (epoch 5), train_loss = 2.941, time/batch = 0.198\n",
            "1745/15750 (epoch 5), train_loss = 3.037, time/batch = 0.202\n",
            "1746/15750 (epoch 5), train_loss = 3.067, time/batch = 0.202\n",
            "1747/15750 (epoch 5), train_loss = 2.986, time/batch = 0.204\n",
            "1748/15750 (epoch 5), train_loss = 3.036, time/batch = 0.205\n",
            "1749/15750 (epoch 5), train_loss = 3.021, time/batch = 0.202\n",
            "1750/15750 (epoch 5), train_loss = 2.897, time/batch = 0.198\n",
            "1751/15750 (epoch 5), train_loss = 2.972, time/batch = 0.197\n",
            "1752/15750 (epoch 5), train_loss = 3.006, time/batch = 0.201\n",
            "1753/15750 (epoch 5), train_loss = 2.946, time/batch = 0.197\n",
            "1754/15750 (epoch 5), train_loss = 2.912, time/batch = 0.200\n",
            "1755/15750 (epoch 5), train_loss = 2.890, time/batch = 0.207\n",
            "1756/15750 (epoch 5), train_loss = 3.019, time/batch = 0.201\n",
            "1757/15750 (epoch 5), train_loss = 2.920, time/batch = 0.201\n",
            "1758/15750 (epoch 5), train_loss = 3.013, time/batch = 0.203\n",
            "1759/15750 (epoch 5), train_loss = 3.015, time/batch = 0.201\n",
            "1760/15750 (epoch 5), train_loss = 2.920, time/batch = 0.197\n",
            "1761/15750 (epoch 5), train_loss = 2.932, time/batch = 0.206\n",
            "1762/15750 (epoch 5), train_loss = 2.988, time/batch = 0.199\n",
            "1763/15750 (epoch 5), train_loss = 3.056, time/batch = 0.208\n",
            "1764/15750 (epoch 5), train_loss = 3.100, time/batch = 0.204\n",
            "1765/15750 (epoch 5), train_loss = 3.019, time/batch = 0.204\n",
            "1766/15750 (epoch 5), train_loss = 2.978, time/batch = 0.199\n",
            "1767/15750 (epoch 5), train_loss = 2.985, time/batch = 0.199\n",
            "1768/15750 (epoch 5), train_loss = 2.943, time/batch = 0.204\n",
            "1769/15750 (epoch 5), train_loss = 3.006, time/batch = 0.197\n",
            "1770/15750 (epoch 5), train_loss = 3.031, time/batch = 0.199\n",
            "1771/15750 (epoch 5), train_loss = 2.929, time/batch = 0.200\n",
            "1772/15750 (epoch 5), train_loss = 2.922, time/batch = 0.203\n",
            "1773/15750 (epoch 5), train_loss = 2.983, time/batch = 0.208\n",
            "1774/15750 (epoch 5), train_loss = 2.844, time/batch = 0.201\n",
            "1775/15750 (epoch 5), train_loss = 2.909, time/batch = 0.200\n",
            "1776/15750 (epoch 5), train_loss = 2.894, time/batch = 0.205\n",
            "1777/15750 (epoch 5), train_loss = 2.971, time/batch = 0.196\n",
            "1778/15750 (epoch 5), train_loss = 2.948, time/batch = 0.203\n",
            "1779/15750 (epoch 5), train_loss = 2.976, time/batch = 0.202\n",
            "1780/15750 (epoch 5), train_loss = 2.960, time/batch = 0.200\n",
            "1781/15750 (epoch 5), train_loss = 2.859, time/batch = 0.197\n",
            "1782/15750 (epoch 5), train_loss = 2.902, time/batch = 0.200\n",
            "1783/15750 (epoch 5), train_loss = 2.913, time/batch = 0.201\n",
            "1784/15750 (epoch 5), train_loss = 2.921, time/batch = 0.194\n",
            "1785/15750 (epoch 5), train_loss = 2.804, time/batch = 0.202\n",
            "1786/15750 (epoch 5), train_loss = 2.905, time/batch = 0.202\n",
            "1787/15750 (epoch 5), train_loss = 2.810, time/batch = 0.198\n",
            "1788/15750 (epoch 5), train_loss = 2.862, time/batch = 0.207\n",
            "1789/15750 (epoch 5), train_loss = 2.840, time/batch = 0.202\n",
            "1790/15750 (epoch 5), train_loss = 2.890, time/batch = 0.204\n",
            "1791/15750 (epoch 5), train_loss = 3.015, time/batch = 0.197\n",
            "1792/15750 (epoch 5), train_loss = 2.846, time/batch = 0.200\n",
            "1793/15750 (epoch 5), train_loss = 3.045, time/batch = 0.206\n",
            "1794/15750 (epoch 5), train_loss = 2.904, time/batch = 0.200\n",
            "1795/15750 (epoch 5), train_loss = 2.821, time/batch = 0.197\n",
            "1796/15750 (epoch 5), train_loss = 2.877, time/batch = 0.197\n",
            "1797/15750 (epoch 5), train_loss = 2.949, time/batch = 0.199\n",
            "1798/15750 (epoch 5), train_loss = 2.933, time/batch = 0.208\n",
            "1799/15750 (epoch 5), train_loss = 2.868, time/batch = 0.204\n",
            "1800/15750 (epoch 5), train_loss = 2.906, time/batch = 0.197\n",
            "1801/15750 (epoch 5), train_loss = 2.983, time/batch = 0.194\n",
            "1802/15750 (epoch 5), train_loss = 2.882, time/batch = 0.207\n",
            "1803/15750 (epoch 5), train_loss = 2.923, time/batch = 0.203\n",
            "1804/15750 (epoch 5), train_loss = 2.959, time/batch = 0.200\n",
            "1805/15750 (epoch 5), train_loss = 2.851, time/batch = 0.209\n",
            "1806/15750 (epoch 5), train_loss = 2.905, time/batch = 0.196\n",
            "1807/15750 (epoch 5), train_loss = 2.894, time/batch = 0.209\n",
            "1808/15750 (epoch 5), train_loss = 2.935, time/batch = 0.209\n",
            "1809/15750 (epoch 5), train_loss = 2.858, time/batch = 0.201\n",
            "1810/15750 (epoch 5), train_loss = 2.916, time/batch = 0.204\n",
            "1811/15750 (epoch 5), train_loss = 2.815, time/batch = 0.204\n",
            "1812/15750 (epoch 5), train_loss = 2.907, time/batch = 0.197\n",
            "1813/15750 (epoch 5), train_loss = 3.099, time/batch = 0.209\n",
            "1814/15750 (epoch 5), train_loss = 2.899, time/batch = 0.201\n",
            "1815/15750 (epoch 5), train_loss = 2.987, time/batch = 0.197\n",
            "1816/15750 (epoch 5), train_loss = 2.867, time/batch = 0.197\n",
            "1817/15750 (epoch 5), train_loss = 2.964, time/batch = 0.202\n",
            "1818/15750 (epoch 5), train_loss = 2.947, time/batch = 0.208\n",
            "1819/15750 (epoch 5), train_loss = 2.941, time/batch = 0.199\n",
            "1820/15750 (epoch 5), train_loss = 2.990, time/batch = 0.196\n",
            "1821/15750 (epoch 5), train_loss = 2.958, time/batch = 0.203\n",
            "1822/15750 (epoch 5), train_loss = 2.975, time/batch = 0.203\n",
            "1823/15750 (epoch 5), train_loss = 2.919, time/batch = 0.199\n",
            "1824/15750 (epoch 5), train_loss = 2.948, time/batch = 0.206\n",
            "1825/15750 (epoch 5), train_loss = 2.872, time/batch = 0.203\n",
            "1826/15750 (epoch 5), train_loss = 2.881, time/batch = 0.202\n",
            "1827/15750 (epoch 5), train_loss = 2.968, time/batch = 0.200\n",
            "1828/15750 (epoch 5), train_loss = 2.940, time/batch = 0.204\n",
            "1829/15750 (epoch 5), train_loss = 2.916, time/batch = 0.199\n",
            "1830/15750 (epoch 5), train_loss = 2.908, time/batch = 0.201\n",
            "1831/15750 (epoch 5), train_loss = 2.824, time/batch = 0.202\n",
            "1832/15750 (epoch 5), train_loss = 2.855, time/batch = 0.201\n",
            "1833/15750 (epoch 5), train_loss = 3.047, time/batch = 0.212\n",
            "1834/15750 (epoch 5), train_loss = 2.965, time/batch = 0.204\n",
            "1835/15750 (epoch 5), train_loss = 2.949, time/batch = 0.199\n",
            "1836/15750 (epoch 5), train_loss = 2.909, time/batch = 0.202\n",
            "1837/15750 (epoch 5), train_loss = 2.974, time/batch = 0.201\n",
            "1838/15750 (epoch 5), train_loss = 2.894, time/batch = 0.201\n",
            "1839/15750 (epoch 5), train_loss = 3.015, time/batch = 0.204\n",
            "1840/15750 (epoch 5), train_loss = 2.999, time/batch = 0.200\n",
            "1841/15750 (epoch 5), train_loss = 3.041, time/batch = 0.197\n",
            "1842/15750 (epoch 5), train_loss = 2.938, time/batch = 0.197\n",
            "1843/15750 (epoch 5), train_loss = 2.962, time/batch = 0.197\n",
            "1844/15750 (epoch 5), train_loss = 3.012, time/batch = 0.209\n",
            "1845/15750 (epoch 5), train_loss = 2.959, time/batch = 0.200\n",
            "1846/15750 (epoch 5), train_loss = 2.825, time/batch = 0.198\n",
            "1847/15750 (epoch 5), train_loss = 2.903, time/batch = 0.205\n",
            "1848/15750 (epoch 5), train_loss = 2.956, time/batch = 0.205\n",
            "1849/15750 (epoch 5), train_loss = 2.970, time/batch = 0.207\n",
            "1850/15750 (epoch 5), train_loss = 2.966, time/batch = 0.201\n",
            "1851/15750 (epoch 5), train_loss = 2.994, time/batch = 0.200\n",
            "1852/15750 (epoch 5), train_loss = 2.902, time/batch = 0.203\n",
            "1853/15750 (epoch 5), train_loss = 2.888, time/batch = 0.201\n",
            "1854/15750 (epoch 5), train_loss = 2.854, time/batch = 0.204\n",
            "1855/15750 (epoch 5), train_loss = 3.111, time/batch = 0.195\n",
            "1856/15750 (epoch 5), train_loss = 2.890, time/batch = 0.201\n",
            "1857/15750 (epoch 5), train_loss = 2.874, time/batch = 0.200\n",
            "1858/15750 (epoch 5), train_loss = 3.003, time/batch = 0.202\n",
            "1859/15750 (epoch 5), train_loss = 2.860, time/batch = 0.204\n",
            "1860/15750 (epoch 5), train_loss = 3.030, time/batch = 0.200\n",
            "1861/15750 (epoch 5), train_loss = 2.884, time/batch = 0.199\n",
            "1862/15750 (epoch 5), train_loss = 2.925, time/batch = 0.200\n",
            "1863/15750 (epoch 5), train_loss = 2.838, time/batch = 0.200\n",
            "1864/15750 (epoch 5), train_loss = 2.912, time/batch = 0.204\n",
            "1865/15750 (epoch 5), train_loss = 2.810, time/batch = 0.202\n",
            "1866/15750 (epoch 5), train_loss = 2.947, time/batch = 0.200\n",
            "1867/15750 (epoch 5), train_loss = 2.913, time/batch = 0.199\n",
            "1868/15750 (epoch 5), train_loss = 2.888, time/batch = 0.204\n",
            "1869/15750 (epoch 5), train_loss = 2.971, time/batch = 0.205\n",
            "1870/15750 (epoch 5), train_loss = 3.020, time/batch = 0.199\n",
            "1871/15750 (epoch 5), train_loss = 2.974, time/batch = 0.199\n",
            "1872/15750 (epoch 5), train_loss = 3.013, time/batch = 0.201\n",
            "1873/15750 (epoch 5), train_loss = 2.859, time/batch = 0.202\n",
            "1874/15750 (epoch 5), train_loss = 2.978, time/batch = 0.207\n",
            "1875/15750 (epoch 5), train_loss = 2.923, time/batch = 0.200\n",
            "1876/15750 (epoch 5), train_loss = 2.838, time/batch = 0.198\n",
            "1877/15750 (epoch 5), train_loss = 2.960, time/batch = 0.202\n",
            "1878/15750 (epoch 5), train_loss = 2.827, time/batch = 0.200\n",
            "1879/15750 (epoch 5), train_loss = 2.961, time/batch = 0.211\n",
            "1880/15750 (epoch 5), train_loss = 2.957, time/batch = 0.200\n",
            "1881/15750 (epoch 5), train_loss = 2.913, time/batch = 0.201\n",
            "1882/15750 (epoch 5), train_loss = 2.846, time/batch = 0.200\n",
            "1883/15750 (epoch 5), train_loss = 2.838, time/batch = 0.199\n",
            "1884/15750 (epoch 5), train_loss = 3.012, time/batch = 0.201\n",
            "1885/15750 (epoch 5), train_loss = 2.836, time/batch = 0.201\n",
            "1886/15750 (epoch 5), train_loss = 2.760, time/batch = 0.204\n",
            "1887/15750 (epoch 5), train_loss = 2.875, time/batch = 0.201\n",
            "1888/15750 (epoch 5), train_loss = 2.879, time/batch = 0.197\n",
            "1889/15750 (epoch 5), train_loss = 2.962, time/batch = 0.203\n",
            "1890/15750 (epoch 6), train_loss = 3.048, time/batch = 0.206\n",
            "1891/15750 (epoch 6), train_loss = 2.985, time/batch = 0.201\n",
            "1892/15750 (epoch 6), train_loss = 2.924, time/batch = 0.205\n",
            "1893/15750 (epoch 6), train_loss = 3.028, time/batch = 0.207\n",
            "1894/15750 (epoch 6), train_loss = 2.925, time/batch = 0.196\n",
            "1895/15750 (epoch 6), train_loss = 2.900, time/batch = 0.196\n",
            "1896/15750 (epoch 6), train_loss = 3.050, time/batch = 0.205\n",
            "1897/15750 (epoch 6), train_loss = 2.987, time/batch = 0.202\n",
            "1898/15750 (epoch 6), train_loss = 2.975, time/batch = 0.203\n",
            "1899/15750 (epoch 6), train_loss = 2.949, time/batch = 0.201\n",
            "1900/15750 (epoch 6), train_loss = 2.888, time/batch = 0.200\n",
            "1901/15750 (epoch 6), train_loss = 2.848, time/batch = 0.206\n",
            "1902/15750 (epoch 6), train_loss = 3.002, time/batch = 0.197\n",
            "1903/15750 (epoch 6), train_loss = 2.903, time/batch = 0.197\n",
            "1904/15750 (epoch 6), train_loss = 2.935, time/batch = 0.209\n",
            "1905/15750 (epoch 6), train_loss = 2.907, time/batch = 0.207\n",
            "1906/15750 (epoch 6), train_loss = 2.978, time/batch = 0.199\n",
            "1907/15750 (epoch 6), train_loss = 3.010, time/batch = 0.198\n",
            "1908/15750 (epoch 6), train_loss = 3.006, time/batch = 0.200\n",
            "1909/15750 (epoch 6), train_loss = 2.958, time/batch = 0.210\n",
            "1910/15750 (epoch 6), train_loss = 2.983, time/batch = 0.198\n",
            "1911/15750 (epoch 6), train_loss = 2.951, time/batch = 0.209\n",
            "1912/15750 (epoch 6), train_loss = 2.914, time/batch = 0.199\n",
            "1913/15750 (epoch 6), train_loss = 2.957, time/batch = 0.207\n",
            "1914/15750 (epoch 6), train_loss = 2.946, time/batch = 0.211\n",
            "1915/15750 (epoch 6), train_loss = 3.012, time/batch = 0.199\n",
            "1916/15750 (epoch 6), train_loss = 2.956, time/batch = 0.199\n",
            "1917/15750 (epoch 6), train_loss = 2.967, time/batch = 0.199\n",
            "1918/15750 (epoch 6), train_loss = 3.117, time/batch = 0.202\n",
            "1919/15750 (epoch 6), train_loss = 2.998, time/batch = 0.203\n",
            "1920/15750 (epoch 6), train_loss = 2.954, time/batch = 0.206\n",
            "1921/15750 (epoch 6), train_loss = 2.942, time/batch = 0.201\n",
            "1922/15750 (epoch 6), train_loss = 2.874, time/batch = 0.201\n",
            "1923/15750 (epoch 6), train_loss = 2.879, time/batch = 0.201\n",
            "1924/15750 (epoch 6), train_loss = 2.920, time/batch = 0.207\n",
            "1925/15750 (epoch 6), train_loss = 2.872, time/batch = 0.203\n",
            "1926/15750 (epoch 6), train_loss = 2.846, time/batch = 0.200\n",
            "1927/15750 (epoch 6), train_loss = 2.938, time/batch = 0.198\n",
            "1928/15750 (epoch 6), train_loss = 2.872, time/batch = 0.200\n",
            "1929/15750 (epoch 6), train_loss = 2.925, time/batch = 0.204\n",
            "1930/15750 (epoch 6), train_loss = 2.910, time/batch = 0.198\n",
            "1931/15750 (epoch 6), train_loss = 2.970, time/batch = 0.198\n",
            "1932/15750 (epoch 6), train_loss = 2.954, time/batch = 0.203\n",
            "1933/15750 (epoch 6), train_loss = 2.865, time/batch = 0.201\n",
            "1934/15750 (epoch 6), train_loss = 2.934, time/batch = 0.208\n",
            "1935/15750 (epoch 6), train_loss = 2.833, time/batch = 0.200\n",
            "1936/15750 (epoch 6), train_loss = 2.861, time/batch = 0.201\n",
            "1937/15750 (epoch 6), train_loss = 2.933, time/batch = 0.200\n",
            "1938/15750 (epoch 6), train_loss = 2.940, time/batch = 0.203\n",
            "1939/15750 (epoch 6), train_loss = 2.876, time/batch = 0.207\n",
            "1940/15750 (epoch 6), train_loss = 2.878, time/batch = 0.201\n",
            "1941/15750 (epoch 6), train_loss = 2.886, time/batch = 0.197\n",
            "1942/15750 (epoch 6), train_loss = 2.943, time/batch = 0.201\n",
            "1943/15750 (epoch 6), train_loss = 2.934, time/batch = 0.204\n",
            "1944/15750 (epoch 6), train_loss = 2.920, time/batch = 0.205\n",
            "1945/15750 (epoch 6), train_loss = 2.954, time/batch = 0.198\n",
            "1946/15750 (epoch 6), train_loss = 2.834, time/batch = 0.199\n",
            "1947/15750 (epoch 6), train_loss = 2.846, time/batch = 0.204\n",
            "1948/15750 (epoch 6), train_loss = 2.906, time/batch = 0.201\n",
            "1949/15750 (epoch 6), train_loss = 2.757, time/batch = 0.206\n",
            "1950/15750 (epoch 6), train_loss = 2.874, time/batch = 0.203\n",
            "1951/15750 (epoch 6), train_loss = 2.858, time/batch = 0.201\n",
            "1952/15750 (epoch 6), train_loss = 2.802, time/batch = 0.195\n",
            "1953/15750 (epoch 6), train_loss = 2.830, time/batch = 0.198\n",
            "1954/15750 (epoch 6), train_loss = 2.831, time/batch = 0.220\n",
            "1955/15750 (epoch 6), train_loss = 2.811, time/batch = 0.197\n",
            "1956/15750 (epoch 6), train_loss = 2.762, time/batch = 0.199\n",
            "1957/15750 (epoch 6), train_loss = 2.774, time/batch = 0.206\n",
            "1958/15750 (epoch 6), train_loss = 2.824, time/batch = 0.202\n",
            "1959/15750 (epoch 6), train_loss = 2.905, time/batch = 0.206\n",
            "1960/15750 (epoch 6), train_loss = 2.828, time/batch = 0.198\n",
            "1961/15750 (epoch 6), train_loss = 2.856, time/batch = 0.203\n",
            "1962/15750 (epoch 6), train_loss = 2.686, time/batch = 0.201\n",
            "1963/15750 (epoch 6), train_loss = 2.836, time/batch = 0.200\n",
            "1964/15750 (epoch 6), train_loss = 2.924, time/batch = 0.204\n",
            "1965/15750 (epoch 6), train_loss = 2.865, time/batch = 0.196\n",
            "1966/15750 (epoch 6), train_loss = 2.871, time/batch = 0.201\n",
            "1967/15750 (epoch 6), train_loss = 2.837, time/batch = 0.201\n",
            "1968/15750 (epoch 6), train_loss = 2.877, time/batch = 0.202\n",
            "1969/15750 (epoch 6), train_loss = 2.891, time/batch = 0.206\n",
            "1970/15750 (epoch 6), train_loss = 2.780, time/batch = 0.198\n",
            "1971/15750 (epoch 6), train_loss = 2.889, time/batch = 0.200\n",
            "1972/15750 (epoch 6), train_loss = 2.801, time/batch = 0.202\n",
            "1973/15750 (epoch 6), train_loss = 2.879, time/batch = 0.200\n",
            "1974/15750 (epoch 6), train_loss = 2.944, time/batch = 0.207\n",
            "1975/15750 (epoch 6), train_loss = 2.948, time/batch = 0.201\n",
            "1976/15750 (epoch 6), train_loss = 2.785, time/batch = 0.205\n",
            "1977/15750 (epoch 6), train_loss = 2.873, time/batch = 0.201\n",
            "1978/15750 (epoch 6), train_loss = 2.884, time/batch = 0.201\n",
            "1979/15750 (epoch 6), train_loss = 2.805, time/batch = 0.210\n",
            "1980/15750 (epoch 6), train_loss = 2.872, time/batch = 0.202\n",
            "1981/15750 (epoch 6), train_loss = 2.926, time/batch = 0.197\n",
            "1982/15750 (epoch 6), train_loss = 2.934, time/batch = 0.202\n",
            "1983/15750 (epoch 6), train_loss = 2.921, time/batch = 0.202\n",
            "1984/15750 (epoch 6), train_loss = 2.943, time/batch = 0.206\n",
            "1985/15750 (epoch 6), train_loss = 2.852, time/batch = 0.198\n",
            "1986/15750 (epoch 6), train_loss = 2.859, time/batch = 0.203\n",
            "1987/15750 (epoch 6), train_loss = 2.860, time/batch = 0.201\n",
            "1988/15750 (epoch 6), train_loss = 2.912, time/batch = 0.199\n",
            "1989/15750 (epoch 6), train_loss = 2.860, time/batch = 0.206\n",
            "1990/15750 (epoch 6), train_loss = 2.850, time/batch = 0.198\n",
            "1991/15750 (epoch 6), train_loss = 2.788, time/batch = 0.201\n",
            "1992/15750 (epoch 6), train_loss = 2.805, time/batch = 0.201\n",
            "1993/15750 (epoch 6), train_loss = 2.954, time/batch = 0.205\n",
            "1994/15750 (epoch 6), train_loss = 2.890, time/batch = 0.202\n",
            "1995/15750 (epoch 6), train_loss = 2.817, time/batch = 0.204\n",
            "1996/15750 (epoch 6), train_loss = 2.890, time/batch = 0.202\n",
            "1997/15750 (epoch 6), train_loss = 2.854, time/batch = 0.205\n",
            "1998/15750 (epoch 6), train_loss = 2.958, time/batch = 0.203\n",
            "1999/15750 (epoch 6), train_loss = 2.942, time/batch = 0.199\n",
            "2000/15750 (epoch 6), train_loss = 2.974, time/batch = 0.214\n",
            "model saved to ./save_star/model.ckpt\n",
            "2001/15750 (epoch 6), train_loss = 2.876, time/batch = 0.201\n",
            "2002/15750 (epoch 6), train_loss = 2.863, time/batch = 0.204\n",
            "2003/15750 (epoch 6), train_loss = 2.880, time/batch = 0.207\n",
            "2004/15750 (epoch 6), train_loss = 2.870, time/batch = 0.205\n",
            "2005/15750 (epoch 6), train_loss = 2.943, time/batch = 0.202\n",
            "2006/15750 (epoch 6), train_loss = 2.875, time/batch = 0.203\n",
            "2007/15750 (epoch 6), train_loss = 3.020, time/batch = 0.207\n",
            "2008/15750 (epoch 6), train_loss = 2.867, time/batch = 0.206\n",
            "2009/15750 (epoch 6), train_loss = 2.835, time/batch = 0.204\n",
            "2010/15750 (epoch 6), train_loss = 2.823, time/batch = 0.208\n",
            "2011/15750 (epoch 6), train_loss = 2.812, time/batch = 0.202\n",
            "2012/15750 (epoch 6), train_loss = 2.843, time/batch = 0.203\n",
            "2013/15750 (epoch 6), train_loss = 2.832, time/batch = 0.210\n",
            "2014/15750 (epoch 6), train_loss = 2.839, time/batch = 0.205\n",
            "2015/15750 (epoch 6), train_loss = 2.875, time/batch = 0.204\n",
            "2016/15750 (epoch 6), train_loss = 2.971, time/batch = 0.204\n",
            "2017/15750 (epoch 6), train_loss = 2.798, time/batch = 0.203\n",
            "2018/15750 (epoch 6), train_loss = 2.768, time/batch = 0.208\n",
            "2019/15750 (epoch 6), train_loss = 2.819, time/batch = 0.202\n",
            "2020/15750 (epoch 6), train_loss = 2.760, time/batch = 0.208\n",
            "2021/15750 (epoch 6), train_loss = 2.778, time/batch = 0.205\n",
            "2022/15750 (epoch 6), train_loss = 2.818, time/batch = 0.206\n",
            "2023/15750 (epoch 6), train_loss = 2.768, time/batch = 0.207\n",
            "2024/15750 (epoch 6), train_loss = 2.852, time/batch = 0.211\n",
            "2025/15750 (epoch 6), train_loss = 2.911, time/batch = 0.203\n",
            "2026/15750 (epoch 6), train_loss = 2.897, time/batch = 0.202\n",
            "2027/15750 (epoch 6), train_loss = 2.929, time/batch = 0.202\n",
            "2028/15750 (epoch 6), train_loss = 2.897, time/batch = 0.207\n",
            "2029/15750 (epoch 6), train_loss = 2.835, time/batch = 0.199\n",
            "2030/15750 (epoch 6), train_loss = 2.827, time/batch = 0.197\n",
            "2031/15750 (epoch 6), train_loss = 2.911, time/batch = 0.202\n",
            "2032/15750 (epoch 6), train_loss = 2.925, time/batch = 0.208\n",
            "2033/15750 (epoch 6), train_loss = 2.894, time/batch = 0.205\n",
            "2034/15750 (epoch 6), train_loss = 2.846, time/batch = 0.198\n",
            "2035/15750 (epoch 6), train_loss = 2.832, time/batch = 0.197\n",
            "2036/15750 (epoch 6), train_loss = 2.775, time/batch = 0.199\n",
            "2037/15750 (epoch 6), train_loss = 2.853, time/batch = 0.198\n",
            "2038/15750 (epoch 6), train_loss = 2.889, time/batch = 0.210\n",
            "2039/15750 (epoch 6), train_loss = 2.824, time/batch = 0.201\n",
            "2040/15750 (epoch 6), train_loss = 2.839, time/batch = 0.201\n",
            "2041/15750 (epoch 6), train_loss = 2.857, time/batch = 0.200\n",
            "2042/15750 (epoch 6), train_loss = 2.954, time/batch = 0.202\n",
            "2043/15750 (epoch 6), train_loss = 2.898, time/batch = 0.208\n",
            "2044/15750 (epoch 6), train_loss = 2.856, time/batch = 0.202\n",
            "2045/15750 (epoch 6), train_loss = 2.904, time/batch = 0.202\n",
            "2046/15750 (epoch 6), train_loss = 2.920, time/batch = 0.201\n",
            "2047/15750 (epoch 6), train_loss = 2.889, time/batch = 0.201\n",
            "2048/15750 (epoch 6), train_loss = 2.963, time/batch = 0.210\n",
            "2049/15750 (epoch 6), train_loss = 2.829, time/batch = 0.202\n",
            "2050/15750 (epoch 6), train_loss = 2.925, time/batch = 0.195\n",
            "2051/15750 (epoch 6), train_loss = 2.861, time/batch = 0.201\n",
            "2052/15750 (epoch 6), train_loss = 2.969, time/batch = 0.201\n",
            "2053/15750 (epoch 6), train_loss = 3.000, time/batch = 0.204\n",
            "2054/15750 (epoch 6), train_loss = 2.942, time/batch = 0.203\n",
            "2055/15750 (epoch 6), train_loss = 2.923, time/batch = 0.196\n",
            "2056/15750 (epoch 6), train_loss = 2.957, time/batch = 0.200\n",
            "2057/15750 (epoch 6), train_loss = 2.877, time/batch = 0.202\n",
            "2058/15750 (epoch 6), train_loss = 2.838, time/batch = 0.207\n",
            "2059/15750 (epoch 6), train_loss = 2.827, time/batch = 0.202\n",
            "2060/15750 (epoch 6), train_loss = 2.923, time/batch = 0.199\n",
            "2061/15750 (epoch 6), train_loss = 2.954, time/batch = 0.203\n",
            "2062/15750 (epoch 6), train_loss = 2.879, time/batch = 0.199\n",
            "2063/15750 (epoch 6), train_loss = 2.925, time/batch = 0.204\n",
            "2064/15750 (epoch 6), train_loss = 2.914, time/batch = 0.205\n",
            "2065/15750 (epoch 6), train_loss = 2.794, time/batch = 0.204\n",
            "2066/15750 (epoch 6), train_loss = 2.855, time/batch = 0.207\n",
            "2067/15750 (epoch 6), train_loss = 2.900, time/batch = 0.196\n",
            "2068/15750 (epoch 6), train_loss = 2.834, time/batch = 0.207\n",
            "2069/15750 (epoch 6), train_loss = 2.800, time/batch = 0.200\n",
            "2070/15750 (epoch 6), train_loss = 2.788, time/batch = 0.203\n",
            "2071/15750 (epoch 6), train_loss = 2.918, time/batch = 0.199\n",
            "2072/15750 (epoch 6), train_loss = 2.820, time/batch = 0.201\n",
            "2073/15750 (epoch 6), train_loss = 2.912, time/batch = 0.207\n",
            "2074/15750 (epoch 6), train_loss = 2.913, time/batch = 0.203\n",
            "2075/15750 (epoch 6), train_loss = 2.820, time/batch = 0.195\n",
            "2076/15750 (epoch 6), train_loss = 2.822, time/batch = 0.200\n",
            "2077/15750 (epoch 6), train_loss = 2.887, time/batch = 0.203\n",
            "2078/15750 (epoch 6), train_loss = 2.953, time/batch = 0.209\n",
            "2079/15750 (epoch 6), train_loss = 2.998, time/batch = 0.198\n",
            "2080/15750 (epoch 6), train_loss = 2.917, time/batch = 0.198\n",
            "2081/15750 (epoch 6), train_loss = 2.871, time/batch = 0.204\n",
            "2082/15750 (epoch 6), train_loss = 2.885, time/batch = 0.200\n",
            "2083/15750 (epoch 6), train_loss = 2.833, time/batch = 0.201\n",
            "2084/15750 (epoch 6), train_loss = 2.908, time/batch = 0.203\n",
            "2085/15750 (epoch 6), train_loss = 2.936, time/batch = 0.203\n",
            "2086/15750 (epoch 6), train_loss = 2.834, time/batch = 0.202\n",
            "2087/15750 (epoch 6), train_loss = 2.822, time/batch = 0.196\n",
            "2088/15750 (epoch 6), train_loss = 2.893, time/batch = 0.204\n",
            "2089/15750 (epoch 6), train_loss = 2.734, time/batch = 0.204\n",
            "2090/15750 (epoch 6), train_loss = 2.807, time/batch = 0.198\n",
            "2091/15750 (epoch 6), train_loss = 2.786, time/batch = 0.202\n",
            "2092/15750 (epoch 6), train_loss = 2.861, time/batch = 0.202\n",
            "2093/15750 (epoch 6), train_loss = 2.848, time/batch = 0.203\n",
            "2094/15750 (epoch 6), train_loss = 2.877, time/batch = 0.215\n",
            "2095/15750 (epoch 6), train_loss = 2.855, time/batch = 0.199\n",
            "2096/15750 (epoch 6), train_loss = 2.750, time/batch = 0.205\n",
            "2097/15750 (epoch 6), train_loss = 2.798, time/batch = 0.202\n",
            "2098/15750 (epoch 6), train_loss = 2.811, time/batch = 0.208\n",
            "2099/15750 (epoch 6), train_loss = 2.819, time/batch = 0.211\n",
            "2100/15750 (epoch 6), train_loss = 2.700, time/batch = 0.209\n",
            "2101/15750 (epoch 6), train_loss = 2.807, time/batch = 0.203\n",
            "2102/15750 (epoch 6), train_loss = 2.707, time/batch = 0.199\n",
            "2103/15750 (epoch 6), train_loss = 2.759, time/batch = 0.206\n",
            "2104/15750 (epoch 6), train_loss = 2.745, time/batch = 0.214\n",
            "2105/15750 (epoch 6), train_loss = 2.787, time/batch = 0.202\n",
            "2106/15750 (epoch 6), train_loss = 2.920, time/batch = 0.204\n",
            "2107/15750 (epoch 6), train_loss = 2.741, time/batch = 0.200\n",
            "2108/15750 (epoch 6), train_loss = 2.950, time/batch = 0.203\n",
            "2109/15750 (epoch 6), train_loss = 2.801, time/batch = 0.214\n",
            "2110/15750 (epoch 6), train_loss = 2.724, time/batch = 0.201\n",
            "2111/15750 (epoch 6), train_loss = 2.776, time/batch = 0.198\n",
            "2112/15750 (epoch 6), train_loss = 2.854, time/batch = 0.201\n",
            "2113/15750 (epoch 6), train_loss = 2.836, time/batch = 0.207\n",
            "2114/15750 (epoch 6), train_loss = 2.775, time/batch = 0.210\n",
            "2115/15750 (epoch 6), train_loss = 2.800, time/batch = 0.209\n",
            "2116/15750 (epoch 6), train_loss = 2.888, time/batch = 0.205\n",
            "2117/15750 (epoch 6), train_loss = 2.790, time/batch = 0.201\n",
            "2118/15750 (epoch 6), train_loss = 2.823, time/batch = 0.200\n",
            "2119/15750 (epoch 6), train_loss = 2.875, time/batch = 0.210\n",
            "2120/15750 (epoch 6), train_loss = 2.756, time/batch = 0.201\n",
            "2121/15750 (epoch 6), train_loss = 2.796, time/batch = 0.201\n",
            "2122/15750 (epoch 6), train_loss = 2.810, time/batch = 0.200\n",
            "2123/15750 (epoch 6), train_loss = 2.842, time/batch = 0.200\n",
            "2124/15750 (epoch 6), train_loss = 2.760, time/batch = 0.207\n",
            "2125/15750 (epoch 6), train_loss = 2.802, time/batch = 0.199\n",
            "2126/15750 (epoch 6), train_loss = 2.714, time/batch = 0.201\n",
            "2127/15750 (epoch 6), train_loss = 2.806, time/batch = 0.198\n",
            "2128/15750 (epoch 6), train_loss = 3.002, time/batch = 0.201\n",
            "2129/15750 (epoch 6), train_loss = 2.800, time/batch = 0.204\n",
            "2130/15750 (epoch 6), train_loss = 2.882, time/batch = 0.202\n",
            "2131/15750 (epoch 6), train_loss = 2.765, time/batch = 0.198\n",
            "2132/15750 (epoch 6), train_loss = 2.861, time/batch = 0.195\n",
            "2133/15750 (epoch 6), train_loss = 2.851, time/batch = 0.210\n",
            "2134/15750 (epoch 6), train_loss = 2.835, time/batch = 0.202\n",
            "2135/15750 (epoch 6), train_loss = 2.889, time/batch = 0.198\n",
            "2136/15750 (epoch 6), train_loss = 2.852, time/batch = 0.202\n",
            "2137/15750 (epoch 6), train_loss = 2.874, time/batch = 0.201\n",
            "2138/15750 (epoch 6), train_loss = 2.826, time/batch = 0.200\n",
            "2139/15750 (epoch 6), train_loss = 2.850, time/batch = 0.206\n",
            "2140/15750 (epoch 6), train_loss = 2.769, time/batch = 0.205\n",
            "2141/15750 (epoch 6), train_loss = 2.782, time/batch = 0.203\n",
            "2142/15750 (epoch 6), train_loss = 2.865, time/batch = 0.201\n",
            "2143/15750 (epoch 6), train_loss = 2.847, time/batch = 0.199\n",
            "2144/15750 (epoch 6), train_loss = 2.818, time/batch = 0.205\n",
            "2145/15750 (epoch 6), train_loss = 2.802, time/batch = 0.203\n",
            "2146/15750 (epoch 6), train_loss = 2.732, time/batch = 0.205\n",
            "2147/15750 (epoch 6), train_loss = 2.758, time/batch = 0.201\n",
            "2148/15750 (epoch 6), train_loss = 2.948, time/batch = 0.202\n",
            "2149/15750 (epoch 6), train_loss = 2.868, time/batch = 0.208\n",
            "2150/15750 (epoch 6), train_loss = 2.855, time/batch = 0.200\n",
            "2151/15750 (epoch 6), train_loss = 2.808, time/batch = 0.200\n",
            "2152/15750 (epoch 6), train_loss = 2.867, time/batch = 0.199\n",
            "2153/15750 (epoch 6), train_loss = 2.807, time/batch = 0.208\n",
            "2154/15750 (epoch 6), train_loss = 2.911, time/batch = 0.204\n",
            "2155/15750 (epoch 6), train_loss = 2.898, time/batch = 0.201\n",
            "2156/15750 (epoch 6), train_loss = 2.942, time/batch = 0.202\n",
            "2157/15750 (epoch 6), train_loss = 2.836, time/batch = 0.206\n",
            "2158/15750 (epoch 6), train_loss = 2.868, time/batch = 0.204\n",
            "2159/15750 (epoch 6), train_loss = 2.914, time/batch = 0.204\n",
            "2160/15750 (epoch 6), train_loss = 2.864, time/batch = 0.205\n",
            "2161/15750 (epoch 6), train_loss = 2.730, time/batch = 0.205\n",
            "2162/15750 (epoch 6), train_loss = 2.811, time/batch = 0.204\n",
            "2163/15750 (epoch 6), train_loss = 2.861, time/batch = 0.203\n",
            "2164/15750 (epoch 6), train_loss = 2.882, time/batch = 0.205\n",
            "2165/15750 (epoch 6), train_loss = 2.876, time/batch = 0.203\n",
            "2166/15750 (epoch 6), train_loss = 2.897, time/batch = 0.203\n",
            "2167/15750 (epoch 6), train_loss = 2.815, time/batch = 0.204\n",
            "2168/15750 (epoch 6), train_loss = 2.787, time/batch = 0.206\n",
            "2169/15750 (epoch 6), train_loss = 2.755, time/batch = 0.205\n",
            "2170/15750 (epoch 6), train_loss = 3.016, time/batch = 0.210\n",
            "2171/15750 (epoch 6), train_loss = 2.794, time/batch = 0.203\n",
            "2172/15750 (epoch 6), train_loss = 2.775, time/batch = 0.206\n",
            "2173/15750 (epoch 6), train_loss = 2.913, time/batch = 0.205\n",
            "2174/15750 (epoch 6), train_loss = 2.761, time/batch = 0.211\n",
            "2175/15750 (epoch 6), train_loss = 2.936, time/batch = 0.203\n",
            "2176/15750 (epoch 6), train_loss = 2.790, time/batch = 0.207\n",
            "2177/15750 (epoch 6), train_loss = 2.829, time/batch = 0.204\n",
            "2178/15750 (epoch 6), train_loss = 2.742, time/batch = 0.208\n",
            "2179/15750 (epoch 6), train_loss = 2.821, time/batch = 0.214\n",
            "2180/15750 (epoch 6), train_loss = 2.716, time/batch = 0.207\n",
            "2181/15750 (epoch 6), train_loss = 2.851, time/batch = 0.204\n",
            "2182/15750 (epoch 6), train_loss = 2.817, time/batch = 0.201\n",
            "2183/15750 (epoch 6), train_loss = 2.800, time/batch = 0.203\n",
            "2184/15750 (epoch 6), train_loss = 2.874, time/batch = 0.208\n",
            "2185/15750 (epoch 6), train_loss = 2.928, time/batch = 0.201\n",
            "2186/15750 (epoch 6), train_loss = 2.881, time/batch = 0.201\n",
            "2187/15750 (epoch 6), train_loss = 2.918, time/batch = 0.202\n",
            "2188/15750 (epoch 6), train_loss = 2.766, time/batch = 0.201\n",
            "2189/15750 (epoch 6), train_loss = 2.880, time/batch = 0.209\n",
            "2190/15750 (epoch 6), train_loss = 2.826, time/batch = 0.198\n",
            "2191/15750 (epoch 6), train_loss = 2.743, time/batch = 0.203\n",
            "2192/15750 (epoch 6), train_loss = 2.865, time/batch = 0.195\n",
            "2193/15750 (epoch 6), train_loss = 2.733, time/batch = 0.201\n",
            "2194/15750 (epoch 6), train_loss = 2.867, time/batch = 0.211\n",
            "2195/15750 (epoch 6), train_loss = 2.854, time/batch = 0.201\n",
            "2196/15750 (epoch 6), train_loss = 2.819, time/batch = 0.204\n",
            "2197/15750 (epoch 6), train_loss = 2.748, time/batch = 0.204\n",
            "2198/15750 (epoch 6), train_loss = 2.749, time/batch = 0.194\n",
            "2199/15750 (epoch 6), train_loss = 2.913, time/batch = 0.209\n",
            "2200/15750 (epoch 6), train_loss = 2.740, time/batch = 0.202\n",
            "2201/15750 (epoch 6), train_loss = 2.675, time/batch = 0.204\n",
            "2202/15750 (epoch 6), train_loss = 2.780, time/batch = 0.203\n",
            "2203/15750 (epoch 6), train_loss = 2.776, time/batch = 0.201\n",
            "2204/15750 (epoch 6), train_loss = 2.864, time/batch = 0.207\n",
            "2205/15750 (epoch 7), train_loss = 2.942, time/batch = 0.205\n",
            "2206/15750 (epoch 7), train_loss = 2.890, time/batch = 0.203\n",
            "2207/15750 (epoch 7), train_loss = 2.829, time/batch = 0.207\n",
            "2208/15750 (epoch 7), train_loss = 2.933, time/batch = 0.208\n",
            "2209/15750 (epoch 7), train_loss = 2.829, time/batch = 0.204\n",
            "2210/15750 (epoch 7), train_loss = 2.811, time/batch = 0.196\n",
            "2211/15750 (epoch 7), train_loss = 2.968, time/batch = 0.204\n",
            "2212/15750 (epoch 7), train_loss = 2.898, time/batch = 0.201\n",
            "2213/15750 (epoch 7), train_loss = 2.882, time/batch = 0.206\n",
            "2214/15750 (epoch 7), train_loss = 2.856, time/batch = 0.206\n",
            "2215/15750 (epoch 7), train_loss = 2.797, time/batch = 0.205\n",
            "2216/15750 (epoch 7), train_loss = 2.757, time/batch = 0.203\n",
            "2217/15750 (epoch 7), train_loss = 2.913, time/batch = 0.208\n",
            "2218/15750 (epoch 7), train_loss = 2.816, time/batch = 0.204\n",
            "2219/15750 (epoch 7), train_loss = 2.842, time/batch = 0.201\n",
            "2220/15750 (epoch 7), train_loss = 2.821, time/batch = 0.206\n",
            "2221/15750 (epoch 7), train_loss = 2.882, time/batch = 0.203\n",
            "2222/15750 (epoch 7), train_loss = 2.926, time/batch = 0.194\n",
            "2223/15750 (epoch 7), train_loss = 2.918, time/batch = 0.209\n",
            "2224/15750 (epoch 7), train_loss = 2.867, time/batch = 0.201\n",
            "2225/15750 (epoch 7), train_loss = 2.889, time/batch = 0.203\n",
            "2226/15750 (epoch 7), train_loss = 2.864, time/batch = 0.202\n",
            "2227/15750 (epoch 7), train_loss = 2.831, time/batch = 0.204\n",
            "2228/15750 (epoch 7), train_loss = 2.869, time/batch = 0.209\n",
            "2229/15750 (epoch 7), train_loss = 2.856, time/batch = 0.203\n",
            "2230/15750 (epoch 7), train_loss = 2.917, time/batch = 0.201\n",
            "2231/15750 (epoch 7), train_loss = 2.871, time/batch = 0.200\n",
            "2232/15750 (epoch 7), train_loss = 2.881, time/batch = 0.201\n",
            "2233/15750 (epoch 7), train_loss = 3.032, time/batch = 0.204\n",
            "2234/15750 (epoch 7), train_loss = 2.913, time/batch = 0.196\n",
            "2235/15750 (epoch 7), train_loss = 2.869, time/batch = 0.201\n",
            "2236/15750 (epoch 7), train_loss = 2.852, time/batch = 0.202\n",
            "2237/15750 (epoch 7), train_loss = 2.779, time/batch = 0.205\n",
            "2238/15750 (epoch 7), train_loss = 2.794, time/batch = 0.202\n",
            "2239/15750 (epoch 7), train_loss = 2.841, time/batch = 0.198\n",
            "2240/15750 (epoch 7), train_loss = 2.783, time/batch = 0.205\n",
            "2241/15750 (epoch 7), train_loss = 2.768, time/batch = 0.206\n",
            "2242/15750 (epoch 7), train_loss = 2.857, time/batch = 0.202\n",
            "2243/15750 (epoch 7), train_loss = 2.778, time/batch = 0.202\n",
            "2244/15750 (epoch 7), train_loss = 2.838, time/batch = 0.205\n",
            "2245/15750 (epoch 7), train_loss = 2.820, time/batch = 0.200\n",
            "2246/15750 (epoch 7), train_loss = 2.876, time/batch = 0.200\n",
            "2247/15750 (epoch 7), train_loss = 2.866, time/batch = 0.205\n",
            "2248/15750 (epoch 7), train_loss = 2.779, time/batch = 0.209\n",
            "2249/15750 (epoch 7), train_loss = 2.845, time/batch = 0.206\n",
            "2250/15750 (epoch 7), train_loss = 2.747, time/batch = 0.195\n",
            "2251/15750 (epoch 7), train_loss = 2.777, time/batch = 0.205\n",
            "2252/15750 (epoch 7), train_loss = 2.848, time/batch = 0.202\n",
            "2253/15750 (epoch 7), train_loss = 2.859, time/batch = 0.201\n",
            "2254/15750 (epoch 7), train_loss = 2.786, time/batch = 0.212\n",
            "2255/15750 (epoch 7), train_loss = 2.797, time/batch = 0.207\n",
            "2256/15750 (epoch 7), train_loss = 2.794, time/batch = 0.201\n",
            "2257/15750 (epoch 7), train_loss = 2.851, time/batch = 0.206\n",
            "2258/15750 (epoch 7), train_loss = 2.845, time/batch = 0.200\n",
            "2259/15750 (epoch 7), train_loss = 2.830, time/batch = 0.213\n",
            "2260/15750 (epoch 7), train_loss = 2.874, time/batch = 0.216\n",
            "2261/15750 (epoch 7), train_loss = 2.746, time/batch = 0.203\n",
            "2262/15750 (epoch 7), train_loss = 2.759, time/batch = 0.203\n",
            "2263/15750 (epoch 7), train_loss = 2.819, time/batch = 0.204\n",
            "2264/15750 (epoch 7), train_loss = 2.670, time/batch = 0.207\n",
            "2265/15750 (epoch 7), train_loss = 2.794, time/batch = 0.201\n",
            "2266/15750 (epoch 7), train_loss = 2.777, time/batch = 0.203\n",
            "2267/15750 (epoch 7), train_loss = 2.716, time/batch = 0.202\n",
            "2268/15750 (epoch 7), train_loss = 2.751, time/batch = 0.209\n",
            "2269/15750 (epoch 7), train_loss = 2.740, time/batch = 0.210\n",
            "2270/15750 (epoch 7), train_loss = 2.725, time/batch = 0.207\n",
            "2271/15750 (epoch 7), train_loss = 2.674, time/batch = 0.204\n",
            "2272/15750 (epoch 7), train_loss = 2.686, time/batch = 0.206\n",
            "2273/15750 (epoch 7), train_loss = 2.739, time/batch = 0.207\n",
            "2274/15750 (epoch 7), train_loss = 2.820, time/batch = 0.211\n",
            "2275/15750 (epoch 7), train_loss = 2.745, time/batch = 0.202\n",
            "2276/15750 (epoch 7), train_loss = 2.768, time/batch = 0.202\n",
            "2277/15750 (epoch 7), train_loss = 2.609, time/batch = 0.203\n",
            "2278/15750 (epoch 7), train_loss = 2.746, time/batch = 0.204\n",
            "2279/15750 (epoch 7), train_loss = 2.842, time/batch = 0.208\n",
            "2280/15750 (epoch 7), train_loss = 2.778, time/batch = 0.201\n",
            "2281/15750 (epoch 7), train_loss = 2.781, time/batch = 0.202\n",
            "2282/15750 (epoch 7), train_loss = 2.757, time/batch = 0.198\n",
            "2283/15750 (epoch 7), train_loss = 2.789, time/batch = 0.197\n",
            "2284/15750 (epoch 7), train_loss = 2.806, time/batch = 0.216\n",
            "2285/15750 (epoch 7), train_loss = 2.695, time/batch = 0.198\n",
            "2286/15750 (epoch 7), train_loss = 2.802, time/batch = 0.198\n",
            "2287/15750 (epoch 7), train_loss = 2.718, time/batch = 0.199\n",
            "2288/15750 (epoch 7), train_loss = 2.792, time/batch = 0.202\n",
            "2289/15750 (epoch 7), train_loss = 2.858, time/batch = 0.207\n",
            "2290/15750 (epoch 7), train_loss = 2.862, time/batch = 0.195\n",
            "2291/15750 (epoch 7), train_loss = 2.699, time/batch = 0.201\n",
            "2292/15750 (epoch 7), train_loss = 2.775, time/batch = 0.205\n",
            "2293/15750 (epoch 7), train_loss = 2.792, time/batch = 0.206\n",
            "2294/15750 (epoch 7), train_loss = 2.723, time/batch = 0.200\n",
            "2295/15750 (epoch 7), train_loss = 2.781, time/batch = 0.199\n",
            "2296/15750 (epoch 7), train_loss = 2.840, time/batch = 0.206\n",
            "2297/15750 (epoch 7), train_loss = 2.847, time/batch = 0.196\n",
            "2298/15750 (epoch 7), train_loss = 2.841, time/batch = 0.203\n",
            "2299/15750 (epoch 7), train_loss = 2.863, time/batch = 0.205\n",
            "2300/15750 (epoch 7), train_loss = 2.769, time/batch = 0.204\n",
            "2301/15750 (epoch 7), train_loss = 2.782, time/batch = 0.204\n",
            "2302/15750 (epoch 7), train_loss = 2.785, time/batch = 0.197\n",
            "2303/15750 (epoch 7), train_loss = 2.825, time/batch = 0.202\n",
            "2304/15750 (epoch 7), train_loss = 2.783, time/batch = 0.205\n",
            "2305/15750 (epoch 7), train_loss = 2.773, time/batch = 0.202\n",
            "2306/15750 (epoch 7), train_loss = 2.704, time/batch = 0.195\n",
            "2307/15750 (epoch 7), train_loss = 2.726, time/batch = 0.201\n",
            "2308/15750 (epoch 7), train_loss = 2.873, time/batch = 0.203\n",
            "2309/15750 (epoch 7), train_loss = 2.811, time/batch = 0.203\n",
            "2310/15750 (epoch 7), train_loss = 2.736, time/batch = 0.203\n",
            "2311/15750 (epoch 7), train_loss = 2.804, time/batch = 0.199\n",
            "2312/15750 (epoch 7), train_loss = 2.777, time/batch = 0.199\n",
            "2313/15750 (epoch 7), train_loss = 2.871, time/batch = 0.204\n",
            "2314/15750 (epoch 7), train_loss = 2.863, time/batch = 0.207\n",
            "2315/15750 (epoch 7), train_loss = 2.897, time/batch = 0.197\n",
            "2316/15750 (epoch 7), train_loss = 2.798, time/batch = 0.205\n",
            "2317/15750 (epoch 7), train_loss = 2.778, time/batch = 0.204\n",
            "2318/15750 (epoch 7), train_loss = 2.800, time/batch = 0.196\n",
            "2319/15750 (epoch 7), train_loss = 2.787, time/batch = 0.211\n",
            "2320/15750 (epoch 7), train_loss = 2.869, time/batch = 0.201\n",
            "2321/15750 (epoch 7), train_loss = 2.798, time/batch = 0.203\n",
            "2322/15750 (epoch 7), train_loss = 2.938, time/batch = 0.204\n",
            "2323/15750 (epoch 7), train_loss = 2.784, time/batch = 0.206\n",
            "2324/15750 (epoch 7), train_loss = 2.757, time/batch = 0.209\n",
            "2325/15750 (epoch 7), train_loss = 2.745, time/batch = 0.208\n",
            "2326/15750 (epoch 7), train_loss = 2.733, time/batch = 0.209\n",
            "2327/15750 (epoch 7), train_loss = 2.762, time/batch = 0.201\n",
            "2328/15750 (epoch 7), train_loss = 2.754, time/batch = 0.207\n",
            "2329/15750 (epoch 7), train_loss = 2.758, time/batch = 0.210\n",
            "2330/15750 (epoch 7), train_loss = 2.792, time/batch = 0.201\n",
            "2331/15750 (epoch 7), train_loss = 2.889, time/batch = 0.205\n",
            "2332/15750 (epoch 7), train_loss = 2.719, time/batch = 0.204\n",
            "2333/15750 (epoch 7), train_loss = 2.693, time/batch = 0.203\n",
            "2334/15750 (epoch 7), train_loss = 2.740, time/batch = 0.214\n",
            "2335/15750 (epoch 7), train_loss = 2.680, time/batch = 0.205\n",
            "2336/15750 (epoch 7), train_loss = 2.694, time/batch = 0.204\n",
            "2337/15750 (epoch 7), train_loss = 2.730, time/batch = 0.206\n",
            "2338/15750 (epoch 7), train_loss = 2.691, time/batch = 0.207\n",
            "2339/15750 (epoch 7), train_loss = 2.771, time/batch = 0.210\n",
            "2340/15750 (epoch 7), train_loss = 2.839, time/batch = 0.200\n",
            "2341/15750 (epoch 7), train_loss = 2.819, time/batch = 0.202\n",
            "2342/15750 (epoch 7), train_loss = 2.845, time/batch = 0.203\n",
            "2343/15750 (epoch 7), train_loss = 2.819, time/batch = 0.205\n",
            "2344/15750 (epoch 7), train_loss = 2.750, time/batch = 0.206\n",
            "2345/15750 (epoch 7), train_loss = 2.746, time/batch = 0.208\n",
            "2346/15750 (epoch 7), train_loss = 2.834, time/batch = 0.201\n",
            "2347/15750 (epoch 7), train_loss = 2.843, time/batch = 0.210\n",
            "2348/15750 (epoch 7), train_loss = 2.819, time/batch = 0.202\n",
            "2349/15750 (epoch 7), train_loss = 2.765, time/batch = 0.210\n",
            "2350/15750 (epoch 7), train_loss = 2.755, time/batch = 0.201\n",
            "2351/15750 (epoch 7), train_loss = 2.692, time/batch = 0.208\n",
            "2352/15750 (epoch 7), train_loss = 2.774, time/batch = 0.204\n",
            "2353/15750 (epoch 7), train_loss = 2.812, time/batch = 0.203\n",
            "2354/15750 (epoch 7), train_loss = 2.747, time/batch = 0.204\n",
            "2355/15750 (epoch 7), train_loss = 2.761, time/batch = 0.196\n",
            "2356/15750 (epoch 7), train_loss = 2.778, time/batch = 0.198\n",
            "2357/15750 (epoch 7), train_loss = 2.876, time/batch = 0.201\n",
            "2358/15750 (epoch 7), train_loss = 2.817, time/batch = 0.199\n",
            "2359/15750 (epoch 7), train_loss = 2.788, time/batch = 0.204\n",
            "2360/15750 (epoch 7), train_loss = 2.822, time/batch = 0.204\n",
            "2361/15750 (epoch 7), train_loss = 2.838, time/batch = 0.202\n",
            "2362/15750 (epoch 7), train_loss = 2.806, time/batch = 0.200\n",
            "2363/15750 (epoch 7), train_loss = 2.885, time/batch = 0.202\n",
            "2364/15750 (epoch 7), train_loss = 2.745, time/batch = 0.208\n",
            "2365/15750 (epoch 7), train_loss = 2.842, time/batch = 0.201\n",
            "2366/15750 (epoch 7), train_loss = 2.789, time/batch = 0.208\n",
            "2367/15750 (epoch 7), train_loss = 2.882, time/batch = 0.207\n",
            "2368/15750 (epoch 7), train_loss = 2.923, time/batch = 0.206\n",
            "2369/15750 (epoch 7), train_loss = 2.858, time/batch = 0.214\n",
            "2370/15750 (epoch 7), train_loss = 2.849, time/batch = 0.203\n",
            "2371/15750 (epoch 7), train_loss = 2.873, time/batch = 0.206\n",
            "2372/15750 (epoch 7), train_loss = 2.796, time/batch = 0.207\n",
            "2373/15750 (epoch 7), train_loss = 2.760, time/batch = 0.203\n",
            "2374/15750 (epoch 7), train_loss = 2.748, time/batch = 0.214\n",
            "2375/15750 (epoch 7), train_loss = 2.835, time/batch = 0.208\n",
            "2376/15750 (epoch 7), train_loss = 2.869, time/batch = 0.205\n",
            "2377/15750 (epoch 7), train_loss = 2.798, time/batch = 0.203\n",
            "2378/15750 (epoch 7), train_loss = 2.846, time/batch = 0.201\n",
            "2379/15750 (epoch 7), train_loss = 2.830, time/batch = 0.209\n",
            "2380/15750 (epoch 7), train_loss = 2.717, time/batch = 0.202\n",
            "2381/15750 (epoch 7), train_loss = 2.769, time/batch = 0.206\n",
            "2382/15750 (epoch 7), train_loss = 2.822, time/batch = 0.204\n",
            "2383/15750 (epoch 7), train_loss = 2.750, time/batch = 0.201\n",
            "2384/15750 (epoch 7), train_loss = 2.716, time/batch = 0.209\n",
            "2385/15750 (epoch 7), train_loss = 2.711, time/batch = 0.201\n",
            "2386/15750 (epoch 7), train_loss = 2.841, time/batch = 0.201\n",
            "2387/15750 (epoch 7), train_loss = 2.746, time/batch = 0.206\n",
            "2388/15750 (epoch 7), train_loss = 2.840, time/batch = 0.206\n",
            "2389/15750 (epoch 7), train_loss = 2.837, time/batch = 0.209\n",
            "2390/15750 (epoch 7), train_loss = 2.746, time/batch = 0.205\n",
            "2391/15750 (epoch 7), train_loss = 2.742, time/batch = 0.209\n",
            "2392/15750 (epoch 7), train_loss = 2.807, time/batch = 0.204\n",
            "2393/15750 (epoch 7), train_loss = 2.875, time/batch = 0.210\n",
            "2394/15750 (epoch 7), train_loss = 2.924, time/batch = 0.219\n",
            "2395/15750 (epoch 7), train_loss = 2.843, time/batch = 0.207\n",
            "2396/15750 (epoch 7), train_loss = 2.794, time/batch = 0.213\n",
            "2397/15750 (epoch 7), train_loss = 2.809, time/batch = 0.201\n",
            "2398/15750 (epoch 7), train_loss = 2.749, time/batch = 0.201\n",
            "2399/15750 (epoch 7), train_loss = 2.834, time/batch = 0.218\n",
            "2400/15750 (epoch 7), train_loss = 2.863, time/batch = 0.211\n",
            "2401/15750 (epoch 7), train_loss = 2.764, time/batch = 0.203\n",
            "2402/15750 (epoch 7), train_loss = 2.747, time/batch = 0.201\n",
            "2403/15750 (epoch 7), train_loss = 2.821, time/batch = 0.205\n",
            "2404/15750 (epoch 7), train_loss = 2.656, time/batch = 0.211\n",
            "2405/15750 (epoch 7), train_loss = 2.730, time/batch = 0.195\n",
            "2406/15750 (epoch 7), train_loss = 2.705, time/batch = 0.201\n",
            "2407/15750 (epoch 7), train_loss = 2.781, time/batch = 0.205\n",
            "2408/15750 (epoch 7), train_loss = 2.772, time/batch = 0.203\n",
            "2409/15750 (epoch 7), train_loss = 2.805, time/batch = 0.209\n",
            "2410/15750 (epoch 7), train_loss = 2.780, time/batch = 0.209\n",
            "2411/15750 (epoch 7), train_loss = 2.668, time/batch = 0.210\n",
            "2412/15750 (epoch 7), train_loss = 2.720, time/batch = 0.202\n",
            "2413/15750 (epoch 7), train_loss = 2.735, time/batch = 0.201\n",
            "2414/15750 (epoch 7), train_loss = 2.746, time/batch = 0.220\n",
            "2415/15750 (epoch 7), train_loss = 2.623, time/batch = 0.206\n",
            "2416/15750 (epoch 7), train_loss = 2.732, time/batch = 0.205\n",
            "2417/15750 (epoch 7), train_loss = 2.631, time/batch = 0.210\n",
            "2418/15750 (epoch 7), train_loss = 2.684, time/batch = 0.204\n",
            "2419/15750 (epoch 7), train_loss = 2.675, time/batch = 0.199\n",
            "2420/15750 (epoch 7), train_loss = 2.710, time/batch = 0.210\n",
            "2421/15750 (epoch 7), train_loss = 2.847, time/batch = 0.206\n",
            "2422/15750 (epoch 7), train_loss = 2.662, time/batch = 0.201\n",
            "2423/15750 (epoch 7), train_loss = 2.881, time/batch = 0.207\n",
            "2424/15750 (epoch 7), train_loss = 2.727, time/batch = 0.209\n",
            "2425/15750 (epoch 7), train_loss = 2.650, time/batch = 0.208\n",
            "2426/15750 (epoch 7), train_loss = 2.698, time/batch = 0.204\n",
            "2427/15750 (epoch 7), train_loss = 2.777, time/batch = 0.208\n",
            "2428/15750 (epoch 7), train_loss = 2.760, time/batch = 0.211\n",
            "2429/15750 (epoch 7), train_loss = 2.707, time/batch = 0.212\n",
            "2430/15750 (epoch 7), train_loss = 2.721, time/batch = 0.203\n",
            "2431/15750 (epoch 7), train_loss = 2.812, time/batch = 0.198\n",
            "2432/15750 (epoch 7), train_loss = 2.717, time/batch = 0.203\n",
            "2433/15750 (epoch 7), train_loss = 2.748, time/batch = 0.203\n",
            "2434/15750 (epoch 7), train_loss = 2.812, time/batch = 0.205\n",
            "2435/15750 (epoch 7), train_loss = 2.687, time/batch = 0.200\n",
            "2436/15750 (epoch 7), train_loss = 2.712, time/batch = 0.200\n",
            "2437/15750 (epoch 7), train_loss = 2.744, time/batch = 0.203\n",
            "2438/15750 (epoch 7), train_loss = 2.769, time/batch = 0.202\n",
            "2439/15750 (epoch 7), train_loss = 2.687, time/batch = 0.216\n",
            "2440/15750 (epoch 7), train_loss = 2.718, time/batch = 0.204\n",
            "2441/15750 (epoch 7), train_loss = 2.639, time/batch = 0.207\n",
            "2442/15750 (epoch 7), train_loss = 2.730, time/batch = 0.202\n",
            "2443/15750 (epoch 7), train_loss = 2.929, time/batch = 0.204\n",
            "2444/15750 (epoch 7), train_loss = 2.726, time/batch = 0.215\n",
            "2445/15750 (epoch 7), train_loss = 2.805, time/batch = 0.207\n",
            "2446/15750 (epoch 7), train_loss = 2.688, time/batch = 0.208\n",
            "2447/15750 (epoch 7), train_loss = 2.780, time/batch = 0.205\n",
            "2448/15750 (epoch 7), train_loss = 2.777, time/batch = 0.208\n",
            "2449/15750 (epoch 7), train_loss = 2.756, time/batch = 0.207\n",
            "2450/15750 (epoch 7), train_loss = 2.813, time/batch = 0.206\n",
            "2451/15750 (epoch 7), train_loss = 2.776, time/batch = 0.205\n",
            "2452/15750 (epoch 7), train_loss = 2.797, time/batch = 0.202\n",
            "2453/15750 (epoch 7), train_loss = 2.758, time/batch = 0.208\n",
            "2454/15750 (epoch 7), train_loss = 2.777, time/batch = 0.203\n",
            "2455/15750 (epoch 7), train_loss = 2.695, time/batch = 0.202\n",
            "2456/15750 (epoch 7), train_loss = 2.708, time/batch = 0.201\n",
            "2457/15750 (epoch 7), train_loss = 2.785, time/batch = 0.203\n",
            "2458/15750 (epoch 7), train_loss = 2.773, time/batch = 0.199\n",
            "2459/15750 (epoch 7), train_loss = 2.744, time/batch = 0.207\n",
            "2460/15750 (epoch 7), train_loss = 2.727, time/batch = 0.203\n",
            "2461/15750 (epoch 7), train_loss = 2.663, time/batch = 0.201\n",
            "2462/15750 (epoch 7), train_loss = 2.685, time/batch = 0.206\n",
            "2463/15750 (epoch 7), train_loss = 2.872, time/batch = 0.204\n",
            "2464/15750 (epoch 7), train_loss = 2.792, time/batch = 0.211\n",
            "2465/15750 (epoch 7), train_loss = 2.784, time/batch = 0.195\n",
            "2466/15750 (epoch 7), train_loss = 2.734, time/batch = 0.206\n",
            "2467/15750 (epoch 7), train_loss = 2.788, time/batch = 0.202\n",
            "2468/15750 (epoch 7), train_loss = 2.740, time/batch = 0.202\n",
            "2469/15750 (epoch 7), train_loss = 2.830, time/batch = 0.210\n",
            "2470/15750 (epoch 7), train_loss = 2.822, time/batch = 0.199\n",
            "2471/15750 (epoch 7), train_loss = 2.866, time/batch = 0.202\n",
            "2472/15750 (epoch 7), train_loss = 2.761, time/batch = 0.195\n",
            "2473/15750 (epoch 7), train_loss = 2.795, time/batch = 0.201\n",
            "2474/15750 (epoch 7), train_loss = 2.838, time/batch = 0.209\n",
            "2475/15750 (epoch 7), train_loss = 2.793, time/batch = 0.197\n",
            "2476/15750 (epoch 7), train_loss = 2.659, time/batch = 0.201\n",
            "2477/15750 (epoch 7), train_loss = 2.739, time/batch = 0.203\n",
            "2478/15750 (epoch 7), train_loss = 2.789, time/batch = 0.196\n",
            "2479/15750 (epoch 7), train_loss = 2.815, time/batch = 0.208\n",
            "2480/15750 (epoch 7), train_loss = 2.804, time/batch = 0.205\n",
            "2481/15750 (epoch 7), train_loss = 2.824, time/batch = 0.200\n",
            "2482/15750 (epoch 7), train_loss = 2.748, time/batch = 0.199\n",
            "2483/15750 (epoch 7), train_loss = 2.710, time/batch = 0.203\n",
            "2484/15750 (epoch 7), train_loss = 2.680, time/batch = 0.209\n",
            "2485/15750 (epoch 7), train_loss = 2.942, time/batch = 0.200\n",
            "2486/15750 (epoch 7), train_loss = 2.723, time/batch = 0.199\n",
            "2487/15750 (epoch 7), train_loss = 2.698, time/batch = 0.201\n",
            "2488/15750 (epoch 7), train_loss = 2.843, time/batch = 0.199\n",
            "2489/15750 (epoch 7), train_loss = 2.690, time/batch = 0.203\n",
            "2490/15750 (epoch 7), train_loss = 2.861, time/batch = 0.204\n",
            "2491/15750 (epoch 7), train_loss = 2.720, time/batch = 0.204\n",
            "2492/15750 (epoch 7), train_loss = 2.753, time/batch = 0.212\n",
            "2493/15750 (epoch 7), train_loss = 2.668, time/batch = 0.201\n",
            "2494/15750 (epoch 7), train_loss = 2.750, time/batch = 0.210\n",
            "2495/15750 (epoch 7), train_loss = 2.647, time/batch = 0.211\n",
            "2496/15750 (epoch 7), train_loss = 2.777, time/batch = 0.202\n",
            "2497/15750 (epoch 7), train_loss = 2.745, time/batch = 0.203\n",
            "2498/15750 (epoch 7), train_loss = 2.731, time/batch = 0.202\n",
            "2499/15750 (epoch 7), train_loss = 2.799, time/batch = 0.207\n",
            "2500/15750 (epoch 7), train_loss = 2.857, time/batch = 0.205\n",
            "2501/15750 (epoch 7), train_loss = 2.809, time/batch = 0.203\n",
            "2502/15750 (epoch 7), train_loss = 2.844, time/batch = 0.202\n",
            "2503/15750 (epoch 7), train_loss = 2.691, time/batch = 0.207\n",
            "2504/15750 (epoch 7), train_loss = 2.802, time/batch = 0.211\n",
            "2505/15750 (epoch 7), train_loss = 2.752, time/batch = 0.202\n",
            "2506/15750 (epoch 7), train_loss = 2.670, time/batch = 0.209\n",
            "2507/15750 (epoch 7), train_loss = 2.792, time/batch = 0.206\n",
            "2508/15750 (epoch 7), train_loss = 2.660, time/batch = 0.205\n",
            "2509/15750 (epoch 7), train_loss = 2.795, time/batch = 0.208\n",
            "2510/15750 (epoch 7), train_loss = 2.773, time/batch = 0.203\n",
            "2511/15750 (epoch 7), train_loss = 2.745, time/batch = 0.203\n",
            "2512/15750 (epoch 7), train_loss = 2.672, time/batch = 0.203\n",
            "2513/15750 (epoch 7), train_loss = 2.684, time/batch = 0.202\n",
            "2514/15750 (epoch 7), train_loss = 2.837, time/batch = 0.206\n",
            "2515/15750 (epoch 7), train_loss = 2.664, time/batch = 0.200\n",
            "2516/15750 (epoch 7), train_loss = 2.611, time/batch = 0.205\n",
            "2517/15750 (epoch 7), train_loss = 2.709, time/batch = 0.202\n",
            "2518/15750 (epoch 7), train_loss = 2.699, time/batch = 0.204\n",
            "2519/15750 (epoch 7), train_loss = 2.792, time/batch = 0.205\n",
            "2520/15750 (epoch 8), train_loss = 2.859, time/batch = 0.206\n",
            "2521/15750 (epoch 8), train_loss = 2.815, time/batch = 0.200\n",
            "2522/15750 (epoch 8), train_loss = 2.754, time/batch = 0.203\n",
            "2523/15750 (epoch 8), train_loss = 2.859, time/batch = 0.207\n",
            "2524/15750 (epoch 8), train_loss = 2.758, time/batch = 0.203\n",
            "2525/15750 (epoch 8), train_loss = 2.742, time/batch = 0.203\n",
            "2526/15750 (epoch 8), train_loss = 2.906, time/batch = 0.205\n",
            "2527/15750 (epoch 8), train_loss = 2.829, time/batch = 0.204\n",
            "2528/15750 (epoch 8), train_loss = 2.809, time/batch = 0.210\n",
            "2529/15750 (epoch 8), train_loss = 2.785, time/batch = 0.206\n",
            "2530/15750 (epoch 8), train_loss = 2.734, time/batch = 0.203\n",
            "2531/15750 (epoch 8), train_loss = 2.687, time/batch = 0.211\n",
            "2532/15750 (epoch 8), train_loss = 2.842, time/batch = 0.202\n",
            "2533/15750 (epoch 8), train_loss = 2.752, time/batch = 0.202\n",
            "2534/15750 (epoch 8), train_loss = 2.770, time/batch = 0.199\n",
            "2535/15750 (epoch 8), train_loss = 2.757, time/batch = 0.205\n",
            "2536/15750 (epoch 8), train_loss = 2.807, time/batch = 0.200\n",
            "2537/15750 (epoch 8), train_loss = 2.862, time/batch = 0.203\n",
            "2538/15750 (epoch 8), train_loss = 2.851, time/batch = 0.206\n",
            "2539/15750 (epoch 8), train_loss = 2.796, time/batch = 0.202\n",
            "2540/15750 (epoch 8), train_loss = 2.815, time/batch = 0.197\n",
            "2541/15750 (epoch 8), train_loss = 2.799, time/batch = 0.207\n",
            "2542/15750 (epoch 8), train_loss = 2.766, time/batch = 0.207\n",
            "2543/15750 (epoch 8), train_loss = 2.806, time/batch = 0.203\n",
            "2544/15750 (epoch 8), train_loss = 2.789, time/batch = 0.199\n",
            "2545/15750 (epoch 8), train_loss = 2.844, time/batch = 0.205\n",
            "2546/15750 (epoch 8), train_loss = 2.807, time/batch = 0.198\n",
            "2547/15750 (epoch 8), train_loss = 2.816, time/batch = 0.196\n",
            "2548/15750 (epoch 8), train_loss = 2.963, time/batch = 0.205\n",
            "2549/15750 (epoch 8), train_loss = 2.846, time/batch = 0.192\n",
            "2550/15750 (epoch 8), train_loss = 2.805, time/batch = 0.204\n",
            "2551/15750 (epoch 8), train_loss = 2.786, time/batch = 0.201\n",
            "2552/15750 (epoch 8), train_loss = 2.707, time/batch = 0.199\n",
            "2553/15750 (epoch 8), train_loss = 2.727, time/batch = 0.204\n",
            "2554/15750 (epoch 8), train_loss = 2.779, time/batch = 0.203\n",
            "2555/15750 (epoch 8), train_loss = 2.714, time/batch = 0.200\n",
            "2556/15750 (epoch 8), train_loss = 2.708, time/batch = 0.201\n",
            "2557/15750 (epoch 8), train_loss = 2.793, time/batch = 0.204\n",
            "2558/15750 (epoch 8), train_loss = 2.708, time/batch = 0.206\n",
            "2559/15750 (epoch 8), train_loss = 2.770, time/batch = 0.192\n",
            "2560/15750 (epoch 8), train_loss = 2.750, time/batch = 0.200\n",
            "2561/15750 (epoch 8), train_loss = 2.805, time/batch = 0.200\n",
            "2562/15750 (epoch 8), train_loss = 2.796, time/batch = 0.201\n",
            "2563/15750 (epoch 8), train_loss = 2.716, time/batch = 0.207\n",
            "2564/15750 (epoch 8), train_loss = 2.776, time/batch = 0.204\n",
            "2565/15750 (epoch 8), train_loss = 2.680, time/batch = 0.199\n",
            "2566/15750 (epoch 8), train_loss = 2.712, time/batch = 0.207\n",
            "2567/15750 (epoch 8), train_loss = 2.782, time/batch = 0.201\n",
            "2568/15750 (epoch 8), train_loss = 2.797, time/batch = 0.208\n",
            "2569/15750 (epoch 8), train_loss = 2.716, time/batch = 0.204\n",
            "2570/15750 (epoch 8), train_loss = 2.735, time/batch = 0.205\n",
            "2571/15750 (epoch 8), train_loss = 2.723, time/batch = 0.203\n",
            "2572/15750 (epoch 8), train_loss = 2.781, time/batch = 0.205\n",
            "2573/15750 (epoch 8), train_loss = 2.777, time/batch = 0.200\n",
            "2574/15750 (epoch 8), train_loss = 2.762, time/batch = 0.210\n",
            "2575/15750 (epoch 8), train_loss = 2.811, time/batch = 0.201\n",
            "2576/15750 (epoch 8), train_loss = 2.678, time/batch = 0.197\n",
            "2577/15750 (epoch 8), train_loss = 2.692, time/batch = 0.206\n",
            "2578/15750 (epoch 8), train_loss = 2.751, time/batch = 0.202\n",
            "2579/15750 (epoch 8), train_loss = 2.605, time/batch = 0.204\n",
            "2580/15750 (epoch 8), train_loss = 2.733, time/batch = 0.203\n",
            "2581/15750 (epoch 8), train_loss = 2.714, time/batch = 0.201\n",
            "2582/15750 (epoch 8), train_loss = 2.653, time/batch = 0.198\n",
            "2583/15750 (epoch 8), train_loss = 2.690, time/batch = 0.205\n",
            "2584/15750 (epoch 8), train_loss = 2.670, time/batch = 0.200\n",
            "2585/15750 (epoch 8), train_loss = 2.657, time/batch = 0.199\n",
            "2586/15750 (epoch 8), train_loss = 2.604, time/batch = 0.203\n",
            "2587/15750 (epoch 8), train_loss = 2.620, time/batch = 0.202\n",
            "2588/15750 (epoch 8), train_loss = 2.672, time/batch = 0.199\n",
            "2589/15750 (epoch 8), train_loss = 2.756, time/batch = 0.206\n",
            "2590/15750 (epoch 8), train_loss = 2.681, time/batch = 0.199\n",
            "2591/15750 (epoch 8), train_loss = 2.699, time/batch = 0.201\n",
            "2592/15750 (epoch 8), train_loss = 2.548, time/batch = 0.204\n",
            "2593/15750 (epoch 8), train_loss = 2.678, time/batch = 0.200\n",
            "2594/15750 (epoch 8), train_loss = 2.777, time/batch = 0.208\n",
            "2595/15750 (epoch 8), train_loss = 2.714, time/batch = 0.202\n",
            "2596/15750 (epoch 8), train_loss = 2.713, time/batch = 0.201\n",
            "2597/15750 (epoch 8), train_loss = 2.694, time/batch = 0.200\n",
            "2598/15750 (epoch 8), train_loss = 2.720, time/batch = 0.196\n",
            "2599/15750 (epoch 8), train_loss = 2.740, time/batch = 0.203\n",
            "2600/15750 (epoch 8), train_loss = 2.631, time/batch = 0.202\n",
            "2601/15750 (epoch 8), train_loss = 2.736, time/batch = 0.203\n",
            "2602/15750 (epoch 8), train_loss = 2.653, time/batch = 0.200\n",
            "2603/15750 (epoch 8), train_loss = 2.725, time/batch = 0.202\n",
            "2604/15750 (epoch 8), train_loss = 2.790, time/batch = 0.208\n",
            "2605/15750 (epoch 8), train_loss = 2.797, time/batch = 0.200\n",
            "2606/15750 (epoch 8), train_loss = 2.634, time/batch = 0.201\n",
            "2607/15750 (epoch 8), train_loss = 2.698, time/batch = 0.208\n",
            "2608/15750 (epoch 8), train_loss = 2.720, time/batch = 0.202\n",
            "2609/15750 (epoch 8), train_loss = 2.659, time/batch = 0.202\n",
            "2610/15750 (epoch 8), train_loss = 2.710, time/batch = 0.199\n",
            "2611/15750 (epoch 8), train_loss = 2.769, time/batch = 0.204\n",
            "2612/15750 (epoch 8), train_loss = 2.777, time/batch = 0.201\n",
            "2613/15750 (epoch 8), train_loss = 2.776, time/batch = 0.195\n",
            "2614/15750 (epoch 8), train_loss = 2.799, time/batch = 0.207\n",
            "2615/15750 (epoch 8), train_loss = 2.705, time/batch = 0.202\n",
            "2616/15750 (epoch 8), train_loss = 2.723, time/batch = 0.204\n",
            "2617/15750 (epoch 8), train_loss = 2.726, time/batch = 0.203\n",
            "2618/15750 (epoch 8), train_loss = 2.757, time/batch = 0.203\n",
            "2619/15750 (epoch 8), train_loss = 2.728, time/batch = 0.202\n",
            "2620/15750 (epoch 8), train_loss = 2.713, time/batch = 0.199\n",
            "2621/15750 (epoch 8), train_loss = 2.640, time/batch = 0.199\n",
            "2622/15750 (epoch 8), train_loss = 2.665, time/batch = 0.193\n",
            "2623/15750 (epoch 8), train_loss = 2.808, time/batch = 0.201\n",
            "2624/15750 (epoch 8), train_loss = 2.746, time/batch = 0.204\n",
            "2625/15750 (epoch 8), train_loss = 2.672, time/batch = 0.199\n",
            "2626/15750 (epoch 8), train_loss = 2.735, time/batch = 0.203\n",
            "2627/15750 (epoch 8), train_loss = 2.718, time/batch = 0.199\n",
            "2628/15750 (epoch 8), train_loss = 2.802, time/batch = 0.203\n",
            "2629/15750 (epoch 8), train_loss = 2.800, time/batch = 0.203\n",
            "2630/15750 (epoch 8), train_loss = 2.835, time/batch = 0.203\n",
            "2631/15750 (epoch 8), train_loss = 2.734, time/batch = 0.203\n",
            "2632/15750 (epoch 8), train_loss = 2.712, time/batch = 0.203\n",
            "2633/15750 (epoch 8), train_loss = 2.735, time/batch = 0.201\n",
            "2634/15750 (epoch 8), train_loss = 2.722, time/batch = 0.208\n",
            "2635/15750 (epoch 8), train_loss = 2.806, time/batch = 0.201\n",
            "2636/15750 (epoch 8), train_loss = 2.734, time/batch = 0.205\n",
            "2637/15750 (epoch 8), train_loss = 2.871, time/batch = 0.197\n",
            "2638/15750 (epoch 8), train_loss = 2.722, time/batch = 0.203\n",
            "2639/15750 (epoch 8), train_loss = 2.695, time/batch = 0.207\n",
            "2640/15750 (epoch 8), train_loss = 2.683, time/batch = 0.200\n",
            "2641/15750 (epoch 8), train_loss = 2.670, time/batch = 0.201\n",
            "2642/15750 (epoch 8), train_loss = 2.696, time/batch = 0.200\n",
            "2643/15750 (epoch 8), train_loss = 2.692, time/batch = 0.201\n",
            "2644/15750 (epoch 8), train_loss = 2.697, time/batch = 0.205\n",
            "2645/15750 (epoch 8), train_loss = 2.727, time/batch = 0.200\n",
            "2646/15750 (epoch 8), train_loss = 2.823, time/batch = 0.198\n",
            "2647/15750 (epoch 8), train_loss = 2.659, time/batch = 0.203\n",
            "2648/15750 (epoch 8), train_loss = 2.637, time/batch = 0.205\n",
            "2649/15750 (epoch 8), train_loss = 2.678, time/batch = 0.206\n",
            "2650/15750 (epoch 8), train_loss = 2.619, time/batch = 0.201\n",
            "2651/15750 (epoch 8), train_loss = 2.630, time/batch = 0.204\n",
            "2652/15750 (epoch 8), train_loss = 2.661, time/batch = 0.200\n",
            "2653/15750 (epoch 8), train_loss = 2.630, time/batch = 0.200\n",
            "2654/15750 (epoch 8), train_loss = 2.706, time/batch = 0.208\n",
            "2655/15750 (epoch 8), train_loss = 2.784, time/batch = 0.200\n",
            "2656/15750 (epoch 8), train_loss = 2.758, time/batch = 0.197\n",
            "2657/15750 (epoch 8), train_loss = 2.779, time/batch = 0.208\n",
            "2658/15750 (epoch 8), train_loss = 2.758, time/batch = 0.199\n",
            "2659/15750 (epoch 8), train_loss = 2.685, time/batch = 0.206\n",
            "2660/15750 (epoch 8), train_loss = 2.681, time/batch = 0.198\n",
            "2661/15750 (epoch 8), train_loss = 2.769, time/batch = 0.201\n",
            "2662/15750 (epoch 8), train_loss = 2.779, time/batch = 0.197\n",
            "2663/15750 (epoch 8), train_loss = 2.762, time/batch = 0.205\n",
            "2664/15750 (epoch 8), train_loss = 2.701, time/batch = 0.207\n",
            "2665/15750 (epoch 8), train_loss = 2.693, time/batch = 0.197\n",
            "2666/15750 (epoch 8), train_loss = 2.627, time/batch = 0.198\n",
            "2667/15750 (epoch 8), train_loss = 2.714, time/batch = 0.200\n",
            "2668/15750 (epoch 8), train_loss = 2.751, time/batch = 0.204\n",
            "2669/15750 (epoch 8), train_loss = 2.687, time/batch = 0.200\n",
            "2670/15750 (epoch 8), train_loss = 2.701, time/batch = 0.198\n",
            "2671/15750 (epoch 8), train_loss = 2.718, time/batch = 0.204\n",
            "2672/15750 (epoch 8), train_loss = 2.814, time/batch = 0.202\n",
            "2673/15750 (epoch 8), train_loss = 2.751, time/batch = 0.201\n",
            "2674/15750 (epoch 8), train_loss = 2.732, time/batch = 0.205\n",
            "2675/15750 (epoch 8), train_loss = 2.757, time/batch = 0.206\n",
            "2676/15750 (epoch 8), train_loss = 2.771, time/batch = 0.198\n",
            "2677/15750 (epoch 8), train_loss = 2.740, time/batch = 0.201\n",
            "2678/15750 (epoch 8), train_loss = 2.825, time/batch = 0.203\n",
            "2679/15750 (epoch 8), train_loss = 2.680, time/batch = 0.199\n",
            "2680/15750 (epoch 8), train_loss = 2.775, time/batch = 0.208\n",
            "2681/15750 (epoch 8), train_loss = 2.732, time/batch = 0.200\n",
            "2682/15750 (epoch 8), train_loss = 2.811, time/batch = 0.201\n",
            "2683/15750 (epoch 8), train_loss = 2.863, time/batch = 0.202\n",
            "2684/15750 (epoch 8), train_loss = 2.791, time/batch = 0.205\n",
            "2685/15750 (epoch 8), train_loss = 2.789, time/batch = 0.207\n",
            "2686/15750 (epoch 8), train_loss = 2.806, time/batch = 0.200\n",
            "2687/15750 (epoch 8), train_loss = 2.731, time/batch = 0.204\n",
            "2688/15750 (epoch 8), train_loss = 2.697, time/batch = 0.194\n",
            "2689/15750 (epoch 8), train_loss = 2.688, time/batch = 0.198\n",
            "2690/15750 (epoch 8), train_loss = 2.768, time/batch = 0.199\n",
            "2691/15750 (epoch 8), train_loss = 2.804, time/batch = 0.204\n",
            "2692/15750 (epoch 8), train_loss = 2.733, time/batch = 0.202\n",
            "2693/15750 (epoch 8), train_loss = 2.783, time/batch = 0.199\n",
            "2694/15750 (epoch 8), train_loss = 2.762, time/batch = 0.202\n",
            "2695/15750 (epoch 8), train_loss = 2.657, time/batch = 0.208\n",
            "2696/15750 (epoch 8), train_loss = 2.703, time/batch = 0.203\n",
            "2697/15750 (epoch 8), train_loss = 2.760, time/batch = 0.201\n",
            "2698/15750 (epoch 8), train_loss = 2.685, time/batch = 0.201\n",
            "2699/15750 (epoch 8), train_loss = 2.651, time/batch = 0.200\n",
            "2700/15750 (epoch 8), train_loss = 2.650, time/batch = 0.209\n",
            "2701/15750 (epoch 8), train_loss = 2.779, time/batch = 0.200\n",
            "2702/15750 (epoch 8), train_loss = 2.688, time/batch = 0.201\n",
            "2703/15750 (epoch 8), train_loss = 2.781, time/batch = 0.205\n",
            "2704/15750 (epoch 8), train_loss = 2.777, time/batch = 0.201\n",
            "2705/15750 (epoch 8), train_loss = 2.686, time/batch = 0.208\n",
            "2706/15750 (epoch 8), train_loss = 2.677, time/batch = 0.200\n",
            "2707/15750 (epoch 8), train_loss = 2.743, time/batch = 0.200\n",
            "2708/15750 (epoch 8), train_loss = 2.812, time/batch = 0.201\n",
            "2709/15750 (epoch 8), train_loss = 2.864, time/batch = 0.206\n",
            "2710/15750 (epoch 8), train_loss = 2.784, time/batch = 0.202\n",
            "2711/15750 (epoch 8), train_loss = 2.734, time/batch = 0.202\n",
            "2712/15750 (epoch 8), train_loss = 2.747, time/batch = 0.202\n",
            "2713/15750 (epoch 8), train_loss = 2.683, time/batch = 0.205\n",
            "2714/15750 (epoch 8), train_loss = 2.775, time/batch = 0.200\n",
            "2715/15750 (epoch 8), train_loss = 2.803, time/batch = 0.209\n",
            "2716/15750 (epoch 8), train_loss = 2.708, time/batch = 0.198\n",
            "2717/15750 (epoch 8), train_loss = 2.685, time/batch = 0.202\n",
            "2718/15750 (epoch 8), train_loss = 2.764, time/batch = 0.195\n",
            "2719/15750 (epoch 8), train_loss = 2.593, time/batch = 0.203\n",
            "2720/15750 (epoch 8), train_loss = 2.668, time/batch = 0.206\n",
            "2721/15750 (epoch 8), train_loss = 2.644, time/batch = 0.193\n",
            "2722/15750 (epoch 8), train_loss = 2.718, time/batch = 0.205\n",
            "2723/15750 (epoch 8), train_loss = 2.710, time/batch = 0.202\n",
            "2724/15750 (epoch 8), train_loss = 2.747, time/batch = 0.201\n",
            "2725/15750 (epoch 8), train_loss = 2.723, time/batch = 0.203\n",
            "2726/15750 (epoch 8), train_loss = 2.600, time/batch = 0.201\n",
            "2727/15750 (epoch 8), train_loss = 2.658, time/batch = 0.205\n",
            "2728/15750 (epoch 8), train_loss = 2.674, time/batch = 0.195\n",
            "2729/15750 (epoch 8), train_loss = 2.690, time/batch = 0.201\n",
            "2730/15750 (epoch 8), train_loss = 2.564, time/batch = 0.210\n",
            "2731/15750 (epoch 8), train_loss = 2.672, time/batch = 0.197\n",
            "2732/15750 (epoch 8), train_loss = 2.569, time/batch = 0.200\n",
            "2733/15750 (epoch 8), train_loss = 2.626, time/batch = 0.206\n",
            "2734/15750 (epoch 8), train_loss = 2.621, time/batch = 0.196\n",
            "2735/15750 (epoch 8), train_loss = 2.647, time/batch = 0.205\n",
            "2736/15750 (epoch 8), train_loss = 2.788, time/batch = 0.196\n",
            "2737/15750 (epoch 8), train_loss = 2.600, time/batch = 0.197\n",
            "2738/15750 (epoch 8), train_loss = 2.826, time/batch = 0.201\n",
            "2739/15750 (epoch 8), train_loss = 2.671, time/batch = 0.203\n",
            "2740/15750 (epoch 8), train_loss = 2.592, time/batch = 0.205\n",
            "2741/15750 (epoch 8), train_loss = 2.637, time/batch = 0.201\n",
            "2742/15750 (epoch 8), train_loss = 2.712, time/batch = 0.204\n",
            "2743/15750 (epoch 8), train_loss = 2.699, time/batch = 0.202\n",
            "2744/15750 (epoch 8), train_loss = 2.653, time/batch = 0.201\n",
            "2745/15750 (epoch 8), train_loss = 2.660, time/batch = 0.205\n",
            "2746/15750 (epoch 8), train_loss = 2.750, time/batch = 0.200\n",
            "2747/15750 (epoch 8), train_loss = 2.658, time/batch = 0.200\n",
            "2748/15750 (epoch 8), train_loss = 2.690, time/batch = 0.205\n",
            "2749/15750 (epoch 8), train_loss = 2.758, time/batch = 0.202\n",
            "2750/15750 (epoch 8), train_loss = 2.631, time/batch = 0.204\n",
            "2751/15750 (epoch 8), train_loss = 2.648, time/batch = 0.197\n",
            "2752/15750 (epoch 8), train_loss = 2.689, time/batch = 0.202\n",
            "2753/15750 (epoch 8), train_loss = 2.709, time/batch = 0.204\n",
            "2754/15750 (epoch 8), train_loss = 2.628, time/batch = 0.199\n",
            "2755/15750 (epoch 8), train_loss = 2.652, time/batch = 0.199\n",
            "2756/15750 (epoch 8), train_loss = 2.581, time/batch = 0.199\n",
            "2757/15750 (epoch 8), train_loss = 2.669, time/batch = 0.201\n",
            "2758/15750 (epoch 8), train_loss = 2.871, time/batch = 0.200\n",
            "2759/15750 (epoch 8), train_loss = 2.668, time/batch = 0.206\n",
            "2760/15750 (epoch 8), train_loss = 2.745, time/batch = 0.200\n",
            "2761/15750 (epoch 8), train_loss = 2.629, time/batch = 0.206\n",
            "2762/15750 (epoch 8), train_loss = 2.716, time/batch = 0.195\n",
            "2763/15750 (epoch 8), train_loss = 2.717, time/batch = 0.206\n",
            "2764/15750 (epoch 8), train_loss = 2.693, time/batch = 0.199\n",
            "2765/15750 (epoch 8), train_loss = 2.753, time/batch = 0.200\n",
            "2766/15750 (epoch 8), train_loss = 2.716, time/batch = 0.209\n",
            "2767/15750 (epoch 8), train_loss = 2.734, time/batch = 0.201\n",
            "2768/15750 (epoch 8), train_loss = 2.701, time/batch = 0.203\n",
            "2769/15750 (epoch 8), train_loss = 2.720, time/batch = 0.202\n",
            "2770/15750 (epoch 8), train_loss = 2.637, time/batch = 0.200\n",
            "2771/15750 (epoch 8), train_loss = 2.648, time/batch = 0.206\n",
            "2772/15750 (epoch 8), train_loss = 2.722, time/batch = 0.202\n",
            "2773/15750 (epoch 8), train_loss = 2.713, time/batch = 0.201\n",
            "2774/15750 (epoch 8), train_loss = 2.685, time/batch = 0.206\n",
            "2775/15750 (epoch 8), train_loss = 2.668, time/batch = 0.203\n",
            "2776/15750 (epoch 8), train_loss = 2.609, time/batch = 0.205\n",
            "2777/15750 (epoch 8), train_loss = 2.627, time/batch = 0.198\n",
            "2778/15750 (epoch 8), train_loss = 2.812, time/batch = 0.202\n",
            "2779/15750 (epoch 8), train_loss = 2.733, time/batch = 0.201\n",
            "2780/15750 (epoch 8), train_loss = 2.726, time/batch = 0.197\n",
            "2781/15750 (epoch 8), train_loss = 2.675, time/batch = 0.205\n",
            "2782/15750 (epoch 8), train_loss = 2.725, time/batch = 0.200\n",
            "2783/15750 (epoch 8), train_loss = 2.683, time/batch = 0.199\n",
            "2784/15750 (epoch 8), train_loss = 2.765, time/batch = 0.201\n",
            "2785/15750 (epoch 8), train_loss = 2.763, time/batch = 0.201\n",
            "2786/15750 (epoch 8), train_loss = 2.803, time/batch = 0.206\n",
            "2787/15750 (epoch 8), train_loss = 2.701, time/batch = 0.202\n",
            "2788/15750 (epoch 8), train_loss = 2.736, time/batch = 0.204\n",
            "2789/15750 (epoch 8), train_loss = 2.777, time/batch = 0.203\n",
            "2790/15750 (epoch 8), train_loss = 2.735, time/batch = 0.200\n",
            "2791/15750 (epoch 8), train_loss = 2.604, time/batch = 0.205\n",
            "2792/15750 (epoch 8), train_loss = 2.683, time/batch = 0.207\n",
            "2793/15750 (epoch 8), train_loss = 2.733, time/batch = 0.198\n",
            "2794/15750 (epoch 8), train_loss = 2.758, time/batch = 0.203\n",
            "2795/15750 (epoch 8), train_loss = 2.744, time/batch = 0.197\n",
            "2796/15750 (epoch 8), train_loss = 2.766, time/batch = 0.208\n",
            "2797/15750 (epoch 8), train_loss = 2.693, time/batch = 0.199\n",
            "2798/15750 (epoch 8), train_loss = 2.648, time/batch = 0.206\n",
            "2799/15750 (epoch 8), train_loss = 2.620, time/batch = 0.196\n",
            "2800/15750 (epoch 8), train_loss = 2.880, time/batch = 0.205\n",
            "2801/15750 (epoch 8), train_loss = 2.666, time/batch = 0.201\n",
            "2802/15750 (epoch 8), train_loss = 2.637, time/batch = 0.199\n",
            "2803/15750 (epoch 8), train_loss = 2.787, time/batch = 0.203\n",
            "2804/15750 (epoch 8), train_loss = 2.633, time/batch = 0.198\n",
            "2805/15750 (epoch 8), train_loss = 2.801, time/batch = 0.198\n",
            "2806/15750 (epoch 8), train_loss = 2.665, time/batch = 0.203\n",
            "2807/15750 (epoch 8), train_loss = 2.692, time/batch = 0.202\n",
            "2808/15750 (epoch 8), train_loss = 2.609, time/batch = 0.199\n",
            "2809/15750 (epoch 8), train_loss = 2.693, time/batch = 0.201\n",
            "2810/15750 (epoch 8), train_loss = 2.594, time/batch = 0.203\n",
            "2811/15750 (epoch 8), train_loss = 2.718, time/batch = 0.207\n",
            "2812/15750 (epoch 8), train_loss = 2.689, time/batch = 0.201\n",
            "2813/15750 (epoch 8), train_loss = 2.674, time/batch = 0.203\n",
            "2814/15750 (epoch 8), train_loss = 2.738, time/batch = 0.202\n",
            "2815/15750 (epoch 8), train_loss = 2.800, time/batch = 0.201\n",
            "2816/15750 (epoch 8), train_loss = 2.749, time/batch = 0.209\n",
            "2817/15750 (epoch 8), train_loss = 2.785, time/batch = 0.196\n",
            "2818/15750 (epoch 8), train_loss = 2.632, time/batch = 0.203\n",
            "2819/15750 (epoch 8), train_loss = 2.740, time/batch = 0.204\n",
            "2820/15750 (epoch 8), train_loss = 2.693, time/batch = 0.199\n",
            "2821/15750 (epoch 8), train_loss = 2.611, time/batch = 0.208\n",
            "2822/15750 (epoch 8), train_loss = 2.736, time/batch = 0.202\n",
            "2823/15750 (epoch 8), train_loss = 2.600, time/batch = 0.206\n",
            "2824/15750 (epoch 8), train_loss = 2.739, time/batch = 0.198\n",
            "2825/15750 (epoch 8), train_loss = 2.706, time/batch = 0.200\n",
            "2826/15750 (epoch 8), train_loss = 2.685, time/batch = 0.206\n",
            "2827/15750 (epoch 8), train_loss = 2.613, time/batch = 0.195\n",
            "2828/15750 (epoch 8), train_loss = 2.630, time/batch = 0.202\n",
            "2829/15750 (epoch 8), train_loss = 2.776, time/batch = 0.201\n",
            "2830/15750 (epoch 8), train_loss = 2.605, time/batch = 0.198\n",
            "2831/15750 (epoch 8), train_loss = 2.561, time/batch = 0.205\n",
            "2832/15750 (epoch 8), train_loss = 2.653, time/batch = 0.202\n",
            "2833/15750 (epoch 8), train_loss = 2.640, time/batch = 0.205\n",
            "2834/15750 (epoch 8), train_loss = 2.736, time/batch = 0.202\n",
            "2835/15750 (epoch 9), train_loss = 2.793, time/batch = 0.199\n",
            "2836/15750 (epoch 9), train_loss = 2.756, time/batch = 0.208\n",
            "2837/15750 (epoch 9), train_loss = 2.694, time/batch = 0.214\n",
            "2838/15750 (epoch 9), train_loss = 2.798, time/batch = 0.206\n",
            "2839/15750 (epoch 9), train_loss = 2.701, time/batch = 0.204\n",
            "2840/15750 (epoch 9), train_loss = 2.686, time/batch = 0.204\n",
            "2841/15750 (epoch 9), train_loss = 2.854, time/batch = 0.210\n",
            "2842/15750 (epoch 9), train_loss = 2.775, time/batch = 0.203\n",
            "2843/15750 (epoch 9), train_loss = 2.750, time/batch = 0.203\n",
            "2844/15750 (epoch 9), train_loss = 2.725, time/batch = 0.209\n",
            "2845/15750 (epoch 9), train_loss = 2.683, time/batch = 0.204\n",
            "2846/15750 (epoch 9), train_loss = 2.633, time/batch = 0.219\n",
            "2847/15750 (epoch 9), train_loss = 2.782, time/batch = 0.204\n",
            "2848/15750 (epoch 9), train_loss = 2.700, time/batch = 0.198\n",
            "2849/15750 (epoch 9), train_loss = 2.712, time/batch = 0.202\n",
            "2850/15750 (epoch 9), train_loss = 2.705, time/batch = 0.205\n",
            "2851/15750 (epoch 9), train_loss = 2.746, time/batch = 0.211\n",
            "2852/15750 (epoch 9), train_loss = 2.808, time/batch = 0.199\n",
            "2853/15750 (epoch 9), train_loss = 2.796, time/batch = 0.201\n",
            "2854/15750 (epoch 9), train_loss = 2.740, time/batch = 0.203\n",
            "2855/15750 (epoch 9), train_loss = 2.754, time/batch = 0.199\n",
            "2856/15750 (epoch 9), train_loss = 2.744, time/batch = 0.205\n",
            "2857/15750 (epoch 9), train_loss = 2.712, time/batch = 0.201\n",
            "2858/15750 (epoch 9), train_loss = 2.756, time/batch = 0.198\n",
            "2859/15750 (epoch 9), train_loss = 2.737, time/batch = 0.201\n",
            "2860/15750 (epoch 9), train_loss = 2.786, time/batch = 0.191\n",
            "2861/15750 (epoch 9), train_loss = 2.757, time/batch = 0.206\n",
            "2862/15750 (epoch 9), train_loss = 2.764, time/batch = 0.204\n",
            "2863/15750 (epoch 9), train_loss = 2.907, time/batch = 0.194\n",
            "2864/15750 (epoch 9), train_loss = 2.794, time/batch = 0.200\n",
            "2865/15750 (epoch 9), train_loss = 2.753, time/batch = 0.208\n",
            "2866/15750 (epoch 9), train_loss = 2.734, time/batch = 0.207\n",
            "2867/15750 (epoch 9), train_loss = 2.649, time/batch = 0.199\n",
            "2868/15750 (epoch 9), train_loss = 2.671, time/batch = 0.203\n",
            "2869/15750 (epoch 9), train_loss = 2.730, time/batch = 0.203\n",
            "2870/15750 (epoch 9), train_loss = 2.656, time/batch = 0.200\n",
            "2871/15750 (epoch 9), train_loss = 2.660, time/batch = 0.199\n",
            "2872/15750 (epoch 9), train_loss = 2.741, time/batch = 0.203\n",
            "2873/15750 (epoch 9), train_loss = 2.654, time/batch = 0.204\n",
            "2874/15750 (epoch 9), train_loss = 2.715, time/batch = 0.205\n",
            "2875/15750 (epoch 9), train_loss = 2.693, time/batch = 0.198\n",
            "2876/15750 (epoch 9), train_loss = 2.748, time/batch = 0.207\n",
            "2877/15750 (epoch 9), train_loss = 2.740, time/batch = 0.193\n",
            "2878/15750 (epoch 9), train_loss = 2.664, time/batch = 0.203\n",
            "2879/15750 (epoch 9), train_loss = 2.723, time/batch = 0.202\n",
            "2880/15750 (epoch 9), train_loss = 2.626, time/batch = 0.204\n",
            "2881/15750 (epoch 9), train_loss = 2.660, time/batch = 0.204\n",
            "2882/15750 (epoch 9), train_loss = 2.728, time/batch = 0.202\n",
            "2883/15750 (epoch 9), train_loss = 2.746, time/batch = 0.202\n",
            "2884/15750 (epoch 9), train_loss = 2.659, time/batch = 0.204\n",
            "2885/15750 (epoch 9), train_loss = 2.685, time/batch = 0.202\n",
            "2886/15750 (epoch 9), train_loss = 2.665, time/batch = 0.209\n",
            "2887/15750 (epoch 9), train_loss = 2.723, time/batch = 0.201\n",
            "2888/15750 (epoch 9), train_loss = 2.722, time/batch = 0.198\n",
            "2889/15750 (epoch 9), train_loss = 2.708, time/batch = 0.195\n",
            "2890/15750 (epoch 9), train_loss = 2.758, time/batch = 0.204\n",
            "2891/15750 (epoch 9), train_loss = 2.623, time/batch = 0.206\n",
            "2892/15750 (epoch 9), train_loss = 2.636, time/batch = 0.192\n",
            "2893/15750 (epoch 9), train_loss = 2.698, time/batch = 0.203\n",
            "2894/15750 (epoch 9), train_loss = 2.553, time/batch = 0.200\n",
            "2895/15750 (epoch 9), train_loss = 2.681, time/batch = 0.200\n",
            "2896/15750 (epoch 9), train_loss = 2.664, time/batch = 0.206\n",
            "2897/15750 (epoch 9), train_loss = 2.602, time/batch = 0.207\n",
            "2898/15750 (epoch 9), train_loss = 2.640, time/batch = 0.203\n",
            "2899/15750 (epoch 9), train_loss = 2.612, time/batch = 0.195\n",
            "2900/15750 (epoch 9), train_loss = 2.601, time/batch = 0.209\n",
            "2901/15750 (epoch 9), train_loss = 2.547, time/batch = 0.203\n",
            "2902/15750 (epoch 9), train_loss = 2.567, time/batch = 0.197\n",
            "2903/15750 (epoch 9), train_loss = 2.618, time/batch = 0.205\n",
            "2904/15750 (epoch 9), train_loss = 2.703, time/batch = 0.195\n",
            "2905/15750 (epoch 9), train_loss = 2.629, time/batch = 0.204\n",
            "2906/15750 (epoch 9), train_loss = 2.640, time/batch = 0.208\n",
            "2907/15750 (epoch 9), train_loss = 2.502, time/batch = 0.199\n",
            "2908/15750 (epoch 9), train_loss = 2.622, time/batch = 0.202\n",
            "2909/15750 (epoch 9), train_loss = 2.724, time/batch = 0.201\n",
            "2910/15750 (epoch 9), train_loss = 2.661, time/batch = 0.202\n",
            "2911/15750 (epoch 9), train_loss = 2.657, time/batch = 0.194\n",
            "2912/15750 (epoch 9), train_loss = 2.642, time/batch = 0.204\n",
            "2913/15750 (epoch 9), train_loss = 2.665, time/batch = 0.199\n",
            "2914/15750 (epoch 9), train_loss = 2.685, time/batch = 0.205\n",
            "2915/15750 (epoch 9), train_loss = 2.577, time/batch = 0.200\n",
            "2916/15750 (epoch 9), train_loss = 2.681, time/batch = 0.202\n",
            "2917/15750 (epoch 9), train_loss = 2.600, time/batch = 0.201\n",
            "2918/15750 (epoch 9), train_loss = 2.669, time/batch = 0.202\n",
            "2919/15750 (epoch 9), train_loss = 2.735, time/batch = 0.202\n",
            "2920/15750 (epoch 9), train_loss = 2.745, time/batch = 0.201\n",
            "2921/15750 (epoch 9), train_loss = 2.581, time/batch = 0.203\n",
            "2922/15750 (epoch 9), train_loss = 2.636, time/batch = 0.201\n",
            "2923/15750 (epoch 9), train_loss = 2.661, time/batch = 0.203\n",
            "2924/15750 (epoch 9), train_loss = 2.607, time/batch = 0.202\n",
            "2925/15750 (epoch 9), train_loss = 2.652, time/batch = 0.202\n",
            "2926/15750 (epoch 9), train_loss = 2.709, time/batch = 0.202\n",
            "2927/15750 (epoch 9), train_loss = 2.716, time/batch = 0.199\n",
            "2928/15750 (epoch 9), train_loss = 2.721, time/batch = 0.201\n",
            "2929/15750 (epoch 9), train_loss = 2.747, time/batch = 0.201\n",
            "2930/15750 (epoch 9), train_loss = 2.654, time/batch = 0.201\n",
            "2931/15750 (epoch 9), train_loss = 2.675, time/batch = 0.199\n",
            "2932/15750 (epoch 9), train_loss = 2.677, time/batch = 0.207\n",
            "2933/15750 (epoch 9), train_loss = 2.702, time/batch = 0.204\n",
            "2934/15750 (epoch 9), train_loss = 2.683, time/batch = 0.201\n",
            "2935/15750 (epoch 9), train_loss = 2.665, time/batch = 0.199\n",
            "2936/15750 (epoch 9), train_loss = 2.588, time/batch = 0.199\n",
            "2937/15750 (epoch 9), train_loss = 2.617, time/batch = 0.209\n",
            "2938/15750 (epoch 9), train_loss = 2.755, time/batch = 0.201\n",
            "2939/15750 (epoch 9), train_loss = 2.693, time/batch = 0.201\n",
            "2940/15750 (epoch 9), train_loss = 2.620, time/batch = 0.203\n",
            "2941/15750 (epoch 9), train_loss = 2.679, time/batch = 0.202\n",
            "2942/15750 (epoch 9), train_loss = 2.669, time/batch = 0.211\n",
            "2943/15750 (epoch 9), train_loss = 2.747, time/batch = 0.198\n",
            "2944/15750 (epoch 9), train_loss = 2.748, time/batch = 0.201\n",
            "2945/15750 (epoch 9), train_loss = 2.782, time/batch = 0.205\n",
            "2946/15750 (epoch 9), train_loss = 2.682, time/batch = 0.198\n",
            "2947/15750 (epoch 9), train_loss = 2.657, time/batch = 0.206\n",
            "2948/15750 (epoch 9), train_loss = 2.681, time/batch = 0.197\n",
            "2949/15750 (epoch 9), train_loss = 2.672, time/batch = 0.202\n",
            "2950/15750 (epoch 9), train_loss = 2.753, time/batch = 0.203\n",
            "2951/15750 (epoch 9), train_loss = 2.681, time/batch = 0.203\n",
            "2952/15750 (epoch 9), train_loss = 2.816, time/batch = 0.208\n",
            "2953/15750 (epoch 9), train_loss = 2.670, time/batch = 0.199\n",
            "2954/15750 (epoch 9), train_loss = 2.645, time/batch = 0.199\n",
            "2955/15750 (epoch 9), train_loss = 2.633, time/batch = 0.203\n",
            "2956/15750 (epoch 9), train_loss = 2.618, time/batch = 0.206\n",
            "2957/15750 (epoch 9), train_loss = 2.644, time/batch = 0.202\n",
            "2958/15750 (epoch 9), train_loss = 2.639, time/batch = 0.198\n",
            "2959/15750 (epoch 9), train_loss = 2.647, time/batch = 0.194\n",
            "2960/15750 (epoch 9), train_loss = 2.674, time/batch = 0.203\n",
            "2961/15750 (epoch 9), train_loss = 2.769, time/batch = 0.204\n",
            "2962/15750 (epoch 9), train_loss = 2.610, time/batch = 0.205\n",
            "2963/15750 (epoch 9), train_loss = 2.590, time/batch = 0.197\n",
            "2964/15750 (epoch 9), train_loss = 2.626, time/batch = 0.208\n",
            "2965/15750 (epoch 9), train_loss = 2.569, time/batch = 0.204\n",
            "2966/15750 (epoch 9), train_loss = 2.579, time/batch = 0.200\n",
            "2967/15750 (epoch 9), train_loss = 2.603, time/batch = 0.211\n",
            "2968/15750 (epoch 9), train_loss = 2.581, time/batch = 0.201\n",
            "2969/15750 (epoch 9), train_loss = 2.653, time/batch = 0.203\n",
            "2970/15750 (epoch 9), train_loss = 2.738, time/batch = 0.194\n",
            "2971/15750 (epoch 9), train_loss = 2.709, time/batch = 0.201\n",
            "2972/15750 (epoch 9), train_loss = 2.725, time/batch = 0.208\n",
            "2973/15750 (epoch 9), train_loss = 2.708, time/batch = 0.202\n",
            "2974/15750 (epoch 9), train_loss = 2.632, time/batch = 0.195\n",
            "2975/15750 (epoch 9), train_loss = 2.628, time/batch = 0.202\n",
            "2976/15750 (epoch 9), train_loss = 2.714, time/batch = 0.200\n",
            "2977/15750 (epoch 9), train_loss = 2.726, time/batch = 0.209\n",
            "2978/15750 (epoch 9), train_loss = 2.714, time/batch = 0.199\n",
            "2979/15750 (epoch 9), train_loss = 2.649, time/batch = 0.198\n",
            "2980/15750 (epoch 9), train_loss = 2.641, time/batch = 0.205\n",
            "2981/15750 (epoch 9), train_loss = 2.575, time/batch = 0.201\n",
            "2982/15750 (epoch 9), train_loss = 2.664, time/batch = 0.203\n",
            "2983/15750 (epoch 9), train_loss = 2.702, time/batch = 0.199\n",
            "2984/15750 (epoch 9), train_loss = 2.638, time/batch = 0.199\n",
            "2985/15750 (epoch 9), train_loss = 2.650, time/batch = 0.203\n",
            "2986/15750 (epoch 9), train_loss = 2.671, time/batch = 0.203\n",
            "2987/15750 (epoch 9), train_loss = 2.763, time/batch = 0.212\n",
            "2988/15750 (epoch 9), train_loss = 2.697, time/batch = 0.196\n",
            "2989/15750 (epoch 9), train_loss = 2.686, time/batch = 0.201\n",
            "2990/15750 (epoch 9), train_loss = 2.704, time/batch = 0.204\n",
            "2991/15750 (epoch 9), train_loss = 2.714, time/batch = 0.196\n",
            "2992/15750 (epoch 9), train_loss = 2.684, time/batch = 0.204\n",
            "2993/15750 (epoch 9), train_loss = 2.776, time/batch = 0.203\n",
            "2994/15750 (epoch 9), train_loss = 2.628, time/batch = 0.202\n",
            "2995/15750 (epoch 9), train_loss = 2.718, time/batch = 0.199\n",
            "2996/15750 (epoch 9), train_loss = 2.684, time/batch = 0.198\n",
            "2997/15750 (epoch 9), train_loss = 2.753, time/batch = 0.205\n",
            "2998/15750 (epoch 9), train_loss = 2.813, time/batch = 0.205\n",
            "2999/15750 (epoch 9), train_loss = 2.736, time/batch = 0.202\n",
            "3000/15750 (epoch 9), train_loss = 2.740, time/batch = 0.201\n",
            "model saved to ./save_star/model.ckpt\n",
            "3001/15750 (epoch 9), train_loss = 2.748, time/batch = 0.206\n",
            "3002/15750 (epoch 9), train_loss = 2.678, time/batch = 0.205\n",
            "3003/15750 (epoch 9), train_loss = 2.643, time/batch = 0.211\n",
            "3004/15750 (epoch 9), train_loss = 2.637, time/batch = 0.202\n",
            "3005/15750 (epoch 9), train_loss = 2.712, time/batch = 0.204\n",
            "3006/15750 (epoch 9), train_loss = 2.751, time/batch = 0.213\n",
            "3007/15750 (epoch 9), train_loss = 2.680, time/batch = 0.206\n",
            "3008/15750 (epoch 9), train_loss = 2.729, time/batch = 0.207\n",
            "3009/15750 (epoch 9), train_loss = 2.705, time/batch = 0.203\n",
            "3010/15750 (epoch 9), train_loss = 2.606, time/batch = 0.205\n",
            "3011/15750 (epoch 9), train_loss = 2.650, time/batch = 0.213\n",
            "3012/15750 (epoch 9), train_loss = 2.707, time/batch = 0.207\n",
            "3013/15750 (epoch 9), train_loss = 2.633, time/batch = 0.204\n",
            "3014/15750 (epoch 9), train_loss = 2.597, time/batch = 0.203\n",
            "3015/15750 (epoch 9), train_loss = 2.601, time/batch = 0.204\n",
            "3016/15750 (epoch 9), train_loss = 2.728, time/batch = 0.215\n",
            "3017/15750 (epoch 9), train_loss = 2.641, time/batch = 0.204\n",
            "3018/15750 (epoch 9), train_loss = 2.733, time/batch = 0.203\n",
            "3019/15750 (epoch 9), train_loss = 2.727, time/batch = 0.202\n",
            "3020/15750 (epoch 9), train_loss = 2.637, time/batch = 0.203\n",
            "3021/15750 (epoch 9), train_loss = 2.622, time/batch = 0.213\n",
            "3022/15750 (epoch 9), train_loss = 2.692, time/batch = 0.198\n",
            "3023/15750 (epoch 9), train_loss = 2.759, time/batch = 0.204\n",
            "3024/15750 (epoch 9), train_loss = 2.814, time/batch = 0.201\n",
            "3025/15750 (epoch 9), train_loss = 2.735, time/batch = 0.204\n",
            "3026/15750 (epoch 9), train_loss = 2.684, time/batch = 0.210\n",
            "3027/15750 (epoch 9), train_loss = 2.695, time/batch = 0.207\n",
            "3028/15750 (epoch 9), train_loss = 2.630, time/batch = 0.213\n",
            "3029/15750 (epoch 9), train_loss = 2.727, time/batch = 0.205\n",
            "3030/15750 (epoch 9), train_loss = 2.754, time/batch = 0.203\n",
            "3031/15750 (epoch 9), train_loss = 2.662, time/batch = 0.215\n",
            "3032/15750 (epoch 9), train_loss = 2.631, time/batch = 0.200\n",
            "3033/15750 (epoch 9), train_loss = 2.716, time/batch = 0.204\n",
            "3034/15750 (epoch 9), train_loss = 2.540, time/batch = 0.207\n",
            "3035/15750 (epoch 9), train_loss = 2.618, time/batch = 0.205\n",
            "3036/15750 (epoch 9), train_loss = 2.595, time/batch = 0.207\n",
            "3037/15750 (epoch 9), train_loss = 2.668, time/batch = 0.202\n",
            "3038/15750 (epoch 9), train_loss = 2.656, time/batch = 0.210\n",
            "3039/15750 (epoch 9), train_loss = 2.699, time/batch = 0.203\n",
            "3040/15750 (epoch 9), train_loss = 2.674, time/batch = 0.209\n",
            "3041/15750 (epoch 9), train_loss = 2.545, time/batch = 0.212\n",
            "3042/15750 (epoch 9), train_loss = 2.608, time/batch = 0.204\n",
            "3043/15750 (epoch 9), train_loss = 2.621, time/batch = 0.204\n",
            "3044/15750 (epoch 9), train_loss = 2.644, time/batch = 0.204\n",
            "3045/15750 (epoch 9), train_loss = 2.516, time/batch = 0.203\n",
            "3046/15750 (epoch 9), train_loss = 2.622, time/batch = 0.203\n",
            "3047/15750 (epoch 9), train_loss = 2.516, time/batch = 0.203\n",
            "3048/15750 (epoch 9), train_loss = 2.577, time/batch = 0.201\n",
            "3049/15750 (epoch 9), train_loss = 2.575, time/batch = 0.199\n",
            "3050/15750 (epoch 9), train_loss = 2.596, time/batch = 0.203\n",
            "3051/15750 (epoch 9), train_loss = 2.737, time/batch = 0.205\n",
            "3052/15750 (epoch 9), train_loss = 2.548, time/batch = 0.198\n",
            "3053/15750 (epoch 9), train_loss = 2.780, time/batch = 0.200\n",
            "3054/15750 (epoch 9), train_loss = 2.625, time/batch = 0.207\n",
            "3055/15750 (epoch 9), train_loss = 2.541, time/batch = 0.201\n",
            "3056/15750 (epoch 9), train_loss = 2.587, time/batch = 0.207\n",
            "3057/15750 (epoch 9), train_loss = 2.658, time/batch = 0.202\n",
            "3058/15750 (epoch 9), train_loss = 2.648, time/batch = 0.204\n",
            "3059/15750 (epoch 9), train_loss = 2.606, time/batch = 0.201\n",
            "3060/15750 (epoch 9), train_loss = 2.610, time/batch = 0.199\n",
            "3061/15750 (epoch 9), train_loss = 2.697, time/batch = 0.207\n",
            "3062/15750 (epoch 9), train_loss = 2.609, time/batch = 0.200\n",
            "3063/15750 (epoch 9), train_loss = 2.642, time/batch = 0.203\n",
            "3064/15750 (epoch 9), train_loss = 2.712, time/batch = 0.200\n",
            "3065/15750 (epoch 9), train_loss = 2.584, time/batch = 0.200\n",
            "3066/15750 (epoch 9), train_loss = 2.595, time/batch = 0.206\n",
            "3067/15750 (epoch 9), train_loss = 2.641, time/batch = 0.205\n",
            "3068/15750 (epoch 9), train_loss = 2.657, time/batch = 0.200\n",
            "3069/15750 (epoch 9), train_loss = 2.577, time/batch = 0.202\n",
            "3070/15750 (epoch 9), train_loss = 2.598, time/batch = 0.203\n",
            "3071/15750 (epoch 9), train_loss = 2.534, time/batch = 0.208\n",
            "3072/15750 (epoch 9), train_loss = 2.621, time/batch = 0.198\n",
            "3073/15750 (epoch 9), train_loss = 2.823, time/batch = 0.199\n",
            "3074/15750 (epoch 9), train_loss = 2.620, time/batch = 0.205\n",
            "3075/15750 (epoch 9), train_loss = 2.695, time/batch = 0.197\n",
            "3076/15750 (epoch 9), train_loss = 2.579, time/batch = 0.206\n",
            "3077/15750 (epoch 9), train_loss = 2.661, time/batch = 0.204\n",
            "3078/15750 (epoch 9), train_loss = 2.665, time/batch = 0.200\n",
            "3079/15750 (epoch 9), train_loss = 2.643, time/batch = 0.197\n",
            "3080/15750 (epoch 9), train_loss = 2.703, time/batch = 0.204\n",
            "3081/15750 (epoch 9), train_loss = 2.666, time/batch = 0.206\n",
            "3082/15750 (epoch 9), train_loss = 2.681, time/batch = 0.201\n",
            "3083/15750 (epoch 9), train_loss = 2.654, time/batch = 0.202\n",
            "3084/15750 (epoch 9), train_loss = 2.672, time/batch = 0.199\n",
            "3085/15750 (epoch 9), train_loss = 2.586, time/batch = 0.198\n",
            "3086/15750 (epoch 9), train_loss = 2.595, time/batch = 0.202\n",
            "3087/15750 (epoch 9), train_loss = 2.670, time/batch = 0.202\n",
            "3088/15750 (epoch 9), train_loss = 2.664, time/batch = 0.203\n",
            "3089/15750 (epoch 9), train_loss = 2.636, time/batch = 0.203\n",
            "3090/15750 (epoch 9), train_loss = 2.619, time/batch = 0.195\n",
            "3091/15750 (epoch 9), train_loss = 2.562, time/batch = 0.206\n",
            "3092/15750 (epoch 9), train_loss = 2.579, time/batch = 0.202\n",
            "3093/15750 (epoch 9), train_loss = 2.762, time/batch = 0.204\n",
            "3094/15750 (epoch 9), train_loss = 2.684, time/batch = 0.202\n",
            "3095/15750 (epoch 9), train_loss = 2.677, time/batch = 0.195\n",
            "3096/15750 (epoch 9), train_loss = 2.624, time/batch = 0.205\n",
            "3097/15750 (epoch 9), train_loss = 2.672, time/batch = 0.200\n",
            "3098/15750 (epoch 9), train_loss = 2.635, time/batch = 0.200\n",
            "3099/15750 (epoch 9), train_loss = 2.712, time/batch = 0.200\n",
            "3100/15750 (epoch 9), train_loss = 2.715, time/batch = 0.203\n",
            "3101/15750 (epoch 9), train_loss = 2.751, time/batch = 0.206\n",
            "3102/15750 (epoch 9), train_loss = 2.651, time/batch = 0.198\n",
            "3103/15750 (epoch 9), train_loss = 2.686, time/batch = 0.199\n",
            "3104/15750 (epoch 9), train_loss = 2.726, time/batch = 0.199\n",
            "3105/15750 (epoch 9), train_loss = 2.686, time/batch = 0.206\n",
            "3106/15750 (epoch 9), train_loss = 2.562, time/batch = 0.207\n",
            "3107/15750 (epoch 9), train_loss = 2.637, time/batch = 0.195\n",
            "3108/15750 (epoch 9), train_loss = 2.687, time/batch = 0.198\n",
            "3109/15750 (epoch 9), train_loss = 2.709, time/batch = 0.203\n",
            "3110/15750 (epoch 9), train_loss = 2.692, time/batch = 0.203\n",
            "3111/15750 (epoch 9), train_loss = 2.718, time/batch = 0.207\n",
            "3112/15750 (epoch 9), train_loss = 2.645, time/batch = 0.202\n",
            "3113/15750 (epoch 9), train_loss = 2.598, time/batch = 0.201\n",
            "3114/15750 (epoch 9), train_loss = 2.571, time/batch = 0.202\n",
            "3115/15750 (epoch 9), train_loss = 2.827, time/batch = 0.202\n",
            "3116/15750 (epoch 9), train_loss = 2.620, time/batch = 0.205\n",
            "3117/15750 (epoch 9), train_loss = 2.587, time/batch = 0.205\n",
            "3118/15750 (epoch 9), train_loss = 2.738, time/batch = 0.202\n",
            "3119/15750 (epoch 9), train_loss = 2.587, time/batch = 0.200\n",
            "3120/15750 (epoch 9), train_loss = 2.751, time/batch = 0.204\n",
            "3121/15750 (epoch 9), train_loss = 2.617, time/batch = 0.205\n",
            "3122/15750 (epoch 9), train_loss = 2.642, time/batch = 0.199\n",
            "3123/15750 (epoch 9), train_loss = 2.562, time/batch = 0.201\n",
            "3124/15750 (epoch 9), train_loss = 2.646, time/batch = 0.201\n",
            "3125/15750 (epoch 9), train_loss = 2.550, time/batch = 0.199\n",
            "3126/15750 (epoch 9), train_loss = 2.669, time/batch = 0.210\n",
            "3127/15750 (epoch 9), train_loss = 2.644, time/batch = 0.197\n",
            "3128/15750 (epoch 9), train_loss = 2.624, time/batch = 0.202\n",
            "3129/15750 (epoch 9), train_loss = 2.686, time/batch = 0.199\n",
            "3130/15750 (epoch 9), train_loss = 2.752, time/batch = 0.200\n",
            "3131/15750 (epoch 9), train_loss = 2.701, time/batch = 0.201\n",
            "3132/15750 (epoch 9), train_loss = 2.736, time/batch = 0.218\n",
            "3133/15750 (epoch 9), train_loss = 2.584, time/batch = 0.208\n",
            "3134/15750 (epoch 9), train_loss = 2.687, time/batch = 0.206\n",
            "3135/15750 (epoch 9), train_loss = 2.645, time/batch = 0.207\n",
            "3136/15750 (epoch 9), train_loss = 2.564, time/batch = 0.199\n",
            "3137/15750 (epoch 9), train_loss = 2.690, time/batch = 0.212\n",
            "3138/15750 (epoch 9), train_loss = 2.551, time/batch = 0.206\n",
            "3139/15750 (epoch 9), train_loss = 2.691, time/batch = 0.199\n",
            "3140/15750 (epoch 9), train_loss = 2.653, time/batch = 0.205\n",
            "3141/15750 (epoch 9), train_loss = 2.634, time/batch = 0.210\n",
            "3142/15750 (epoch 9), train_loss = 2.562, time/batch = 0.211\n",
            "3143/15750 (epoch 9), train_loss = 2.585, time/batch = 0.203\n",
            "3144/15750 (epoch 9), train_loss = 2.725, time/batch = 0.201\n",
            "3145/15750 (epoch 9), train_loss = 2.557, time/batch = 0.203\n",
            "3146/15750 (epoch 9), train_loss = 2.518, time/batch = 0.210\n",
            "3147/15750 (epoch 9), train_loss = 2.607, time/batch = 0.214\n",
            "3148/15750 (epoch 9), train_loss = 2.591, time/batch = 0.208\n",
            "3149/15750 (epoch 9), train_loss = 2.690, time/batch = 0.200\n",
            "3150/15750 (epoch 10), train_loss = 2.739, time/batch = 0.207\n",
            "3151/15750 (epoch 10), train_loss = 2.706, time/batch = 0.207\n",
            "3152/15750 (epoch 10), train_loss = 2.644, time/batch = 0.210\n",
            "3153/15750 (epoch 10), train_loss = 2.746, time/batch = 0.206\n",
            "3154/15750 (epoch 10), train_loss = 2.652, time/batch = 0.204\n",
            "3155/15750 (epoch 10), train_loss = 2.638, time/batch = 0.208\n",
            "3156/15750 (epoch 10), train_loss = 2.811, time/batch = 0.209\n",
            "3157/15750 (epoch 10), train_loss = 2.730, time/batch = 0.205\n",
            "3158/15750 (epoch 10), train_loss = 2.703, time/batch = 0.207\n",
            "3159/15750 (epoch 10), train_loss = 2.674, time/batch = 0.200\n",
            "3160/15750 (epoch 10), train_loss = 2.641, time/batch = 0.213\n",
            "3161/15750 (epoch 10), train_loss = 2.588, time/batch = 0.207\n",
            "3162/15750 (epoch 10), train_loss = 2.730, time/batch = 0.198\n",
            "3163/15750 (epoch 10), train_loss = 2.656, time/batch = 0.204\n",
            "3164/15750 (epoch 10), train_loss = 2.663, time/batch = 0.203\n",
            "3165/15750 (epoch 10), train_loss = 2.661, time/batch = 0.203\n",
            "3166/15750 (epoch 10), train_loss = 2.695, time/batch = 0.203\n",
            "3167/15750 (epoch 10), train_loss = 2.760, time/batch = 0.202\n",
            "3168/15750 (epoch 10), train_loss = 2.750, time/batch = 0.201\n",
            "3169/15750 (epoch 10), train_loss = 2.693, time/batch = 0.200\n",
            "3170/15750 (epoch 10), train_loss = 2.703, time/batch = 0.201\n",
            "3171/15750 (epoch 10), train_loss = 2.699, time/batch = 0.205\n",
            "3172/15750 (epoch 10), train_loss = 2.664, time/batch = 0.199\n",
            "3173/15750 (epoch 10), train_loss = 2.713, time/batch = 0.203\n",
            "3174/15750 (epoch 10), train_loss = 2.693, time/batch = 0.201\n",
            "3175/15750 (epoch 10), train_loss = 2.739, time/batch = 0.198\n",
            "3176/15750 (epoch 10), train_loss = 2.714, time/batch = 0.207\n",
            "3177/15750 (epoch 10), train_loss = 2.720, time/batch = 0.204\n",
            "3178/15750 (epoch 10), train_loss = 2.860, time/batch = 0.199\n",
            "3179/15750 (epoch 10), train_loss = 2.751, time/batch = 0.200\n",
            "3180/15750 (epoch 10), train_loss = 2.708, time/batch = 0.204\n",
            "3181/15750 (epoch 10), train_loss = 2.690, time/batch = 0.211\n",
            "3182/15750 (epoch 10), train_loss = 2.599, time/batch = 0.202\n",
            "3183/15750 (epoch 10), train_loss = 2.623, time/batch = 0.195\n",
            "3184/15750 (epoch 10), train_loss = 2.686, time/batch = 0.198\n",
            "3185/15750 (epoch 10), train_loss = 2.607, time/batch = 0.204\n",
            "3186/15750 (epoch 10), train_loss = 2.620, time/batch = 0.202\n",
            "3187/15750 (epoch 10), train_loss = 2.698, time/batch = 0.201\n",
            "3188/15750 (epoch 10), train_loss = 2.610, time/batch = 0.203\n",
            "3189/15750 (epoch 10), train_loss = 2.669, time/batch = 0.194\n",
            "3190/15750 (epoch 10), train_loss = 2.646, time/batch = 0.200\n",
            "3191/15750 (epoch 10), train_loss = 2.700, time/batch = 0.203\n",
            "3192/15750 (epoch 10), train_loss = 2.693, time/batch = 0.203\n",
            "3193/15750 (epoch 10), train_loss = 2.620, time/batch = 0.201\n",
            "3194/15750 (epoch 10), train_loss = 2.679, time/batch = 0.202\n",
            "3195/15750 (epoch 10), train_loss = 2.580, time/batch = 0.204\n",
            "3196/15750 (epoch 10), train_loss = 2.616, time/batch = 0.201\n",
            "3197/15750 (epoch 10), train_loss = 2.682, time/batch = 0.202\n",
            "3198/15750 (epoch 10), train_loss = 2.703, time/batch = 0.203\n",
            "3199/15750 (epoch 10), train_loss = 2.611, time/batch = 0.197\n",
            "3200/15750 (epoch 10), train_loss = 2.643, time/batch = 0.207\n",
            "3201/15750 (epoch 10), train_loss = 2.617, time/batch = 0.207\n",
            "3202/15750 (epoch 10), train_loss = 2.674, time/batch = 0.196\n",
            "3203/15750 (epoch 10), train_loss = 2.677, time/batch = 0.200\n",
            "3204/15750 (epoch 10), train_loss = 2.664, time/batch = 0.202\n",
            "3205/15750 (epoch 10), train_loss = 2.712, time/batch = 0.196\n",
            "3206/15750 (epoch 10), train_loss = 2.575, time/batch = 0.211\n",
            "3207/15750 (epoch 10), train_loss = 2.589, time/batch = 0.200\n",
            "3208/15750 (epoch 10), train_loss = 2.654, time/batch = 0.200\n",
            "3209/15750 (epoch 10), train_loss = 2.510, time/batch = 0.202\n",
            "3210/15750 (epoch 10), train_loss = 2.638, time/batch = 0.204\n",
            "3211/15750 (epoch 10), train_loss = 2.622, time/batch = 0.206\n",
            "3212/15750 (epoch 10), train_loss = 2.560, time/batch = 0.199\n",
            "3213/15750 (epoch 10), train_loss = 2.599, time/batch = 0.196\n",
            "3214/15750 (epoch 10), train_loss = 2.564, time/batch = 0.203\n",
            "3215/15750 (epoch 10), train_loss = 2.555, time/batch = 0.204\n",
            "3216/15750 (epoch 10), train_loss = 2.498, time/batch = 0.209\n",
            "3217/15750 (epoch 10), train_loss = 2.523, time/batch = 0.202\n",
            "3218/15750 (epoch 10), train_loss = 2.574, time/batch = 0.201\n",
            "3219/15750 (epoch 10), train_loss = 2.659, time/batch = 0.203\n",
            "3220/15750 (epoch 10), train_loss = 2.585, time/batch = 0.215\n",
            "3221/15750 (epoch 10), train_loss = 2.591, time/batch = 0.207\n",
            "3222/15750 (epoch 10), train_loss = 2.464, time/batch = 0.206\n",
            "3223/15750 (epoch 10), train_loss = 2.575, time/batch = 0.203\n",
            "3224/15750 (epoch 10), train_loss = 2.677, time/batch = 0.207\n",
            "3225/15750 (epoch 10), train_loss = 2.617, time/batch = 0.206\n",
            "3226/15750 (epoch 10), train_loss = 2.609, time/batch = 0.210\n",
            "3227/15750 (epoch 10), train_loss = 2.598, time/batch = 0.201\n",
            "3228/15750 (epoch 10), train_loss = 2.621, time/batch = 0.206\n",
            "3229/15750 (epoch 10), train_loss = 2.638, time/batch = 0.203\n",
            "3230/15750 (epoch 10), train_loss = 2.532, time/batch = 0.197\n",
            "3231/15750 (epoch 10), train_loss = 2.634, time/batch = 0.204\n",
            "3232/15750 (epoch 10), train_loss = 2.555, time/batch = 0.201\n",
            "3233/15750 (epoch 10), train_loss = 2.624, time/batch = 0.204\n",
            "3234/15750 (epoch 10), train_loss = 2.689, time/batch = 0.201\n",
            "3235/15750 (epoch 10), train_loss = 2.700, time/batch = 0.210\n",
            "3236/15750 (epoch 10), train_loss = 2.537, time/batch = 0.204\n",
            "3237/15750 (epoch 10), train_loss = 2.585, time/batch = 0.212\n",
            "3238/15750 (epoch 10), train_loss = 2.612, time/batch = 0.201\n",
            "3239/15750 (epoch 10), train_loss = 2.565, time/batch = 0.199\n",
            "3240/15750 (epoch 10), train_loss = 2.603, time/batch = 0.210\n",
            "3241/15750 (epoch 10), train_loss = 2.658, time/batch = 0.210\n",
            "3242/15750 (epoch 10), train_loss = 2.664, time/batch = 0.202\n",
            "3243/15750 (epoch 10), train_loss = 2.673, time/batch = 0.202\n",
            "3244/15750 (epoch 10), train_loss = 2.705, time/batch = 0.203\n",
            "3245/15750 (epoch 10), train_loss = 2.611, time/batch = 0.203\n",
            "3246/15750 (epoch 10), train_loss = 2.633, time/batch = 0.205\n",
            "3247/15750 (epoch 10), train_loss = 2.635, time/batch = 0.200\n",
            "3248/15750 (epoch 10), train_loss = 2.654, time/batch = 0.202\n",
            "3249/15750 (epoch 10), train_loss = 2.645, time/batch = 0.203\n",
            "3250/15750 (epoch 10), train_loss = 2.624, time/batch = 0.201\n",
            "3251/15750 (epoch 10), train_loss = 2.545, time/batch = 0.207\n",
            "3252/15750 (epoch 10), train_loss = 2.576, time/batch = 0.190\n",
            "3253/15750 (epoch 10), train_loss = 2.711, time/batch = 0.199\n",
            "3254/15750 (epoch 10), train_loss = 2.649, time/batch = 0.200\n",
            "3255/15750 (epoch 10), train_loss = 2.575, time/batch = 0.199\n",
            "3256/15750 (epoch 10), train_loss = 2.633, time/batch = 0.205\n",
            "3257/15750 (epoch 10), train_loss = 2.629, time/batch = 0.204\n",
            "3258/15750 (epoch 10), train_loss = 2.699, time/batch = 0.204\n",
            "3259/15750 (epoch 10), train_loss = 2.703, time/batch = 0.199\n",
            "3260/15750 (epoch 10), train_loss = 2.738, time/batch = 0.202\n",
            "3261/15750 (epoch 10), train_loss = 2.637, time/batch = 0.203\n",
            "3262/15750 (epoch 10), train_loss = 2.611, time/batch = 0.204\n",
            "3263/15750 (epoch 10), train_loss = 2.635, time/batch = 0.199\n",
            "3264/15750 (epoch 10), train_loss = 2.631, time/batch = 0.203\n",
            "3265/15750 (epoch 10), train_loss = 2.709, time/batch = 0.202\n",
            "3266/15750 (epoch 10), train_loss = 2.637, time/batch = 0.203\n",
            "3267/15750 (epoch 10), train_loss = 2.771, time/batch = 0.197\n",
            "3268/15750 (epoch 10), train_loss = 2.628, time/batch = 0.200\n",
            "3269/15750 (epoch 10), train_loss = 2.604, time/batch = 0.200\n",
            "3270/15750 (epoch 10), train_loss = 2.591, time/batch = 0.203\n",
            "3271/15750 (epoch 10), train_loss = 2.574, time/batch = 0.201\n",
            "3272/15750 (epoch 10), train_loss = 2.601, time/batch = 0.195\n",
            "3273/15750 (epoch 10), train_loss = 2.594, time/batch = 0.203\n",
            "3274/15750 (epoch 10), train_loss = 2.605, time/batch = 0.201\n",
            "3275/15750 (epoch 10), train_loss = 2.629, time/batch = 0.199\n",
            "3276/15750 (epoch 10), train_loss = 2.724, time/batch = 0.207\n",
            "3277/15750 (epoch 10), train_loss = 2.568, time/batch = 0.212\n",
            "3278/15750 (epoch 10), train_loss = 2.553, time/batch = 0.202\n",
            "3279/15750 (epoch 10), train_loss = 2.582, time/batch = 0.202\n",
            "3280/15750 (epoch 10), train_loss = 2.527, time/batch = 0.196\n",
            "3281/15750 (epoch 10), train_loss = 2.536, time/batch = 0.206\n",
            "3282/15750 (epoch 10), train_loss = 2.556, time/batch = 0.210\n",
            "3283/15750 (epoch 10), train_loss = 2.539, time/batch = 0.204\n",
            "3284/15750 (epoch 10), train_loss = 2.607, time/batch = 0.205\n",
            "3285/15750 (epoch 10), train_loss = 2.699, time/batch = 0.200\n",
            "3286/15750 (epoch 10), train_loss = 2.666, time/batch = 0.196\n",
            "3287/15750 (epoch 10), train_loss = 2.681, time/batch = 0.211\n",
            "3288/15750 (epoch 10), train_loss = 2.664, time/batch = 0.200\n",
            "3289/15750 (epoch 10), train_loss = 2.587, time/batch = 0.196\n",
            "3290/15750 (epoch 10), train_loss = 2.584, time/batch = 0.198\n",
            "3291/15750 (epoch 10), train_loss = 2.669, time/batch = 0.203\n",
            "3292/15750 (epoch 10), train_loss = 2.682, time/batch = 0.206\n",
            "3293/15750 (epoch 10), train_loss = 2.674, time/batch = 0.204\n",
            "3294/15750 (epoch 10), train_loss = 2.607, time/batch = 0.194\n",
            "3295/15750 (epoch 10), train_loss = 2.596, time/batch = 0.199\n",
            "3296/15750 (epoch 10), train_loss = 2.532, time/batch = 0.201\n",
            "3297/15750 (epoch 10), train_loss = 2.622, time/batch = 0.206\n",
            "3298/15750 (epoch 10), train_loss = 2.660, time/batch = 0.204\n",
            "3299/15750 (epoch 10), train_loss = 2.599, time/batch = 0.201\n",
            "3300/15750 (epoch 10), train_loss = 2.608, time/batch = 0.200\n",
            "3301/15750 (epoch 10), train_loss = 2.632, time/batch = 0.203\n",
            "3302/15750 (epoch 10), train_loss = 2.719, time/batch = 0.211\n",
            "3303/15750 (epoch 10), train_loss = 2.653, time/batch = 0.201\n",
            "3304/15750 (epoch 10), train_loss = 2.645, time/batch = 0.200\n",
            "3305/15750 (epoch 10), train_loss = 2.659, time/batch = 0.201\n",
            "3306/15750 (epoch 10), train_loss = 2.664, time/batch = 0.192\n",
            "3307/15750 (epoch 10), train_loss = 2.638, time/batch = 0.207\n",
            "3308/15750 (epoch 10), train_loss = 2.735, time/batch = 0.202\n",
            "3309/15750 (epoch 10), train_loss = 2.583, time/batch = 0.197\n",
            "3310/15750 (epoch 10), train_loss = 2.671, time/batch = 0.201\n",
            "3311/15750 (epoch 10), train_loss = 2.644, time/batch = 0.199\n",
            "3312/15750 (epoch 10), train_loss = 2.704, time/batch = 0.206\n",
            "3313/15750 (epoch 10), train_loss = 2.770, time/batch = 0.199\n",
            "3314/15750 (epoch 10), train_loss = 2.689, time/batch = 0.204\n",
            "3315/15750 (epoch 10), train_loss = 2.698, time/batch = 0.201\n",
            "3316/15750 (epoch 10), train_loss = 2.700, time/batch = 0.202\n",
            "3317/15750 (epoch 10), train_loss = 2.634, time/batch = 0.207\n",
            "3318/15750 (epoch 10), train_loss = 2.597, time/batch = 0.198\n",
            "3319/15750 (epoch 10), train_loss = 2.592, time/batch = 0.206\n",
            "3320/15750 (epoch 10), train_loss = 2.664, time/batch = 0.203\n",
            "3321/15750 (epoch 10), train_loss = 2.704, time/batch = 0.200\n",
            "3322/15750 (epoch 10), train_loss = 2.635, time/batch = 0.205\n",
            "3323/15750 (epoch 10), train_loss = 2.684, time/batch = 0.202\n",
            "3324/15750 (epoch 10), train_loss = 2.657, time/batch = 0.201\n",
            "3325/15750 (epoch 10), train_loss = 2.564, time/batch = 0.207\n",
            "3326/15750 (epoch 10), train_loss = 2.605, time/batch = 0.205\n",
            "3327/15750 (epoch 10), train_loss = 2.662, time/batch = 0.218\n",
            "3328/15750 (epoch 10), train_loss = 2.589, time/batch = 0.208\n",
            "3329/15750 (epoch 10), train_loss = 2.553, time/batch = 0.203\n",
            "3330/15750 (epoch 10), train_loss = 2.559, time/batch = 0.205\n",
            "3331/15750 (epoch 10), train_loss = 2.685, time/batch = 0.207\n",
            "3332/15750 (epoch 10), train_loss = 2.602, time/batch = 0.207\n",
            "3333/15750 (epoch 10), train_loss = 2.692, time/batch = 0.203\n",
            "3334/15750 (epoch 10), train_loss = 2.686, time/batch = 0.203\n",
            "3335/15750 (epoch 10), train_loss = 2.594, time/batch = 0.205\n",
            "3336/15750 (epoch 10), train_loss = 2.577, time/batch = 0.203\n",
            "3337/15750 (epoch 10), train_loss = 2.649, time/batch = 0.208\n",
            "3338/15750 (epoch 10), train_loss = 2.714, time/batch = 0.205\n",
            "3339/15750 (epoch 10), train_loss = 2.771, time/batch = 0.205\n",
            "3340/15750 (epoch 10), train_loss = 2.696, time/batch = 0.201\n",
            "3341/15750 (epoch 10), train_loss = 2.641, time/batch = 0.209\n",
            "3342/15750 (epoch 10), train_loss = 2.651, time/batch = 0.213\n",
            "3343/15750 (epoch 10), train_loss = 2.587, time/batch = 0.201\n",
            "3344/15750 (epoch 10), train_loss = 2.686, time/batch = 0.203\n",
            "3345/15750 (epoch 10), train_loss = 2.712, time/batch = 0.205\n",
            "3346/15750 (epoch 10), train_loss = 2.623, time/batch = 0.205\n",
            "3347/15750 (epoch 10), train_loss = 2.587, time/batch = 0.205\n",
            "3348/15750 (epoch 10), train_loss = 2.674, time/batch = 0.196\n",
            "3349/15750 (epoch 10), train_loss = 2.495, time/batch = 0.203\n",
            "3350/15750 (epoch 10), train_loss = 2.576, time/batch = 0.204\n",
            "3351/15750 (epoch 10), train_loss = 2.553, time/batch = 0.198\n",
            "3352/15750 (epoch 10), train_loss = 2.627, time/batch = 0.205\n",
            "3353/15750 (epoch 10), train_loss = 2.611, time/batch = 0.195\n",
            "3354/15750 (epoch 10), train_loss = 2.658, time/batch = 0.207\n",
            "3355/15750 (epoch 10), train_loss = 2.632, time/batch = 0.202\n",
            "3356/15750 (epoch 10), train_loss = 2.498, time/batch = 0.198\n",
            "3357/15750 (epoch 10), train_loss = 2.566, time/batch = 0.205\n",
            "3358/15750 (epoch 10), train_loss = 2.576, time/batch = 0.205\n",
            "3359/15750 (epoch 10), train_loss = 2.604, time/batch = 0.199\n",
            "3360/15750 (epoch 10), train_loss = 2.476, time/batch = 0.195\n",
            "3361/15750 (epoch 10), train_loss = 2.580, time/batch = 0.203\n",
            "3362/15750 (epoch 10), train_loss = 2.473, time/batch = 0.206\n",
            "3363/15750 (epoch 10), train_loss = 2.536, time/batch = 0.200\n",
            "3364/15750 (epoch 10), train_loss = 2.535, time/batch = 0.201\n",
            "3365/15750 (epoch 10), train_loss = 2.552, time/batch = 0.201\n",
            "3366/15750 (epoch 10), train_loss = 2.695, time/batch = 0.200\n",
            "3367/15750 (epoch 10), train_loss = 2.504, time/batch = 0.203\n",
            "3368/15750 (epoch 10), train_loss = 2.741, time/batch = 0.203\n",
            "3369/15750 (epoch 10), train_loss = 2.586, time/batch = 0.201\n",
            "3370/15750 (epoch 10), train_loss = 2.498, time/batch = 0.202\n",
            "3371/15750 (epoch 10), train_loss = 2.546, time/batch = 0.202\n",
            "3372/15750 (epoch 10), train_loss = 2.613, time/batch = 0.205\n",
            "3373/15750 (epoch 10), train_loss = 2.603, time/batch = 0.199\n",
            "3374/15750 (epoch 10), train_loss = 2.566, time/batch = 0.202\n",
            "3375/15750 (epoch 10), train_loss = 2.566, time/batch = 0.202\n",
            "3376/15750 (epoch 10), train_loss = 2.652, time/batch = 0.201\n",
            "3377/15750 (epoch 10), train_loss = 2.567, time/batch = 0.208\n",
            "3378/15750 (epoch 10), train_loss = 2.601, time/batch = 0.202\n",
            "3379/15750 (epoch 10), train_loss = 2.674, time/batch = 0.197\n",
            "3380/15750 (epoch 10), train_loss = 2.543, time/batch = 0.203\n",
            "3381/15750 (epoch 10), train_loss = 2.552, time/batch = 0.201\n",
            "3382/15750 (epoch 10), train_loss = 2.600, time/batch = 0.207\n",
            "3383/15750 (epoch 10), train_loss = 2.615, time/batch = 0.198\n",
            "3384/15750 (epoch 10), train_loss = 2.535, time/batch = 0.201\n",
            "3385/15750 (epoch 10), train_loss = 2.553, time/batch = 0.203\n",
            "3386/15750 (epoch 10), train_loss = 2.494, time/batch = 0.202\n",
            "3387/15750 (epoch 10), train_loss = 2.581, time/batch = 0.201\n",
            "3388/15750 (epoch 10), train_loss = 2.782, time/batch = 0.198\n",
            "3389/15750 (epoch 10), train_loss = 2.579, time/batch = 0.203\n",
            "3390/15750 (epoch 10), train_loss = 2.654, time/batch = 0.203\n",
            "3391/15750 (epoch 10), train_loss = 2.537, time/batch = 0.202\n",
            "3392/15750 (epoch 10), train_loss = 2.614, time/batch = 0.200\n",
            "3393/15750 (epoch 10), train_loss = 2.621, time/batch = 0.194\n",
            "3394/15750 (epoch 10), train_loss = 2.600, time/batch = 0.201\n",
            "3395/15750 (epoch 10), train_loss = 2.662, time/batch = 0.201\n",
            "3396/15750 (epoch 10), train_loss = 2.624, time/batch = 0.200\n",
            "3397/15750 (epoch 10), train_loss = 2.636, time/batch = 0.200\n",
            "3398/15750 (epoch 10), train_loss = 2.612, time/batch = 0.211\n",
            "3399/15750 (epoch 10), train_loss = 2.630, time/batch = 0.199\n",
            "3400/15750 (epoch 10), train_loss = 2.543, time/batch = 0.205\n",
            "3401/15750 (epoch 10), train_loss = 2.551, time/batch = 0.202\n",
            "3402/15750 (epoch 10), train_loss = 2.625, time/batch = 0.201\n",
            "3403/15750 (epoch 10), train_loss = 2.621, time/batch = 0.205\n",
            "3404/15750 (epoch 10), train_loss = 2.594, time/batch = 0.202\n",
            "3405/15750 (epoch 10), train_loss = 2.578, time/batch = 0.201\n",
            "3406/15750 (epoch 10), train_loss = 2.522, time/batch = 0.201\n",
            "3407/15750 (epoch 10), train_loss = 2.539, time/batch = 0.201\n",
            "3408/15750 (epoch 10), train_loss = 2.719, time/batch = 0.209\n",
            "3409/15750 (epoch 10), train_loss = 2.645, time/batch = 0.199\n",
            "3410/15750 (epoch 10), train_loss = 2.636, time/batch = 0.201\n",
            "3411/15750 (epoch 10), train_loss = 2.582, time/batch = 0.201\n",
            "3412/15750 (epoch 10), train_loss = 2.627, time/batch = 0.201\n",
            "3413/15750 (epoch 10), train_loss = 2.594, time/batch = 0.208\n",
            "3414/15750 (epoch 10), train_loss = 2.665, time/batch = 0.193\n",
            "3415/15750 (epoch 10), train_loss = 2.675, time/batch = 0.209\n",
            "3416/15750 (epoch 10), train_loss = 2.706, time/batch = 0.204\n",
            "3417/15750 (epoch 10), train_loss = 2.609, time/batch = 0.199\n",
            "3418/15750 (epoch 10), train_loss = 2.644, time/batch = 0.202\n",
            "3419/15750 (epoch 10), train_loss = 2.683, time/batch = 0.200\n",
            "3420/15750 (epoch 10), train_loss = 2.645, time/batch = 0.200\n",
            "3421/15750 (epoch 10), train_loss = 2.527, time/batch = 0.203\n",
            "3422/15750 (epoch 10), train_loss = 2.597, time/batch = 0.205\n",
            "3423/15750 (epoch 10), train_loss = 2.648, time/batch = 0.203\n",
            "3424/15750 (epoch 10), train_loss = 2.668, time/batch = 0.202\n",
            "3425/15750 (epoch 10), train_loss = 2.647, time/batch = 0.206\n",
            "3426/15750 (epoch 10), train_loss = 2.679, time/batch = 0.200\n",
            "3427/15750 (epoch 10), train_loss = 2.604, time/batch = 0.198\n",
            "3428/15750 (epoch 10), train_loss = 2.555, time/batch = 0.209\n",
            "3429/15750 (epoch 10), train_loss = 2.528, time/batch = 0.198\n",
            "3430/15750 (epoch 10), train_loss = 2.783, time/batch = 0.195\n",
            "3431/15750 (epoch 10), train_loss = 2.581, time/batch = 0.207\n",
            "3432/15750 (epoch 10), train_loss = 2.546, time/batch = 0.201\n",
            "3433/15750 (epoch 10), train_loss = 2.695, time/batch = 0.206\n",
            "3434/15750 (epoch 10), train_loss = 2.548, time/batch = 0.198\n",
            "3435/15750 (epoch 10), train_loss = 2.710, time/batch = 0.200\n",
            "3436/15750 (epoch 10), train_loss = 2.576, time/batch = 0.202\n",
            "3437/15750 (epoch 10), train_loss = 2.600, time/batch = 0.201\n",
            "3438/15750 (epoch 10), train_loss = 2.521, time/batch = 0.205\n",
            "3439/15750 (epoch 10), train_loss = 2.606, time/batch = 0.200\n",
            "3440/15750 (epoch 10), train_loss = 2.513, time/batch = 0.195\n",
            "3441/15750 (epoch 10), train_loss = 2.627, time/batch = 0.199\n",
            "3442/15750 (epoch 10), train_loss = 2.606, time/batch = 0.199\n",
            "3443/15750 (epoch 10), train_loss = 2.583, time/batch = 0.211\n",
            "3444/15750 (epoch 10), train_loss = 2.641, time/batch = 0.202\n",
            "3445/15750 (epoch 10), train_loss = 2.711, time/batch = 0.200\n",
            "3446/15750 (epoch 10), train_loss = 2.661, time/batch = 0.204\n",
            "3447/15750 (epoch 10), train_loss = 2.694, time/batch = 0.200\n",
            "3448/15750 (epoch 10), train_loss = 2.543, time/batch = 0.205\n",
            "3449/15750 (epoch 10), train_loss = 2.642, time/batch = 0.199\n",
            "3450/15750 (epoch 10), train_loss = 2.604, time/batch = 0.200\n",
            "3451/15750 (epoch 10), train_loss = 2.524, time/batch = 0.200\n",
            "3452/15750 (epoch 10), train_loss = 2.650, time/batch = 0.202\n",
            "3453/15750 (epoch 10), train_loss = 2.510, time/batch = 0.201\n",
            "3454/15750 (epoch 10), train_loss = 2.650, time/batch = 0.202\n",
            "3455/15750 (epoch 10), train_loss = 2.608, time/batch = 0.204\n",
            "3456/15750 (epoch 10), train_loss = 2.590, time/batch = 0.206\n",
            "3457/15750 (epoch 10), train_loss = 2.520, time/batch = 0.201\n",
            "3458/15750 (epoch 10), train_loss = 2.547, time/batch = 0.204\n",
            "3459/15750 (epoch 10), train_loss = 2.683, time/batch = 0.201\n",
            "3460/15750 (epoch 10), train_loss = 2.517, time/batch = 0.205\n",
            "3461/15750 (epoch 10), train_loss = 2.481, time/batch = 0.198\n",
            "3462/15750 (epoch 10), train_loss = 2.566, time/batch = 0.204\n",
            "3463/15750 (epoch 10), train_loss = 2.550, time/batch = 0.207\n",
            "3464/15750 (epoch 10), train_loss = 2.651, time/batch = 0.204\n",
            "3465/15750 (epoch 11), train_loss = 2.694, time/batch = 0.200\n",
            "3466/15750 (epoch 11), train_loss = 2.665, time/batch = 0.199\n",
            "3467/15750 (epoch 11), train_loss = 2.602, time/batch = 0.208\n",
            "3468/15750 (epoch 11), train_loss = 2.703, time/batch = 0.199\n",
            "3469/15750 (epoch 11), train_loss = 2.613, time/batch = 0.199\n",
            "3470/15750 (epoch 11), train_loss = 2.597, time/batch = 0.206\n",
            "3471/15750 (epoch 11), train_loss = 2.772, time/batch = 0.206\n",
            "3472/15750 (epoch 11), train_loss = 2.690, time/batch = 0.204\n",
            "3473/15750 (epoch 11), train_loss = 2.660, time/batch = 0.199\n",
            "3474/15750 (epoch 11), train_loss = 2.630, time/batch = 0.203\n",
            "3475/15750 (epoch 11), train_loss = 2.604, time/batch = 0.205\n",
            "3476/15750 (epoch 11), train_loss = 2.549, time/batch = 0.202\n",
            "3477/15750 (epoch 11), train_loss = 2.688, time/batch = 0.202\n",
            "3478/15750 (epoch 11), train_loss = 2.619, time/batch = 0.208\n",
            "3479/15750 (epoch 11), train_loss = 2.622, time/batch = 0.204\n",
            "3480/15750 (epoch 11), train_loss = 2.624, time/batch = 0.205\n",
            "3481/15750 (epoch 11), train_loss = 2.653, time/batch = 0.201\n",
            "3482/15750 (epoch 11), train_loss = 2.719, time/batch = 0.198\n",
            "3483/15750 (epoch 11), train_loss = 2.711, time/batch = 0.205\n",
            "3484/15750 (epoch 11), train_loss = 2.654, time/batch = 0.204\n",
            "3485/15750 (epoch 11), train_loss = 2.661, time/batch = 0.200\n",
            "3486/15750 (epoch 11), train_loss = 2.661, time/batch = 0.204\n",
            "3487/15750 (epoch 11), train_loss = 2.625, time/batch = 0.202\n",
            "3488/15750 (epoch 11), train_loss = 2.677, time/batch = 0.209\n",
            "3489/15750 (epoch 11), train_loss = 2.655, time/batch = 0.201\n",
            "3490/15750 (epoch 11), train_loss = 2.697, time/batch = 0.202\n",
            "3491/15750 (epoch 11), train_loss = 2.678, time/batch = 0.199\n",
            "3492/15750 (epoch 11), train_loss = 2.683, time/batch = 0.203\n",
            "3493/15750 (epoch 11), train_loss = 2.819, time/batch = 0.208\n",
            "3494/15750 (epoch 11), train_loss = 2.713, time/batch = 0.196\n",
            "3495/15750 (epoch 11), train_loss = 2.669, time/batch = 0.204\n",
            "3496/15750 (epoch 11), train_loss = 2.651, time/batch = 0.200\n",
            "3497/15750 (epoch 11), train_loss = 2.558, time/batch = 0.202\n",
            "3498/15750 (epoch 11), train_loss = 2.581, time/batch = 0.203\n",
            "3499/15750 (epoch 11), train_loss = 2.648, time/batch = 0.199\n",
            "3500/15750 (epoch 11), train_loss = 2.566, time/batch = 0.203\n",
            "3501/15750 (epoch 11), train_loss = 2.586, time/batch = 0.200\n",
            "3502/15750 (epoch 11), train_loss = 2.662, time/batch = 0.204\n",
            "3503/15750 (epoch 11), train_loss = 2.574, time/batch = 0.206\n",
            "3504/15750 (epoch 11), train_loss = 2.630, time/batch = 0.201\n",
            "3505/15750 (epoch 11), train_loss = 2.607, time/batch = 0.197\n",
            "3506/15750 (epoch 11), train_loss = 2.659, time/batch = 0.198\n",
            "3507/15750 (epoch 11), train_loss = 2.653, time/batch = 0.202\n",
            "3508/15750 (epoch 11), train_loss = 2.583, time/batch = 0.204\n",
            "3509/15750 (epoch 11), train_loss = 2.644, time/batch = 0.202\n",
            "3510/15750 (epoch 11), train_loss = 2.543, time/batch = 0.199\n",
            "3511/15750 (epoch 11), train_loss = 2.578, time/batch = 0.202\n",
            "3512/15750 (epoch 11), train_loss = 2.642, time/batch = 0.204\n",
            "3513/15750 (epoch 11), train_loss = 2.665, time/batch = 0.204\n",
            "3514/15750 (epoch 11), train_loss = 2.570, time/batch = 0.201\n",
            "3515/15750 (epoch 11), train_loss = 2.605, time/batch = 0.204\n",
            "3516/15750 (epoch 11), train_loss = 2.575, time/batch = 0.202\n",
            "3517/15750 (epoch 11), train_loss = 2.633, time/batch = 0.201\n",
            "3518/15750 (epoch 11), train_loss = 2.638, time/batch = 0.207\n",
            "3519/15750 (epoch 11), train_loss = 2.626, time/batch = 0.199\n",
            "3520/15750 (epoch 11), train_loss = 2.674, time/batch = 0.198\n",
            "3521/15750 (epoch 11), train_loss = 2.536, time/batch = 0.202\n",
            "3522/15750 (epoch 11), train_loss = 2.548, time/batch = 0.204\n",
            "3523/15750 (epoch 11), train_loss = 2.618, time/batch = 0.205\n",
            "3524/15750 (epoch 11), train_loss = 2.473, time/batch = 0.200\n",
            "3525/15750 (epoch 11), train_loss = 2.601, time/batch = 0.199\n",
            "3526/15750 (epoch 11), train_loss = 2.586, time/batch = 0.202\n",
            "3527/15750 (epoch 11), train_loss = 2.524, time/batch = 0.203\n",
            "3528/15750 (epoch 11), train_loss = 2.564, time/batch = 0.210\n",
            "3529/15750 (epoch 11), train_loss = 2.522, time/batch = 0.202\n",
            "3530/15750 (epoch 11), train_loss = 2.516, time/batch = 0.199\n",
            "3531/15750 (epoch 11), train_loss = 2.457, time/batch = 0.200\n",
            "3532/15750 (epoch 11), train_loss = 2.486, time/batch = 0.203\n",
            "3533/15750 (epoch 11), train_loss = 2.536, time/batch = 0.199\n",
            "3534/15750 (epoch 11), train_loss = 2.621, time/batch = 0.200\n",
            "3535/15750 (epoch 11), train_loss = 2.548, time/batch = 0.203\n",
            "3536/15750 (epoch 11), train_loss = 2.549, time/batch = 0.200\n",
            "3537/15750 (epoch 11), train_loss = 2.431, time/batch = 0.201\n",
            "3538/15750 (epoch 11), train_loss = 2.537, time/batch = 0.204\n",
            "3539/15750 (epoch 11), train_loss = 2.638, time/batch = 0.195\n",
            "3540/15750 (epoch 11), train_loss = 2.580, time/batch = 0.204\n",
            "3541/15750 (epoch 11), train_loss = 2.568, time/batch = 0.202\n",
            "3542/15750 (epoch 11), train_loss = 2.563, time/batch = 0.201\n",
            "3543/15750 (epoch 11), train_loss = 2.583, time/batch = 0.210\n",
            "3544/15750 (epoch 11), train_loss = 2.597, time/batch = 0.204\n",
            "3545/15750 (epoch 11), train_loss = 2.493, time/batch = 0.207\n",
            "3546/15750 (epoch 11), train_loss = 2.596, time/batch = 0.202\n",
            "3547/15750 (epoch 11), train_loss = 2.516, time/batch = 0.206\n",
            "3548/15750 (epoch 11), train_loss = 2.585, time/batch = 0.207\n",
            "3549/15750 (epoch 11), train_loss = 2.651, time/batch = 0.206\n",
            "3550/15750 (epoch 11), train_loss = 2.661, time/batch = 0.199\n",
            "3551/15750 (epoch 11), train_loss = 2.499, time/batch = 0.207\n",
            "3552/15750 (epoch 11), train_loss = 2.543, time/batch = 0.207\n",
            "3553/15750 (epoch 11), train_loss = 2.571, time/batch = 0.208\n",
            "3554/15750 (epoch 11), train_loss = 2.529, time/batch = 0.205\n",
            "3555/15750 (epoch 11), train_loss = 2.561, time/batch = 0.206\n",
            "3556/15750 (epoch 11), train_loss = 2.615, time/batch = 0.204\n",
            "3557/15750 (epoch 11), train_loss = 2.620, time/batch = 0.202\n",
            "3558/15750 (epoch 11), train_loss = 2.632, time/batch = 0.210\n",
            "3559/15750 (epoch 11), train_loss = 2.669, time/batch = 0.201\n",
            "3560/15750 (epoch 11), train_loss = 2.574, time/batch = 0.206\n",
            "3561/15750 (epoch 11), train_loss = 2.597, time/batch = 0.203\n",
            "3562/15750 (epoch 11), train_loss = 2.598, time/batch = 0.204\n",
            "3563/15750 (epoch 11), train_loss = 2.613, time/batch = 0.212\n",
            "3564/15750 (epoch 11), train_loss = 2.611, time/batch = 0.201\n",
            "3565/15750 (epoch 11), train_loss = 2.588, time/batch = 0.197\n",
            "3566/15750 (epoch 11), train_loss = 2.508, time/batch = 0.205\n",
            "3567/15750 (epoch 11), train_loss = 2.541, time/batch = 0.202\n",
            "3568/15750 (epoch 11), train_loss = 2.673, time/batch = 0.208\n",
            "3569/15750 (epoch 11), train_loss = 2.611, time/batch = 0.204\n",
            "3570/15750 (epoch 11), train_loss = 2.536, time/batch = 0.205\n",
            "3571/15750 (epoch 11), train_loss = 2.593, time/batch = 0.203\n",
            "3572/15750 (epoch 11), train_loss = 2.593, time/batch = 0.195\n",
            "3573/15750 (epoch 11), train_loss = 2.657, time/batch = 0.207\n",
            "3574/15750 (epoch 11), train_loss = 2.665, time/batch = 0.199\n",
            "3575/15750 (epoch 11), train_loss = 2.700, time/batch = 0.205\n",
            "3576/15750 (epoch 11), train_loss = 2.599, time/batch = 0.199\n",
            "3577/15750 (epoch 11), train_loss = 2.573, time/batch = 0.197\n",
            "3578/15750 (epoch 11), train_loss = 2.594, time/batch = 0.206\n",
            "3579/15750 (epoch 11), train_loss = 2.597, time/batch = 0.204\n",
            "3580/15750 (epoch 11), train_loss = 2.673, time/batch = 0.200\n",
            "3581/15750 (epoch 11), train_loss = 2.599, time/batch = 0.201\n",
            "3582/15750 (epoch 11), train_loss = 2.732, time/batch = 0.200\n",
            "3583/15750 (epoch 11), train_loss = 2.591, time/batch = 0.208\n",
            "3584/15750 (epoch 11), train_loss = 2.569, time/batch = 0.204\n",
            "3585/15750 (epoch 11), train_loss = 2.554, time/batch = 0.200\n",
            "3586/15750 (epoch 11), train_loss = 2.537, time/batch = 0.198\n",
            "3587/15750 (epoch 11), train_loss = 2.564, time/batch = 0.205\n",
            "3588/15750 (epoch 11), train_loss = 2.555, time/batch = 0.202\n",
            "3589/15750 (epoch 11), train_loss = 2.569, time/batch = 0.195\n",
            "3590/15750 (epoch 11), train_loss = 2.592, time/batch = 0.204\n",
            "3591/15750 (epoch 11), train_loss = 2.685, time/batch = 0.202\n",
            "3592/15750 (epoch 11), train_loss = 2.531, time/batch = 0.203\n",
            "3593/15750 (epoch 11), train_loss = 2.522, time/batch = 0.207\n",
            "3594/15750 (epoch 11), train_loss = 2.545, time/batch = 0.195\n",
            "3595/15750 (epoch 11), train_loss = 2.490, time/batch = 0.202\n",
            "3596/15750 (epoch 11), train_loss = 2.497, time/batch = 0.205\n",
            "3597/15750 (epoch 11), train_loss = 2.516, time/batch = 0.199\n",
            "3598/15750 (epoch 11), train_loss = 2.505, time/batch = 0.197\n",
            "3599/15750 (epoch 11), train_loss = 2.568, time/batch = 0.203\n",
            "3600/15750 (epoch 11), train_loss = 2.664, time/batch = 0.200\n",
            "3601/15750 (epoch 11), train_loss = 2.627, time/batch = 0.203\n",
            "3602/15750 (epoch 11), train_loss = 2.642, time/batch = 0.201\n",
            "3603/15750 (epoch 11), train_loss = 2.625, time/batch = 0.208\n",
            "3604/15750 (epoch 11), train_loss = 2.549, time/batch = 0.201\n",
            "3605/15750 (epoch 11), train_loss = 2.547, time/batch = 0.194\n",
            "3606/15750 (epoch 11), train_loss = 2.631, time/batch = 0.201\n",
            "3607/15750 (epoch 11), train_loss = 2.645, time/batch = 0.202\n",
            "3608/15750 (epoch 11), train_loss = 2.638, time/batch = 0.200\n",
            "3609/15750 (epoch 11), train_loss = 2.570, time/batch = 0.207\n",
            "3610/15750 (epoch 11), train_loss = 2.560, time/batch = 0.202\n",
            "3611/15750 (epoch 11), train_loss = 2.496, time/batch = 0.202\n",
            "3612/15750 (epoch 11), train_loss = 2.587, time/batch = 0.202\n",
            "3613/15750 (epoch 11), train_loss = 2.623, time/batch = 0.201\n",
            "3614/15750 (epoch 11), train_loss = 2.564, time/batch = 0.200\n",
            "3615/15750 (epoch 11), train_loss = 2.572, time/batch = 0.202\n",
            "3616/15750 (epoch 11), train_loss = 2.598, time/batch = 0.196\n",
            "3617/15750 (epoch 11), train_loss = 2.681, time/batch = 0.199\n",
            "3618/15750 (epoch 11), train_loss = 2.616, time/batch = 0.206\n",
            "3619/15750 (epoch 11), train_loss = 2.611, time/batch = 0.209\n",
            "3620/15750 (epoch 11), train_loss = 2.620, time/batch = 0.199\n",
            "3621/15750 (epoch 11), train_loss = 2.624, time/batch = 0.205\n",
            "3622/15750 (epoch 11), train_loss = 2.600, time/batch = 0.201\n",
            "3623/15750 (epoch 11), train_loss = 2.700, time/batch = 0.203\n",
            "3624/15750 (epoch 11), train_loss = 2.547, time/batch = 0.207\n",
            "3625/15750 (epoch 11), train_loss = 2.631, time/batch = 0.203\n",
            "3626/15750 (epoch 11), train_loss = 2.611, time/batch = 0.201\n",
            "3627/15750 (epoch 11), train_loss = 2.664, time/batch = 0.205\n",
            "3628/15750 (epoch 11), train_loss = 2.734, time/batch = 0.206\n",
            "3629/15750 (epoch 11), train_loss = 2.650, time/batch = 0.210\n",
            "3630/15750 (epoch 11), train_loss = 2.662, time/batch = 0.199\n",
            "3631/15750 (epoch 11), train_loss = 2.658, time/batch = 0.206\n",
            "3632/15750 (epoch 11), train_loss = 2.596, time/batch = 0.206\n",
            "3633/15750 (epoch 11), train_loss = 2.558, time/batch = 0.201\n",
            "3634/15750 (epoch 11), train_loss = 2.554, time/batch = 0.210\n",
            "3635/15750 (epoch 11), train_loss = 2.622, time/batch = 0.202\n",
            "3636/15750 (epoch 11), train_loss = 2.662, time/batch = 0.203\n",
            "3637/15750 (epoch 11), train_loss = 2.597, time/batch = 0.206\n",
            "3638/15750 (epoch 11), train_loss = 2.646, time/batch = 0.204\n",
            "3639/15750 (epoch 11), train_loss = 2.617, time/batch = 0.207\n",
            "3640/15750 (epoch 11), train_loss = 2.526, time/batch = 0.199\n",
            "3641/15750 (epoch 11), train_loss = 2.567, time/batch = 0.206\n",
            "3642/15750 (epoch 11), train_loss = 2.624, time/batch = 0.204\n",
            "3643/15750 (epoch 11), train_loss = 2.552, time/batch = 0.203\n",
            "3644/15750 (epoch 11), train_loss = 2.515, time/batch = 0.215\n",
            "3645/15750 (epoch 11), train_loss = 2.525, time/batch = 0.204\n",
            "3646/15750 (epoch 11), train_loss = 2.647, time/batch = 0.201\n",
            "3647/15750 (epoch 11), train_loss = 2.569, time/batch = 0.207\n",
            "3648/15750 (epoch 11), train_loss = 2.658, time/batch = 0.211\n",
            "3649/15750 (epoch 11), train_loss = 2.650, time/batch = 0.208\n",
            "3650/15750 (epoch 11), train_loss = 2.557, time/batch = 0.201\n",
            "3651/15750 (epoch 11), train_loss = 2.538, time/batch = 0.203\n",
            "3652/15750 (epoch 11), train_loss = 2.613, time/batch = 0.207\n",
            "3653/15750 (epoch 11), train_loss = 2.676, time/batch = 0.203\n",
            "3654/15750 (epoch 11), train_loss = 2.734, time/batch = 0.208\n",
            "3655/15750 (epoch 11), train_loss = 2.663, time/batch = 0.202\n",
            "3656/15750 (epoch 11), train_loss = 2.604, time/batch = 0.193\n",
            "3657/15750 (epoch 11), train_loss = 2.614, time/batch = 0.202\n",
            "3658/15750 (epoch 11), train_loss = 2.549, time/batch = 0.204\n",
            "3659/15750 (epoch 11), train_loss = 2.650, time/batch = 0.205\n",
            "3660/15750 (epoch 11), train_loss = 2.675, time/batch = 0.200\n",
            "3661/15750 (epoch 11), train_loss = 2.588, time/batch = 0.199\n",
            "3662/15750 (epoch 11), train_loss = 2.549, time/batch = 0.201\n",
            "3663/15750 (epoch 11), train_loss = 2.638, time/batch = 0.200\n",
            "3664/15750 (epoch 11), train_loss = 2.457, time/batch = 0.206\n",
            "3665/15750 (epoch 11), train_loss = 2.540, time/batch = 0.195\n",
            "3666/15750 (epoch 11), train_loss = 2.516, time/batch = 0.199\n",
            "3667/15750 (epoch 11), train_loss = 2.591, time/batch = 0.209\n",
            "3668/15750 (epoch 11), train_loss = 2.572, time/batch = 0.202\n",
            "3669/15750 (epoch 11), train_loss = 2.623, time/batch = 0.209\n",
            "3670/15750 (epoch 11), train_loss = 2.596, time/batch = 0.199\n",
            "3671/15750 (epoch 11), train_loss = 2.459, time/batch = 0.205\n",
            "3672/15750 (epoch 11), train_loss = 2.530, time/batch = 0.202\n",
            "3673/15750 (epoch 11), train_loss = 2.537, time/batch = 0.204\n",
            "3674/15750 (epoch 11), train_loss = 2.570, time/batch = 0.203\n",
            "3675/15750 (epoch 11), train_loss = 2.443, time/batch = 0.201\n",
            "3676/15750 (epoch 11), train_loss = 2.545, time/batch = 0.203\n",
            "3677/15750 (epoch 11), train_loss = 2.437, time/batch = 0.203\n",
            "3678/15750 (epoch 11), train_loss = 2.501, time/batch = 0.200\n",
            "3679/15750 (epoch 11), train_loss = 2.502, time/batch = 0.204\n",
            "3680/15750 (epoch 11), train_loss = 2.513, time/batch = 0.201\n",
            "3681/15750 (epoch 11), train_loss = 2.659, time/batch = 0.196\n",
            "3682/15750 (epoch 11), train_loss = 2.466, time/batch = 0.202\n",
            "3683/15750 (epoch 11), train_loss = 2.706, time/batch = 0.199\n",
            "3684/15750 (epoch 11), train_loss = 2.553, time/batch = 0.206\n",
            "3685/15750 (epoch 11), train_loss = 2.460, time/batch = 0.201\n",
            "3686/15750 (epoch 11), train_loss = 2.510, time/batch = 0.203\n",
            "3687/15750 (epoch 11), train_loss = 2.573, time/batch = 0.202\n",
            "3688/15750 (epoch 11), train_loss = 2.565, time/batch = 0.203\n",
            "3689/15750 (epoch 11), train_loss = 2.532, time/batch = 0.203\n",
            "3690/15750 (epoch 11), train_loss = 2.531, time/batch = 0.200\n",
            "3691/15750 (epoch 11), train_loss = 2.615, time/batch = 0.202\n",
            "3692/15750 (epoch 11), train_loss = 2.531, time/batch = 0.206\n",
            "3693/15750 (epoch 11), train_loss = 2.565, time/batch = 0.196\n",
            "3694/15750 (epoch 11), train_loss = 2.642, time/batch = 0.208\n",
            "3695/15750 (epoch 11), train_loss = 2.509, time/batch = 0.193\n",
            "3696/15750 (epoch 11), train_loss = 2.516, time/batch = 0.202\n",
            "3697/15750 (epoch 11), train_loss = 2.565, time/batch = 0.206\n",
            "3698/15750 (epoch 11), train_loss = 2.578, time/batch = 0.202\n",
            "3699/15750 (epoch 11), train_loss = 2.500, time/batch = 0.205\n",
            "3700/15750 (epoch 11), train_loss = 2.516, time/batch = 0.199\n",
            "3701/15750 (epoch 11), train_loss = 2.462, time/batch = 0.205\n",
            "3702/15750 (epoch 11), train_loss = 2.546, time/batch = 0.199\n",
            "3703/15750 (epoch 11), train_loss = 2.747, time/batch = 0.201\n",
            "3704/15750 (epoch 11), train_loss = 2.544, time/batch = 0.210\n",
            "3705/15750 (epoch 11), train_loss = 2.618, time/batch = 0.202\n",
            "3706/15750 (epoch 11), train_loss = 2.500, time/batch = 0.199\n",
            "3707/15750 (epoch 11), train_loss = 2.574, time/batch = 0.197\n",
            "3708/15750 (epoch 11), train_loss = 2.582, time/batch = 0.203\n",
            "3709/15750 (epoch 11), train_loss = 2.564, time/batch = 0.206\n",
            "3710/15750 (epoch 11), train_loss = 2.626, time/batch = 0.201\n",
            "3711/15750 (epoch 11), train_loss = 2.589, time/batch = 0.201\n",
            "3712/15750 (epoch 11), train_loss = 2.596, time/batch = 0.196\n",
            "3713/15750 (epoch 11), train_loss = 2.576, time/batch = 0.204\n",
            "3714/15750 (epoch 11), train_loss = 2.594, time/batch = 0.205\n",
            "3715/15750 (epoch 11), train_loss = 2.506, time/batch = 0.198\n",
            "3716/15750 (epoch 11), train_loss = 2.514, time/batch = 0.203\n",
            "3717/15750 (epoch 11), train_loss = 2.587, time/batch = 0.203\n",
            "3718/15750 (epoch 11), train_loss = 2.585, time/batch = 0.203\n",
            "3719/15750 (epoch 11), train_loss = 2.558, time/batch = 0.207\n",
            "3720/15750 (epoch 11), train_loss = 2.542, time/batch = 0.200\n",
            "3721/15750 (epoch 11), train_loss = 2.487, time/batch = 0.194\n",
            "3722/15750 (epoch 11), train_loss = 2.504, time/batch = 0.214\n",
            "3723/15750 (epoch 11), train_loss = 2.681, time/batch = 0.200\n",
            "3724/15750 (epoch 11), train_loss = 2.612, time/batch = 0.202\n",
            "3725/15750 (epoch 11), train_loss = 2.601, time/batch = 0.199\n",
            "3726/15750 (epoch 11), train_loss = 2.545, time/batch = 0.196\n",
            "3727/15750 (epoch 11), train_loss = 2.590, time/batch = 0.203\n",
            "3728/15750 (epoch 11), train_loss = 2.558, time/batch = 0.203\n",
            "3729/15750 (epoch 11), train_loss = 2.625, time/batch = 0.202\n",
            "3730/15750 (epoch 11), train_loss = 2.641, time/batch = 0.197\n",
            "3731/15750 (epoch 11), train_loss = 2.667, time/batch = 0.204\n",
            "3732/15750 (epoch 11), train_loss = 2.572, time/batch = 0.202\n",
            "3733/15750 (epoch 11), train_loss = 2.608, time/batch = 0.198\n",
            "3734/15750 (epoch 11), train_loss = 2.645, time/batch = 0.199\n",
            "3735/15750 (epoch 11), train_loss = 2.609, time/batch = 0.216\n",
            "3736/15750 (epoch 11), train_loss = 2.497, time/batch = 0.203\n",
            "3737/15750 (epoch 11), train_loss = 2.562, time/batch = 0.194\n",
            "3738/15750 (epoch 11), train_loss = 2.613, time/batch = 0.200\n",
            "3739/15750 (epoch 11), train_loss = 2.633, time/batch = 0.205\n",
            "3740/15750 (epoch 11), train_loss = 2.607, time/batch = 0.204\n",
            "3741/15750 (epoch 11), train_loss = 2.644, time/batch = 0.200\n",
            "3742/15750 (epoch 11), train_loss = 2.568, time/batch = 0.203\n",
            "3743/15750 (epoch 11), train_loss = 2.519, time/batch = 0.199\n",
            "3744/15750 (epoch 11), train_loss = 2.491, time/batch = 0.200\n",
            "3745/15750 (epoch 11), train_loss = 2.746, time/batch = 0.209\n",
            "3746/15750 (epoch 11), train_loss = 2.548, time/batch = 0.197\n",
            "3747/15750 (epoch 11), train_loss = 2.511, time/batch = 0.201\n",
            "3748/15750 (epoch 11), train_loss = 2.658, time/batch = 0.204\n",
            "3749/15750 (epoch 11), train_loss = 2.515, time/batch = 0.202\n",
            "3750/15750 (epoch 11), train_loss = 2.674, time/batch = 0.205\n",
            "3751/15750 (epoch 11), train_loss = 2.541, time/batch = 0.199\n",
            "3752/15750 (epoch 11), train_loss = 2.563, time/batch = 0.200\n",
            "3753/15750 (epoch 11), train_loss = 2.486, time/batch = 0.202\n",
            "3754/15750 (epoch 11), train_loss = 2.571, time/batch = 0.203\n",
            "3755/15750 (epoch 11), train_loss = 2.482, time/batch = 0.207\n",
            "3756/15750 (epoch 11), train_loss = 2.591, time/batch = 0.202\n",
            "3757/15750 (epoch 11), train_loss = 2.574, time/batch = 0.204\n",
            "3758/15750 (epoch 11), train_loss = 2.547, time/batch = 0.198\n",
            "3759/15750 (epoch 11), train_loss = 2.603, time/batch = 0.200\n",
            "3760/15750 (epoch 11), train_loss = 2.677, time/batch = 0.210\n",
            "3761/15750 (epoch 11), train_loss = 2.628, time/batch = 0.200\n",
            "3762/15750 (epoch 11), train_loss = 2.657, time/batch = 0.201\n",
            "3763/15750 (epoch 11), train_loss = 2.508, time/batch = 0.201\n",
            "3764/15750 (epoch 11), train_loss = 2.603, time/batch = 0.206\n",
            "3765/15750 (epoch 11), train_loss = 2.569, time/batch = 0.205\n",
            "3766/15750 (epoch 11), train_loss = 2.489, time/batch = 0.197\n",
            "3767/15750 (epoch 11), train_loss = 2.617, time/batch = 0.200\n",
            "3768/15750 (epoch 11), train_loss = 2.475, time/batch = 0.200\n",
            "3769/15750 (epoch 11), train_loss = 2.616, time/batch = 0.201\n",
            "3770/15750 (epoch 11), train_loss = 2.570, time/batch = 0.205\n",
            "3771/15750 (epoch 11), train_loss = 2.552, time/batch = 0.202\n",
            "3772/15750 (epoch 11), train_loss = 2.484, time/batch = 0.201\n",
            "3773/15750 (epoch 11), train_loss = 2.513, time/batch = 0.199\n",
            "3774/15750 (epoch 11), train_loss = 2.647, time/batch = 0.205\n",
            "3775/15750 (epoch 11), train_loss = 2.484, time/batch = 0.207\n",
            "3776/15750 (epoch 11), train_loss = 2.450, time/batch = 0.208\n",
            "3777/15750 (epoch 11), train_loss = 2.530, time/batch = 0.199\n",
            "3778/15750 (epoch 11), train_loss = 2.514, time/batch = 0.200\n",
            "3779/15750 (epoch 11), train_loss = 2.616, time/batch = 0.203\n",
            "3780/15750 (epoch 12), train_loss = 2.656, time/batch = 0.206\n",
            "3781/15750 (epoch 12), train_loss = 2.629, time/batch = 0.200\n",
            "3782/15750 (epoch 12), train_loss = 2.567, time/batch = 0.207\n",
            "3783/15750 (epoch 12), train_loss = 2.664, time/batch = 0.205\n",
            "3784/15750 (epoch 12), train_loss = 2.577, time/batch = 0.205\n",
            "3785/15750 (epoch 12), train_loss = 2.563, time/batch = 0.202\n",
            "3786/15750 (epoch 12), train_loss = 2.738, time/batch = 0.205\n",
            "3787/15750 (epoch 12), train_loss = 2.655, time/batch = 0.206\n",
            "3788/15750 (epoch 12), train_loss = 2.626, time/batch = 0.202\n",
            "3789/15750 (epoch 12), train_loss = 2.593, time/batch = 0.207\n",
            "3790/15750 (epoch 12), train_loss = 2.572, time/batch = 0.204\n",
            "3791/15750 (epoch 12), train_loss = 2.518, time/batch = 0.205\n",
            "3792/15750 (epoch 12), train_loss = 2.649, time/batch = 0.205\n",
            "3793/15750 (epoch 12), train_loss = 2.586, time/batch = 0.203\n",
            "3794/15750 (epoch 12), train_loss = 2.588, time/batch = 0.205\n",
            "3795/15750 (epoch 12), train_loss = 2.592, time/batch = 0.203\n",
            "3796/15750 (epoch 12), train_loss = 2.617, time/batch = 0.201\n",
            "3797/15750 (epoch 12), train_loss = 2.683, time/batch = 0.202\n",
            "3798/15750 (epoch 12), train_loss = 2.675, time/batch = 0.203\n",
            "3799/15750 (epoch 12), train_loss = 2.620, time/batch = 0.211\n",
            "3800/15750 (epoch 12), train_loss = 2.626, time/batch = 0.202\n",
            "3801/15750 (epoch 12), train_loss = 2.628, time/batch = 0.208\n",
            "3802/15750 (epoch 12), train_loss = 2.590, time/batch = 0.207\n",
            "3803/15750 (epoch 12), train_loss = 2.644, time/batch = 0.200\n",
            "3804/15750 (epoch 12), train_loss = 2.624, time/batch = 0.209\n",
            "3805/15750 (epoch 12), train_loss = 2.664, time/batch = 0.202\n",
            "3806/15750 (epoch 12), train_loss = 2.646, time/batch = 0.204\n",
            "3807/15750 (epoch 12), train_loss = 2.650, time/batch = 0.209\n",
            "3808/15750 (epoch 12), train_loss = 2.783, time/batch = 0.205\n",
            "3809/15750 (epoch 12), train_loss = 2.682, time/batch = 0.211\n",
            "3810/15750 (epoch 12), train_loss = 2.637, time/batch = 0.201\n",
            "3811/15750 (epoch 12), train_loss = 2.618, time/batch = 0.206\n",
            "3812/15750 (epoch 12), train_loss = 2.522, time/batch = 0.209\n",
            "3813/15750 (epoch 12), train_loss = 2.546, time/batch = 0.202\n",
            "3814/15750 (epoch 12), train_loss = 2.616, time/batch = 0.212\n",
            "3815/15750 (epoch 12), train_loss = 2.531, time/batch = 0.206\n",
            "3816/15750 (epoch 12), train_loss = 2.556, time/batch = 0.206\n",
            "3817/15750 (epoch 12), train_loss = 2.630, time/batch = 0.202\n",
            "3818/15750 (epoch 12), train_loss = 2.544, time/batch = 0.206\n",
            "3819/15750 (epoch 12), train_loss = 2.596, time/batch = 0.207\n",
            "3820/15750 (epoch 12), train_loss = 2.573, time/batch = 0.203\n",
            "3821/15750 (epoch 12), train_loss = 2.624, time/batch = 0.203\n",
            "3822/15750 (epoch 12), train_loss = 2.618, time/batch = 0.202\n",
            "3823/15750 (epoch 12), train_loss = 2.551, time/batch = 0.195\n",
            "3824/15750 (epoch 12), train_loss = 2.611, time/batch = 0.206\n",
            "3825/15750 (epoch 12), train_loss = 2.510, time/batch = 0.204\n",
            "3826/15750 (epoch 12), train_loss = 2.547, time/batch = 0.195\n",
            "3827/15750 (epoch 12), train_loss = 2.606, time/batch = 0.203\n",
            "3828/15750 (epoch 12), train_loss = 2.633, time/batch = 0.200\n",
            "3829/15750 (epoch 12), train_loss = 2.535, time/batch = 0.210\n",
            "3830/15750 (epoch 12), train_loss = 2.572, time/batch = 0.197\n",
            "3831/15750 (epoch 12), train_loss = 2.538, time/batch = 0.200\n",
            "3832/15750 (epoch 12), train_loss = 2.598, time/batch = 0.195\n",
            "3833/15750 (epoch 12), train_loss = 2.606, time/batch = 0.203\n",
            "3834/15750 (epoch 12), train_loss = 2.592, time/batch = 0.206\n",
            "3835/15750 (epoch 12), train_loss = 2.641, time/batch = 0.203\n",
            "3836/15750 (epoch 12), train_loss = 2.503, time/batch = 0.203\n",
            "3837/15750 (epoch 12), train_loss = 2.514, time/batch = 0.195\n",
            "3838/15750 (epoch 12), train_loss = 2.588, time/batch = 0.207\n",
            "3839/15750 (epoch 12), train_loss = 2.441, time/batch = 0.209\n",
            "3840/15750 (epoch 12), train_loss = 2.568, time/batch = 0.199\n",
            "3841/15750 (epoch 12), train_loss = 2.555, time/batch = 0.195\n",
            "3842/15750 (epoch 12), train_loss = 2.493, time/batch = 0.204\n",
            "3843/15750 (epoch 12), train_loss = 2.534, time/batch = 0.205\n",
            "3844/15750 (epoch 12), train_loss = 2.486, time/batch = 0.204\n",
            "3845/15750 (epoch 12), train_loss = 2.483, time/batch = 0.193\n",
            "3846/15750 (epoch 12), train_loss = 2.422, time/batch = 0.206\n",
            "3847/15750 (epoch 12), train_loss = 2.454, time/batch = 0.203\n",
            "3848/15750 (epoch 12), train_loss = 2.504, time/batch = 0.201\n",
            "3849/15750 (epoch 12), train_loss = 2.589, time/batch = 0.204\n",
            "3850/15750 (epoch 12), train_loss = 2.515, time/batch = 0.201\n",
            "3851/15750 (epoch 12), train_loss = 2.513, time/batch = 0.201\n",
            "3852/15750 (epoch 12), train_loss = 2.402, time/batch = 0.195\n",
            "3853/15750 (epoch 12), train_loss = 2.505, time/batch = 0.201\n",
            "3854/15750 (epoch 12), train_loss = 2.606, time/batch = 0.208\n",
            "3855/15750 (epoch 12), train_loss = 2.549, time/batch = 0.197\n",
            "3856/15750 (epoch 12), train_loss = 2.534, time/batch = 0.201\n",
            "3857/15750 (epoch 12), train_loss = 2.533, time/batch = 0.204\n",
            "3858/15750 (epoch 12), train_loss = 2.550, time/batch = 0.203\n",
            "3859/15750 (epoch 12), train_loss = 2.561, time/batch = 0.208\n",
            "3860/15750 (epoch 12), train_loss = 2.458, time/batch = 0.203\n",
            "3861/15750 (epoch 12), train_loss = 2.562, time/batch = 0.204\n",
            "3862/15750 (epoch 12), train_loss = 2.482, time/batch = 0.204\n",
            "3863/15750 (epoch 12), train_loss = 2.550, time/batch = 0.212\n",
            "3864/15750 (epoch 12), train_loss = 2.618, time/batch = 0.213\n",
            "3865/15750 (epoch 12), train_loss = 2.627, time/batch = 0.208\n",
            "3866/15750 (epoch 12), train_loss = 2.467, time/batch = 0.212\n",
            "3867/15750 (epoch 12), train_loss = 2.507, time/batch = 0.204\n",
            "3868/15750 (epoch 12), train_loss = 2.536, time/batch = 0.207\n",
            "3869/15750 (epoch 12), train_loss = 2.498, time/batch = 0.210\n",
            "3870/15750 (epoch 12), train_loss = 2.525, time/batch = 0.206\n",
            "3871/15750 (epoch 12), train_loss = 2.579, time/batch = 0.199\n",
            "3872/15750 (epoch 12), train_loss = 2.582, time/batch = 0.207\n",
            "3873/15750 (epoch 12), train_loss = 2.596, time/batch = 0.207\n",
            "3874/15750 (epoch 12), train_loss = 2.639, time/batch = 0.208\n",
            "3875/15750 (epoch 12), train_loss = 2.540, time/batch = 0.202\n",
            "3876/15750 (epoch 12), train_loss = 2.564, time/batch = 0.202\n",
            "3877/15750 (epoch 12), train_loss = 2.566, time/batch = 0.202\n",
            "3878/15750 (epoch 12), train_loss = 2.579, time/batch = 0.203\n",
            "3879/15750 (epoch 12), train_loss = 2.581, time/batch = 0.208\n",
            "3880/15750 (epoch 12), train_loss = 2.557, time/batch = 0.204\n",
            "3881/15750 (epoch 12), train_loss = 2.476, time/batch = 0.201\n",
            "3882/15750 (epoch 12), train_loss = 2.510, time/batch = 0.203\n",
            "3883/15750 (epoch 12), train_loss = 2.639, time/batch = 0.202\n",
            "3884/15750 (epoch 12), train_loss = 2.578, time/batch = 0.206\n",
            "3885/15750 (epoch 12), train_loss = 2.502, time/batch = 0.206\n",
            "3886/15750 (epoch 12), train_loss = 2.559, time/batch = 0.202\n",
            "3887/15750 (epoch 12), train_loss = 2.561, time/batch = 0.201\n",
            "3888/15750 (epoch 12), train_loss = 2.622, time/batch = 0.196\n",
            "3889/15750 (epoch 12), train_loss = 2.632, time/batch = 0.210\n",
            "3890/15750 (epoch 12), train_loss = 2.669, time/batch = 0.205\n",
            "3891/15750 (epoch 12), train_loss = 2.565, time/batch = 0.205\n",
            "3892/15750 (epoch 12), train_loss = 2.540, time/batch = 0.206\n",
            "3893/15750 (epoch 12), train_loss = 2.560, time/batch = 0.208\n",
            "3894/15750 (epoch 12), train_loss = 2.567, time/batch = 0.212\n",
            "3895/15750 (epoch 12), train_loss = 2.641, time/batch = 0.212\n",
            "3896/15750 (epoch 12), train_loss = 2.565, time/batch = 0.203\n",
            "3897/15750 (epoch 12), train_loss = 2.699, time/batch = 0.203\n",
            "3898/15750 (epoch 12), train_loss = 2.560, time/batch = 0.203\n",
            "3899/15750 (epoch 12), train_loss = 2.537, time/batch = 0.210\n",
            "3900/15750 (epoch 12), train_loss = 2.523, time/batch = 0.208\n",
            "3901/15750 (epoch 12), train_loss = 2.505, time/batch = 0.206\n",
            "3902/15750 (epoch 12), train_loss = 2.533, time/batch = 0.207\n",
            "3903/15750 (epoch 12), train_loss = 2.520, time/batch = 0.207\n",
            "3904/15750 (epoch 12), train_loss = 2.539, time/batch = 0.212\n",
            "3905/15750 (epoch 12), train_loss = 2.558, time/batch = 0.207\n",
            "3906/15750 (epoch 12), train_loss = 2.651, time/batch = 0.204\n",
            "3907/15750 (epoch 12), train_loss = 2.500, time/batch = 0.204\n",
            "3908/15750 (epoch 12), train_loss = 2.495, time/batch = 0.197\n",
            "3909/15750 (epoch 12), train_loss = 2.513, time/batch = 0.211\n",
            "3910/15750 (epoch 12), train_loss = 2.459, time/batch = 0.203\n",
            "3911/15750 (epoch 12), train_loss = 2.464, time/batch = 0.200\n",
            "3912/15750 (epoch 12), train_loss = 2.483, time/batch = 0.200\n",
            "3913/15750 (epoch 12), train_loss = 2.474, time/batch = 0.198\n",
            "3914/15750 (epoch 12), train_loss = 2.533, time/batch = 0.207\n",
            "3915/15750 (epoch 12), train_loss = 2.634, time/batch = 0.202\n",
            "3916/15750 (epoch 12), train_loss = 2.594, time/batch = 0.198\n",
            "3917/15750 (epoch 12), train_loss = 2.610, time/batch = 0.203\n",
            "3918/15750 (epoch 12), train_loss = 2.592, time/batch = 0.203\n",
            "3919/15750 (epoch 12), train_loss = 2.518, time/batch = 0.211\n",
            "3920/15750 (epoch 12), train_loss = 2.515, time/batch = 0.205\n",
            "3921/15750 (epoch 12), train_loss = 2.598, time/batch = 0.198\n",
            "3922/15750 (epoch 12), train_loss = 2.613, time/batch = 0.203\n",
            "3923/15750 (epoch 12), train_loss = 2.607, time/batch = 0.196\n",
            "3924/15750 (epoch 12), train_loss = 2.537, time/batch = 0.211\n",
            "3925/15750 (epoch 12), train_loss = 2.528, time/batch = 0.199\n",
            "3926/15750 (epoch 12), train_loss = 2.465, time/batch = 0.202\n",
            "3927/15750 (epoch 12), train_loss = 2.556, time/batch = 0.206\n",
            "3928/15750 (epoch 12), train_loss = 2.590, time/batch = 0.199\n",
            "3929/15750 (epoch 12), train_loss = 2.534, time/batch = 0.206\n",
            "3930/15750 (epoch 12), train_loss = 2.539, time/batch = 0.203\n",
            "3931/15750 (epoch 12), train_loss = 2.568, time/batch = 0.201\n",
            "3932/15750 (epoch 12), train_loss = 2.648, time/batch = 0.205\n",
            "3933/15750 (epoch 12), train_loss = 2.584, time/batch = 0.203\n",
            "3934/15750 (epoch 12), train_loss = 2.582, time/batch = 0.209\n",
            "3935/15750 (epoch 12), train_loss = 2.585, time/batch = 0.208\n",
            "3936/15750 (epoch 12), train_loss = 2.590, time/batch = 0.202\n",
            "3937/15750 (epoch 12), train_loss = 2.567, time/batch = 0.210\n",
            "3938/15750 (epoch 12), train_loss = 2.669, time/batch = 0.207\n",
            "3939/15750 (epoch 12), train_loss = 2.515, time/batch = 0.211\n",
            "3940/15750 (epoch 12), train_loss = 2.597, time/batch = 0.202\n",
            "3941/15750 (epoch 12), train_loss = 2.581, time/batch = 0.209\n",
            "3942/15750 (epoch 12), train_loss = 2.629, time/batch = 0.212\n",
            "3943/15750 (epoch 12), train_loss = 2.702, time/batch = 0.203\n",
            "3944/15750 (epoch 12), train_loss = 2.616, time/batch = 0.211\n",
            "3945/15750 (epoch 12), train_loss = 2.630, time/batch = 0.202\n",
            "3946/15750 (epoch 12), train_loss = 2.621, time/batch = 0.200\n",
            "3947/15750 (epoch 12), train_loss = 2.562, time/batch = 0.202\n",
            "3948/15750 (epoch 12), train_loss = 2.526, time/batch = 0.201\n",
            "3949/15750 (epoch 12), train_loss = 2.521, time/batch = 0.217\n",
            "3950/15750 (epoch 12), train_loss = 2.586, time/batch = 0.205\n",
            "3951/15750 (epoch 12), train_loss = 2.626, time/batch = 0.206\n",
            "3952/15750 (epoch 12), train_loss = 2.564, time/batch = 0.206\n",
            "3953/15750 (epoch 12), train_loss = 2.612, time/batch = 0.200\n",
            "3954/15750 (epoch 12), train_loss = 2.584, time/batch = 0.207\n",
            "3955/15750 (epoch 12), train_loss = 2.494, time/batch = 0.206\n",
            "3956/15750 (epoch 12), train_loss = 2.535, time/batch = 0.203\n",
            "3957/15750 (epoch 12), train_loss = 2.591, time/batch = 0.207\n",
            "3958/15750 (epoch 12), train_loss = 2.519, time/batch = 0.203\n",
            "3959/15750 (epoch 12), train_loss = 2.484, time/batch = 0.214\n",
            "3960/15750 (epoch 12), train_loss = 2.496, time/batch = 0.204\n",
            "3961/15750 (epoch 12), train_loss = 2.614, time/batch = 0.209\n",
            "3962/15750 (epoch 12), train_loss = 2.541, time/batch = 0.207\n",
            "3963/15750 (epoch 12), train_loss = 2.627, time/batch = 0.205\n",
            "3964/15750 (epoch 12), train_loss = 2.620, time/batch = 0.221\n",
            "3965/15750 (epoch 12), train_loss = 2.527, time/batch = 0.206\n",
            "3966/15750 (epoch 12), train_loss = 2.505, time/batch = 0.209\n",
            "3967/15750 (epoch 12), train_loss = 2.581, time/batch = 0.210\n",
            "3968/15750 (epoch 12), train_loss = 2.641, time/batch = 0.203\n",
            "3969/15750 (epoch 12), train_loss = 2.702, time/batch = 0.204\n",
            "3970/15750 (epoch 12), train_loss = 2.635, time/batch = 0.209\n",
            "3971/15750 (epoch 12), train_loss = 2.572, time/batch = 0.206\n",
            "3972/15750 (epoch 12), train_loss = 2.581, time/batch = 0.208\n",
            "3973/15750 (epoch 12), train_loss = 2.517, time/batch = 0.199\n",
            "3974/15750 (epoch 12), train_loss = 2.620, time/batch = 0.203\n",
            "3975/15750 (epoch 12), train_loss = 2.641, time/batch = 0.200\n",
            "3976/15750 (epoch 12), train_loss = 2.558, time/batch = 0.202\n",
            "3977/15750 (epoch 12), train_loss = 2.515, time/batch = 0.199\n",
            "3978/15750 (epoch 12), train_loss = 2.607, time/batch = 0.200\n",
            "3979/15750 (epoch 12), train_loss = 2.423, time/batch = 0.211\n",
            "3980/15750 (epoch 12), train_loss = 2.508, time/batch = 0.198\n",
            "3981/15750 (epoch 12), train_loss = 2.483, time/batch = 0.196\n",
            "3982/15750 (epoch 12), train_loss = 2.559, time/batch = 0.200\n",
            "3983/15750 (epoch 12), train_loss = 2.537, time/batch = 0.205\n",
            "3984/15750 (epoch 12), train_loss = 2.593, time/batch = 0.210\n",
            "3985/15750 (epoch 12), train_loss = 2.563, time/batch = 0.211\n",
            "3986/15750 (epoch 12), train_loss = 2.425, time/batch = 0.205\n",
            "3987/15750 (epoch 12), train_loss = 2.498, time/batch = 0.208\n",
            "3988/15750 (epoch 12), train_loss = 2.503, time/batch = 0.208\n",
            "3989/15750 (epoch 12), train_loss = 2.541, time/batch = 0.209\n",
            "3990/15750 (epoch 12), train_loss = 2.414, time/batch = 0.207\n",
            "3991/15750 (epoch 12), train_loss = 2.514, time/batch = 0.208\n",
            "3992/15750 (epoch 12), train_loss = 2.406, time/batch = 0.208\n",
            "3993/15750 (epoch 12), train_loss = 2.470, time/batch = 0.204\n",
            "3994/15750 (epoch 12), train_loss = 2.472, time/batch = 0.206\n",
            "3995/15750 (epoch 12), train_loss = 2.479, time/batch = 0.206\n",
            "3996/15750 (epoch 12), train_loss = 2.627, time/batch = 0.205\n",
            "3997/15750 (epoch 12), train_loss = 2.435, time/batch = 0.203\n",
            "3998/15750 (epoch 12), train_loss = 2.675, time/batch = 0.207\n",
            "3999/15750 (epoch 12), train_loss = 2.525, time/batch = 0.212\n",
            "4000/15750 (epoch 12), train_loss = 2.428, time/batch = 0.203\n",
            "model saved to ./save_star/model.ckpt\n",
            "4001/15750 (epoch 12), train_loss = 2.478, time/batch = 0.205\n",
            "4002/15750 (epoch 12), train_loss = 2.539, time/batch = 0.207\n",
            "4003/15750 (epoch 12), train_loss = 2.532, time/batch = 0.207\n",
            "4004/15750 (epoch 12), train_loss = 2.502, time/batch = 0.202\n",
            "4005/15750 (epoch 12), train_loss = 2.500, time/batch = 0.197\n",
            "4006/15750 (epoch 12), train_loss = 2.584, time/batch = 0.202\n",
            "4007/15750 (epoch 12), train_loss = 2.499, time/batch = 0.208\n",
            "4008/15750 (epoch 12), train_loss = 2.534, time/batch = 0.210\n",
            "4009/15750 (epoch 12), train_loss = 2.614, time/batch = 0.206\n",
            "4010/15750 (epoch 12), train_loss = 2.478, time/batch = 0.209\n",
            "4011/15750 (epoch 12), train_loss = 2.486, time/batch = 0.208\n",
            "4012/15750 (epoch 12), train_loss = 2.535, time/batch = 0.211\n",
            "4013/15750 (epoch 12), train_loss = 2.546, time/batch = 0.207\n",
            "4014/15750 (epoch 12), train_loss = 2.470, time/batch = 0.208\n",
            "4015/15750 (epoch 12), train_loss = 2.482, time/batch = 0.205\n",
            "4016/15750 (epoch 12), train_loss = 2.433, time/batch = 0.210\n",
            "4017/15750 (epoch 12), train_loss = 2.516, time/batch = 0.212\n",
            "4018/15750 (epoch 12), train_loss = 2.717, time/batch = 0.206\n",
            "4019/15750 (epoch 12), train_loss = 2.515, time/batch = 0.209\n",
            "4020/15750 (epoch 12), train_loss = 2.587, time/batch = 0.200\n",
            "4021/15750 (epoch 12), train_loss = 2.466, time/batch = 0.207\n",
            "4022/15750 (epoch 12), train_loss = 2.538, time/batch = 0.206\n",
            "4023/15750 (epoch 12), train_loss = 2.548, time/batch = 0.204\n",
            "4024/15750 (epoch 12), train_loss = 2.533, time/batch = 0.197\n",
            "4025/15750 (epoch 12), train_loss = 2.595, time/batch = 0.199\n",
            "4026/15750 (epoch 12), train_loss = 2.560, time/batch = 0.203\n",
            "4027/15750 (epoch 12), train_loss = 2.563, time/batch = 0.208\n",
            "4028/15750 (epoch 12), train_loss = 2.544, time/batch = 0.204\n",
            "4029/15750 (epoch 12), train_loss = 2.565, time/batch = 0.201\n",
            "4030/15750 (epoch 12), train_loss = 2.473, time/batch = 0.201\n",
            "4031/15750 (epoch 12), train_loss = 2.482, time/batch = 0.203\n",
            "4032/15750 (epoch 12), train_loss = 2.553, time/batch = 0.212\n",
            "4033/15750 (epoch 12), train_loss = 2.554, time/batch = 0.203\n",
            "4034/15750 (epoch 12), train_loss = 2.527, time/batch = 0.203\n",
            "4035/15750 (epoch 12), train_loss = 2.510, time/batch = 0.203\n",
            "4036/15750 (epoch 12), train_loss = 2.455, time/batch = 0.201\n",
            "4037/15750 (epoch 12), train_loss = 2.471, time/batch = 0.210\n",
            "4038/15750 (epoch 12), train_loss = 2.647, time/batch = 0.205\n",
            "4039/15750 (epoch 12), train_loss = 2.583, time/batch = 0.210\n",
            "4040/15750 (epoch 12), train_loss = 2.568, time/batch = 0.210\n",
            "4041/15750 (epoch 12), train_loss = 2.514, time/batch = 0.203\n",
            "4042/15750 (epoch 12), train_loss = 2.556, time/batch = 0.208\n",
            "4043/15750 (epoch 12), train_loss = 2.527, time/batch = 0.208\n",
            "4044/15750 (epoch 12), train_loss = 2.590, time/batch = 0.206\n",
            "4045/15750 (epoch 12), train_loss = 2.612, time/batch = 0.205\n",
            "4046/15750 (epoch 12), train_loss = 2.634, time/batch = 0.203\n",
            "4047/15750 (epoch 12), train_loss = 2.541, time/batch = 0.209\n",
            "4048/15750 (epoch 12), train_loss = 2.577, time/batch = 0.200\n",
            "4049/15750 (epoch 12), train_loss = 2.611, time/batch = 0.207\n",
            "4050/15750 (epoch 12), train_loss = 2.579, time/batch = 0.209\n",
            "4051/15750 (epoch 12), train_loss = 2.470, time/batch = 0.207\n",
            "4052/15750 (epoch 12), train_loss = 2.530, time/batch = 0.209\n",
            "4053/15750 (epoch 12), train_loss = 2.583, time/batch = 0.205\n",
            "4054/15750 (epoch 12), train_loss = 2.603, time/batch = 0.204\n",
            "4055/15750 (epoch 12), train_loss = 2.572, time/batch = 0.205\n",
            "4056/15750 (epoch 12), train_loss = 2.614, time/batch = 0.203\n",
            "4057/15750 (epoch 12), train_loss = 2.536, time/batch = 0.205\n",
            "4058/15750 (epoch 12), train_loss = 2.489, time/batch = 0.205\n",
            "4059/15750 (epoch 12), train_loss = 2.460, time/batch = 0.210\n",
            "4060/15750 (epoch 12), train_loss = 2.714, time/batch = 0.203\n",
            "4061/15750 (epoch 12), train_loss = 2.520, time/batch = 0.203\n",
            "4062/15750 (epoch 12), train_loss = 2.481, time/batch = 0.220\n",
            "4063/15750 (epoch 12), train_loss = 2.624, time/batch = 0.200\n",
            "4064/15750 (epoch 12), train_loss = 2.485, time/batch = 0.203\n",
            "4065/15750 (epoch 12), train_loss = 2.644, time/batch = 0.203\n",
            "4066/15750 (epoch 12), train_loss = 2.511, time/batch = 0.205\n",
            "4067/15750 (epoch 12), train_loss = 2.532, time/batch = 0.211\n",
            "4068/15750 (epoch 12), train_loss = 2.455, time/batch = 0.205\n",
            "4069/15750 (epoch 12), train_loss = 2.540, time/batch = 0.204\n",
            "4070/15750 (epoch 12), train_loss = 2.456, time/batch = 0.208\n",
            "4071/15750 (epoch 12), train_loss = 2.560, time/batch = 0.206\n",
            "4072/15750 (epoch 12), train_loss = 2.547, time/batch = 0.215\n",
            "4073/15750 (epoch 12), train_loss = 2.516, time/batch = 0.201\n",
            "4074/15750 (epoch 12), train_loss = 2.570, time/batch = 0.204\n",
            "4075/15750 (epoch 12), train_loss = 2.647, time/batch = 0.203\n",
            "4076/15750 (epoch 12), train_loss = 2.600, time/batch = 0.205\n",
            "4077/15750 (epoch 12), train_loss = 2.624, time/batch = 0.222\n",
            "4078/15750 (epoch 12), train_loss = 2.478, time/batch = 0.204\n",
            "4079/15750 (epoch 12), train_loss = 2.571, time/batch = 0.202\n",
            "4080/15750 (epoch 12), train_loss = 2.540, time/batch = 0.202\n",
            "4081/15750 (epoch 12), train_loss = 2.458, time/batch = 0.205\n",
            "4082/15750 (epoch 12), train_loss = 2.586, time/batch = 0.210\n",
            "4083/15750 (epoch 12), train_loss = 2.444, time/batch = 0.201\n",
            "4084/15750 (epoch 12), train_loss = 2.588, time/batch = 0.204\n",
            "4085/15750 (epoch 12), train_loss = 2.538, time/batch = 0.197\n",
            "4086/15750 (epoch 12), train_loss = 2.519, time/batch = 0.200\n",
            "4087/15750 (epoch 12), train_loss = 2.453, time/batch = 0.211\n",
            "4088/15750 (epoch 12), train_loss = 2.482, time/batch = 0.198\n",
            "4089/15750 (epoch 12), train_loss = 2.616, time/batch = 0.206\n",
            "4090/15750 (epoch 12), train_loss = 2.455, time/batch = 0.201\n",
            "4091/15750 (epoch 12), train_loss = 2.423, time/batch = 0.203\n",
            "4092/15750 (epoch 12), train_loss = 2.499, time/batch = 0.204\n",
            "4093/15750 (epoch 12), train_loss = 2.483, time/batch = 0.196\n",
            "4094/15750 (epoch 12), train_loss = 2.585, time/batch = 0.204\n",
            "4095/15750 (epoch 13), train_loss = 2.609, time/batch = 0.207\n",
            "4096/15750 (epoch 13), train_loss = 2.597, time/batch = 0.208\n",
            "4097/15750 (epoch 13), train_loss = 2.536, time/batch = 0.204\n",
            "4098/15750 (epoch 13), train_loss = 2.632, time/batch = 0.213\n",
            "4099/15750 (epoch 13), train_loss = 2.546, time/batch = 0.202\n",
            "4100/15750 (epoch 13), train_loss = 2.531, time/batch = 0.203\n",
            "4101/15750 (epoch 13), train_loss = 2.708, time/batch = 0.207\n",
            "4102/15750 (epoch 13), train_loss = 2.623, time/batch = 0.206\n",
            "4103/15750 (epoch 13), train_loss = 2.596, time/batch = 0.204\n",
            "4104/15750 (epoch 13), train_loss = 2.559, time/batch = 0.206\n",
            "4105/15750 (epoch 13), train_loss = 2.544, time/batch = 0.203\n",
            "4106/15750 (epoch 13), train_loss = 2.489, time/batch = 0.202\n",
            "4107/15750 (epoch 13), train_loss = 2.615, time/batch = 0.204\n",
            "4108/15750 (epoch 13), train_loss = 2.558, time/batch = 0.201\n",
            "4109/15750 (epoch 13), train_loss = 2.557, time/batch = 0.198\n",
            "4110/15750 (epoch 13), train_loss = 2.564, time/batch = 0.196\n",
            "4111/15750 (epoch 13), train_loss = 2.586, time/batch = 0.213\n",
            "4112/15750 (epoch 13), train_loss = 2.650, time/batch = 0.198\n",
            "4113/15750 (epoch 13), train_loss = 2.644, time/batch = 0.199\n",
            "4114/15750 (epoch 13), train_loss = 2.591, time/batch = 0.200\n",
            "4115/15750 (epoch 13), train_loss = 2.594, time/batch = 0.203\n",
            "4116/15750 (epoch 13), train_loss = 2.599, time/batch = 0.205\n",
            "4117/15750 (epoch 13), train_loss = 2.558, time/batch = 0.197\n",
            "4118/15750 (epoch 13), train_loss = 2.614, time/batch = 0.200\n",
            "4119/15750 (epoch 13), train_loss = 2.597, time/batch = 0.203\n",
            "4120/15750 (epoch 13), train_loss = 2.632, time/batch = 0.193\n",
            "4121/15750 (epoch 13), train_loss = 2.618, time/batch = 0.202\n",
            "4122/15750 (epoch 13), train_loss = 2.620, time/batch = 0.205\n",
            "4123/15750 (epoch 13), train_loss = 2.751, time/batch = 0.199\n",
            "4124/15750 (epoch 13), train_loss = 2.654, time/batch = 0.201\n",
            "4125/15750 (epoch 13), train_loss = 2.607, time/batch = 0.200\n",
            "4126/15750 (epoch 13), train_loss = 2.586, time/batch = 0.211\n",
            "4127/15750 (epoch 13), train_loss = 2.491, time/batch = 0.206\n",
            "4128/15750 (epoch 13), train_loss = 2.516, time/batch = 0.200\n",
            "4129/15750 (epoch 13), train_loss = 2.588, time/batch = 0.200\n",
            "4130/15750 (epoch 13), train_loss = 2.501, time/batch = 0.199\n",
            "4131/15750 (epoch 13), train_loss = 2.530, time/batch = 0.211\n",
            "4132/15750 (epoch 13), train_loss = 2.603, time/batch = 0.207\n",
            "4133/15750 (epoch 13), train_loss = 2.517, time/batch = 0.204\n",
            "4134/15750 (epoch 13), train_loss = 2.566, time/batch = 0.211\n",
            "4135/15750 (epoch 13), train_loss = 2.542, time/batch = 0.203\n",
            "4136/15750 (epoch 13), train_loss = 2.593, time/batch = 0.212\n",
            "4137/15750 (epoch 13), train_loss = 2.586, time/batch = 0.208\n",
            "4138/15750 (epoch 13), train_loss = 2.523, time/batch = 0.205\n",
            "4139/15750 (epoch 13), train_loss = 2.582, time/batch = 0.208\n",
            "4140/15750 (epoch 13), train_loss = 2.481, time/batch = 0.205\n",
            "4141/15750 (epoch 13), train_loss = 2.519, time/batch = 0.208\n",
            "4142/15750 (epoch 13), train_loss = 2.574, time/batch = 0.206\n",
            "4143/15750 (epoch 13), train_loss = 2.604, time/batch = 0.206\n",
            "4144/15750 (epoch 13), train_loss = 2.502, time/batch = 0.204\n",
            "4145/15750 (epoch 13), train_loss = 2.543, time/batch = 0.209\n",
            "4146/15750 (epoch 13), train_loss = 2.507, time/batch = 0.210\n",
            "4147/15750 (epoch 13), train_loss = 2.567, time/batch = 0.204\n",
            "4148/15750 (epoch 13), train_loss = 2.576, time/batch = 0.203\n",
            "4149/15750 (epoch 13), train_loss = 2.563, time/batch = 0.205\n",
            "4150/15750 (epoch 13), train_loss = 2.612, time/batch = 0.200\n",
            "4151/15750 (epoch 13), train_loss = 2.474, time/batch = 0.207\n",
            "4152/15750 (epoch 13), train_loss = 2.486, time/batch = 0.202\n",
            "4153/15750 (epoch 13), train_loss = 2.562, time/batch = 0.207\n",
            "4154/15750 (epoch 13), train_loss = 2.413, time/batch = 0.196\n",
            "4155/15750 (epoch 13), train_loss = 2.541, time/batch = 0.204\n",
            "4156/15750 (epoch 13), train_loss = 2.530, time/batch = 0.207\n",
            "4157/15750 (epoch 13), train_loss = 2.465, time/batch = 0.204\n",
            "4158/15750 (epoch 13), train_loss = 2.507, time/batch = 0.196\n",
            "4159/15750 (epoch 13), train_loss = 2.454, time/batch = 0.201\n",
            "4160/15750 (epoch 13), train_loss = 2.453, time/batch = 0.206\n",
            "4161/15750 (epoch 13), train_loss = 2.393, time/batch = 0.212\n",
            "4162/15750 (epoch 13), train_loss = 2.425, time/batch = 0.208\n",
            "4163/15750 (epoch 13), train_loss = 2.475, time/batch = 0.206\n",
            "4164/15750 (epoch 13), train_loss = 2.560, time/batch = 0.204\n",
            "4165/15750 (epoch 13), train_loss = 2.486, time/batch = 0.208\n",
            "4166/15750 (epoch 13), train_loss = 2.483, time/batch = 0.208\n",
            "4167/15750 (epoch 13), train_loss = 2.376, time/batch = 0.204\n",
            "4168/15750 (epoch 13), train_loss = 2.477, time/batch = 0.204\n",
            "4169/15750 (epoch 13), train_loss = 2.577, time/batch = 0.204\n",
            "4170/15750 (epoch 13), train_loss = 2.521, time/batch = 0.205\n",
            "4171/15750 (epoch 13), train_loss = 2.504, time/batch = 0.208\n",
            "4172/15750 (epoch 13), train_loss = 2.507, time/batch = 0.202\n",
            "4173/15750 (epoch 13), train_loss = 2.522, time/batch = 0.207\n",
            "4174/15750 (epoch 13), train_loss = 2.529, time/batch = 0.206\n",
            "4175/15750 (epoch 13), train_loss = 2.427, time/batch = 0.203\n",
            "4176/15750 (epoch 13), train_loss = 2.531, time/batch = 0.207\n",
            "4177/15750 (epoch 13), train_loss = 2.451, time/batch = 0.210\n",
            "4178/15750 (epoch 13), train_loss = 2.519, time/batch = 0.210\n",
            "4179/15750 (epoch 13), train_loss = 2.589, time/batch = 0.201\n",
            "4180/15750 (epoch 13), train_loss = 2.597, time/batch = 0.209\n",
            "4181/15750 (epoch 13), train_loss = 2.438, time/batch = 0.218\n",
            "4182/15750 (epoch 13), train_loss = 2.473, time/batch = 0.204\n",
            "4183/15750 (epoch 13), train_loss = 2.504, time/batch = 0.201\n",
            "4184/15750 (epoch 13), train_loss = 2.471, time/batch = 0.205\n",
            "4185/15750 (epoch 13), train_loss = 2.493, time/batch = 0.200\n",
            "4186/15750 (epoch 13), train_loss = 2.547, time/batch = 0.209\n",
            "4187/15750 (epoch 13), train_loss = 2.549, time/batch = 0.201\n",
            "4188/15750 (epoch 13), train_loss = 2.564, time/batch = 0.200\n",
            "4189/15750 (epoch 13), train_loss = 2.611, time/batch = 0.204\n",
            "4190/15750 (epoch 13), train_loss = 2.511, time/batch = 0.205\n",
            "4191/15750 (epoch 13), train_loss = 2.535, time/batch = 0.209\n",
            "4192/15750 (epoch 13), train_loss = 2.539, time/batch = 0.203\n",
            "4193/15750 (epoch 13), train_loss = 2.547, time/batch = 0.208\n",
            "4194/15750 (epoch 13), train_loss = 2.555, time/batch = 0.204\n",
            "4195/15750 (epoch 13), train_loss = 2.529, time/batch = 0.202\n",
            "4196/15750 (epoch 13), train_loss = 2.448, time/batch = 0.211\n",
            "4197/15750 (epoch 13), train_loss = 2.481, time/batch = 0.204\n",
            "4198/15750 (epoch 13), train_loss = 2.610, time/batch = 0.205\n",
            "4199/15750 (epoch 13), train_loss = 2.547, time/batch = 0.203\n",
            "4200/15750 (epoch 13), train_loss = 2.472, time/batch = 0.205\n",
            "4201/15750 (epoch 13), train_loss = 2.528, time/batch = 0.211\n",
            "4202/15750 (epoch 13), train_loss = 2.532, time/batch = 0.209\n",
            "4203/15750 (epoch 13), train_loss = 2.591, time/batch = 0.207\n",
            "4204/15750 (epoch 13), train_loss = 2.603, time/batch = 0.202\n",
            "4205/15750 (epoch 13), train_loss = 2.641, time/batch = 0.208\n",
            "4206/15750 (epoch 13), train_loss = 2.535, time/batch = 0.208\n",
            "4207/15750 (epoch 13), train_loss = 2.512, time/batch = 0.204\n",
            "4208/15750 (epoch 13), train_loss = 2.530, time/batch = 0.207\n",
            "4209/15750 (epoch 13), train_loss = 2.539, time/batch = 0.203\n",
            "4210/15750 (epoch 13), train_loss = 2.612, time/batch = 0.202\n",
            "4211/15750 (epoch 13), train_loss = 2.537, time/batch = 0.212\n",
            "4212/15750 (epoch 13), train_loss = 2.670, time/batch = 0.199\n",
            "4213/15750 (epoch 13), train_loss = 2.533, time/batch = 0.203\n",
            "4214/15750 (epoch 13), train_loss = 2.509, time/batch = 0.196\n",
            "4215/15750 (epoch 13), train_loss = 2.495, time/batch = 0.201\n",
            "4216/15750 (epoch 13), train_loss = 2.476, time/batch = 0.210\n",
            "4217/15750 (epoch 13), train_loss = 2.505, time/batch = 0.198\n",
            "4218/15750 (epoch 13), train_loss = 2.490, time/batch = 0.200\n",
            "4219/15750 (epoch 13), train_loss = 2.511, time/batch = 0.204\n",
            "4220/15750 (epoch 13), train_loss = 2.529, time/batch = 0.195\n",
            "4221/15750 (epoch 13), train_loss = 2.621, time/batch = 0.217\n",
            "4222/15750 (epoch 13), train_loss = 2.471, time/batch = 0.209\n",
            "4223/15750 (epoch 13), train_loss = 2.472, time/batch = 0.200\n",
            "4224/15750 (epoch 13), train_loss = 2.485, time/batch = 0.204\n",
            "4225/15750 (epoch 13), train_loss = 2.431, time/batch = 0.208\n",
            "4226/15750 (epoch 13), train_loss = 2.436, time/batch = 0.209\n",
            "4227/15750 (epoch 13), train_loss = 2.454, time/batch = 0.208\n",
            "4228/15750 (epoch 13), train_loss = 2.445, time/batch = 0.209\n",
            "4229/15750 (epoch 13), train_loss = 2.502, time/batch = 0.204\n",
            "4230/15750 (epoch 13), train_loss = 2.607, time/batch = 0.209\n",
            "4231/15750 (epoch 13), train_loss = 2.565, time/batch = 0.218\n",
            "4232/15750 (epoch 13), train_loss = 2.581, time/batch = 0.202\n",
            "4233/15750 (epoch 13), train_loss = 2.565, time/batch = 0.205\n",
            "4234/15750 (epoch 13), train_loss = 2.492, time/batch = 0.209\n",
            "4235/15750 (epoch 13), train_loss = 2.485, time/batch = 0.203\n",
            "4236/15750 (epoch 13), train_loss = 2.568, time/batch = 0.206\n",
            "4237/15750 (epoch 13), train_loss = 2.585, time/batch = 0.211\n",
            "4238/15750 (epoch 13), train_loss = 2.580, time/batch = 0.205\n",
            "4239/15750 (epoch 13), train_loss = 2.508, time/batch = 0.204\n",
            "4240/15750 (epoch 13), train_loss = 2.500, time/batch = 0.202\n",
            "4241/15750 (epoch 13), train_loss = 2.438, time/batch = 0.209\n",
            "4242/15750 (epoch 13), train_loss = 2.529, time/batch = 0.201\n",
            "4243/15750 (epoch 13), train_loss = 2.561, time/batch = 0.193\n",
            "4244/15750 (epoch 13), train_loss = 2.507, time/batch = 0.201\n",
            "4245/15750 (epoch 13), train_loss = 2.510, time/batch = 0.197\n",
            "4246/15750 (epoch 13), train_loss = 2.542, time/batch = 0.212\n",
            "4247/15750 (epoch 13), train_loss = 2.618, time/batch = 0.197\n",
            "4248/15750 (epoch 13), train_loss = 2.556, time/batch = 0.201\n",
            "4249/15750 (epoch 13), train_loss = 2.555, time/batch = 0.201\n",
            "4250/15750 (epoch 13), train_loss = 2.553, time/batch = 0.204\n",
            "4251/15750 (epoch 13), train_loss = 2.558, time/batch = 0.211\n",
            "4252/15750 (epoch 13), train_loss = 2.537, time/batch = 0.203\n",
            "4253/15750 (epoch 13), train_loss = 2.640, time/batch = 0.203\n",
            "4254/15750 (epoch 13), train_loss = 2.488, time/batch = 0.210\n",
            "4255/15750 (epoch 13), train_loss = 2.567, time/batch = 0.203\n",
            "4256/15750 (epoch 13), train_loss = 2.554, time/batch = 0.205\n",
            "4257/15750 (epoch 13), train_loss = 2.598, time/batch = 0.207\n",
            "4258/15750 (epoch 13), train_loss = 2.672, time/batch = 0.206\n",
            "4259/15750 (epoch 13), train_loss = 2.585, time/batch = 0.208\n",
            "4260/15750 (epoch 13), train_loss = 2.600, time/batch = 0.204\n",
            "4261/15750 (epoch 13), train_loss = 2.589, time/batch = 0.210\n",
            "4262/15750 (epoch 13), train_loss = 2.532, time/batch = 0.206\n",
            "4263/15750 (epoch 13), train_loss = 2.496, time/batch = 0.206\n",
            "4264/15750 (epoch 13), train_loss = 2.492, time/batch = 0.206\n",
            "4265/15750 (epoch 13), train_loss = 2.553, time/batch = 0.206\n",
            "4266/15750 (epoch 13), train_loss = 2.595, time/batch = 0.205\n",
            "4267/15750 (epoch 13), train_loss = 2.535, time/batch = 0.203\n",
            "4268/15750 (epoch 13), train_loss = 2.582, time/batch = 0.201\n",
            "4269/15750 (epoch 13), train_loss = 2.554, time/batch = 0.208\n",
            "4270/15750 (epoch 13), train_loss = 2.466, time/batch = 0.202\n",
            "4271/15750 (epoch 13), train_loss = 2.505, time/batch = 0.220\n",
            "4272/15750 (epoch 13), train_loss = 2.561, time/batch = 0.202\n",
            "4273/15750 (epoch 13), train_loss = 2.490, time/batch = 0.203\n",
            "4274/15750 (epoch 13), train_loss = 2.455, time/batch = 0.203\n",
            "4275/15750 (epoch 13), train_loss = 2.471, time/batch = 0.205\n",
            "4276/15750 (epoch 13), train_loss = 2.583, time/batch = 0.204\n",
            "4277/15750 (epoch 13), train_loss = 2.516, time/batch = 0.200\n",
            "4278/15750 (epoch 13), train_loss = 2.598, time/batch = 0.201\n",
            "4279/15750 (epoch 13), train_loss = 2.593, time/batch = 0.198\n",
            "4280/15750 (epoch 13), train_loss = 2.501, time/batch = 0.200\n",
            "4281/15750 (epoch 13), train_loss = 2.478, time/batch = 0.205\n",
            "4282/15750 (epoch 13), train_loss = 2.553, time/batch = 0.201\n",
            "4283/15750 (epoch 13), train_loss = 2.612, time/batch = 0.203\n",
            "4284/15750 (epoch 13), train_loss = 2.674, time/batch = 0.198\n",
            "4285/15750 (epoch 13), train_loss = 2.610, time/batch = 0.200\n",
            "4286/15750 (epoch 13), train_loss = 2.543, time/batch = 0.201\n",
            "4287/15750 (epoch 13), train_loss = 2.553, time/batch = 0.205\n",
            "4288/15750 (epoch 13), train_loss = 2.488, time/batch = 0.198\n",
            "4289/15750 (epoch 13), train_loss = 2.593, time/batch = 0.200\n",
            "4290/15750 (epoch 13), train_loss = 2.611, time/batch = 0.206\n",
            "4291/15750 (epoch 13), train_loss = 2.531, time/batch = 0.208\n",
            "4292/15750 (epoch 13), train_loss = 2.486, time/batch = 0.202\n",
            "4293/15750 (epoch 13), train_loss = 2.579, time/batch = 0.201\n",
            "4294/15750 (epoch 13), train_loss = 2.394, time/batch = 0.200\n",
            "4295/15750 (epoch 13), train_loss = 2.479, time/batch = 0.199\n",
            "4296/15750 (epoch 13), train_loss = 2.453, time/batch = 0.199\n",
            "4297/15750 (epoch 13), train_loss = 2.530, time/batch = 0.207\n",
            "4298/15750 (epoch 13), train_loss = 2.507, time/batch = 0.201\n",
            "4299/15750 (epoch 13), train_loss = 2.565, time/batch = 0.200\n",
            "4300/15750 (epoch 13), train_loss = 2.534, time/batch = 0.204\n",
            "4301/15750 (epoch 13), train_loss = 2.395, time/batch = 0.211\n",
            "4302/15750 (epoch 13), train_loss = 2.471, time/batch = 0.204\n",
            "4303/15750 (epoch 13), train_loss = 2.473, time/batch = 0.202\n",
            "4304/15750 (epoch 13), train_loss = 2.517, time/batch = 0.200\n",
            "4305/15750 (epoch 13), train_loss = 2.390, time/batch = 0.201\n",
            "4306/15750 (epoch 13), train_loss = 2.487, time/batch = 0.204\n",
            "4307/15750 (epoch 13), train_loss = 2.378, time/batch = 0.196\n",
            "4308/15750 (epoch 13), train_loss = 2.443, time/batch = 0.198\n",
            "4309/15750 (epoch 13), train_loss = 2.445, time/batch = 0.219\n",
            "4310/15750 (epoch 13), train_loss = 2.449, time/batch = 0.201\n",
            "4311/15750 (epoch 13), train_loss = 2.599, time/batch = 0.209\n",
            "4312/15750 (epoch 13), train_loss = 2.407, time/batch = 0.204\n",
            "4313/15750 (epoch 13), train_loss = 2.648, time/batch = 0.204\n",
            "4314/15750 (epoch 13), train_loss = 2.501, time/batch = 0.206\n",
            "4315/15750 (epoch 13), train_loss = 2.401, time/batch = 0.204\n",
            "4316/15750 (epoch 13), train_loss = 2.449, time/batch = 0.210\n",
            "4317/15750 (epoch 13), train_loss = 2.510, time/batch = 0.206\n",
            "4318/15750 (epoch 13), train_loss = 2.501, time/batch = 0.203\n",
            "4319/15750 (epoch 13), train_loss = 2.475, time/batch = 0.209\n",
            "4320/15750 (epoch 13), train_loss = 2.473, time/batch = 0.206\n",
            "4321/15750 (epoch 13), train_loss = 2.557, time/batch = 0.208\n",
            "4322/15750 (epoch 13), train_loss = 2.471, time/batch = 0.212\n",
            "4323/15750 (epoch 13), train_loss = 2.507, time/batch = 0.207\n",
            "4324/15750 (epoch 13), train_loss = 2.589, time/batch = 0.206\n",
            "4325/15750 (epoch 13), train_loss = 2.450, time/batch = 0.208\n",
            "4326/15750 (epoch 13), train_loss = 2.459, time/batch = 0.215\n",
            "4327/15750 (epoch 13), train_loss = 2.508, time/batch = 0.200\n",
            "4328/15750 (epoch 13), train_loss = 2.517, time/batch = 0.201\n",
            "4329/15750 (epoch 13), train_loss = 2.443, time/batch = 0.206\n",
            "4330/15750 (epoch 13), train_loss = 2.452, time/batch = 0.204\n",
            "4331/15750 (epoch 13), train_loss = 2.408, time/batch = 0.208\n",
            "4332/15750 (epoch 13), train_loss = 2.489, time/batch = 0.205\n",
            "4333/15750 (epoch 13), train_loss = 2.690, time/batch = 0.204\n",
            "4334/15750 (epoch 13), train_loss = 2.490, time/batch = 0.204\n",
            "4335/15750 (epoch 13), train_loss = 2.559, time/batch = 0.200\n",
            "4336/15750 (epoch 13), train_loss = 2.437, time/batch = 0.210\n",
            "4337/15750 (epoch 13), train_loss = 2.507, time/batch = 0.202\n",
            "4338/15750 (epoch 13), train_loss = 2.519, time/batch = 0.206\n",
            "4339/15750 (epoch 13), train_loss = 2.506, time/batch = 0.204\n",
            "4340/15750 (epoch 13), train_loss = 2.568, time/batch = 0.205\n",
            "4341/15750 (epoch 13), train_loss = 2.534, time/batch = 0.212\n",
            "4342/15750 (epoch 13), train_loss = 2.534, time/batch = 0.208\n",
            "4343/15750 (epoch 13), train_loss = 2.517, time/batch = 0.205\n",
            "4344/15750 (epoch 13), train_loss = 2.539, time/batch = 0.202\n",
            "4345/15750 (epoch 13), train_loss = 2.445, time/batch = 0.205\n",
            "4346/15750 (epoch 13), train_loss = 2.453, time/batch = 0.210\n",
            "4347/15750 (epoch 13), train_loss = 2.523, time/batch = 0.203\n",
            "4348/15750 (epoch 13), train_loss = 2.525, time/batch = 0.203\n",
            "4349/15750 (epoch 13), train_loss = 2.499, time/batch = 0.204\n",
            "4350/15750 (epoch 13), train_loss = 2.481, time/batch = 0.202\n",
            "4351/15750 (epoch 13), train_loss = 2.427, time/batch = 0.211\n",
            "4352/15750 (epoch 13), train_loss = 2.442, time/batch = 0.202\n",
            "4353/15750 (epoch 13), train_loss = 2.617, time/batch = 0.209\n",
            "4354/15750 (epoch 13), train_loss = 2.558, time/batch = 0.209\n",
            "4355/15750 (epoch 13), train_loss = 2.542, time/batch = 0.203\n",
            "4356/15750 (epoch 13), train_loss = 2.486, time/batch = 0.218\n",
            "4357/15750 (epoch 13), train_loss = 2.526, time/batch = 0.204\n",
            "4358/15750 (epoch 13), train_loss = 2.498, time/batch = 0.204\n",
            "4359/15750 (epoch 13), train_loss = 2.560, time/batch = 0.204\n",
            "4360/15750 (epoch 13), train_loss = 2.586, time/batch = 0.200\n",
            "4361/15750 (epoch 13), train_loss = 2.605, time/batch = 0.208\n",
            "4362/15750 (epoch 13), train_loss = 2.512, time/batch = 0.197\n",
            "4363/15750 (epoch 13), train_loss = 2.549, time/batch = 0.203\n",
            "4364/15750 (epoch 13), train_loss = 2.580, time/batch = 0.198\n",
            "4365/15750 (epoch 13), train_loss = 2.552, time/batch = 0.202\n",
            "4366/15750 (epoch 13), train_loss = 2.445, time/batch = 0.210\n",
            "4367/15750 (epoch 13), train_loss = 2.501, time/batch = 0.198\n",
            "4368/15750 (epoch 13), train_loss = 2.555, time/batch = 0.201\n",
            "4369/15750 (epoch 13), train_loss = 2.576, time/batch = 0.194\n",
            "4370/15750 (epoch 13), train_loss = 2.541, time/batch = 0.204\n",
            "4371/15750 (epoch 13), train_loss = 2.587, time/batch = 0.206\n",
            "4372/15750 (epoch 13), train_loss = 2.510, time/batch = 0.204\n",
            "4373/15750 (epoch 13), train_loss = 2.462, time/batch = 0.202\n",
            "4374/15750 (epoch 13), train_loss = 2.430, time/batch = 0.206\n",
            "4375/15750 (epoch 13), train_loss = 2.684, time/batch = 0.202\n",
            "4376/15750 (epoch 13), train_loss = 2.494, time/batch = 0.206\n",
            "4377/15750 (epoch 13), train_loss = 2.454, time/batch = 0.202\n",
            "4378/15750 (epoch 13), train_loss = 2.594, time/batch = 0.211\n",
            "4379/15750 (epoch 13), train_loss = 2.459, time/batch = 0.202\n",
            "4380/15750 (epoch 13), train_loss = 2.617, time/batch = 0.205\n",
            "4381/15750 (epoch 13), train_loss = 2.484, time/batch = 0.208\n",
            "4382/15750 (epoch 13), train_loss = 2.504, time/batch = 0.204\n",
            "4383/15750 (epoch 13), train_loss = 2.427, time/batch = 0.204\n",
            "4384/15750 (epoch 13), train_loss = 2.512, time/batch = 0.202\n",
            "4385/15750 (epoch 13), train_loss = 2.433, time/batch = 0.205\n",
            "4386/15750 (epoch 13), train_loss = 2.533, time/batch = 0.214\n",
            "4387/15750 (epoch 13), train_loss = 2.522, time/batch = 0.205\n",
            "4388/15750 (epoch 13), train_loss = 2.489, time/batch = 0.206\n",
            "4389/15750 (epoch 13), train_loss = 2.541, time/batch = 0.210\n",
            "4390/15750 (epoch 13), train_loss = 2.619, time/batch = 0.202\n",
            "4391/15750 (epoch 13), train_loss = 2.575, time/batch = 0.212\n",
            "4392/15750 (epoch 13), train_loss = 2.596, time/batch = 0.204\n",
            "4393/15750 (epoch 13), train_loss = 2.451, time/batch = 0.207\n",
            "4394/15750 (epoch 13), train_loss = 2.542, time/batch = 0.209\n",
            "4395/15750 (epoch 13), train_loss = 2.513, time/batch = 0.204\n",
            "4396/15750 (epoch 13), train_loss = 2.431, time/batch = 0.215\n",
            "4397/15750 (epoch 13), train_loss = 2.561, time/batch = 0.195\n",
            "4398/15750 (epoch 13), train_loss = 2.418, time/batch = 0.205\n",
            "4399/15750 (epoch 13), train_loss = 2.561, time/batch = 0.200\n",
            "4400/15750 (epoch 13), train_loss = 2.509, time/batch = 0.200\n",
            "4401/15750 (epoch 13), train_loss = 2.490, time/batch = 0.209\n",
            "4402/15750 (epoch 13), train_loss = 2.425, time/batch = 0.205\n",
            "4403/15750 (epoch 13), train_loss = 2.455, time/batch = 0.203\n",
            "4404/15750 (epoch 13), train_loss = 2.588, time/batch = 0.198\n",
            "4405/15750 (epoch 13), train_loss = 2.429, time/batch = 0.204\n",
            "4406/15750 (epoch 13), train_loss = 2.400, time/batch = 0.204\n",
            "4407/15750 (epoch 13), train_loss = 2.471, time/batch = 0.204\n",
            "4408/15750 (epoch 13), train_loss = 2.455, time/batch = 0.207\n",
            "4409/15750 (epoch 13), train_loss = 2.558, time/batch = 0.202\n",
            "4410/15750 (epoch 14), train_loss = 2.577, time/batch = 0.209\n",
            "4411/15750 (epoch 14), train_loss = 2.568, time/batch = 0.202\n",
            "4412/15750 (epoch 14), train_loss = 2.509, time/batch = 0.203\n",
            "4413/15750 (epoch 14), train_loss = 2.603, time/batch = 0.203\n",
            "4414/15750 (epoch 14), train_loss = 2.519, time/batch = 0.203\n",
            "4415/15750 (epoch 14), train_loss = 2.504, time/batch = 0.205\n",
            "4416/15750 (epoch 14), train_loss = 2.682, time/batch = 0.199\n",
            "4417/15750 (epoch 14), train_loss = 2.595, time/batch = 0.203\n",
            "4418/15750 (epoch 14), train_loss = 2.571, time/batch = 0.199\n",
            "4419/15750 (epoch 14), train_loss = 2.529, time/batch = 0.203\n",
            "4420/15750 (epoch 14), train_loss = 2.517, time/batch = 0.206\n",
            "4421/15750 (epoch 14), train_loss = 2.465, time/batch = 0.196\n",
            "4422/15750 (epoch 14), train_loss = 2.585, time/batch = 0.200\n",
            "4423/15750 (epoch 14), train_loss = 2.533, time/batch = 0.204\n",
            "4424/15750 (epoch 14), train_loss = 2.531, time/batch = 0.195\n",
            "4425/15750 (epoch 14), train_loss = 2.539, time/batch = 0.207\n",
            "4426/15750 (epoch 14), train_loss = 2.560, time/batch = 0.199\n",
            "4427/15750 (epoch 14), train_loss = 2.622, time/batch = 0.203\n",
            "4428/15750 (epoch 14), train_loss = 2.619, time/batch = 0.205\n",
            "4429/15750 (epoch 14), train_loss = 2.564, time/batch = 0.200\n",
            "4430/15750 (epoch 14), train_loss = 2.567, time/batch = 0.212\n",
            "4431/15750 (epoch 14), train_loss = 2.573, time/batch = 0.202\n",
            "4432/15750 (epoch 14), train_loss = 2.531, time/batch = 0.207\n",
            "4433/15750 (epoch 14), train_loss = 2.587, time/batch = 0.204\n",
            "4434/15750 (epoch 14), train_loss = 2.573, time/batch = 0.205\n",
            "4435/15750 (epoch 14), train_loss = 2.606, time/batch = 0.211\n",
            "4436/15750 (epoch 14), train_loss = 2.594, time/batch = 0.209\n",
            "4437/15750 (epoch 14), train_loss = 2.593, time/batch = 0.202\n",
            "4438/15750 (epoch 14), train_loss = 2.722, time/batch = 0.202\n",
            "4439/15750 (epoch 14), train_loss = 2.628, time/batch = 0.205\n",
            "4440/15750 (epoch 14), train_loss = 2.582, time/batch = 0.210\n",
            "4441/15750 (epoch 14), train_loss = 2.559, time/batch = 0.205\n",
            "4442/15750 (epoch 14), train_loss = 2.464, time/batch = 0.214\n",
            "4443/15750 (epoch 14), train_loss = 2.489, time/batch = 0.203\n",
            "4444/15750 (epoch 14), train_loss = 2.565, time/batch = 0.204\n",
            "4445/15750 (epoch 14), train_loss = 2.475, time/batch = 0.211\n",
            "4446/15750 (epoch 14), train_loss = 2.507, time/batch = 0.212\n",
            "4447/15750 (epoch 14), train_loss = 2.580, time/batch = 0.204\n",
            "4448/15750 (epoch 14), train_loss = 2.492, time/batch = 0.203\n",
            "4449/15750 (epoch 14), train_loss = 2.540, time/batch = 0.205\n",
            "4450/15750 (epoch 14), train_loss = 2.514, time/batch = 0.212\n",
            "4451/15750 (epoch 14), train_loss = 2.565, time/batch = 0.203\n",
            "4452/15750 (epoch 14), train_loss = 2.557, time/batch = 0.198\n",
            "4453/15750 (epoch 14), train_loss = 2.500, time/batch = 0.205\n",
            "4454/15750 (epoch 14), train_loss = 2.555, time/batch = 0.207\n",
            "4455/15750 (epoch 14), train_loss = 2.461, time/batch = 0.201\n",
            "4456/15750 (epoch 14), train_loss = 2.496, time/batch = 0.199\n",
            "4457/15750 (epoch 14), train_loss = 2.546, time/batch = 0.204\n",
            "4458/15750 (epoch 14), train_loss = 2.578, time/batch = 0.201\n",
            "4459/15750 (epoch 14), train_loss = 2.476, time/batch = 0.198\n",
            "4460/15750 (epoch 14), train_loss = 2.519, time/batch = 0.199\n",
            "4461/15750 (epoch 14), train_loss = 2.478, time/batch = 0.211\n",
            "4462/15750 (epoch 14), train_loss = 2.541, time/batch = 0.202\n",
            "4463/15750 (epoch 14), train_loss = 2.549, time/batch = 0.197\n",
            "4464/15750 (epoch 14), train_loss = 2.537, time/batch = 0.202\n",
            "4465/15750 (epoch 14), train_loss = 2.585, time/batch = 0.208\n",
            "4466/15750 (epoch 14), train_loss = 2.449, time/batch = 0.209\n",
            "4467/15750 (epoch 14), train_loss = 2.461, time/batch = 0.204\n",
            "4468/15750 (epoch 14), train_loss = 2.538, time/batch = 0.208\n",
            "4469/15750 (epoch 14), train_loss = 2.389, time/batch = 0.208\n",
            "4470/15750 (epoch 14), train_loss = 2.514, time/batch = 0.211\n",
            "4471/15750 (epoch 14), train_loss = 2.506, time/batch = 0.209\n",
            "4472/15750 (epoch 14), train_loss = 2.440, time/batch = 0.206\n",
            "4473/15750 (epoch 14), train_loss = 2.484, time/batch = 0.203\n",
            "4474/15750 (epoch 14), train_loss = 2.425, time/batch = 0.206\n",
            "4475/15750 (epoch 14), train_loss = 2.426, time/batch = 0.210\n",
            "4476/15750 (epoch 14), train_loss = 2.367, time/batch = 0.208\n",
            "4477/15750 (epoch 14), train_loss = 2.399, time/batch = 0.207\n",
            "4478/15750 (epoch 14), train_loss = 2.449, time/batch = 0.208\n",
            "4479/15750 (epoch 14), train_loss = 2.535, time/batch = 0.202\n",
            "4480/15750 (epoch 14), train_loss = 2.461, time/batch = 0.213\n",
            "4481/15750 (epoch 14), train_loss = 2.457, time/batch = 0.203\n",
            "4482/15750 (epoch 14), train_loss = 2.353, time/batch = 0.202\n",
            "4483/15750 (epoch 14), train_loss = 2.452, time/batch = 0.200\n",
            "4484/15750 (epoch 14), train_loss = 2.552, time/batch = 0.201\n",
            "4485/15750 (epoch 14), train_loss = 2.495, time/batch = 0.208\n",
            "4486/15750 (epoch 14), train_loss = 2.479, time/batch = 0.201\n",
            "4487/15750 (epoch 14), train_loss = 2.483, time/batch = 0.197\n",
            "4488/15750 (epoch 14), train_loss = 2.495, time/batch = 0.204\n",
            "4489/15750 (epoch 14), train_loss = 2.499, time/batch = 0.203\n",
            "4490/15750 (epoch 14), train_loss = 2.399, time/batch = 0.206\n",
            "4491/15750 (epoch 14), train_loss = 2.504, time/batch = 0.199\n",
            "4492/15750 (epoch 14), train_loss = 2.425, time/batch = 0.199\n",
            "4493/15750 (epoch 14), train_loss = 2.492, time/batch = 0.208\n",
            "4494/15750 (epoch 14), train_loss = 2.563, time/batch = 0.201\n",
            "4495/15750 (epoch 14), train_loss = 2.572, time/batch = 0.206\n",
            "4496/15750 (epoch 14), train_loss = 2.412, time/batch = 0.205\n",
            "4497/15750 (epoch 14), train_loss = 2.445, time/batch = 0.211\n",
            "4498/15750 (epoch 14), train_loss = 2.474, time/batch = 0.204\n",
            "4499/15750 (epoch 14), train_loss = 2.447, time/batch = 0.206\n",
            "4500/15750 (epoch 14), train_loss = 2.466, time/batch = 0.213\n",
            "4501/15750 (epoch 14), train_loss = 2.520, time/batch = 0.207\n",
            "4502/15750 (epoch 14), train_loss = 2.520, time/batch = 0.208\n",
            "4503/15750 (epoch 14), train_loss = 2.536, time/batch = 0.207\n",
            "4504/15750 (epoch 14), train_loss = 2.587, time/batch = 0.209\n",
            "4505/15750 (epoch 14), train_loss = 2.485, time/batch = 0.223\n",
            "4506/15750 (epoch 14), train_loss = 2.508, time/batch = 0.206\n",
            "4507/15750 (epoch 14), train_loss = 2.514, time/batch = 0.202\n",
            "4508/15750 (epoch 14), train_loss = 2.521, time/batch = 0.208\n",
            "4509/15750 (epoch 14), train_loss = 2.532, time/batch = 0.204\n",
            "4510/15750 (epoch 14), train_loss = 2.506, time/batch = 0.203\n",
            "4511/15750 (epoch 14), train_loss = 2.424, time/batch = 0.205\n",
            "4512/15750 (epoch 14), train_loss = 2.457, time/batch = 0.204\n",
            "4513/15750 (epoch 14), train_loss = 2.584, time/batch = 0.203\n",
            "4514/15750 (epoch 14), train_loss = 2.521, time/batch = 0.205\n",
            "4515/15750 (epoch 14), train_loss = 2.443, time/batch = 0.198\n",
            "4516/15750 (epoch 14), train_loss = 2.500, time/batch = 0.204\n",
            "4517/15750 (epoch 14), train_loss = 2.507, time/batch = 0.207\n",
            "4518/15750 (epoch 14), train_loss = 2.564, time/batch = 0.200\n",
            "4519/15750 (epoch 14), train_loss = 2.578, time/batch = 0.208\n",
            "4520/15750 (epoch 14), train_loss = 2.617, time/batch = 0.216\n",
            "4521/15750 (epoch 14), train_loss = 2.508, time/batch = 0.209\n",
            "4522/15750 (epoch 14), train_loss = 2.486, time/batch = 0.205\n",
            "4523/15750 (epoch 14), train_loss = 2.504, time/batch = 0.212\n",
            "4524/15750 (epoch 14), train_loss = 2.516, time/batch = 0.200\n",
            "4525/15750 (epoch 14), train_loss = 2.586, time/batch = 0.206\n",
            "4526/15750 (epoch 14), train_loss = 2.512, time/batch = 0.208\n",
            "4527/15750 (epoch 14), train_loss = 2.644, time/batch = 0.207\n",
            "4528/15750 (epoch 14), train_loss = 2.509, time/batch = 0.211\n",
            "4529/15750 (epoch 14), train_loss = 2.484, time/batch = 0.208\n",
            "4530/15750 (epoch 14), train_loss = 2.471, time/batch = 0.203\n",
            "4531/15750 (epoch 14), train_loss = 2.451, time/batch = 0.217\n",
            "4532/15750 (epoch 14), train_loss = 2.481, time/batch = 0.211\n",
            "4533/15750 (epoch 14), train_loss = 2.462, time/batch = 0.213\n",
            "4534/15750 (epoch 14), train_loss = 2.487, time/batch = 0.215\n",
            "4535/15750 (epoch 14), train_loss = 2.502, time/batch = 0.206\n",
            "4536/15750 (epoch 14), train_loss = 2.594, time/batch = 0.211\n",
            "4537/15750 (epoch 14), train_loss = 2.447, time/batch = 0.212\n",
            "4538/15750 (epoch 14), train_loss = 2.451, time/batch = 0.211\n",
            "4539/15750 (epoch 14), train_loss = 2.461, time/batch = 0.216\n",
            "4540/15750 (epoch 14), train_loss = 2.405, time/batch = 0.205\n",
            "4541/15750 (epoch 14), train_loss = 2.411, time/batch = 0.209\n",
            "4542/15750 (epoch 14), train_loss = 2.428, time/batch = 0.204\n",
            "4543/15750 (epoch 14), train_loss = 2.422, time/batch = 0.203\n",
            "4544/15750 (epoch 14), train_loss = 2.475, time/batch = 0.212\n",
            "4545/15750 (epoch 14), train_loss = 2.583, time/batch = 0.206\n",
            "4546/15750 (epoch 14), train_loss = 2.540, time/batch = 0.206\n",
            "4547/15750 (epoch 14), train_loss = 2.555, time/batch = 0.204\n",
            "4548/15750 (epoch 14), train_loss = 2.542, time/batch = 0.199\n",
            "4549/15750 (epoch 14), train_loss = 2.468, time/batch = 0.208\n",
            "4550/15750 (epoch 14), train_loss = 2.461, time/batch = 0.201\n",
            "4551/15750 (epoch 14), train_loss = 2.543, time/batch = 0.201\n",
            "4552/15750 (epoch 14), train_loss = 2.561, time/batch = 0.202\n",
            "4553/15750 (epoch 14), train_loss = 2.556, time/batch = 0.204\n",
            "4554/15750 (epoch 14), train_loss = 2.483, time/batch = 0.205\n",
            "4555/15750 (epoch 14), train_loss = 2.474, time/batch = 0.199\n",
            "4556/15750 (epoch 14), train_loss = 2.414, time/batch = 0.215\n",
            "4557/15750 (epoch 14), train_loss = 2.505, time/batch = 0.207\n",
            "4558/15750 (epoch 14), train_loss = 2.536, time/batch = 0.207\n",
            "4559/15750 (epoch 14), train_loss = 2.482, time/batch = 0.212\n",
            "4560/15750 (epoch 14), train_loss = 2.485, time/batch = 0.203\n",
            "4561/15750 (epoch 14), train_loss = 2.519, time/batch = 0.208\n",
            "4562/15750 (epoch 14), train_loss = 2.592, time/batch = 0.207\n",
            "4563/15750 (epoch 14), train_loss = 2.531, time/batch = 0.203\n",
            "4564/15750 (epoch 14), train_loss = 2.532, time/batch = 0.213\n",
            "4565/15750 (epoch 14), train_loss = 2.526, time/batch = 0.215\n",
            "4566/15750 (epoch 14), train_loss = 2.532, time/batch = 0.208\n",
            "4567/15750 (epoch 14), train_loss = 2.512, time/batch = 0.203\n",
            "4568/15750 (epoch 14), train_loss = 2.614, time/batch = 0.207\n",
            "4569/15750 (epoch 14), train_loss = 2.462, time/batch = 0.208\n",
            "4570/15750 (epoch 14), train_loss = 2.540, time/batch = 0.203\n",
            "4571/15750 (epoch 14), train_loss = 2.530, time/batch = 0.207\n",
            "4572/15750 (epoch 14), train_loss = 2.569, time/batch = 0.212\n",
            "4573/15750 (epoch 14), train_loss = 2.645, time/batch = 0.207\n",
            "4574/15750 (epoch 14), train_loss = 2.559, time/batch = 0.212\n",
            "4575/15750 (epoch 14), train_loss = 2.572, time/batch = 0.208\n",
            "4576/15750 (epoch 14), train_loss = 2.559, time/batch = 0.211\n",
            "4577/15750 (epoch 14), train_loss = 2.505, time/batch = 0.210\n",
            "4578/15750 (epoch 14), train_loss = 2.471, time/batch = 0.211\n",
            "4579/15750 (epoch 14), train_loss = 2.466, time/batch = 0.214\n",
            "4580/15750 (epoch 14), train_loss = 2.525, time/batch = 0.207\n",
            "4581/15750 (epoch 14), train_loss = 2.567, time/batch = 0.219\n",
            "4582/15750 (epoch 14), train_loss = 2.508, time/batch = 0.204\n",
            "4583/15750 (epoch 14), train_loss = 2.557, time/batch = 0.203\n",
            "4584/15750 (epoch 14), train_loss = 2.527, time/batch = 0.204\n",
            "4585/15750 (epoch 14), train_loss = 2.440, time/batch = 0.213\n",
            "4586/15750 (epoch 14), train_loss = 2.479, time/batch = 0.220\n",
            "4587/15750 (epoch 14), train_loss = 2.535, time/batch = 0.212\n",
            "4588/15750 (epoch 14), train_loss = 2.463, time/batch = 0.217\n",
            "4589/15750 (epoch 14), train_loss = 2.431, time/batch = 0.214\n",
            "4590/15750 (epoch 14), train_loss = 2.448, time/batch = 0.214\n",
            "4591/15750 (epoch 14), train_loss = 2.557, time/batch = 0.217\n",
            "4592/15750 (epoch 14), train_loss = 2.494, time/batch = 0.210\n",
            "4593/15750 (epoch 14), train_loss = 2.573, time/batch = 0.209\n",
            "4594/15750 (epoch 14), train_loss = 2.569, time/batch = 0.207\n",
            "4595/15750 (epoch 14), train_loss = 2.478, time/batch = 0.213\n",
            "4596/15750 (epoch 14), train_loss = 2.453, time/batch = 0.204\n",
            "4597/15750 (epoch 14), train_loss = 2.529, time/batch = 0.215\n",
            "4598/15750 (epoch 14), train_loss = 2.585, time/batch = 0.220\n",
            "4599/15750 (epoch 14), train_loss = 2.649, time/batch = 0.209\n",
            "4600/15750 (epoch 14), train_loss = 2.587, time/batch = 0.210\n",
            "4601/15750 (epoch 14), train_loss = 2.518, time/batch = 0.209\n",
            "4602/15750 (epoch 14), train_loss = 2.528, time/batch = 0.209\n",
            "4603/15750 (epoch 14), train_loss = 2.462, time/batch = 0.209\n",
            "4604/15750 (epoch 14), train_loss = 2.569, time/batch = 0.204\n",
            "4605/15750 (epoch 14), train_loss = 2.584, time/batch = 0.208\n",
            "4606/15750 (epoch 14), train_loss = 2.507, time/batch = 0.202\n",
            "4607/15750 (epoch 14), train_loss = 2.461, time/batch = 0.211\n",
            "4608/15750 (epoch 14), train_loss = 2.554, time/batch = 0.215\n",
            "4609/15750 (epoch 14), train_loss = 2.368, time/batch = 0.210\n",
            "4610/15750 (epoch 14), train_loss = 2.454, time/batch = 0.213\n",
            "4611/15750 (epoch 14), train_loss = 2.427, time/batch = 0.208\n",
            "4612/15750 (epoch 14), train_loss = 2.505, time/batch = 0.209\n",
            "4613/15750 (epoch 14), train_loss = 2.480, time/batch = 0.213\n",
            "4614/15750 (epoch 14), train_loss = 2.540, time/batch = 0.208\n",
            "4615/15750 (epoch 14), train_loss = 2.508, time/batch = 0.206\n",
            "4616/15750 (epoch 14), train_loss = 2.370, time/batch = 0.215\n",
            "4617/15750 (epoch 14), train_loss = 2.447, time/batch = 0.208\n",
            "4618/15750 (epoch 14), train_loss = 2.449, time/batch = 0.203\n",
            "4619/15750 (epoch 14), train_loss = 2.495, time/batch = 0.205\n",
            "4620/15750 (epoch 14), train_loss = 2.369, time/batch = 0.207\n",
            "4621/15750 (epoch 14), train_loss = 2.464, time/batch = 0.202\n",
            "4622/15750 (epoch 14), train_loss = 2.353, time/batch = 0.198\n",
            "4623/15750 (epoch 14), train_loss = 2.418, time/batch = 0.204\n",
            "4624/15750 (epoch 14), train_loss = 2.421, time/batch = 0.207\n",
            "4625/15750 (epoch 14), train_loss = 2.423, time/batch = 0.200\n",
            "4626/15750 (epoch 14), train_loss = 2.574, time/batch = 0.214\n",
            "4627/15750 (epoch 14), train_loss = 2.382, time/batch = 0.209\n",
            "4628/15750 (epoch 14), train_loss = 2.624, time/batch = 0.213\n",
            "4629/15750 (epoch 14), train_loss = 2.479, time/batch = 0.213\n",
            "4630/15750 (epoch 14), train_loss = 2.375, time/batch = 0.216\n",
            "4631/15750 (epoch 14), train_loss = 2.423, time/batch = 0.214\n",
            "4632/15750 (epoch 14), train_loss = 2.484, time/batch = 0.214\n",
            "4633/15750 (epoch 14), train_loss = 2.475, time/batch = 0.210\n",
            "4634/15750 (epoch 14), train_loss = 2.451, time/batch = 0.212\n",
            "4635/15750 (epoch 14), train_loss = 2.449, time/batch = 0.205\n",
            "4636/15750 (epoch 14), train_loss = 2.533, time/batch = 0.211\n",
            "4637/15750 (epoch 14), train_loss = 2.446, time/batch = 0.206\n",
            "4638/15750 (epoch 14), train_loss = 2.484, time/batch = 0.208\n",
            "4639/15750 (epoch 14), train_loss = 2.565, time/batch = 0.208\n",
            "4640/15750 (epoch 14), train_loss = 2.423, time/batch = 0.214\n",
            "4641/15750 (epoch 14), train_loss = 2.435, time/batch = 0.211\n",
            "4642/15750 (epoch 14), train_loss = 2.485, time/batch = 0.223\n",
            "4643/15750 (epoch 14), train_loss = 2.492, time/batch = 0.218\n",
            "4644/15750 (epoch 14), train_loss = 2.420, time/batch = 0.212\n",
            "4645/15750 (epoch 14), train_loss = 2.425, time/batch = 0.205\n",
            "4646/15750 (epoch 14), train_loss = 2.386, time/batch = 0.212\n",
            "4647/15750 (epoch 14), train_loss = 2.464, time/batch = 0.215\n",
            "4648/15750 (epoch 14), train_loss = 2.666, time/batch = 0.211\n",
            "4649/15750 (epoch 14), train_loss = 2.468, time/batch = 0.215\n",
            "4650/15750 (epoch 14), train_loss = 2.535, time/batch = 0.212\n",
            "4651/15750 (epoch 14), train_loss = 2.411, time/batch = 0.214\n",
            "4652/15750 (epoch 14), train_loss = 2.480, time/batch = 0.223\n",
            "4653/15750 (epoch 14), train_loss = 2.493, time/batch = 0.206\n",
            "4654/15750 (epoch 14), train_loss = 2.482, time/batch = 0.212\n",
            "4655/15750 (epoch 14), train_loss = 2.544, time/batch = 0.209\n",
            "4656/15750 (epoch 14), train_loss = 2.511, time/batch = 0.209\n",
            "4657/15750 (epoch 14), train_loss = 2.507, time/batch = 0.206\n",
            "4658/15750 (epoch 14), train_loss = 2.491, time/batch = 0.200\n",
            "4659/15750 (epoch 14), train_loss = 2.515, time/batch = 0.207\n",
            "4660/15750 (epoch 14), train_loss = 2.420, time/batch = 0.212\n",
            "4661/15750 (epoch 14), train_loss = 2.426, time/batch = 0.218\n",
            "4662/15750 (epoch 14), train_loss = 2.497, time/batch = 0.211\n",
            "4663/15750 (epoch 14), train_loss = 2.501, time/batch = 0.208\n",
            "4664/15750 (epoch 14), train_loss = 2.474, time/batch = 0.211\n",
            "4665/15750 (epoch 14), train_loss = 2.455, time/batch = 0.219\n",
            "4666/15750 (epoch 14), train_loss = 2.401, time/batch = 0.222\n",
            "4667/15750 (epoch 14), train_loss = 2.417, time/batch = 0.210\n",
            "4668/15750 (epoch 14), train_loss = 2.591, time/batch = 0.202\n",
            "4669/15750 (epoch 14), train_loss = 2.535, time/batch = 0.204\n",
            "4670/15750 (epoch 14), train_loss = 2.517, time/batch = 0.203\n",
            "4671/15750 (epoch 14), train_loss = 2.461, time/batch = 0.207\n",
            "4672/15750 (epoch 14), train_loss = 2.500, time/batch = 0.212\n",
            "4673/15750 (epoch 14), train_loss = 2.472, time/batch = 0.210\n",
            "4674/15750 (epoch 14), train_loss = 2.532, time/batch = 0.209\n",
            "4675/15750 (epoch 14), train_loss = 2.563, time/batch = 0.203\n",
            "4676/15750 (epoch 14), train_loss = 2.579, time/batch = 0.215\n",
            "4677/15750 (epoch 14), train_loss = 2.487, time/batch = 0.213\n",
            "4678/15750 (epoch 14), train_loss = 2.524, time/batch = 0.205\n",
            "4679/15750 (epoch 14), train_loss = 2.553, time/batch = 0.206\n",
            "4680/15750 (epoch 14), train_loss = 2.529, time/batch = 0.211\n",
            "4681/15750 (epoch 14), train_loss = 2.423, time/batch = 0.223\n",
            "4682/15750 (epoch 14), train_loss = 2.476, time/batch = 0.206\n",
            "4683/15750 (epoch 14), train_loss = 2.530, time/batch = 0.208\n",
            "4684/15750 (epoch 14), train_loss = 2.553, time/batch = 0.213\n",
            "4685/15750 (epoch 14), train_loss = 2.515, time/batch = 0.217\n",
            "4686/15750 (epoch 14), train_loss = 2.563, time/batch = 0.221\n",
            "4687/15750 (epoch 14), train_loss = 2.487, time/batch = 0.209\n",
            "4688/15750 (epoch 14), train_loss = 2.438, time/batch = 0.212\n",
            "4689/15750 (epoch 14), train_loss = 2.404, time/batch = 0.207\n",
            "4690/15750 (epoch 14), train_loss = 2.657, time/batch = 0.217\n",
            "4691/15750 (epoch 14), train_loss = 2.470, time/batch = 0.210\n",
            "4692/15750 (epoch 14), train_loss = 2.430, time/batch = 0.204\n",
            "4693/15750 (epoch 14), train_loss = 2.567, time/batch = 0.206\n",
            "4694/15750 (epoch 14), train_loss = 2.436, time/batch = 0.209\n",
            "4695/15750 (epoch 14), train_loss = 2.592, time/batch = 0.212\n",
            "4696/15750 (epoch 14), train_loss = 2.460, time/batch = 0.213\n",
            "4697/15750 (epoch 14), train_loss = 2.480, time/batch = 0.218\n",
            "4698/15750 (epoch 14), train_loss = 2.403, time/batch = 0.212\n",
            "4699/15750 (epoch 14), train_loss = 2.489, time/batch = 0.204\n",
            "4700/15750 (epoch 14), train_loss = 2.412, time/batch = 0.218\n",
            "4701/15750 (epoch 14), train_loss = 2.509, time/batch = 0.212\n",
            "4702/15750 (epoch 14), train_loss = 2.500, time/batch = 0.211\n",
            "4703/15750 (epoch 14), train_loss = 2.465, time/batch = 0.208\n",
            "4704/15750 (epoch 14), train_loss = 2.516, time/batch = 0.206\n",
            "4705/15750 (epoch 14), train_loss = 2.595, time/batch = 0.212\n",
            "4706/15750 (epoch 14), train_loss = 2.552, time/batch = 0.212\n",
            "4707/15750 (epoch 14), train_loss = 2.570, time/batch = 0.207\n",
            "4708/15750 (epoch 14), train_loss = 2.427, time/batch = 0.210\n",
            "4709/15750 (epoch 14), train_loss = 2.517, time/batch = 0.212\n",
            "4710/15750 (epoch 14), train_loss = 2.490, time/batch = 0.216\n",
            "4711/15750 (epoch 14), train_loss = 2.407, time/batch = 0.219\n",
            "4712/15750 (epoch 14), train_loss = 2.538, time/batch = 0.206\n",
            "4713/15750 (epoch 14), train_loss = 2.395, time/batch = 0.209\n",
            "4714/15750 (epoch 14), train_loss = 2.537, time/batch = 0.203\n",
            "4715/15750 (epoch 14), train_loss = 2.484, time/batch = 0.219\n",
            "4716/15750 (epoch 14), train_loss = 2.464, time/batch = 0.212\n",
            "4717/15750 (epoch 14), train_loss = 2.402, time/batch = 0.217\n",
            "4718/15750 (epoch 14), train_loss = 2.431, time/batch = 0.214\n",
            "4719/15750 (epoch 14), train_loss = 2.563, time/batch = 0.206\n",
            "4720/15750 (epoch 14), train_loss = 2.406, time/batch = 0.219\n",
            "4721/15750 (epoch 14), train_loss = 2.380, time/batch = 0.213\n",
            "4722/15750 (epoch 14), train_loss = 2.446, time/batch = 0.209\n",
            "4723/15750 (epoch 14), train_loss = 2.431, time/batch = 0.211\n",
            "4724/15750 (epoch 14), train_loss = 2.535, time/batch = 0.202\n",
            "4725/15750 (epoch 15), train_loss = 2.540, time/batch = 0.206\n",
            "4726/15750 (epoch 15), train_loss = 2.544, time/batch = 0.202\n",
            "4727/15750 (epoch 15), train_loss = 2.484, time/batch = 0.211\n",
            "4728/15750 (epoch 15), train_loss = 2.577, time/batch = 0.209\n",
            "4729/15750 (epoch 15), train_loss = 2.495, time/batch = 0.216\n",
            "4730/15750 (epoch 15), train_loss = 2.481, time/batch = 0.212\n",
            "4731/15750 (epoch 15), train_loss = 2.658, time/batch = 0.210\n",
            "4732/15750 (epoch 15), train_loss = 2.569, time/batch = 0.214\n",
            "4733/15750 (epoch 15), train_loss = 2.548, time/batch = 0.214\n",
            "4734/15750 (epoch 15), train_loss = 2.504, time/batch = 0.218\n",
            "4735/15750 (epoch 15), train_loss = 2.494, time/batch = 0.214\n",
            "4736/15750 (epoch 15), train_loss = 2.443, time/batch = 0.211\n",
            "4737/15750 (epoch 15), train_loss = 2.559, time/batch = 0.211\n",
            "4738/15750 (epoch 15), train_loss = 2.510, time/batch = 0.216\n",
            "4739/15750 (epoch 15), train_loss = 2.506, time/batch = 0.212\n",
            "4740/15750 (epoch 15), train_loss = 2.516, time/batch = 0.204\n",
            "4741/15750 (epoch 15), train_loss = 2.537, time/batch = 0.215\n",
            "4742/15750 (epoch 15), train_loss = 2.597, time/batch = 0.213\n",
            "4743/15750 (epoch 15), train_loss = 2.596, time/batch = 0.220\n",
            "4744/15750 (epoch 15), train_loss = 2.541, time/batch = 0.213\n",
            "4745/15750 (epoch 15), train_loss = 2.542, time/batch = 0.214\n",
            "4746/15750 (epoch 15), train_loss = 2.550, time/batch = 0.215\n",
            "4747/15750 (epoch 15), train_loss = 2.505, time/batch = 0.207\n",
            "4748/15750 (epoch 15), train_loss = 2.563, time/batch = 0.213\n",
            "4749/15750 (epoch 15), train_loss = 2.552, time/batch = 0.214\n",
            "4750/15750 (epoch 15), train_loss = 2.583, time/batch = 0.206\n",
            "4751/15750 (epoch 15), train_loss = 2.573, time/batch = 0.214\n",
            "4752/15750 (epoch 15), train_loss = 2.571, time/batch = 0.212\n",
            "4753/15750 (epoch 15), train_loss = 2.697, time/batch = 0.221\n",
            "4754/15750 (epoch 15), train_loss = 2.604, time/batch = 0.207\n",
            "4755/15750 (epoch 15), train_loss = 2.559, time/batch = 0.211\n",
            "4756/15750 (epoch 15), train_loss = 2.534, time/batch = 0.208\n",
            "4757/15750 (epoch 15), train_loss = 2.439, time/batch = 0.210\n",
            "4758/15750 (epoch 15), train_loss = 2.466, time/batch = 0.209\n",
            "4759/15750 (epoch 15), train_loss = 2.542, time/batch = 0.202\n",
            "4760/15750 (epoch 15), train_loss = 2.452, time/batch = 0.200\n",
            "4761/15750 (epoch 15), train_loss = 2.486, time/batch = 0.210\n",
            "4762/15750 (epoch 15), train_loss = 2.559, time/batch = 0.208\n",
            "4763/15750 (epoch 15), train_loss = 2.470, time/batch = 0.207\n",
            "4764/15750 (epoch 15), train_loss = 2.518, time/batch = 0.212\n",
            "4765/15750 (epoch 15), train_loss = 2.489, time/batch = 0.212\n",
            "4766/15750 (epoch 15), train_loss = 2.540, time/batch = 0.212\n",
            "4767/15750 (epoch 15), train_loss = 2.532, time/batch = 0.218\n",
            "4768/15750 (epoch 15), train_loss = 2.478, time/batch = 0.207\n",
            "4769/15750 (epoch 15), train_loss = 2.532, time/batch = 0.207\n",
            "4770/15750 (epoch 15), train_loss = 2.433, time/batch = 0.210\n",
            "4771/15750 (epoch 15), train_loss = 2.473, time/batch = 0.207\n",
            "4772/15750 (epoch 15), train_loss = 2.521, time/batch = 0.215\n",
            "4773/15750 (epoch 15), train_loss = 2.554, time/batch = 0.205\n",
            "4774/15750 (epoch 15), train_loss = 2.450, time/batch = 0.207\n",
            "4775/15750 (epoch 15), train_loss = 2.494, time/batch = 0.210\n",
            "4776/15750 (epoch 15), train_loss = 2.453, time/batch = 0.209\n",
            "4777/15750 (epoch 15), train_loss = 2.516, time/batch = 0.214\n",
            "4778/15750 (epoch 15), train_loss = 2.523, time/batch = 0.210\n",
            "4779/15750 (epoch 15), train_loss = 2.515, time/batch = 0.217\n",
            "4780/15750 (epoch 15), train_loss = 2.561, time/batch = 0.214\n",
            "4781/15750 (epoch 15), train_loss = 2.426, time/batch = 0.213\n",
            "4782/15750 (epoch 15), train_loss = 2.438, time/batch = 0.222\n",
            "4783/15750 (epoch 15), train_loss = 2.516, time/batch = 0.214\n",
            "4784/15750 (epoch 15), train_loss = 2.368, time/batch = 0.212\n",
            "4785/15750 (epoch 15), train_loss = 2.491, time/batch = 0.207\n",
            "4786/15750 (epoch 15), train_loss = 2.486, time/batch = 0.210\n",
            "4787/15750 (epoch 15), train_loss = 2.418, time/batch = 0.216\n",
            "4788/15750 (epoch 15), train_loss = 2.463, time/batch = 0.215\n",
            "4789/15750 (epoch 15), train_loss = 2.400, time/batch = 0.209\n",
            "4790/15750 (epoch 15), train_loss = 2.403, time/batch = 0.216\n",
            "4791/15750 (epoch 15), train_loss = 2.345, time/batch = 0.211\n",
            "4792/15750 (epoch 15), train_loss = 2.376, time/batch = 0.215\n",
            "4793/15750 (epoch 15), train_loss = 2.427, time/batch = 0.200\n",
            "4794/15750 (epoch 15), train_loss = 2.512, time/batch = 0.203\n",
            "4795/15750 (epoch 15), train_loss = 2.439, time/batch = 0.203\n",
            "4796/15750 (epoch 15), train_loss = 2.433, time/batch = 0.212\n",
            "4797/15750 (epoch 15), train_loss = 2.333, time/batch = 0.215\n",
            "4798/15750 (epoch 15), train_loss = 2.430, time/batch = 0.212\n",
            "4799/15750 (epoch 15), train_loss = 2.530, time/batch = 0.220\n",
            "4800/15750 (epoch 15), train_loss = 2.472, time/batch = 0.211\n",
            "4801/15750 (epoch 15), train_loss = 2.456, time/batch = 0.209\n",
            "4802/15750 (epoch 15), train_loss = 2.462, time/batch = 0.216\n",
            "4803/15750 (epoch 15), train_loss = 2.473, time/batch = 0.207\n",
            "4804/15750 (epoch 15), train_loss = 2.473, time/batch = 0.213\n",
            "4805/15750 (epoch 15), train_loss = 2.374, time/batch = 0.207\n",
            "4806/15750 (epoch 15), train_loss = 2.481, time/batch = 0.211\n",
            "4807/15750 (epoch 15), train_loss = 2.402, time/batch = 0.206\n",
            "4808/15750 (epoch 15), train_loss = 2.469, time/batch = 0.218\n",
            "4809/15750 (epoch 15), train_loss = 2.541, time/batch = 0.212\n",
            "4810/15750 (epoch 15), train_loss = 2.549, time/batch = 0.211\n",
            "4811/15750 (epoch 15), train_loss = 2.388, time/batch = 0.212\n",
            "4812/15750 (epoch 15), train_loss = 2.421, time/batch = 0.227\n",
            "4813/15750 (epoch 15), train_loss = 2.448, time/batch = 0.209\n",
            "4814/15750 (epoch 15), train_loss = 2.425, time/batch = 0.211\n",
            "4815/15750 (epoch 15), train_loss = 2.442, time/batch = 0.203\n",
            "4816/15750 (epoch 15), train_loss = 2.496, time/batch = 0.218\n",
            "4817/15750 (epoch 15), train_loss = 2.495, time/batch = 0.209\n",
            "4818/15750 (epoch 15), train_loss = 2.511, time/batch = 0.212\n",
            "4819/15750 (epoch 15), train_loss = 2.566, time/batch = 0.213\n",
            "4820/15750 (epoch 15), train_loss = 2.462, time/batch = 0.217\n",
            "4821/15750 (epoch 15), train_loss = 2.485, time/batch = 0.218\n",
            "4822/15750 (epoch 15), train_loss = 2.493, time/batch = 0.207\n",
            "4823/15750 (epoch 15), train_loss = 2.497, time/batch = 0.208\n",
            "4824/15750 (epoch 15), train_loss = 2.511, time/batch = 0.217\n",
            "4825/15750 (epoch 15), train_loss = 2.484, time/batch = 0.211\n",
            "4826/15750 (epoch 15), train_loss = 2.402, time/batch = 0.204\n",
            "4827/15750 (epoch 15), train_loss = 2.435, time/batch = 0.214\n",
            "4828/15750 (epoch 15), train_loss = 2.561, time/batch = 0.216\n",
            "4829/15750 (epoch 15), train_loss = 2.497, time/batch = 0.214\n",
            "4830/15750 (epoch 15), train_loss = 2.418, time/batch = 0.215\n",
            "4831/15750 (epoch 15), train_loss = 2.476, time/batch = 0.212\n",
            "4832/15750 (epoch 15), train_loss = 2.484, time/batch = 0.206\n",
            "4833/15750 (epoch 15), train_loss = 2.541, time/batch = 0.212\n",
            "4834/15750 (epoch 15), train_loss = 2.555, time/batch = 0.211\n",
            "4835/15750 (epoch 15), train_loss = 2.595, time/batch = 0.212\n",
            "4836/15750 (epoch 15), train_loss = 2.484, time/batch = 0.212\n",
            "4837/15750 (epoch 15), train_loss = 2.463, time/batch = 0.214\n",
            "4838/15750 (epoch 15), train_loss = 2.481, time/batch = 0.210\n",
            "4839/15750 (epoch 15), train_loss = 2.493, time/batch = 0.213\n",
            "4840/15750 (epoch 15), train_loss = 2.564, time/batch = 0.216\n",
            "4841/15750 (epoch 15), train_loss = 2.489, time/batch = 0.215\n",
            "4842/15750 (epoch 15), train_loss = 2.621, time/batch = 0.213\n",
            "4843/15750 (epoch 15), train_loss = 2.488, time/batch = 0.210\n",
            "4844/15750 (epoch 15), train_loss = 2.462, time/batch = 0.203\n",
            "4845/15750 (epoch 15), train_loss = 2.449, time/batch = 0.215\n",
            "4846/15750 (epoch 15), train_loss = 2.428, time/batch = 0.216\n",
            "4847/15750 (epoch 15), train_loss = 2.461, time/batch = 0.210\n",
            "4848/15750 (epoch 15), train_loss = 2.439, time/batch = 0.209\n",
            "4849/15750 (epoch 15), train_loss = 2.465, time/batch = 0.211\n",
            "4850/15750 (epoch 15), train_loss = 2.479, time/batch = 0.215\n",
            "4851/15750 (epoch 15), train_loss = 2.571, time/batch = 0.211\n",
            "4852/15750 (epoch 15), train_loss = 2.426, time/batch = 0.213\n",
            "4853/15750 (epoch 15), train_loss = 2.432, time/batch = 0.211\n",
            "4854/15750 (epoch 15), train_loss = 2.440, time/batch = 0.201\n",
            "4855/15750 (epoch 15), train_loss = 2.381, time/batch = 0.210\n",
            "4856/15750 (epoch 15), train_loss = 2.389, time/batch = 0.208\n",
            "4857/15750 (epoch 15), train_loss = 2.405, time/batch = 0.213\n",
            "4858/15750 (epoch 15), train_loss = 2.401, time/batch = 0.213\n",
            "4859/15750 (epoch 15), train_loss = 2.450, time/batch = 0.218\n",
            "4860/15750 (epoch 15), train_loss = 2.562, time/batch = 0.219\n",
            "4861/15750 (epoch 15), train_loss = 2.518, time/batch = 0.213\n",
            "4862/15750 (epoch 15), train_loss = 2.531, time/batch = 0.210\n",
            "4863/15750 (epoch 15), train_loss = 2.520, time/batch = 0.212\n",
            "4864/15750 (epoch 15), train_loss = 2.446, time/batch = 0.213\n",
            "4865/15750 (epoch 15), train_loss = 2.440, time/batch = 0.200\n",
            "4866/15750 (epoch 15), train_loss = 2.521, time/batch = 0.206\n",
            "4867/15750 (epoch 15), train_loss = 2.539, time/batch = 0.220\n",
            "4868/15750 (epoch 15), train_loss = 2.535, time/batch = 0.209\n",
            "4869/15750 (epoch 15), train_loss = 2.459, time/batch = 0.220\n",
            "4870/15750 (epoch 15), train_loss = 2.452, time/batch = 0.206\n",
            "4871/15750 (epoch 15), train_loss = 2.393, time/batch = 0.213\n",
            "4872/15750 (epoch 15), train_loss = 2.484, time/batch = 0.217\n",
            "4873/15750 (epoch 15), train_loss = 2.513, time/batch = 0.215\n",
            "4874/15750 (epoch 15), train_loss = 2.460, time/batch = 0.215\n",
            "4875/15750 (epoch 15), train_loss = 2.463, time/batch = 0.218\n",
            "4876/15750 (epoch 15), train_loss = 2.499, time/batch = 0.215\n",
            "4877/15750 (epoch 15), train_loss = 2.568, time/batch = 0.214\n",
            "4878/15750 (epoch 15), train_loss = 2.509, time/batch = 0.213\n",
            "4879/15750 (epoch 15), train_loss = 2.512, time/batch = 0.215\n",
            "4880/15750 (epoch 15), train_loss = 2.502, time/batch = 0.225\n",
            "4881/15750 (epoch 15), train_loss = 2.510, time/batch = 0.212\n",
            "4882/15750 (epoch 15), train_loss = 2.490, time/batch = 0.205\n",
            "4883/15750 (epoch 15), train_loss = 2.591, time/batch = 0.217\n",
            "4884/15750 (epoch 15), train_loss = 2.440, time/batch = 0.210\n",
            "4885/15750 (epoch 15), train_loss = 2.517, time/batch = 0.219\n",
            "4886/15750 (epoch 15), train_loss = 2.509, time/batch = 0.216\n",
            "4887/15750 (epoch 15), train_loss = 2.544, time/batch = 0.211\n",
            "4888/15750 (epoch 15), train_loss = 2.622, time/batch = 0.210\n",
            "4889/15750 (epoch 15), train_loss = 2.536, time/batch = 0.212\n",
            "4890/15750 (epoch 15), train_loss = 2.547, time/batch = 0.211\n",
            "4891/15750 (epoch 15), train_loss = 2.533, time/batch = 0.214\n",
            "4892/15750 (epoch 15), train_loss = 2.482, time/batch = 0.218\n",
            "4893/15750 (epoch 15), train_loss = 2.448, time/batch = 0.214\n",
            "4894/15750 (epoch 15), train_loss = 2.444, time/batch = 0.218\n",
            "4895/15750 (epoch 15), train_loss = 2.500, time/batch = 0.219\n",
            "4896/15750 (epoch 15), train_loss = 2.542, time/batch = 0.208\n",
            "4897/15750 (epoch 15), train_loss = 2.486, time/batch = 0.214\n",
            "4898/15750 (epoch 15), train_loss = 2.535, time/batch = 0.212\n",
            "4899/15750 (epoch 15), train_loss = 2.503, time/batch = 0.210\n",
            "4900/15750 (epoch 15), train_loss = 2.417, time/batch = 0.215\n",
            "4901/15750 (epoch 15), train_loss = 2.456, time/batch = 0.208\n",
            "4902/15750 (epoch 15), train_loss = 2.512, time/batch = 0.212\n",
            "4903/15750 (epoch 15), train_loss = 2.440, time/batch = 0.212\n",
            "4904/15750 (epoch 15), train_loss = 2.410, time/batch = 0.207\n",
            "4905/15750 (epoch 15), train_loss = 2.427, time/batch = 0.213\n",
            "4906/15750 (epoch 15), train_loss = 2.533, time/batch = 0.212\n",
            "4907/15750 (epoch 15), train_loss = 2.475, time/batch = 0.218\n",
            "4908/15750 (epoch 15), train_loss = 2.551, time/batch = 0.213\n",
            "4909/15750 (epoch 15), train_loss = 2.548, time/batch = 0.211\n",
            "4910/15750 (epoch 15), train_loss = 2.459, time/batch = 0.201\n",
            "4911/15750 (epoch 15), train_loss = 2.432, time/batch = 0.205\n",
            "4912/15750 (epoch 15), train_loss = 2.508, time/batch = 0.213\n",
            "4913/15750 (epoch 15), train_loss = 2.561, time/batch = 0.210\n",
            "4914/15750 (epoch 15), train_loss = 2.626, time/batch = 0.205\n",
            "4915/15750 (epoch 15), train_loss = 2.567, time/batch = 0.204\n",
            "4916/15750 (epoch 15), train_loss = 2.495, time/batch = 0.203\n",
            "4917/15750 (epoch 15), train_loss = 2.506, time/batch = 0.206\n",
            "4918/15750 (epoch 15), train_loss = 2.439, time/batch = 0.206\n",
            "4919/15750 (epoch 15), train_loss = 2.548, time/batch = 0.204\n",
            "4920/15750 (epoch 15), train_loss = 2.560, time/batch = 0.209\n",
            "4921/15750 (epoch 15), train_loss = 2.485, time/batch = 0.205\n",
            "4922/15750 (epoch 15), train_loss = 2.438, time/batch = 0.209\n",
            "4923/15750 (epoch 15), train_loss = 2.531, time/batch = 0.208\n",
            "4924/15750 (epoch 15), train_loss = 2.345, time/batch = 0.213\n",
            "4925/15750 (epoch 15), train_loss = 2.433, time/batch = 0.210\n",
            "4926/15750 (epoch 15), train_loss = 2.404, time/batch = 0.208\n",
            "4927/15750 (epoch 15), train_loss = 2.483, time/batch = 0.212\n",
            "4928/15750 (epoch 15), train_loss = 2.456, time/batch = 0.213\n",
            "4929/15750 (epoch 15), train_loss = 2.517, time/batch = 0.201\n",
            "4930/15750 (epoch 15), train_loss = 2.485, time/batch = 0.202\n",
            "4931/15750 (epoch 15), train_loss = 2.347, time/batch = 0.209\n",
            "4932/15750 (epoch 15), train_loss = 2.425, time/batch = 0.217\n",
            "4933/15750 (epoch 15), train_loss = 2.427, time/batch = 0.210\n",
            "4934/15750 (epoch 15), train_loss = 2.476, time/batch = 0.213\n",
            "4935/15750 (epoch 15), train_loss = 2.350, time/batch = 0.215\n",
            "4936/15750 (epoch 15), train_loss = 2.443, time/batch = 0.212\n",
            "4937/15750 (epoch 15), train_loss = 2.331, time/batch = 0.207\n",
            "4938/15750 (epoch 15), train_loss = 2.397, time/batch = 0.211\n",
            "4939/15750 (epoch 15), train_loss = 2.399, time/batch = 0.209\n",
            "4940/15750 (epoch 15), train_loss = 2.399, time/batch = 0.207\n",
            "4941/15750 (epoch 15), train_loss = 2.551, time/batch = 0.211\n",
            "4942/15750 (epoch 15), train_loss = 2.360, time/batch = 0.205\n",
            "4943/15750 (epoch 15), train_loss = 2.603, time/batch = 0.203\n",
            "4944/15750 (epoch 15), train_loss = 2.460, time/batch = 0.204\n",
            "4945/15750 (epoch 15), train_loss = 2.352, time/batch = 0.208\n",
            "4946/15750 (epoch 15), train_loss = 2.400, time/batch = 0.211\n",
            "4947/15750 (epoch 15), train_loss = 2.461, time/batch = 0.207\n",
            "4948/15750 (epoch 15), train_loss = 2.452, time/batch = 0.211\n",
            "4949/15750 (epoch 15), train_loss = 2.430, time/batch = 0.214\n",
            "4950/15750 (epoch 15), train_loss = 2.428, time/batch = 0.213\n",
            "4951/15750 (epoch 15), train_loss = 2.511, time/batch = 0.217\n",
            "4952/15750 (epoch 15), train_loss = 2.423, time/batch = 0.212\n",
            "4953/15750 (epoch 15), train_loss = 2.463, time/batch = 0.208\n",
            "4954/15750 (epoch 15), train_loss = 2.543, time/batch = 0.209\n",
            "4955/15750 (epoch 15), train_loss = 2.400, time/batch = 0.202\n",
            "4956/15750 (epoch 15), train_loss = 2.415, time/batch = 0.213\n",
            "4957/15750 (epoch 15), train_loss = 2.464, time/batch = 0.212\n",
            "4958/15750 (epoch 15), train_loss = 2.469, time/batch = 0.212\n",
            "4959/15750 (epoch 15), train_loss = 2.399, time/batch = 0.215\n",
            "4960/15750 (epoch 15), train_loss = 2.403, time/batch = 0.207\n",
            "4961/15750 (epoch 15), train_loss = 2.366, time/batch = 0.213\n",
            "4962/15750 (epoch 15), train_loss = 2.441, time/batch = 0.210\n",
            "4963/15750 (epoch 15), train_loss = 2.645, time/batch = 0.206\n",
            "4964/15750 (epoch 15), train_loss = 2.448, time/batch = 0.212\n",
            "4965/15750 (epoch 15), train_loss = 2.512, time/batch = 0.211\n",
            "4966/15750 (epoch 15), train_loss = 2.387, time/batch = 0.211\n",
            "4967/15750 (epoch 15), train_loss = 2.456, time/batch = 0.200\n",
            "4968/15750 (epoch 15), train_loss = 2.470, time/batch = 0.205\n",
            "4969/15750 (epoch 15), train_loss = 2.461, time/batch = 0.203\n",
            "4970/15750 (epoch 15), train_loss = 2.522, time/batch = 0.202\n",
            "4971/15750 (epoch 15), train_loss = 2.490, time/batch = 0.222\n",
            "4972/15750 (epoch 15), train_loss = 2.483, time/batch = 0.203\n",
            "4973/15750 (epoch 15), train_loss = 2.468, time/batch = 0.212\n",
            "4974/15750 (epoch 15), train_loss = 2.494, time/batch = 0.210\n",
            "4975/15750 (epoch 15), train_loss = 2.398, time/batch = 0.209\n",
            "4976/15750 (epoch 15), train_loss = 2.402, time/batch = 0.220\n",
            "4977/15750 (epoch 15), train_loss = 2.474, time/batch = 0.211\n",
            "4978/15750 (epoch 15), train_loss = 2.479, time/batch = 0.206\n",
            "4979/15750 (epoch 15), train_loss = 2.451, time/batch = 0.211\n",
            "4980/15750 (epoch 15), train_loss = 2.431, time/batch = 0.207\n",
            "4981/15750 (epoch 15), train_loss = 2.379, time/batch = 0.206\n",
            "4982/15750 (epoch 15), train_loss = 2.394, time/batch = 0.207\n",
            "4983/15750 (epoch 15), train_loss = 2.568, time/batch = 0.202\n",
            "4984/15750 (epoch 15), train_loss = 2.515, time/batch = 0.203\n",
            "4985/15750 (epoch 15), train_loss = 2.495, time/batch = 0.208\n",
            "4986/15750 (epoch 15), train_loss = 2.438, time/batch = 0.211\n",
            "4987/15750 (epoch 15), train_loss = 2.477, time/batch = 0.207\n",
            "4988/15750 (epoch 15), train_loss = 2.449, time/batch = 0.209\n",
            "4989/15750 (epoch 15), train_loss = 2.508, time/batch = 0.213\n",
            "4990/15750 (epoch 15), train_loss = 2.541, time/batch = 0.208\n",
            "4991/15750 (epoch 15), train_loss = 2.556, time/batch = 0.209\n",
            "4992/15750 (epoch 15), train_loss = 2.465, time/batch = 0.213\n",
            "4993/15750 (epoch 15), train_loss = 2.503, time/batch = 0.206\n",
            "4994/15750 (epoch 15), train_loss = 2.528, time/batch = 0.206\n",
            "4995/15750 (epoch 15), train_loss = 2.508, time/batch = 0.213\n",
            "4996/15750 (epoch 15), train_loss = 2.402, time/batch = 0.205\n",
            "4997/15750 (epoch 15), train_loss = 2.452, time/batch = 0.206\n",
            "4998/15750 (epoch 15), train_loss = 2.507, time/batch = 0.212\n",
            "4999/15750 (epoch 15), train_loss = 2.531, time/batch = 0.209\n",
            "5000/15750 (epoch 15), train_loss = 2.492, time/batch = 0.217\n",
            "W0828 01:30:59.934181 140429351114624 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "model saved to ./save_star/model.ckpt\n",
            "5001/15750 (epoch 15), train_loss = 2.542, time/batch = 0.206\n",
            "5002/15750 (epoch 15), train_loss = 2.467, time/batch = 0.206\n",
            "5003/15750 (epoch 15), train_loss = 2.417, time/batch = 0.215\n",
            "5004/15750 (epoch 15), train_loss = 2.381, time/batch = 0.207\n",
            "5005/15750 (epoch 15), train_loss = 2.632, time/batch = 0.208\n",
            "5006/15750 (epoch 15), train_loss = 2.449, time/batch = 0.210\n",
            "5007/15750 (epoch 15), train_loss = 2.409, time/batch = 0.205\n",
            "5008/15750 (epoch 15), train_loss = 2.542, time/batch = 0.202\n",
            "5009/15750 (epoch 15), train_loss = 2.416, time/batch = 0.203\n",
            "5010/15750 (epoch 15), train_loss = 2.570, time/batch = 0.206\n",
            "5011/15750 (epoch 15), train_loss = 2.438, time/batch = 0.207\n",
            "5012/15750 (epoch 15), train_loss = 2.458, time/batch = 0.208\n",
            "5013/15750 (epoch 15), train_loss = 2.381, time/batch = 0.204\n",
            "5014/15750 (epoch 15), train_loss = 2.468, time/batch = 0.205\n",
            "5015/15750 (epoch 15), train_loss = 2.393, time/batch = 0.215\n",
            "5016/15750 (epoch 15), train_loss = 2.487, time/batch = 0.215\n",
            "5017/15750 (epoch 15), train_loss = 2.479, time/batch = 0.214\n",
            "5018/15750 (epoch 15), train_loss = 2.443, time/batch = 0.214\n",
            "5019/15750 (epoch 15), train_loss = 2.493, time/batch = 0.213\n",
            "5020/15750 (epoch 15), train_loss = 2.573, time/batch = 0.211\n",
            "5021/15750 (epoch 15), train_loss = 2.531, time/batch = 0.202\n",
            "5022/15750 (epoch 15), train_loss = 2.548, time/batch = 0.210\n",
            "5023/15750 (epoch 15), train_loss = 2.406, time/batch = 0.212\n",
            "5024/15750 (epoch 15), train_loss = 2.495, time/batch = 0.210\n",
            "5025/15750 (epoch 15), train_loss = 2.470, time/batch = 0.205\n",
            "5026/15750 (epoch 15), train_loss = 2.386, time/batch = 0.208\n",
            "5027/15750 (epoch 15), train_loss = 2.517, time/batch = 0.212\n",
            "5028/15750 (epoch 15), train_loss = 2.375, time/batch = 0.213\n",
            "5029/15750 (epoch 15), train_loss = 2.516, time/batch = 0.207\n",
            "5030/15750 (epoch 15), train_loss = 2.461, time/batch = 0.209\n",
            "5031/15750 (epoch 15), train_loss = 2.441, time/batch = 0.209\n",
            "5032/15750 (epoch 15), train_loss = 2.381, time/batch = 0.206\n",
            "5033/15750 (epoch 15), train_loss = 2.409, time/batch = 0.218\n",
            "5034/15750 (epoch 15), train_loss = 2.542, time/batch = 0.202\n",
            "5035/15750 (epoch 15), train_loss = 2.385, time/batch = 0.202\n",
            "5036/15750 (epoch 15), train_loss = 2.361, time/batch = 0.202\n",
            "5037/15750 (epoch 15), train_loss = 2.423, time/batch = 0.208\n",
            "5038/15750 (epoch 15), train_loss = 2.409, time/batch = 0.211\n",
            "5039/15750 (epoch 15), train_loss = 2.514, time/batch = 0.204\n",
            "5040/15750 (epoch 16), train_loss = 2.511, time/batch = 0.205\n",
            "5041/15750 (epoch 16), train_loss = 2.523, time/batch = 0.202\n",
            "5042/15750 (epoch 16), train_loss = 2.463, time/batch = 0.214\n",
            "5043/15750 (epoch 16), train_loss = 2.552, time/batch = 0.210\n",
            "5044/15750 (epoch 16), train_loss = 2.473, time/batch = 0.206\n",
            "5045/15750 (epoch 16), train_loss = 2.460, time/batch = 0.199\n",
            "5046/15750 (epoch 16), train_loss = 2.637, time/batch = 0.203\n",
            "5047/15750 (epoch 16), train_loss = 2.547, time/batch = 0.213\n",
            "5048/15750 (epoch 16), train_loss = 2.528, time/batch = 0.207\n",
            "5049/15750 (epoch 16), train_loss = 2.481, time/batch = 0.207\n",
            "5050/15750 (epoch 16), train_loss = 2.474, time/batch = 0.209\n",
            "5051/15750 (epoch 16), train_loss = 2.423, time/batch = 0.211\n",
            "5052/15750 (epoch 16), train_loss = 2.535, time/batch = 0.210\n",
            "5053/15750 (epoch 16), train_loss = 2.490, time/batch = 0.204\n",
            "5054/15750 (epoch 16), train_loss = 2.485, time/batch = 0.206\n",
            "5055/15750 (epoch 16), train_loss = 2.497, time/batch = 0.210\n",
            "5056/15750 (epoch 16), train_loss = 2.526, time/batch = 0.204\n",
            "5057/15750 (epoch 16), train_loss = 2.610, time/batch = 0.216\n",
            "5058/15750 (epoch 16), train_loss = 2.594, time/batch = 0.218\n",
            "5059/15750 (epoch 16), train_loss = 2.522, time/batch = 0.207\n",
            "5060/15750 (epoch 16), train_loss = 2.520, time/batch = 0.203\n",
            "5061/15750 (epoch 16), train_loss = 2.533, time/batch = 0.204\n",
            "5062/15750 (epoch 16), train_loss = 2.481, time/batch = 0.207\n",
            "5063/15750 (epoch 16), train_loss = 2.542, time/batch = 0.196\n",
            "5064/15750 (epoch 16), train_loss = 2.535, time/batch = 0.205\n",
            "5065/15750 (epoch 16), train_loss = 2.561, time/batch = 0.206\n",
            "5066/15750 (epoch 16), train_loss = 2.555, time/batch = 0.208\n",
            "5067/15750 (epoch 16), train_loss = 2.552, time/batch = 0.213\n",
            "5068/15750 (epoch 16), train_loss = 2.674, time/batch = 0.206\n",
            "5069/15750 (epoch 16), train_loss = 2.583, time/batch = 0.206\n",
            "5070/15750 (epoch 16), train_loss = 2.539, time/batch = 0.214\n",
            "5071/15750 (epoch 16), train_loss = 2.514, time/batch = 0.209\n",
            "5072/15750 (epoch 16), train_loss = 2.419, time/batch = 0.217\n",
            "5073/15750 (epoch 16), train_loss = 2.445, time/batch = 0.209\n",
            "5074/15750 (epoch 16), train_loss = 2.523, time/batch = 0.213\n",
            "5075/15750 (epoch 16), train_loss = 2.431, time/batch = 0.207\n",
            "5076/15750 (epoch 16), train_loss = 2.468, time/batch = 0.205\n",
            "5077/15750 (epoch 16), train_loss = 2.541, time/batch = 0.208\n",
            "5078/15750 (epoch 16), train_loss = 2.451, time/batch = 0.206\n",
            "5079/15750 (epoch 16), train_loss = 2.498, time/batch = 0.206\n",
            "5080/15750 (epoch 16), train_loss = 2.467, time/batch = 0.206\n",
            "5081/15750 (epoch 16), train_loss = 2.518, time/batch = 0.212\n",
            "5082/15750 (epoch 16), train_loss = 2.509, time/batch = 0.207\n",
            "5083/15750 (epoch 16), train_loss = 2.458, time/batch = 0.213\n",
            "5084/15750 (epoch 16), train_loss = 2.509, time/batch = 0.206\n",
            "5085/15750 (epoch 16), train_loss = 2.412, time/batch = 0.203\n",
            "5086/15750 (epoch 16), train_loss = 2.454, time/batch = 0.212\n",
            "5087/15750 (epoch 16), train_loss = 2.497, time/batch = 0.209\n",
            "5088/15750 (epoch 16), train_loss = 2.533, time/batch = 0.208\n",
            "5089/15750 (epoch 16), train_loss = 2.428, time/batch = 0.210\n",
            "5090/15750 (epoch 16), train_loss = 2.473, time/batch = 0.210\n",
            "5091/15750 (epoch 16), train_loss = 2.432, time/batch = 0.213\n",
            "5092/15750 (epoch 16), train_loss = 2.495, time/batch = 0.200\n",
            "5093/15750 (epoch 16), train_loss = 2.501, time/batch = 0.203\n",
            "5094/15750 (epoch 16), train_loss = 2.495, time/batch = 0.207\n",
            "5095/15750 (epoch 16), train_loss = 2.539, time/batch = 0.205\n",
            "5096/15750 (epoch 16), train_loss = 2.406, time/batch = 0.208\n",
            "5097/15750 (epoch 16), train_loss = 2.418, time/batch = 0.202\n",
            "5098/15750 (epoch 16), train_loss = 2.497, time/batch = 0.205\n",
            "5099/15750 (epoch 16), train_loss = 2.350, time/batch = 0.202\n",
            "5100/15750 (epoch 16), train_loss = 2.470, time/batch = 0.200\n",
            "5101/15750 (epoch 16), train_loss = 2.469, time/batch = 0.209\n",
            "5102/15750 (epoch 16), train_loss = 2.399, time/batch = 0.196\n",
            "5103/15750 (epoch 16), train_loss = 2.444, time/batch = 0.204\n",
            "5104/15750 (epoch 16), train_loss = 2.377, time/batch = 0.202\n",
            "5105/15750 (epoch 16), train_loss = 2.383, time/batch = 0.192\n",
            "5106/15750 (epoch 16), train_loss = 2.326, time/batch = 0.205\n",
            "5107/15750 (epoch 16), train_loss = 2.355, time/batch = 0.201\n",
            "5108/15750 (epoch 16), train_loss = 2.407, time/batch = 0.202\n",
            "5109/15750 (epoch 16), train_loss = 2.491, time/batch = 0.202\n",
            "5110/15750 (epoch 16), train_loss = 2.419, time/batch = 0.206\n",
            "5111/15750 (epoch 16), train_loss = 2.412, time/batch = 0.214\n",
            "5112/15750 (epoch 16), train_loss = 2.314, time/batch = 0.209\n",
            "5113/15750 (epoch 16), train_loss = 2.409, time/batch = 0.206\n",
            "5114/15750 (epoch 16), train_loss = 2.510, time/batch = 0.207\n",
            "5115/15750 (epoch 16), train_loss = 2.451, time/batch = 0.210\n",
            "5116/15750 (epoch 16), train_loss = 2.435, time/batch = 0.218\n",
            "5117/15750 (epoch 16), train_loss = 2.442, time/batch = 0.207\n",
            "5118/15750 (epoch 16), train_loss = 2.453, time/batch = 0.208\n",
            "5119/15750 (epoch 16), train_loss = 2.449, time/batch = 0.209\n",
            "5120/15750 (epoch 16), train_loss = 2.352, time/batch = 0.207\n",
            "5121/15750 (epoch 16), train_loss = 2.459, time/batch = 0.212\n",
            "5122/15750 (epoch 16), train_loss = 2.382, time/batch = 0.209\n",
            "5123/15750 (epoch 16), train_loss = 2.448, time/batch = 0.206\n",
            "5124/15750 (epoch 16), train_loss = 2.520, time/batch = 0.208\n",
            "5125/15750 (epoch 16), train_loss = 2.528, time/batch = 0.201\n",
            "5126/15750 (epoch 16), train_loss = 2.367, time/batch = 0.213\n",
            "5127/15750 (epoch 16), train_loss = 2.399, time/batch = 0.204\n",
            "5128/15750 (epoch 16), train_loss = 2.426, time/batch = 0.207\n",
            "5129/15750 (epoch 16), train_loss = 2.406, time/batch = 0.209\n",
            "5130/15750 (epoch 16), train_loss = 2.421, time/batch = 0.206\n",
            "5131/15750 (epoch 16), train_loss = 2.475, time/batch = 0.212\n",
            "5132/15750 (epoch 16), train_loss = 2.472, time/batch = 0.212\n",
            "5133/15750 (epoch 16), train_loss = 2.489, time/batch = 0.206\n",
            "5134/15750 (epoch 16), train_loss = 2.546, time/batch = 0.212\n",
            "5135/15750 (epoch 16), train_loss = 2.442, time/batch = 0.203\n",
            "5136/15750 (epoch 16), train_loss = 2.465, time/batch = 0.208\n",
            "5137/15750 (epoch 16), train_loss = 2.474, time/batch = 0.209\n",
            "5138/15750 (epoch 16), train_loss = 2.476, time/batch = 0.200\n",
            "5139/15750 (epoch 16), train_loss = 2.491, time/batch = 0.207\n",
            "5140/15750 (epoch 16), train_loss = 2.465, time/batch = 0.208\n",
            "5141/15750 (epoch 16), train_loss = 2.384, time/batch = 0.216\n",
            "5142/15750 (epoch 16), train_loss = 2.416, time/batch = 0.204\n",
            "5143/15750 (epoch 16), train_loss = 2.540, time/batch = 0.211\n",
            "5144/15750 (epoch 16), train_loss = 2.475, time/batch = 0.213\n",
            "5145/15750 (epoch 16), train_loss = 2.395, time/batch = 0.207\n",
            "5146/15750 (epoch 16), train_loss = 2.453, time/batch = 0.209\n",
            "5147/15750 (epoch 16), train_loss = 2.463, time/batch = 0.209\n",
            "5148/15750 (epoch 16), train_loss = 2.519, time/batch = 0.208\n",
            "5149/15750 (epoch 16), train_loss = 2.535, time/batch = 0.215\n",
            "5150/15750 (epoch 16), train_loss = 2.576, time/batch = 0.214\n",
            "5151/15750 (epoch 16), train_loss = 2.463, time/batch = 0.211\n",
            "5152/15750 (epoch 16), train_loss = 2.443, time/batch = 0.210\n",
            "5153/15750 (epoch 16), train_loss = 2.460, time/batch = 0.210\n",
            "5154/15750 (epoch 16), train_loss = 2.474, time/batch = 0.207\n",
            "5155/15750 (epoch 16), train_loss = 2.543, time/batch = 0.213\n",
            "5156/15750 (epoch 16), train_loss = 2.469, time/batch = 0.213\n",
            "5157/15750 (epoch 16), train_loss = 2.601, time/batch = 0.202\n",
            "5158/15750 (epoch 16), train_loss = 2.468, time/batch = 0.215\n",
            "5159/15750 (epoch 16), train_loss = 2.442, time/batch = 0.212\n",
            "5160/15750 (epoch 16), train_loss = 2.429, time/batch = 0.214\n",
            "5161/15750 (epoch 16), train_loss = 2.408, time/batch = 0.216\n",
            "5162/15750 (epoch 16), train_loss = 2.442, time/batch = 0.206\n",
            "5163/15750 (epoch 16), train_loss = 2.418, time/batch = 0.213\n",
            "5164/15750 (epoch 16), train_loss = 2.445, time/batch = 0.207\n",
            "5165/15750 (epoch 16), train_loss = 2.459, time/batch = 0.218\n",
            "5166/15750 (epoch 16), train_loss = 2.550, time/batch = 0.203\n",
            "5167/15750 (epoch 16), train_loss = 2.407, time/batch = 0.203\n",
            "5168/15750 (epoch 16), train_loss = 2.415, time/batch = 0.204\n",
            "5169/15750 (epoch 16), train_loss = 2.420, time/batch = 0.202\n",
            "5170/15750 (epoch 16), train_loss = 2.359, time/batch = 0.209\n",
            "5171/15750 (epoch 16), train_loss = 2.369, time/batch = 0.209\n",
            "5172/15750 (epoch 16), train_loss = 2.384, time/batch = 0.215\n",
            "5173/15750 (epoch 16), train_loss = 2.384, time/batch = 0.213\n",
            "5174/15750 (epoch 16), train_loss = 2.428, time/batch = 0.214\n",
            "5175/15750 (epoch 16), train_loss = 2.543, time/batch = 0.217\n",
            "5176/15750 (epoch 16), train_loss = 2.499, time/batch = 0.210\n",
            "5177/15750 (epoch 16), train_loss = 2.510, time/batch = 0.210\n",
            "5178/15750 (epoch 16), train_loss = 2.499, time/batch = 0.209\n",
            "5179/15750 (epoch 16), train_loss = 2.426, time/batch = 0.202\n",
            "5180/15750 (epoch 16), train_loss = 2.421, time/batch = 0.218\n",
            "5181/15750 (epoch 16), train_loss = 2.501, time/batch = 0.212\n",
            "5182/15750 (epoch 16), train_loss = 2.520, time/batch = 0.208\n",
            "5183/15750 (epoch 16), train_loss = 2.515, time/batch = 0.213\n",
            "5184/15750 (epoch 16), train_loss = 2.437, time/batch = 0.210\n",
            "5185/15750 (epoch 16), train_loss = 2.431, time/batch = 0.205\n",
            "5186/15750 (epoch 16), train_loss = 2.375, time/batch = 0.213\n",
            "5187/15750 (epoch 16), train_loss = 2.464, time/batch = 0.212\n",
            "5188/15750 (epoch 16), train_loss = 2.493, time/batch = 0.211\n",
            "5189/15750 (epoch 16), train_loss = 2.440, time/batch = 0.214\n",
            "5190/15750 (epoch 16), train_loss = 2.443, time/batch = 0.204\n",
            "5191/15750 (epoch 16), train_loss = 2.480, time/batch = 0.210\n",
            "5192/15750 (epoch 16), train_loss = 2.547, time/batch = 0.201\n",
            "5193/15750 (epoch 16), train_loss = 2.489, time/batch = 0.203\n",
            "5194/15750 (epoch 16), train_loss = 2.493, time/batch = 0.209\n",
            "5195/15750 (epoch 16), train_loss = 2.481, time/batch = 0.218\n",
            "5196/15750 (epoch 16), train_loss = 2.488, time/batch = 0.212\n",
            "5197/15750 (epoch 16), train_loss = 2.470, time/batch = 0.212\n",
            "5198/15750 (epoch 16), train_loss = 2.569, time/batch = 0.208\n",
            "5199/15750 (epoch 16), train_loss = 2.421, time/batch = 0.214\n",
            "5200/15750 (epoch 16), train_loss = 2.496, time/batch = 0.205\n",
            "5201/15750 (epoch 16), train_loss = 2.489, time/batch = 0.213\n",
            "5202/15750 (epoch 16), train_loss = 2.522, time/batch = 0.209\n",
            "5203/15750 (epoch 16), train_loss = 2.601, time/batch = 0.204\n",
            "5204/15750 (epoch 16), train_loss = 2.515, time/batch = 0.211\n",
            "5205/15750 (epoch 16), train_loss = 2.525, time/batch = 0.203\n",
            "5206/15750 (epoch 16), train_loss = 2.510, time/batch = 0.209\n",
            "5207/15750 (epoch 16), train_loss = 2.461, time/batch = 0.207\n",
            "5208/15750 (epoch 16), train_loss = 2.427, time/batch = 0.199\n",
            "5209/15750 (epoch 16), train_loss = 2.423, time/batch = 0.205\n",
            "5210/15750 (epoch 16), train_loss = 2.477, time/batch = 0.202\n",
            "5211/15750 (epoch 16), train_loss = 2.519, time/batch = 0.202\n",
            "5212/15750 (epoch 16), train_loss = 2.465, time/batch = 0.206\n",
            "5213/15750 (epoch 16), train_loss = 2.516, time/batch = 0.213\n",
            "5214/15750 (epoch 16), train_loss = 2.481, time/batch = 0.221\n",
            "5215/15750 (epoch 16), train_loss = 2.397, time/batch = 0.206\n",
            "5216/15750 (epoch 16), train_loss = 2.434, time/batch = 0.210\n",
            "5217/15750 (epoch 16), train_loss = 2.490, time/batch = 0.207\n",
            "5218/15750 (epoch 16), train_loss = 2.419, time/batch = 0.211\n",
            "5219/15750 (epoch 16), train_loss = 2.390, time/batch = 0.213\n",
            "5220/15750 (epoch 16), train_loss = 2.409, time/batch = 0.216\n",
            "5221/15750 (epoch 16), train_loss = 2.510, time/batch = 0.202\n",
            "5222/15750 (epoch 16), train_loss = 2.457, time/batch = 0.213\n",
            "5223/15750 (epoch 16), train_loss = 2.531, time/batch = 0.214\n",
            "5224/15750 (epoch 16), train_loss = 2.529, time/batch = 0.210\n",
            "5225/15750 (epoch 16), train_loss = 2.441, time/batch = 0.213\n",
            "5226/15750 (epoch 16), train_loss = 2.414, time/batch = 0.211\n",
            "5227/15750 (epoch 16), train_loss = 2.488, time/batch = 0.211\n",
            "5228/15750 (epoch 16), train_loss = 2.538, time/batch = 0.211\n",
            "5229/15750 (epoch 16), train_loss = 2.606, time/batch = 0.202\n",
            "5230/15750 (epoch 16), train_loss = 2.549, time/batch = 0.207\n",
            "5231/15750 (epoch 16), train_loss = 2.475, time/batch = 0.213\n",
            "5232/15750 (epoch 16), train_loss = 2.486, time/batch = 0.208\n",
            "5233/15750 (epoch 16), train_loss = 2.419, time/batch = 0.210\n",
            "5234/15750 (epoch 16), train_loss = 2.529, time/batch = 0.211\n",
            "5235/15750 (epoch 16), train_loss = 2.538, time/batch = 0.204\n",
            "5236/15750 (epoch 16), train_loss = 2.466, time/batch = 0.205\n",
            "5237/15750 (epoch 16), train_loss = 2.419, time/batch = 0.206\n",
            "5238/15750 (epoch 16), train_loss = 2.511, time/batch = 0.218\n",
            "5239/15750 (epoch 16), train_loss = 2.324, time/batch = 0.206\n",
            "5240/15750 (epoch 16), train_loss = 2.414, time/batch = 0.215\n",
            "5241/15750 (epoch 16), train_loss = 2.384, time/batch = 0.212\n",
            "5242/15750 (epoch 16), train_loss = 2.462, time/batch = 0.209\n",
            "5243/15750 (epoch 16), train_loss = 2.435, time/batch = 0.213\n",
            "5244/15750 (epoch 16), train_loss = 2.496, time/batch = 0.205\n",
            "5245/15750 (epoch 16), train_loss = 2.464, time/batch = 0.211\n",
            "5246/15750 (epoch 16), train_loss = 2.326, time/batch = 0.204\n",
            "5247/15750 (epoch 16), train_loss = 2.406, time/batch = 0.207\n",
            "5248/15750 (epoch 16), train_loss = 2.409, time/batch = 0.209\n",
            "5249/15750 (epoch 16), train_loss = 2.458, time/batch = 0.203\n",
            "5250/15750 (epoch 16), train_loss = 2.332, time/batch = 0.204\n",
            "5251/15750 (epoch 16), train_loss = 2.425, time/batch = 0.204\n",
            "5252/15750 (epoch 16), train_loss = 2.312, time/batch = 0.199\n",
            "5253/15750 (epoch 16), train_loss = 2.378, time/batch = 0.208\n",
            "5254/15750 (epoch 16), train_loss = 2.380, time/batch = 0.197\n",
            "5255/15750 (epoch 16), train_loss = 2.378, time/batch = 0.203\n",
            "5256/15750 (epoch 16), train_loss = 2.530, time/batch = 0.195\n",
            "5257/15750 (epoch 16), train_loss = 2.340, time/batch = 0.205\n",
            "5258/15750 (epoch 16), train_loss = 2.584, time/batch = 0.211\n",
            "5259/15750 (epoch 16), train_loss = 2.442, time/batch = 0.207\n",
            "5260/15750 (epoch 16), train_loss = 2.332, time/batch = 0.207\n",
            "5261/15750 (epoch 16), train_loss = 2.380, time/batch = 0.217\n",
            "5262/15750 (epoch 16), train_loss = 2.440, time/batch = 0.209\n",
            "5263/15750 (epoch 16), train_loss = 2.430, time/batch = 0.211\n",
            "5264/15750 (epoch 16), train_loss = 2.410, time/batch = 0.209\n",
            "5265/15750 (epoch 16), train_loss = 2.409, time/batch = 0.209\n",
            "5266/15750 (epoch 16), train_loss = 2.492, time/batch = 0.214\n",
            "5267/15750 (epoch 16), train_loss = 2.403, time/batch = 0.208\n",
            "5268/15750 (epoch 16), train_loss = 2.445, time/batch = 0.219\n",
            "5269/15750 (epoch 16), train_loss = 2.524, time/batch = 0.206\n",
            "5270/15750 (epoch 16), train_loss = 2.379, time/batch = 0.200\n",
            "5271/15750 (epoch 16), train_loss = 2.396, time/batch = 0.206\n",
            "5272/15750 (epoch 16), train_loss = 2.444, time/batch = 0.203\n",
            "5273/15750 (epoch 16), train_loss = 2.448, time/batch = 0.217\n",
            "5274/15750 (epoch 16), train_loss = 2.381, time/batch = 0.207\n",
            "5275/15750 (epoch 16), train_loss = 2.383, time/batch = 0.210\n",
            "5276/15750 (epoch 16), train_loss = 2.348, time/batch = 0.208\n",
            "5277/15750 (epoch 16), train_loss = 2.421, time/batch = 0.215\n",
            "5278/15750 (epoch 16), train_loss = 2.626, time/batch = 0.220\n",
            "5279/15750 (epoch 16), train_loss = 2.430, time/batch = 0.213\n",
            "5280/15750 (epoch 16), train_loss = 2.492, time/batch = 0.216\n",
            "5281/15750 (epoch 16), train_loss = 2.367, time/batch = 0.207\n",
            "5282/15750 (epoch 16), train_loss = 2.435, time/batch = 0.210\n",
            "5283/15750 (epoch 16), train_loss = 2.450, time/batch = 0.214\n",
            "5284/15750 (epoch 16), train_loss = 2.441, time/batch = 0.206\n",
            "5285/15750 (epoch 16), train_loss = 2.502, time/batch = 0.215\n",
            "5286/15750 (epoch 16), train_loss = 2.471, time/batch = 0.218\n",
            "5287/15750 (epoch 16), train_loss = 2.463, time/batch = 0.208\n",
            "5288/15750 (epoch 16), train_loss = 2.448, time/batch = 0.203\n",
            "5289/15750 (epoch 16), train_loss = 2.474, time/batch = 0.202\n",
            "5290/15750 (epoch 16), train_loss = 2.378, time/batch = 0.208\n",
            "5291/15750 (epoch 16), train_loss = 2.380, time/batch = 0.202\n",
            "5292/15750 (epoch 16), train_loss = 2.454, time/batch = 0.210\n",
            "5293/15750 (epoch 16), train_loss = 2.460, time/batch = 0.211\n",
            "5294/15750 (epoch 16), train_loss = 2.431, time/batch = 0.206\n",
            "5295/15750 (epoch 16), train_loss = 2.410, time/batch = 0.209\n",
            "5296/15750 (epoch 16), train_loss = 2.359, time/batch = 0.205\n",
            "5297/15750 (epoch 16), train_loss = 2.373, time/batch = 0.207\n",
            "5298/15750 (epoch 16), train_loss = 2.546, time/batch = 0.195\n",
            "5299/15750 (epoch 16), train_loss = 2.497, time/batch = 0.199\n",
            "5300/15750 (epoch 16), train_loss = 2.476, time/batch = 0.199\n",
            "5301/15750 (epoch 16), train_loss = 2.419, time/batch = 0.201\n",
            "5302/15750 (epoch 16), train_loss = 2.456, time/batch = 0.209\n",
            "5303/15750 (epoch 16), train_loss = 2.428, time/batch = 0.200\n",
            "5304/15750 (epoch 16), train_loss = 2.485, time/batch = 0.205\n",
            "5305/15750 (epoch 16), train_loss = 2.521, time/batch = 0.207\n",
            "5306/15750 (epoch 16), train_loss = 2.535, time/batch = 0.204\n",
            "5307/15750 (epoch 16), train_loss = 2.445, time/batch = 0.205\n",
            "5308/15750 (epoch 16), train_loss = 2.483, time/batch = 0.206\n",
            "5309/15750 (epoch 16), train_loss = 2.506, time/batch = 0.213\n",
            "5310/15750 (epoch 16), train_loss = 2.490, time/batch = 0.203\n",
            "5311/15750 (epoch 16), train_loss = 2.385, time/batch = 0.212\n",
            "5312/15750 (epoch 16), train_loss = 2.431, time/batch = 0.214\n",
            "5313/15750 (epoch 16), train_loss = 2.488, time/batch = 0.211\n",
            "5314/15750 (epoch 16), train_loss = 2.512, time/batch = 0.207\n",
            "5315/15750 (epoch 16), train_loss = 2.471, time/batch = 0.211\n",
            "5316/15750 (epoch 16), train_loss = 2.522, time/batch = 0.204\n",
            "5317/15750 (epoch 16), train_loss = 2.448, time/batch = 0.220\n",
            "5318/15750 (epoch 16), train_loss = 2.399, time/batch = 0.208\n",
            "5319/15750 (epoch 16), train_loss = 2.360, time/batch = 0.208\n",
            "5320/15750 (epoch 16), train_loss = 2.610, time/batch = 0.200\n",
            "5321/15750 (epoch 16), train_loss = 2.430, time/batch = 0.200\n",
            "5322/15750 (epoch 16), train_loss = 2.389, time/batch = 0.215\n",
            "5323/15750 (epoch 16), train_loss = 2.519, time/batch = 0.216\n",
            "5324/15750 (epoch 16), train_loss = 2.398, time/batch = 0.205\n",
            "5325/15750 (epoch 16), train_loss = 2.550, time/batch = 0.204\n",
            "5326/15750 (epoch 16), train_loss = 2.419, time/batch = 0.209\n",
            "5327/15750 (epoch 16), train_loss = 2.439, time/batch = 0.218\n",
            "5328/15750 (epoch 16), train_loss = 2.361, time/batch = 0.208\n",
            "5329/15750 (epoch 16), train_loss = 2.449, time/batch = 0.212\n",
            "5330/15750 (epoch 16), train_loss = 2.376, time/batch = 0.210\n",
            "5331/15750 (epoch 16), train_loss = 2.467, time/batch = 0.212\n",
            "5332/15750 (epoch 16), train_loss = 2.459, time/batch = 0.217\n",
            "5333/15750 (epoch 16), train_loss = 2.423, time/batch = 0.205\n",
            "5334/15750 (epoch 16), train_loss = 2.473, time/batch = 0.200\n",
            "5335/15750 (epoch 16), train_loss = 2.555, time/batch = 0.202\n",
            "5336/15750 (epoch 16), train_loss = 2.511, time/batch = 0.199\n",
            "5337/15750 (epoch 16), train_loss = 2.527, time/batch = 0.203\n",
            "5338/15750 (epoch 16), train_loss = 2.387, time/batch = 0.206\n",
            "5339/15750 (epoch 16), train_loss = 2.474, time/batch = 0.205\n",
            "5340/15750 (epoch 16), train_loss = 2.453, time/batch = 0.210\n",
            "5341/15750 (epoch 16), train_loss = 2.368, time/batch = 0.206\n",
            "5342/15750 (epoch 16), train_loss = 2.498, time/batch = 0.220\n",
            "5343/15750 (epoch 16), train_loss = 2.357, time/batch = 0.211\n",
            "5344/15750 (epoch 16), train_loss = 2.497, time/batch = 0.201\n",
            "5345/15750 (epoch 16), train_loss = 2.442, time/batch = 0.206\n",
            "5346/15750 (epoch 16), train_loss = 2.421, time/batch = 0.204\n",
            "5347/15750 (epoch 16), train_loss = 2.363, time/batch = 0.207\n",
            "5348/15750 (epoch 16), train_loss = 2.389, time/batch = 0.214\n",
            "5349/15750 (epoch 16), train_loss = 2.522, time/batch = 0.208\n",
            "5350/15750 (epoch 16), train_loss = 2.367, time/batch = 0.208\n",
            "5351/15750 (epoch 16), train_loss = 2.345, time/batch = 0.206\n",
            "5352/15750 (epoch 16), train_loss = 2.403, time/batch = 0.204\n",
            "5353/15750 (epoch 16), train_loss = 2.390, time/batch = 0.205\n",
            "5354/15750 (epoch 16), train_loss = 2.496, time/batch = 0.206\n",
            "5355/15750 (epoch 17), train_loss = 2.494, time/batch = 0.208\n",
            "5356/15750 (epoch 17), train_loss = 2.505, time/batch = 0.210\n",
            "5357/15750 (epoch 17), train_loss = 2.443, time/batch = 0.220\n",
            "5358/15750 (epoch 17), train_loss = 2.532, time/batch = 0.208\n",
            "5359/15750 (epoch 17), train_loss = 2.455, time/batch = 0.202\n",
            "5360/15750 (epoch 17), train_loss = 2.443, time/batch = 0.204\n",
            "5361/15750 (epoch 17), train_loss = 2.617, time/batch = 0.213\n",
            "5362/15750 (epoch 17), train_loss = 2.526, time/batch = 0.204\n",
            "5363/15750 (epoch 17), train_loss = 2.510, time/batch = 0.197\n",
            "5364/15750 (epoch 17), train_loss = 2.460, time/batch = 0.202\n",
            "5365/15750 (epoch 17), train_loss = 2.456, time/batch = 0.199\n",
            "5366/15750 (epoch 17), train_loss = 2.406, time/batch = 0.209\n",
            "5367/15750 (epoch 17), train_loss = 2.514, time/batch = 0.203\n",
            "5368/15750 (epoch 17), train_loss = 2.473, time/batch = 0.208\n",
            "5369/15750 (epoch 17), train_loss = 2.465, time/batch = 0.200\n",
            "5370/15750 (epoch 17), train_loss = 2.478, time/batch = 0.209\n",
            "5371/15750 (epoch 17), train_loss = 2.497, time/batch = 0.218\n",
            "5372/15750 (epoch 17), train_loss = 2.555, time/batch = 0.209\n",
            "5373/15750 (epoch 17), train_loss = 2.558, time/batch = 0.211\n",
            "5374/15750 (epoch 17), train_loss = 2.502, time/batch = 0.214\n",
            "5375/15750 (epoch 17), train_loss = 2.499, time/batch = 0.205\n",
            "5376/15750 (epoch 17), train_loss = 2.512, time/batch = 0.215\n",
            "5377/15750 (epoch 17), train_loss = 2.461, time/batch = 0.205\n",
            "5378/15750 (epoch 17), train_loss = 2.522, time/batch = 0.209\n",
            "5379/15750 (epoch 17), train_loss = 2.515, time/batch = 0.203\n",
            "5380/15750 (epoch 17), train_loss = 2.543, time/batch = 0.202\n",
            "5381/15750 (epoch 17), train_loss = 2.537, time/batch = 0.206\n",
            "5382/15750 (epoch 17), train_loss = 2.533, time/batch = 0.202\n",
            "5383/15750 (epoch 17), train_loss = 2.654, time/batch = 0.200\n",
            "5384/15750 (epoch 17), train_loss = 2.562, time/batch = 0.207\n",
            "5385/15750 (epoch 17), train_loss = 2.519, time/batch = 0.202\n",
            "5386/15750 (epoch 17), train_loss = 2.491, time/batch = 0.203\n",
            "5387/15750 (epoch 17), train_loss = 2.398, time/batch = 0.202\n",
            "5388/15750 (epoch 17), train_loss = 2.424, time/batch = 0.201\n",
            "5389/15750 (epoch 17), train_loss = 2.502, time/batch = 0.201\n",
            "5390/15750 (epoch 17), train_loss = 2.412, time/batch = 0.200\n",
            "5391/15750 (epoch 17), train_loss = 2.450, time/batch = 0.208\n",
            "5392/15750 (epoch 17), train_loss = 2.522, time/batch = 0.201\n",
            "5393/15750 (epoch 17), train_loss = 2.432, time/batch = 0.204\n",
            "5394/15750 (epoch 17), train_loss = 2.480, time/batch = 0.207\n",
            "5395/15750 (epoch 17), train_loss = 2.446, time/batch = 0.209\n",
            "5396/15750 (epoch 17), train_loss = 2.497, time/batch = 0.212\n",
            "5397/15750 (epoch 17), train_loss = 2.489, time/batch = 0.212\n",
            "5398/15750 (epoch 17), train_loss = 2.441, time/batch = 0.205\n",
            "5399/15750 (epoch 17), train_loss = 2.490, time/batch = 0.210\n",
            "5400/15750 (epoch 17), train_loss = 2.394, time/batch = 0.212\n",
            "5401/15750 (epoch 17), train_loss = 2.437, time/batch = 0.206\n",
            "5402/15750 (epoch 17), train_loss = 2.476, time/batch = 0.212\n",
            "5403/15750 (epoch 17), train_loss = 2.513, time/batch = 0.212\n",
            "5404/15750 (epoch 17), train_loss = 2.407, time/batch = 0.214\n",
            "5405/15750 (epoch 17), train_loss = 2.454, time/batch = 0.200\n",
            "5406/15750 (epoch 17), train_loss = 2.412, time/batch = 0.198\n",
            "5407/15750 (epoch 17), train_loss = 2.474, time/batch = 0.206\n",
            "5408/15750 (epoch 17), train_loss = 2.481, time/batch = 0.200\n",
            "5409/15750 (epoch 17), train_loss = 2.477, time/batch = 0.207\n",
            "5410/15750 (epoch 17), train_loss = 2.519, time/batch = 0.209\n",
            "5411/15750 (epoch 17), train_loss = 2.387, time/batch = 0.204\n",
            "5412/15750 (epoch 17), train_loss = 2.399, time/batch = 0.208\n",
            "5413/15750 (epoch 17), train_loss = 2.479, time/batch = 0.212\n",
            "5414/15750 (epoch 17), train_loss = 2.333, time/batch = 0.213\n",
            "5415/15750 (epoch 17), train_loss = 2.450, time/batch = 0.212\n",
            "5416/15750 (epoch 17), train_loss = 2.452, time/batch = 0.210\n",
            "5417/15750 (epoch 17), train_loss = 2.380, time/batch = 0.210\n",
            "5418/15750 (epoch 17), train_loss = 2.427, time/batch = 0.211\n",
            "5419/15750 (epoch 17), train_loss = 2.356, time/batch = 0.210\n",
            "5420/15750 (epoch 17), train_loss = 2.364, time/batch = 0.204\n",
            "5421/15750 (epoch 17), train_loss = 2.308, time/batch = 0.208\n",
            "5422/15750 (epoch 17), train_loss = 2.336, time/batch = 0.203\n",
            "5423/15750 (epoch 17), train_loss = 2.389, time/batch = 0.201\n",
            "5424/15750 (epoch 17), train_loss = 2.472, time/batch = 0.199\n",
            "5425/15750 (epoch 17), train_loss = 2.401, time/batch = 0.207\n",
            "5426/15750 (epoch 17), train_loss = 2.393, time/batch = 0.208\n",
            "5427/15750 (epoch 17), train_loss = 2.297, time/batch = 0.200\n",
            "5428/15750 (epoch 17), train_loss = 2.390, time/batch = 0.205\n",
            "5429/15750 (epoch 17), train_loss = 2.490, time/batch = 0.198\n",
            "5430/15750 (epoch 17), train_loss = 2.431, time/batch = 0.206\n",
            "5431/15750 (epoch 17), train_loss = 2.417, time/batch = 0.203\n",
            "5432/15750 (epoch 17), train_loss = 2.424, time/batch = 0.201\n",
            "5433/15750 (epoch 17), train_loss = 2.433, time/batch = 0.201\n",
            "5434/15750 (epoch 17), train_loss = 2.429, time/batch = 0.212\n",
            "5435/15750 (epoch 17), train_loss = 2.332, time/batch = 0.214\n",
            "5436/15750 (epoch 17), train_loss = 2.439, time/batch = 0.209\n",
            "5437/15750 (epoch 17), train_loss = 2.364, time/batch = 0.215\n",
            "5438/15750 (epoch 17), train_loss = 2.428, time/batch = 0.212\n",
            "5439/15750 (epoch 17), train_loss = 2.500, time/batch = 0.207\n",
            "5440/15750 (epoch 17), train_loss = 2.510, time/batch = 0.213\n",
            "5441/15750 (epoch 17), train_loss = 2.347, time/batch = 0.211\n",
            "5442/15750 (epoch 17), train_loss = 2.380, time/batch = 0.208\n",
            "5443/15750 (epoch 17), train_loss = 2.405, time/batch = 0.205\n",
            "5444/15750 (epoch 17), train_loss = 2.389, time/batch = 0.207\n",
            "5445/15750 (epoch 17), train_loss = 2.403, time/batch = 0.219\n",
            "5446/15750 (epoch 17), train_loss = 2.457, time/batch = 0.209\n",
            "5447/15750 (epoch 17), train_loss = 2.452, time/batch = 0.217\n",
            "5448/15750 (epoch 17), train_loss = 2.468, time/batch = 0.203\n",
            "5449/15750 (epoch 17), train_loss = 2.528, time/batch = 0.200\n",
            "5450/15750 (epoch 17), train_loss = 2.424, time/batch = 0.211\n",
            "5451/15750 (epoch 17), train_loss = 2.447, time/batch = 0.213\n",
            "5452/15750 (epoch 17), train_loss = 2.457, time/batch = 0.211\n",
            "5453/15750 (epoch 17), train_loss = 2.457, time/batch = 0.209\n",
            "5454/15750 (epoch 17), train_loss = 2.473, time/batch = 0.206\n",
            "5455/15750 (epoch 17), train_loss = 2.447, time/batch = 0.215\n",
            "5456/15750 (epoch 17), train_loss = 2.367, time/batch = 0.210\n",
            "5457/15750 (epoch 17), train_loss = 2.398, time/batch = 0.216\n",
            "5458/15750 (epoch 17), train_loss = 2.523, time/batch = 0.213\n",
            "5459/15750 (epoch 17), train_loss = 2.456, time/batch = 0.207\n",
            "5460/15750 (epoch 17), train_loss = 2.375, time/batch = 0.218\n",
            "5461/15750 (epoch 17), train_loss = 2.433, time/batch = 0.211\n",
            "5462/15750 (epoch 17), train_loss = 2.444, time/batch = 0.204\n",
            "5463/15750 (epoch 17), train_loss = 2.499, time/batch = 0.207\n",
            "5464/15750 (epoch 17), train_loss = 2.516, time/batch = 0.207\n",
            "5465/15750 (epoch 17), train_loss = 2.558, time/batch = 0.209\n",
            "5466/15750 (epoch 17), train_loss = 2.442, time/batch = 0.214\n",
            "5467/15750 (epoch 17), train_loss = 2.424, time/batch = 0.204\n",
            "5468/15750 (epoch 17), train_loss = 2.441, time/batch = 0.203\n",
            "5469/15750 (epoch 17), train_loss = 2.456, time/batch = 0.209\n",
            "5470/15750 (epoch 17), train_loss = 2.525, time/batch = 0.204\n",
            "5471/15750 (epoch 17), train_loss = 2.450, time/batch = 0.205\n",
            "5472/15750 (epoch 17), train_loss = 2.582, time/batch = 0.206\n",
            "5473/15750 (epoch 17), train_loss = 2.451, time/batch = 0.209\n",
            "5474/15750 (epoch 17), train_loss = 2.425, time/batch = 0.216\n",
            "5475/15750 (epoch 17), train_loss = 2.411, time/batch = 0.207\n",
            "5476/15750 (epoch 17), train_loss = 2.389, time/batch = 0.209\n",
            "5477/15750 (epoch 17), train_loss = 2.425, time/batch = 0.210\n",
            "5478/15750 (epoch 17), train_loss = 2.399, time/batch = 0.212\n",
            "5479/15750 (epoch 17), train_loss = 2.426, time/batch = 0.214\n",
            "5480/15750 (epoch 17), train_loss = 2.440, time/batch = 0.206\n",
            "5481/15750 (epoch 17), train_loss = 2.531, time/batch = 0.204\n",
            "5482/15750 (epoch 17), train_loss = 2.391, time/batch = 0.212\n",
            "5483/15750 (epoch 17), train_loss = 2.400, time/batch = 0.206\n",
            "5484/15750 (epoch 17), train_loss = 2.402, time/batch = 0.212\n",
            "5485/15750 (epoch 17), train_loss = 2.340, time/batch = 0.209\n",
            "5486/15750 (epoch 17), train_loss = 2.350, time/batch = 0.209\n",
            "5487/15750 (epoch 17), train_loss = 2.366, time/batch = 0.207\n",
            "5488/15750 (epoch 17), train_loss = 2.367, time/batch = 0.200\n",
            "5489/15750 (epoch 17), train_loss = 2.408, time/batch = 0.201\n",
            "5490/15750 (epoch 17), train_loss = 2.526, time/batch = 0.200\n",
            "5491/15750 (epoch 17), train_loss = 2.482, time/batch = 0.197\n",
            "5492/15750 (epoch 17), train_loss = 2.491, time/batch = 0.205\n",
            "5493/15750 (epoch 17), train_loss = 2.481, time/batch = 0.207\n",
            "5494/15750 (epoch 17), train_loss = 2.407, time/batch = 0.203\n",
            "5495/15750 (epoch 17), train_loss = 2.404, time/batch = 0.204\n",
            "5496/15750 (epoch 17), train_loss = 2.484, time/batch = 0.209\n",
            "5497/15750 (epoch 17), train_loss = 2.503, time/batch = 0.203\n",
            "5498/15750 (epoch 17), train_loss = 2.497, time/batch = 0.206\n",
            "5499/15750 (epoch 17), train_loss = 2.418, time/batch = 0.209\n",
            "5500/15750 (epoch 17), train_loss = 2.411, time/batch = 0.204\n",
            "5501/15750 (epoch 17), train_loss = 2.358, time/batch = 0.213\n",
            "5502/15750 (epoch 17), train_loss = 2.447, time/batch = 0.211\n",
            "5503/15750 (epoch 17), train_loss = 2.475, time/batch = 0.210\n",
            "5504/15750 (epoch 17), train_loss = 2.422, time/batch = 0.219\n",
            "5505/15750 (epoch 17), train_loss = 2.425, time/batch = 0.206\n",
            "5506/15750 (epoch 17), train_loss = 2.463, time/batch = 0.207\n",
            "5507/15750 (epoch 17), train_loss = 2.528, time/batch = 0.201\n",
            "5508/15750 (epoch 17), train_loss = 2.470, time/batch = 0.206\n",
            "5509/15750 (epoch 17), train_loss = 2.476, time/batch = 0.223\n",
            "5510/15750 (epoch 17), train_loss = 2.462, time/batch = 0.210\n",
            "5511/15750 (epoch 17), train_loss = 2.468, time/batch = 0.208\n",
            "5512/15750 (epoch 17), train_loss = 2.452, time/batch = 0.211\n",
            "5513/15750 (epoch 17), train_loss = 2.549, time/batch = 0.213\n",
            "5514/15750 (epoch 17), train_loss = 2.403, time/batch = 0.218\n",
            "5515/15750 (epoch 17), train_loss = 2.476, time/batch = 0.211\n",
            "5516/15750 (epoch 17), train_loss = 2.472, time/batch = 0.203\n",
            "5517/15750 (epoch 17), train_loss = 2.502, time/batch = 0.209\n",
            "5518/15750 (epoch 17), train_loss = 2.582, time/batch = 0.214\n",
            "5519/15750 (epoch 17), train_loss = 2.496, time/batch = 0.203\n",
            "5520/15750 (epoch 17), train_loss = 2.504, time/batch = 0.204\n",
            "5521/15750 (epoch 17), train_loss = 2.489, time/batch = 0.206\n",
            "5522/15750 (epoch 17), train_loss = 2.442, time/batch = 0.210\n",
            "5523/15750 (epoch 17), train_loss = 2.409, time/batch = 0.210\n",
            "5524/15750 (epoch 17), train_loss = 2.404, time/batch = 0.211\n",
            "5525/15750 (epoch 17), train_loss = 2.457, time/batch = 0.213\n",
            "5526/15750 (epoch 17), train_loss = 2.499, time/batch = 0.209\n",
            "5527/15750 (epoch 17), train_loss = 2.447, time/batch = 0.207\n",
            "5528/15750 (epoch 17), train_loss = 2.499, time/batch = 0.210\n",
            "5529/15750 (epoch 17), train_loss = 2.462, time/batch = 0.209\n",
            "5530/15750 (epoch 17), train_loss = 2.380, time/batch = 0.207\n",
            "5531/15750 (epoch 17), train_loss = 2.416, time/batch = 0.205\n",
            "5532/15750 (epoch 17), train_loss = 2.471, time/batch = 0.208\n",
            "5533/15750 (epoch 17), train_loss = 2.401, time/batch = 0.218\n",
            "5534/15750 (epoch 17), train_loss = 2.371, time/batch = 0.213\n",
            "5535/15750 (epoch 17), train_loss = 2.392, time/batch = 0.205\n",
            "5536/15750 (epoch 17), train_loss = 2.490, time/batch = 0.207\n",
            "5537/15750 (epoch 17), train_loss = 2.440, time/batch = 0.207\n",
            "5538/15750 (epoch 17), train_loss = 2.512, time/batch = 0.216\n",
            "5539/15750 (epoch 17), train_loss = 2.510, time/batch = 0.208\n",
            "5540/15750 (epoch 17), train_loss = 2.426, time/batch = 0.206\n",
            "5541/15750 (epoch 17), train_loss = 2.397, time/batch = 0.217\n",
            "5542/15750 (epoch 17), train_loss = 2.471, time/batch = 0.210\n",
            "5543/15750 (epoch 17), train_loss = 2.518, time/batch = 0.213\n",
            "5544/15750 (epoch 17), train_loss = 2.587, time/batch = 0.213\n",
            "5545/15750 (epoch 17), train_loss = 2.532, time/batch = 0.203\n",
            "5546/15750 (epoch 17), train_loss = 2.457, time/batch = 0.209\n",
            "5547/15750 (epoch 17), train_loss = 2.468, time/batch = 0.197\n",
            "5548/15750 (epoch 17), train_loss = 2.400, time/batch = 0.211\n",
            "5549/15750 (epoch 17), train_loss = 2.513, time/batch = 0.204\n",
            "5550/15750 (epoch 17), train_loss = 2.517, time/batch = 0.206\n",
            "5551/15750 (epoch 17), train_loss = 2.449, time/batch = 0.215\n",
            "5552/15750 (epoch 17), train_loss = 2.401, time/batch = 0.213\n",
            "5553/15750 (epoch 17), train_loss = 2.493, time/batch = 0.211\n",
            "5554/15750 (epoch 17), train_loss = 2.304, time/batch = 0.206\n",
            "5555/15750 (epoch 17), train_loss = 2.397, time/batch = 0.208\n",
            "5556/15750 (epoch 17), train_loss = 2.365, time/batch = 0.209\n",
            "5557/15750 (epoch 17), train_loss = 2.444, time/batch = 0.206\n",
            "5558/15750 (epoch 17), train_loss = 2.416, time/batch = 0.207\n",
            "5559/15750 (epoch 17), train_loss = 2.478, time/batch = 0.205\n",
            "5560/15750 (epoch 17), train_loss = 2.445, time/batch = 0.202\n",
            "5561/15750 (epoch 17), train_loss = 2.308, time/batch = 0.209\n",
            "5562/15750 (epoch 17), train_loss = 2.387, time/batch = 0.211\n",
            "5563/15750 (epoch 17), train_loss = 2.391, time/batch = 0.214\n",
            "5564/15750 (epoch 17), train_loss = 2.442, time/batch = 0.197\n",
            "5565/15750 (epoch 17), train_loss = 2.316, time/batch = 0.204\n",
            "5566/15750 (epoch 17), train_loss = 2.407, time/batch = 0.200\n",
            "5567/15750 (epoch 17), train_loss = 2.294, time/batch = 0.198\n",
            "5568/15750 (epoch 17), train_loss = 2.361, time/batch = 0.217\n",
            "5569/15750 (epoch 17), train_loss = 2.362, time/batch = 0.206\n",
            "5570/15750 (epoch 17), train_loss = 2.359, time/batch = 0.206\n",
            "5571/15750 (epoch 17), train_loss = 2.512, time/batch = 0.203\n",
            "5572/15750 (epoch 17), train_loss = 2.321, time/batch = 0.207\n",
            "5573/15750 (epoch 17), train_loss = 2.567, time/batch = 0.217\n",
            "5574/15750 (epoch 17), train_loss = 2.426, time/batch = 0.207\n",
            "5575/15750 (epoch 17), train_loss = 2.314, time/batch = 0.206\n",
            "5576/15750 (epoch 17), train_loss = 2.361, time/batch = 0.205\n",
            "5577/15750 (epoch 17), train_loss = 2.420, time/batch = 0.206\n",
            "5578/15750 (epoch 17), train_loss = 2.411, time/batch = 0.209\n",
            "5579/15750 (epoch 17), train_loss = 2.393, time/batch = 0.206\n",
            "5580/15750 (epoch 17), train_loss = 2.391, time/batch = 0.206\n",
            "5581/15750 (epoch 17), train_loss = 2.473, time/batch = 0.212\n",
            "5582/15750 (epoch 17), train_loss = 2.384, time/batch = 0.210\n",
            "5583/15750 (epoch 17), train_loss = 2.427, time/batch = 0.196\n",
            "5584/15750 (epoch 17), train_loss = 2.506, time/batch = 0.213\n",
            "5585/15750 (epoch 17), train_loss = 2.360, time/batch = 0.207\n",
            "5586/15750 (epoch 17), train_loss = 2.379, time/batch = 0.210\n",
            "5587/15750 (epoch 17), train_loss = 2.426, time/batch = 0.195\n",
            "5588/15750 (epoch 17), train_loss = 2.428, time/batch = 0.201\n",
            "5589/15750 (epoch 17), train_loss = 2.364, time/batch = 0.202\n",
            "5590/15750 (epoch 17), train_loss = 2.365, time/batch = 0.204\n",
            "5591/15750 (epoch 17), train_loss = 2.332, time/batch = 0.207\n",
            "5592/15750 (epoch 17), train_loss = 2.402, time/batch = 0.216\n",
            "5593/15750 (epoch 17), train_loss = 2.609, time/batch = 0.218\n",
            "5594/15750 (epoch 17), train_loss = 2.414, time/batch = 0.208\n",
            "5595/15750 (epoch 17), train_loss = 2.473, time/batch = 0.212\n",
            "5596/15750 (epoch 17), train_loss = 2.348, time/batch = 0.206\n",
            "5597/15750 (epoch 17), train_loss = 2.415, time/batch = 0.213\n",
            "5598/15750 (epoch 17), train_loss = 2.431, time/batch = 0.206\n",
            "5599/15750 (epoch 17), train_loss = 2.424, time/batch = 0.210\n",
            "5600/15750 (epoch 17), train_loss = 2.484, time/batch = 0.207\n",
            "5601/15750 (epoch 17), train_loss = 2.453, time/batch = 0.213\n",
            "5602/15750 (epoch 17), train_loss = 2.444, time/batch = 0.214\n",
            "5603/15750 (epoch 17), train_loss = 2.430, time/batch = 0.206\n",
            "5604/15750 (epoch 17), train_loss = 2.457, time/batch = 0.203\n",
            "5605/15750 (epoch 17), train_loss = 2.360, time/batch = 0.211\n",
            "5606/15750 (epoch 17), train_loss = 2.359, time/batch = 0.210\n",
            "5607/15750 (epoch 17), train_loss = 2.435, time/batch = 0.212\n",
            "5608/15750 (epoch 17), train_loss = 2.443, time/batch = 0.206\n",
            "5609/15750 (epoch 17), train_loss = 2.413, time/batch = 0.211\n",
            "5610/15750 (epoch 17), train_loss = 2.391, time/batch = 0.212\n",
            "5611/15750 (epoch 17), train_loss = 2.340, time/batch = 0.212\n",
            "5612/15750 (epoch 17), train_loss = 2.354, time/batch = 0.205\n",
            "5613/15750 (epoch 17), train_loss = 2.526, time/batch = 0.206\n",
            "5614/15750 (epoch 17), train_loss = 2.480, time/batch = 0.208\n",
            "5615/15750 (epoch 17), train_loss = 2.458, time/batch = 0.207\n",
            "5616/15750 (epoch 17), train_loss = 2.401, time/batch = 0.205\n",
            "5617/15750 (epoch 17), train_loss = 2.437, time/batch = 0.205\n",
            "5618/15750 (epoch 17), train_loss = 2.410, time/batch = 0.208\n",
            "5619/15750 (epoch 17), train_loss = 2.464, time/batch = 0.208\n",
            "5620/15750 (epoch 17), train_loss = 2.502, time/batch = 0.201\n",
            "5621/15750 (epoch 17), train_loss = 2.515, time/batch = 0.213\n",
            "5622/15750 (epoch 17), train_loss = 2.426, time/batch = 0.212\n",
            "5623/15750 (epoch 17), train_loss = 2.465, time/batch = 0.207\n",
            "5624/15750 (epoch 17), train_loss = 2.486, time/batch = 0.205\n",
            "5625/15750 (epoch 17), train_loss = 2.472, time/batch = 0.210\n",
            "5626/15750 (epoch 17), train_loss = 2.368, time/batch = 0.209\n",
            "5627/15750 (epoch 17), train_loss = 2.412, time/batch = 0.209\n",
            "5628/15750 (epoch 17), train_loss = 2.470, time/batch = 0.215\n",
            "5629/15750 (epoch 17), train_loss = 2.494, time/batch = 0.210\n",
            "5630/15750 (epoch 17), train_loss = 2.452, time/batch = 0.207\n",
            "5631/15750 (epoch 17), train_loss = 2.504, time/batch = 0.198\n",
            "5632/15750 (epoch 17), train_loss = 2.431, time/batch = 0.211\n",
            "5633/15750 (epoch 17), train_loss = 2.383, time/batch = 0.206\n",
            "5634/15750 (epoch 17), train_loss = 2.342, time/batch = 0.196\n",
            "5635/15750 (epoch 17), train_loss = 2.590, time/batch = 0.209\n",
            "5636/15750 (epoch 17), train_loss = 2.412, time/batch = 0.205\n",
            "5637/15750 (epoch 17), train_loss = 2.371, time/batch = 0.213\n",
            "5638/15750 (epoch 17), train_loss = 2.499, time/batch = 0.209\n",
            "5639/15750 (epoch 17), train_loss = 2.381, time/batch = 0.203\n",
            "5640/15750 (epoch 17), train_loss = 2.532, time/batch = 0.204\n",
            "5641/15750 (epoch 17), train_loss = 2.402, time/batch = 0.202\n",
            "5642/15750 (epoch 17), train_loss = 2.422, time/batch = 0.205\n",
            "5643/15750 (epoch 17), train_loss = 2.343, time/batch = 0.205\n",
            "5644/15750 (epoch 17), train_loss = 2.433, time/batch = 0.208\n",
            "5645/15750 (epoch 17), train_loss = 2.360, time/batch = 0.208\n",
            "5646/15750 (epoch 17), train_loss = 2.449, time/batch = 0.208\n",
            "5647/15750 (epoch 17), train_loss = 2.441, time/batch = 0.225\n",
            "5648/15750 (epoch 17), train_loss = 2.405, time/batch = 0.210\n",
            "5649/15750 (epoch 17), train_loss = 2.455, time/batch = 0.204\n",
            "5650/15750 (epoch 17), train_loss = 2.538, time/batch = 0.211\n",
            "5651/15750 (epoch 17), train_loss = 2.493, time/batch = 0.205\n",
            "5652/15750 (epoch 17), train_loss = 2.509, time/batch = 0.205\n",
            "5653/15750 (epoch 17), train_loss = 2.369, time/batch = 0.204\n",
            "5654/15750 (epoch 17), train_loss = 2.455, time/batch = 0.204\n",
            "5655/15750 (epoch 17), train_loss = 2.437, time/batch = 0.203\n",
            "5656/15750 (epoch 17), train_loss = 2.351, time/batch = 0.210\n",
            "5657/15750 (epoch 17), train_loss = 2.481, time/batch = 0.205\n",
            "5658/15750 (epoch 17), train_loss = 2.340, time/batch = 0.217\n",
            "5659/15750 (epoch 17), train_loss = 2.480, time/batch = 0.208\n",
            "5660/15750 (epoch 17), train_loss = 2.424, time/batch = 0.206\n",
            "5661/15750 (epoch 17), train_loss = 2.402, time/batch = 0.209\n",
            "5662/15750 (epoch 17), train_loss = 2.346, time/batch = 0.203\n",
            "5663/15750 (epoch 17), train_loss = 2.372, time/batch = 0.214\n",
            "5664/15750 (epoch 17), train_loss = 2.504, time/batch = 0.203\n",
            "5665/15750 (epoch 17), train_loss = 2.349, time/batch = 0.210\n",
            "5666/15750 (epoch 17), train_loss = 2.330, time/batch = 0.212\n",
            "5667/15750 (epoch 17), train_loss = 2.385, time/batch = 0.212\n",
            "5668/15750 (epoch 17), train_loss = 2.372, time/batch = 0.206\n",
            "5669/15750 (epoch 17), train_loss = 2.479, time/batch = 0.211\n",
            "5670/15750 (epoch 18), train_loss = 2.477, time/batch = 0.217\n",
            "5671/15750 (epoch 18), train_loss = 2.488, time/batch = 0.205\n",
            "5672/15750 (epoch 18), train_loss = 2.425, time/batch = 0.214\n",
            "5673/15750 (epoch 18), train_loss = 2.511, time/batch = 0.212\n",
            "5674/15750 (epoch 18), train_loss = 2.437, time/batch = 0.203\n",
            "5675/15750 (epoch 18), train_loss = 2.425, time/batch = 0.217\n",
            "5676/15750 (epoch 18), train_loss = 2.599, time/batch = 0.213\n",
            "5677/15750 (epoch 18), train_loss = 2.508, time/batch = 0.207\n",
            "5678/15750 (epoch 18), train_loss = 2.492, time/batch = 0.205\n",
            "5679/15750 (epoch 18), train_loss = 2.442, time/batch = 0.211\n",
            "5680/15750 (epoch 18), train_loss = 2.439, time/batch = 0.208\n",
            "5681/15750 (epoch 18), train_loss = 2.389, time/batch = 0.209\n",
            "5682/15750 (epoch 18), train_loss = 2.494, time/batch = 0.206\n",
            "5683/15750 (epoch 18), train_loss = 2.457, time/batch = 0.202\n",
            "5684/15750 (epoch 18), train_loss = 2.448, time/batch = 0.201\n",
            "5685/15750 (epoch 18), train_loss = 2.463, time/batch = 0.210\n",
            "5686/15750 (epoch 18), train_loss = 2.480, time/batch = 0.202\n",
            "5687/15750 (epoch 18), train_loss = 2.537, time/batch = 0.209\n",
            "5688/15750 (epoch 18), train_loss = 2.541, time/batch = 0.207\n",
            "5689/15750 (epoch 18), train_loss = 2.485, time/batch = 0.203\n",
            "5690/15750 (epoch 18), train_loss = 2.482, time/batch = 0.208\n",
            "5691/15750 (epoch 18), train_loss = 2.495, time/batch = 0.213\n",
            "5692/15750 (epoch 18), train_loss = 2.443, time/batch = 0.210\n",
            "5693/15750 (epoch 18), train_loss = 2.504, time/batch = 0.211\n",
            "5694/15750 (epoch 18), train_loss = 2.498, time/batch = 0.213\n",
            "5695/15750 (epoch 18), train_loss = 2.525, time/batch = 0.208\n",
            "5696/15750 (epoch 18), train_loss = 2.523, time/batch = 0.203\n",
            "5697/15750 (epoch 18), train_loss = 2.516, time/batch = 0.204\n",
            "5698/15750 (epoch 18), train_loss = 2.634, time/batch = 0.206\n",
            "5699/15750 (epoch 18), train_loss = 2.544, time/batch = 0.206\n",
            "5700/15750 (epoch 18), train_loss = 2.501, time/batch = 0.210\n",
            "5701/15750 (epoch 18), train_loss = 2.472, time/batch = 0.206\n",
            "5702/15750 (epoch 18), train_loss = 2.381, time/batch = 0.208\n",
            "5703/15750 (epoch 18), train_loss = 2.406, time/batch = 0.202\n",
            "5704/15750 (epoch 18), train_loss = 2.485, time/batch = 0.215\n",
            "5705/15750 (epoch 18), train_loss = 2.393, time/batch = 0.221\n",
            "5706/15750 (epoch 18), train_loss = 2.435, time/batch = 0.215\n",
            "5707/15750 (epoch 18), train_loss = 2.506, time/batch = 0.206\n",
            "5708/15750 (epoch 18), train_loss = 2.416, time/batch = 0.211\n",
            "5709/15750 (epoch 18), train_loss = 2.464, time/batch = 0.210\n",
            "5710/15750 (epoch 18), train_loss = 2.427, time/batch = 0.203\n",
            "5711/15750 (epoch 18), train_loss = 2.478, time/batch = 0.205\n",
            "5712/15750 (epoch 18), train_loss = 2.471, time/batch = 0.208\n",
            "5713/15750 (epoch 18), train_loss = 2.425, time/batch = 0.208\n",
            "5714/15750 (epoch 18), train_loss = 2.471, time/batch = 0.199\n",
            "5715/15750 (epoch 18), train_loss = 2.377, time/batch = 0.202\n",
            "5716/15750 (epoch 18), train_loss = 2.421, time/batch = 0.209\n",
            "5717/15750 (epoch 18), train_loss = 2.458, time/batch = 0.202\n",
            "5718/15750 (epoch 18), train_loss = 2.495, time/batch = 0.202\n",
            "5719/15750 (epoch 18), train_loss = 2.389, time/batch = 0.198\n",
            "5720/15750 (epoch 18), train_loss = 2.437, time/batch = 0.206\n",
            "5721/15750 (epoch 18), train_loss = 2.394, time/batch = 0.217\n",
            "5722/15750 (epoch 18), train_loss = 2.456, time/batch = 0.206\n",
            "5723/15750 (epoch 18), train_loss = 2.463, time/batch = 0.209\n",
            "5724/15750 (epoch 18), train_loss = 2.460, time/batch = 0.217\n",
            "5725/15750 (epoch 18), train_loss = 2.501, time/batch = 0.202\n",
            "5726/15750 (epoch 18), train_loss = 2.371, time/batch = 0.207\n",
            "5727/15750 (epoch 18), train_loss = 2.382, time/batch = 0.204\n",
            "5728/15750 (epoch 18), train_loss = 2.462, time/batch = 0.205\n",
            "5729/15750 (epoch 18), train_loss = 2.319, time/batch = 0.215\n",
            "5730/15750 (epoch 18), train_loss = 2.432, time/batch = 0.207\n",
            "5731/15750 (epoch 18), train_loss = 2.437, time/batch = 0.206\n",
            "5732/15750 (epoch 18), train_loss = 2.363, time/batch = 0.205\n",
            "5733/15750 (epoch 18), train_loss = 2.412, time/batch = 0.211\n",
            "5734/15750 (epoch 18), train_loss = 2.338, time/batch = 0.206\n",
            "5735/15750 (epoch 18), train_loss = 2.347, time/batch = 0.206\n",
            "5736/15750 (epoch 18), train_loss = 2.293, time/batch = 0.203\n",
            "5737/15750 (epoch 18), train_loss = 2.319, time/batch = 0.204\n",
            "5738/15750 (epoch 18), train_loss = 2.372, time/batch = 0.197\n",
            "5739/15750 (epoch 18), train_loss = 2.455, time/batch = 0.203\n",
            "5740/15750 (epoch 18), train_loss = 2.384, time/batch = 0.198\n",
            "5741/15750 (epoch 18), train_loss = 2.374, time/batch = 0.208\n",
            "5742/15750 (epoch 18), train_loss = 2.280, time/batch = 0.206\n",
            "5743/15750 (epoch 18), train_loss = 2.372, time/batch = 0.210\n",
            "5744/15750 (epoch 18), train_loss = 2.473, time/batch = 0.217\n",
            "5745/15750 (epoch 18), train_loss = 2.412, time/batch = 0.214\n",
            "5746/15750 (epoch 18), train_loss = 2.400, time/batch = 0.202\n",
            "5747/15750 (epoch 18), train_loss = 2.407, time/batch = 0.210\n",
            "5748/15750 (epoch 18), train_loss = 2.415, time/batch = 0.215\n",
            "5749/15750 (epoch 18), train_loss = 2.410, time/batch = 0.216\n",
            "5750/15750 (epoch 18), train_loss = 2.314, time/batch = 0.210\n",
            "5751/15750 (epoch 18), train_loss = 2.421, time/batch = 0.206\n",
            "5752/15750 (epoch 18), train_loss = 2.348, time/batch = 0.204\n",
            "5753/15750 (epoch 18), train_loss = 2.411, time/batch = 0.206\n",
            "5754/15750 (epoch 18), train_loss = 2.481, time/batch = 0.211\n",
            "5755/15750 (epoch 18), train_loss = 2.493, time/batch = 0.203\n",
            "5756/15750 (epoch 18), train_loss = 2.329, time/batch = 0.203\n",
            "5757/15750 (epoch 18), train_loss = 2.362, time/batch = 0.206\n",
            "5758/15750 (epoch 18), train_loss = 2.386, time/batch = 0.207\n",
            "5759/15750 (epoch 18), train_loss = 2.375, time/batch = 0.205\n",
            "5760/15750 (epoch 18), train_loss = 2.386, time/batch = 0.214\n",
            "5761/15750 (epoch 18), train_loss = 2.440, time/batch = 0.207\n",
            "5762/15750 (epoch 18), train_loss = 2.434, time/batch = 0.205\n",
            "5763/15750 (epoch 18), train_loss = 2.449, time/batch = 0.211\n",
            "5764/15750 (epoch 18), train_loss = 2.511, time/batch = 0.224\n",
            "5765/15750 (epoch 18), train_loss = 2.406, time/batch = 0.214\n",
            "5766/15750 (epoch 18), train_loss = 2.430, time/batch = 0.208\n",
            "5767/15750 (epoch 18), train_loss = 2.441, time/batch = 0.206\n",
            "5768/15750 (epoch 18), train_loss = 2.440, time/batch = 0.208\n",
            "5769/15750 (epoch 18), train_loss = 2.456, time/batch = 0.221\n",
            "5770/15750 (epoch 18), train_loss = 2.431, time/batch = 0.199\n",
            "5771/15750 (epoch 18), train_loss = 2.352, time/batch = 0.209\n",
            "5772/15750 (epoch 18), train_loss = 2.382, time/batch = 0.207\n",
            "5773/15750 (epoch 18), train_loss = 2.507, time/batch = 0.212\n",
            "5774/15750 (epoch 18), train_loss = 2.438, time/batch = 0.214\n",
            "5775/15750 (epoch 18), train_loss = 2.356, time/batch = 0.204\n",
            "5776/15750 (epoch 18), train_loss = 2.415, time/batch = 0.214\n",
            "5777/15750 (epoch 18), train_loss = 2.427, time/batch = 0.212\n",
            "5778/15750 (epoch 18), train_loss = 2.481, time/batch = 0.209\n",
            "5779/15750 (epoch 18), train_loss = 2.499, time/batch = 0.197\n",
            "5780/15750 (epoch 18), train_loss = 2.543, time/batch = 0.205\n",
            "5781/15750 (epoch 18), train_loss = 2.424, time/batch = 0.205\n",
            "5782/15750 (epoch 18), train_loss = 2.408, time/batch = 0.207\n",
            "5783/15750 (epoch 18), train_loss = 2.424, time/batch = 0.205\n",
            "5784/15750 (epoch 18), train_loss = 2.439, time/batch = 0.200\n",
            "5785/15750 (epoch 18), train_loss = 2.508, time/batch = 0.209\n",
            "5786/15750 (epoch 18), train_loss = 2.433, time/batch = 0.198\n",
            "5787/15750 (epoch 18), train_loss = 2.564, time/batch = 0.202\n",
            "5788/15750 (epoch 18), train_loss = 2.435, time/batch = 0.206\n",
            "5789/15750 (epoch 18), train_loss = 2.409, time/batch = 0.205\n",
            "5790/15750 (epoch 18), train_loss = 2.394, time/batch = 0.206\n",
            "5791/15750 (epoch 18), train_loss = 2.372, time/batch = 0.205\n",
            "5792/15750 (epoch 18), train_loss = 2.409, time/batch = 0.208\n",
            "5793/15750 (epoch 18), train_loss = 2.381, time/batch = 0.200\n",
            "5794/15750 (epoch 18), train_loss = 2.408, time/batch = 0.204\n",
            "5795/15750 (epoch 18), train_loss = 2.423, time/batch = 0.202\n",
            "5796/15750 (epoch 18), train_loss = 2.514, time/batch = 0.206\n",
            "5797/15750 (epoch 18), train_loss = 2.376, time/batch = 0.209\n",
            "5798/15750 (epoch 18), train_loss = 2.386, time/batch = 0.208\n",
            "5799/15750 (epoch 18), train_loss = 2.385, time/batch = 0.203\n",
            "5800/15750 (epoch 18), train_loss = 2.323, time/batch = 0.209\n",
            "5801/15750 (epoch 18), train_loss = 2.333, time/batch = 0.205\n",
            "5802/15750 (epoch 18), train_loss = 2.348, time/batch = 0.204\n",
            "5803/15750 (epoch 18), train_loss = 2.352, time/batch = 0.205\n",
            "5804/15750 (epoch 18), train_loss = 2.390, time/batch = 0.200\n",
            "5805/15750 (epoch 18), train_loss = 2.509, time/batch = 0.207\n",
            "5806/15750 (epoch 18), train_loss = 2.466, time/batch = 0.204\n",
            "5807/15750 (epoch 18), train_loss = 2.473, time/batch = 0.202\n",
            "5808/15750 (epoch 18), train_loss = 2.463, time/batch = 0.205\n",
            "5809/15750 (epoch 18), train_loss = 2.391, time/batch = 0.198\n",
            "5810/15750 (epoch 18), train_loss = 2.389, time/batch = 0.201\n",
            "5811/15750 (epoch 18), train_loss = 2.469, time/batch = 0.207\n",
            "5812/15750 (epoch 18), train_loss = 2.489, time/batch = 0.203\n",
            "5813/15750 (epoch 18), train_loss = 2.482, time/batch = 0.204\n",
            "5814/15750 (epoch 18), train_loss = 2.400, time/batch = 0.205\n",
            "5815/15750 (epoch 18), train_loss = 2.394, time/batch = 0.202\n",
            "5816/15750 (epoch 18), train_loss = 2.343, time/batch = 0.204\n",
            "5817/15750 (epoch 18), train_loss = 2.430, time/batch = 0.203\n",
            "5818/15750 (epoch 18), train_loss = 2.459, time/batch = 0.202\n",
            "5819/15750 (epoch 18), train_loss = 2.406, time/batch = 0.210\n",
            "5820/15750 (epoch 18), train_loss = 2.409, time/batch = 0.199\n",
            "5821/15750 (epoch 18), train_loss = 2.448, time/batch = 0.202\n",
            "5822/15750 (epoch 18), train_loss = 2.510, time/batch = 0.203\n",
            "5823/15750 (epoch 18), train_loss = 2.453, time/batch = 0.204\n",
            "5824/15750 (epoch 18), train_loss = 2.460, time/batch = 0.215\n",
            "5825/15750 (epoch 18), train_loss = 2.445, time/batch = 0.204\n",
            "5826/15750 (epoch 18), train_loss = 2.451, time/batch = 0.200\n",
            "5827/15750 (epoch 18), train_loss = 2.435, time/batch = 0.196\n",
            "5828/15750 (epoch 18), train_loss = 2.532, time/batch = 0.200\n",
            "5829/15750 (epoch 18), train_loss = 2.386, time/batch = 0.197\n",
            "5830/15750 (epoch 18), train_loss = 2.459, time/batch = 0.210\n",
            "5831/15750 (epoch 18), train_loss = 2.455, time/batch = 0.206\n",
            "5832/15750 (epoch 18), train_loss = 2.484, time/batch = 0.198\n",
            "5833/15750 (epoch 18), train_loss = 2.565, time/batch = 0.200\n",
            "5834/15750 (epoch 18), train_loss = 2.479, time/batch = 0.206\n",
            "5835/15750 (epoch 18), train_loss = 2.485, time/batch = 0.200\n",
            "5836/15750 (epoch 18), train_loss = 2.470, time/batch = 0.202\n",
            "5837/15750 (epoch 18), train_loss = 2.425, time/batch = 0.197\n",
            "5838/15750 (epoch 18), train_loss = 2.391, time/batch = 0.203\n",
            "5839/15750 (epoch 18), train_loss = 2.387, time/batch = 0.208\n",
            "5840/15750 (epoch 18), train_loss = 2.438, time/batch = 0.200\n",
            "5841/15750 (epoch 18), train_loss = 2.480, time/batch = 0.203\n",
            "5842/15750 (epoch 18), train_loss = 2.431, time/batch = 0.207\n",
            "5843/15750 (epoch 18), train_loss = 2.483, time/batch = 0.202\n",
            "5844/15750 (epoch 18), train_loss = 2.444, time/batch = 0.210\n",
            "5845/15750 (epoch 18), train_loss = 2.364, time/batch = 0.204\n",
            "5846/15750 (epoch 18), train_loss = 2.399, time/batch = 0.200\n",
            "5847/15750 (epoch 18), train_loss = 2.453, time/batch = 0.204\n",
            "5848/15750 (epoch 18), train_loss = 2.384, time/batch = 0.204\n",
            "5849/15750 (epoch 18), train_loss = 2.354, time/batch = 0.212\n",
            "5850/15750 (epoch 18), train_loss = 2.376, time/batch = 0.208\n",
            "5851/15750 (epoch 18), train_loss = 2.472, time/batch = 0.208\n",
            "5852/15750 (epoch 18), train_loss = 2.424, time/batch = 0.208\n",
            "5853/15750 (epoch 18), train_loss = 2.494, time/batch = 0.207\n",
            "5854/15750 (epoch 18), train_loss = 2.494, time/batch = 0.204\n",
            "5855/15750 (epoch 18), train_loss = 2.412, time/batch = 0.203\n",
            "5856/15750 (epoch 18), train_loss = 2.381, time/batch = 0.207\n",
            "5857/15750 (epoch 18), train_loss = 2.456, time/batch = 0.212\n",
            "5858/15750 (epoch 18), train_loss = 2.499, time/batch = 0.203\n",
            "5859/15750 (epoch 18), train_loss = 2.569, time/batch = 0.207\n",
            "5860/15750 (epoch 18), train_loss = 2.516, time/batch = 0.203\n",
            "5861/15750 (epoch 18), train_loss = 2.440, time/batch = 0.210\n",
            "5862/15750 (epoch 18), train_loss = 2.452, time/batch = 0.199\n",
            "5863/15750 (epoch 18), train_loss = 2.383, time/batch = 0.208\n",
            "5864/15750 (epoch 18), train_loss = 2.497, time/batch = 0.208\n",
            "5865/15750 (epoch 18), train_loss = 2.498, time/batch = 0.214\n",
            "5866/15750 (epoch 18), train_loss = 2.433, time/batch = 0.206\n",
            "5867/15750 (epoch 18), train_loss = 2.385, time/batch = 0.210\n",
            "5868/15750 (epoch 18), train_loss = 2.477, time/batch = 0.209\n",
            "5869/15750 (epoch 18), train_loss = 2.286, time/batch = 0.205\n",
            "5870/15750 (epoch 18), train_loss = 2.382, time/batch = 0.207\n",
            "5871/15750 (epoch 18), train_loss = 2.347, time/batch = 0.206\n",
            "5872/15750 (epoch 18), train_loss = 2.427, time/batch = 0.202\n",
            "5873/15750 (epoch 18), train_loss = 2.399, time/batch = 0.210\n",
            "5874/15750 (epoch 18), train_loss = 2.461, time/batch = 0.200\n",
            "5875/15750 (epoch 18), train_loss = 2.426, time/batch = 0.203\n",
            "5876/15750 (epoch 18), train_loss = 2.291, time/batch = 0.209\n",
            "5877/15750 (epoch 18), train_loss = 2.370, time/batch = 0.205\n",
            "5878/15750 (epoch 18), train_loss = 2.375, time/batch = 0.203\n",
            "5879/15750 (epoch 18), train_loss = 2.428, time/batch = 0.200\n",
            "5880/15750 (epoch 18), train_loss = 2.302, time/batch = 0.209\n",
            "5881/15750 (epoch 18), train_loss = 2.392, time/batch = 0.207\n",
            "5882/15750 (epoch 18), train_loss = 2.278, time/batch = 0.207\n",
            "5883/15750 (epoch 18), train_loss = 2.346, time/batch = 0.202\n",
            "5884/15750 (epoch 18), train_loss = 2.346, time/batch = 0.197\n",
            "5885/15750 (epoch 18), train_loss = 2.342, time/batch = 0.205\n",
            "5886/15750 (epoch 18), train_loss = 2.494, time/batch = 0.209\n",
            "5887/15750 (epoch 18), train_loss = 2.304, time/batch = 0.219\n",
            "5888/15750 (epoch 18), train_loss = 2.551, time/batch = 0.213\n",
            "5889/15750 (epoch 18), train_loss = 2.410, time/batch = 0.195\n",
            "5890/15750 (epoch 18), train_loss = 2.297, time/batch = 0.208\n",
            "5891/15750 (epoch 18), train_loss = 2.344, time/batch = 0.206\n",
            "5892/15750 (epoch 18), train_loss = 2.401, time/batch = 0.206\n",
            "5893/15750 (epoch 18), train_loss = 2.393, time/batch = 0.203\n",
            "5894/15750 (epoch 18), train_loss = 2.376, time/batch = 0.201\n",
            "5895/15750 (epoch 18), train_loss = 2.375, time/batch = 0.206\n",
            "5896/15750 (epoch 18), train_loss = 2.456, time/batch = 0.202\n",
            "5897/15750 (epoch 18), train_loss = 2.368, time/batch = 0.208\n",
            "5898/15750 (epoch 18), train_loss = 2.411, time/batch = 0.205\n",
            "5899/15750 (epoch 18), train_loss = 2.490, time/batch = 0.201\n",
            "5900/15750 (epoch 18), train_loss = 2.342, time/batch = 0.210\n",
            "5901/15750 (epoch 18), train_loss = 2.363, time/batch = 0.209\n",
            "5902/15750 (epoch 18), train_loss = 2.408, time/batch = 0.202\n",
            "5903/15750 (epoch 18), train_loss = 2.410, time/batch = 0.204\n",
            "5904/15750 (epoch 18), train_loss = 2.348, time/batch = 0.205\n",
            "5905/15750 (epoch 18), train_loss = 2.349, time/batch = 0.209\n",
            "5906/15750 (epoch 18), train_loss = 2.317, time/batch = 0.202\n",
            "5907/15750 (epoch 18), train_loss = 2.385, time/batch = 0.208\n",
            "5908/15750 (epoch 18), train_loss = 2.592, time/batch = 0.207\n",
            "5909/15750 (epoch 18), train_loss = 2.399, time/batch = 0.201\n",
            "5910/15750 (epoch 18), train_loss = 2.456, time/batch = 0.203\n",
            "5911/15750 (epoch 18), train_loss = 2.330, time/batch = 0.203\n",
            "5912/15750 (epoch 18), train_loss = 2.398, time/batch = 0.202\n",
            "5913/15750 (epoch 18), train_loss = 2.414, time/batch = 0.200\n",
            "5914/15750 (epoch 18), train_loss = 2.408, time/batch = 0.197\n",
            "5915/15750 (epoch 18), train_loss = 2.468, time/batch = 0.201\n",
            "5916/15750 (epoch 18), train_loss = 2.437, time/batch = 0.212\n",
            "5917/15750 (epoch 18), train_loss = 2.427, time/batch = 0.206\n",
            "5918/15750 (epoch 18), train_loss = 2.413, time/batch = 0.203\n",
            "5919/15750 (epoch 18), train_loss = 2.441, time/batch = 0.197\n",
            "5920/15750 (epoch 18), train_loss = 2.343, time/batch = 0.207\n",
            "5921/15750 (epoch 18), train_loss = 2.340, time/batch = 0.202\n",
            "5922/15750 (epoch 18), train_loss = 2.419, time/batch = 0.203\n",
            "5923/15750 (epoch 18), train_loss = 2.427, time/batch = 0.202\n",
            "5924/15750 (epoch 18), train_loss = 2.397, time/batch = 0.203\n",
            "5925/15750 (epoch 18), train_loss = 2.373, time/batch = 0.202\n",
            "5926/15750 (epoch 18), train_loss = 2.323, time/batch = 0.202\n",
            "5927/15750 (epoch 18), train_loss = 2.337, time/batch = 0.200\n",
            "5928/15750 (epoch 18), train_loss = 2.508, time/batch = 0.205\n",
            "5929/15750 (epoch 18), train_loss = 2.465, time/batch = 0.208\n",
            "5930/15750 (epoch 18), train_loss = 2.441, time/batch = 0.202\n",
            "5931/15750 (epoch 18), train_loss = 2.384, time/batch = 0.198\n",
            "5932/15750 (epoch 18), train_loss = 2.419, time/batch = 0.197\n",
            "5933/15750 (epoch 18), train_loss = 2.393, time/batch = 0.204\n",
            "5934/15750 (epoch 18), train_loss = 2.445, time/batch = 0.210\n",
            "5935/15750 (epoch 18), train_loss = 2.485, time/batch = 0.201\n",
            "5936/15750 (epoch 18), train_loss = 2.497, time/batch = 0.205\n",
            "5937/15750 (epoch 18), train_loss = 2.408, time/batch = 0.203\n",
            "5938/15750 (epoch 18), train_loss = 2.448, time/batch = 0.207\n",
            "5939/15750 (epoch 18), train_loss = 2.468, time/batch = 0.213\n",
            "5940/15750 (epoch 18), train_loss = 2.456, time/batch = 0.205\n",
            "5941/15750 (epoch 18), train_loss = 2.352, time/batch = 0.209\n",
            "5942/15750 (epoch 18), train_loss = 2.394, time/batch = 0.207\n",
            "5943/15750 (epoch 18), train_loss = 2.455, time/batch = 0.207\n",
            "5944/15750 (epoch 18), train_loss = 2.477, time/batch = 0.207\n",
            "5945/15750 (epoch 18), train_loss = 2.435, time/batch = 0.203\n",
            "5946/15750 (epoch 18), train_loss = 2.487, time/batch = 0.204\n",
            "5947/15750 (epoch 18), train_loss = 2.415, time/batch = 0.207\n",
            "5948/15750 (epoch 18), train_loss = 2.368, time/batch = 0.202\n",
            "5949/15750 (epoch 18), train_loss = 2.326, time/batch = 0.211\n",
            "5950/15750 (epoch 18), train_loss = 2.572, time/batch = 0.211\n",
            "5951/15750 (epoch 18), train_loss = 2.396, time/batch = 0.202\n",
            "5952/15750 (epoch 18), train_loss = 2.355, time/batch = 0.204\n",
            "5953/15750 (epoch 18), train_loss = 2.481, time/batch = 0.205\n",
            "5954/15750 (epoch 18), train_loss = 2.365, time/batch = 0.206\n",
            "5955/15750 (epoch 18), train_loss = 2.515, time/batch = 0.201\n",
            "5956/15750 (epoch 18), train_loss = 2.387, time/batch = 0.203\n",
            "5957/15750 (epoch 18), train_loss = 2.405, time/batch = 0.204\n",
            "5958/15750 (epoch 18), train_loss = 2.326, time/batch = 0.199\n",
            "5959/15750 (epoch 18), train_loss = 2.417, time/batch = 0.209\n",
            "5960/15750 (epoch 18), train_loss = 2.346, time/batch = 0.200\n",
            "5961/15750 (epoch 18), train_loss = 2.432, time/batch = 0.198\n",
            "5962/15750 (epoch 18), train_loss = 2.424, time/batch = 0.203\n",
            "5963/15750 (epoch 18), train_loss = 2.389, time/batch = 0.201\n",
            "5964/15750 (epoch 18), train_loss = 2.439, time/batch = 0.207\n",
            "5965/15750 (epoch 18), train_loss = 2.521, time/batch = 0.197\n",
            "5966/15750 (epoch 18), train_loss = 2.476, time/batch = 0.205\n",
            "5967/15750 (epoch 18), train_loss = 2.492, time/batch = 0.194\n",
            "5968/15750 (epoch 18), train_loss = 2.353, time/batch = 0.203\n",
            "5969/15750 (epoch 18), train_loss = 2.437, time/batch = 0.210\n",
            "5970/15750 (epoch 18), train_loss = 2.422, time/batch = 0.198\n",
            "5971/15750 (epoch 18), train_loss = 2.336, time/batch = 0.200\n",
            "5972/15750 (epoch 18), train_loss = 2.467, time/batch = 0.200\n",
            "5973/15750 (epoch 18), train_loss = 2.325, time/batch = 0.206\n",
            "5974/15750 (epoch 18), train_loss = 2.463, time/batch = 0.200\n",
            "5975/15750 (epoch 18), train_loss = 2.408, time/batch = 0.202\n",
            "5976/15750 (epoch 18), train_loss = 2.384, time/batch = 0.206\n",
            "5977/15750 (epoch 18), train_loss = 2.330, time/batch = 0.198\n",
            "5978/15750 (epoch 18), train_loss = 2.356, time/batch = 0.204\n",
            "5979/15750 (epoch 18), train_loss = 2.487, time/batch = 0.205\n",
            "5980/15750 (epoch 18), train_loss = 2.334, time/batch = 0.196\n",
            "5981/15750 (epoch 18), train_loss = 2.316, time/batch = 0.201\n",
            "5982/15750 (epoch 18), train_loss = 2.368, time/batch = 0.203\n",
            "5983/15750 (epoch 18), train_loss = 2.356, time/batch = 0.198\n",
            "5984/15750 (epoch 18), train_loss = 2.464, time/batch = 0.204\n",
            "5985/15750 (epoch 19), train_loss = 2.451, time/batch = 0.201\n",
            "5986/15750 (epoch 19), train_loss = 2.471, time/batch = 0.206\n",
            "5987/15750 (epoch 19), train_loss = 2.408, time/batch = 0.206\n",
            "5988/15750 (epoch 19), train_loss = 2.495, time/batch = 0.207\n",
            "5989/15750 (epoch 19), train_loss = 2.422, time/batch = 0.201\n",
            "5990/15750 (epoch 19), train_loss = 2.412, time/batch = 0.204\n",
            "5991/15750 (epoch 19), train_loss = 2.582, time/batch = 0.203\n",
            "5992/15750 (epoch 19), train_loss = 2.491, time/batch = 0.202\n",
            "5993/15750 (epoch 19), train_loss = 2.476, time/batch = 0.206\n",
            "5994/15750 (epoch 19), train_loss = 2.425, time/batch = 0.199\n",
            "5995/15750 (epoch 19), train_loss = 2.424, time/batch = 0.200\n",
            "5996/15750 (epoch 19), train_loss = 2.376, time/batch = 0.205\n",
            "5997/15750 (epoch 19), train_loss = 2.477, time/batch = 0.205\n",
            "5998/15750 (epoch 19), train_loss = 2.442, time/batch = 0.206\n",
            "5999/15750 (epoch 19), train_loss = 2.430, time/batch = 0.197\n",
            "6000/15750 (epoch 19), train_loss = 2.448, time/batch = 0.202\n",
            "model saved to ./save_star/model.ckpt\n",
            "6001/15750 (epoch 19), train_loss = 2.464, time/batch = 0.204\n",
            "6002/15750 (epoch 19), train_loss = 2.520, time/batch = 0.199\n",
            "6003/15750 (epoch 19), train_loss = 2.525, time/batch = 0.210\n",
            "6004/15750 (epoch 19), train_loss = 2.469, time/batch = 0.209\n",
            "6005/15750 (epoch 19), train_loss = 2.466, time/batch = 0.205\n",
            "6006/15750 (epoch 19), train_loss = 2.479, time/batch = 0.203\n",
            "6007/15750 (epoch 19), train_loss = 2.428, time/batch = 0.198\n",
            "6008/15750 (epoch 19), train_loss = 2.488, time/batch = 0.210\n",
            "6009/15750 (epoch 19), train_loss = 2.483, time/batch = 0.205\n",
            "6010/15750 (epoch 19), train_loss = 2.510, time/batch = 0.205\n",
            "6011/15750 (epoch 19), train_loss = 2.508, time/batch = 0.206\n",
            "6012/15750 (epoch 19), train_loss = 2.500, time/batch = 0.204\n",
            "6013/15750 (epoch 19), train_loss = 2.617, time/batch = 0.204\n",
            "6014/15750 (epoch 19), train_loss = 2.526, time/batch = 0.201\n",
            "6015/15750 (epoch 19), train_loss = 2.485, time/batch = 0.207\n",
            "6016/15750 (epoch 19), train_loss = 2.456, time/batch = 0.210\n",
            "6017/15750 (epoch 19), train_loss = 2.364, time/batch = 0.201\n",
            "6018/15750 (epoch 19), train_loss = 2.389, time/batch = 0.208\n",
            "6019/15750 (epoch 19), train_loss = 2.469, time/batch = 0.203\n",
            "6020/15750 (epoch 19), train_loss = 2.376, time/batch = 0.205\n",
            "6021/15750 (epoch 19), train_loss = 2.422, time/batch = 0.206\n",
            "6022/15750 (epoch 19), train_loss = 2.491, time/batch = 0.199\n",
            "6023/15750 (epoch 19), train_loss = 2.400, time/batch = 0.207\n",
            "6024/15750 (epoch 19), train_loss = 2.450, time/batch = 0.201\n",
            "6025/15750 (epoch 19), train_loss = 2.410, time/batch = 0.199\n",
            "6026/15750 (epoch 19), train_loss = 2.461, time/batch = 0.200\n",
            "6027/15750 (epoch 19), train_loss = 2.454, time/batch = 0.195\n",
            "6028/15750 (epoch 19), train_loss = 2.410, time/batch = 0.203\n",
            "6029/15750 (epoch 19), train_loss = 2.455, time/batch = 0.204\n",
            "6030/15750 (epoch 19), train_loss = 2.363, time/batch = 0.202\n",
            "6031/15750 (epoch 19), train_loss = 2.407, time/batch = 0.201\n",
            "6032/15750 (epoch 19), train_loss = 2.441, time/batch = 0.206\n",
            "6033/15750 (epoch 19), train_loss = 2.478, time/batch = 0.203\n",
            "6034/15750 (epoch 19), train_loss = 2.372, time/batch = 0.195\n",
            "6035/15750 (epoch 19), train_loss = 2.421, time/batch = 0.205\n",
            "6036/15750 (epoch 19), train_loss = 2.378, time/batch = 0.204\n",
            "6037/15750 (epoch 19), train_loss = 2.440, time/batch = 0.211\n",
            "6038/15750 (epoch 19), train_loss = 2.447, time/batch = 0.201\n",
            "6039/15750 (epoch 19), train_loss = 2.445, time/batch = 0.201\n",
            "6040/15750 (epoch 19), train_loss = 2.484, time/batch = 0.200\n",
            "6041/15750 (epoch 19), train_loss = 2.356, time/batch = 0.199\n",
            "6042/15750 (epoch 19), train_loss = 2.366, time/batch = 0.213\n",
            "6043/15750 (epoch 19), train_loss = 2.448, time/batch = 0.203\n",
            "6044/15750 (epoch 19), train_loss = 2.305, time/batch = 0.213\n",
            "6045/15750 (epoch 19), train_loss = 2.416, time/batch = 0.204\n",
            "6046/15750 (epoch 19), train_loss = 2.422, time/batch = 0.202\n",
            "6047/15750 (epoch 19), train_loss = 2.348, time/batch = 0.209\n",
            "6048/15750 (epoch 19), train_loss = 2.397, time/batch = 0.212\n",
            "6049/15750 (epoch 19), train_loss = 2.321, time/batch = 0.203\n",
            "6050/15750 (epoch 19), train_loss = 2.332, time/batch = 0.203\n",
            "6051/15750 (epoch 19), train_loss = 2.278, time/batch = 0.206\n",
            "6052/15750 (epoch 19), train_loss = 2.303, time/batch = 0.215\n",
            "6053/15750 (epoch 19), train_loss = 2.356, time/batch = 0.203\n",
            "6054/15750 (epoch 19), train_loss = 2.439, time/batch = 0.203\n",
            "6055/15750 (epoch 19), train_loss = 2.369, time/batch = 0.207\n",
            "6056/15750 (epoch 19), train_loss = 2.358, time/batch = 0.204\n",
            "6057/15750 (epoch 19), train_loss = 2.265, time/batch = 0.216\n",
            "6058/15750 (epoch 19), train_loss = 2.356, time/batch = 0.202\n",
            "6059/15750 (epoch 19), train_loss = 2.457, time/batch = 0.205\n",
            "6060/15750 (epoch 19), train_loss = 2.396, time/batch = 0.199\n",
            "6061/15750 (epoch 19), train_loss = 2.385, time/batch = 0.208\n",
            "6062/15750 (epoch 19), train_loss = 2.392, time/batch = 0.214\n",
            "6063/15750 (epoch 19), train_loss = 2.399, time/batch = 0.199\n",
            "6064/15750 (epoch 19), train_loss = 2.393, time/batch = 0.209\n",
            "6065/15750 (epoch 19), train_loss = 2.298, time/batch = 0.198\n",
            "6066/15750 (epoch 19), train_loss = 2.404, time/batch = 0.206\n",
            "6067/15750 (epoch 19), train_loss = 2.333, time/batch = 0.208\n",
            "6068/15750 (epoch 19), train_loss = 2.395, time/batch = 0.203\n",
            "6069/15750 (epoch 19), train_loss = 2.463, time/batch = 0.209\n",
            "6070/15750 (epoch 19), train_loss = 2.477, time/batch = 0.202\n",
            "6071/15750 (epoch 19), train_loss = 2.312, time/batch = 0.204\n",
            "6072/15750 (epoch 19), train_loss = 2.345, time/batch = 0.212\n",
            "6073/15750 (epoch 19), train_loss = 2.368, time/batch = 0.204\n",
            "6074/15750 (epoch 19), train_loss = 2.360, time/batch = 0.208\n",
            "6075/15750 (epoch 19), train_loss = 2.371, time/batch = 0.204\n",
            "6076/15750 (epoch 19), train_loss = 2.424, time/batch = 0.202\n",
            "6077/15750 (epoch 19), train_loss = 2.417, time/batch = 0.219\n",
            "6078/15750 (epoch 19), train_loss = 2.432, time/batch = 0.206\n",
            "6079/15750 (epoch 19), train_loss = 2.495, time/batch = 0.210\n",
            "6080/15750 (epoch 19), train_loss = 2.389, time/batch = 0.208\n",
            "6081/15750 (epoch 19), train_loss = 2.415, time/batch = 0.203\n",
            "6082/15750 (epoch 19), train_loss = 2.426, time/batch = 0.208\n",
            "6083/15750 (epoch 19), train_loss = 2.424, time/batch = 0.203\n",
            "6084/15750 (epoch 19), train_loss = 2.439, time/batch = 0.204\n",
            "6085/15750 (epoch 19), train_loss = 2.415, time/batch = 0.203\n",
            "6086/15750 (epoch 19), train_loss = 2.338, time/batch = 0.202\n",
            "6087/15750 (epoch 19), train_loss = 2.367, time/batch = 0.212\n",
            "6088/15750 (epoch 19), train_loss = 2.492, time/batch = 0.201\n",
            "6089/15750 (epoch 19), train_loss = 2.422, time/batch = 0.198\n",
            "6090/15750 (epoch 19), train_loss = 2.339, time/batch = 0.199\n",
            "6091/15750 (epoch 19), train_loss = 2.399, time/batch = 0.202\n",
            "6092/15750 (epoch 19), train_loss = 2.411, time/batch = 0.208\n",
            "6093/15750 (epoch 19), train_loss = 2.464, time/batch = 0.198\n",
            "6094/15750 (epoch 19), train_loss = 2.483, time/batch = 0.202\n",
            "6095/15750 (epoch 19), train_loss = 2.528, time/batch = 0.205\n",
            "6096/15750 (epoch 19), train_loss = 2.407, time/batch = 0.199\n",
            "6097/15750 (epoch 19), train_loss = 2.392, time/batch = 0.202\n",
            "6098/15750 (epoch 19), train_loss = 2.408, time/batch = 0.208\n",
            "6099/15750 (epoch 19), train_loss = 2.424, time/batch = 0.207\n",
            "6100/15750 (epoch 19), train_loss = 2.492, time/batch = 0.204\n",
            "6101/15750 (epoch 19), train_loss = 2.417, time/batch = 0.204\n",
            "6102/15750 (epoch 19), train_loss = 2.548, time/batch = 0.211\n",
            "6103/15750 (epoch 19), train_loss = 2.420, time/batch = 0.207\n",
            "6104/15750 (epoch 19), train_loss = 2.394, time/batch = 0.211\n",
            "6105/15750 (epoch 19), train_loss = 2.378, time/batch = 0.203\n",
            "6106/15750 (epoch 19), train_loss = 2.357, time/batch = 0.207\n",
            "6107/15750 (epoch 19), train_loss = 2.394, time/batch = 0.209\n",
            "6108/15750 (epoch 19), train_loss = 2.365, time/batch = 0.210\n",
            "6109/15750 (epoch 19), train_loss = 2.392, time/batch = 0.205\n",
            "6110/15750 (epoch 19), train_loss = 2.408, time/batch = 0.206\n",
            "6111/15750 (epoch 19), train_loss = 2.498, time/batch = 0.203\n",
            "6112/15750 (epoch 19), train_loss = 2.362, time/batch = 0.223\n",
            "6113/15750 (epoch 19), train_loss = 2.373, time/batch = 0.202\n",
            "6114/15750 (epoch 19), train_loss = 2.370, time/batch = 0.200\n",
            "6115/15750 (epoch 19), train_loss = 2.307, time/batch = 0.202\n",
            "6116/15750 (epoch 19), train_loss = 2.317, time/batch = 0.203\n",
            "6117/15750 (epoch 19), train_loss = 2.332, time/batch = 0.207\n",
            "6118/15750 (epoch 19), train_loss = 2.338, time/batch = 0.206\n",
            "6119/15750 (epoch 19), train_loss = 2.375, time/batch = 0.201\n",
            "6120/15750 (epoch 19), train_loss = 2.495, time/batch = 0.194\n",
            "6121/15750 (epoch 19), train_loss = 2.451, time/batch = 0.206\n",
            "6122/15750 (epoch 19), train_loss = 2.457, time/batch = 0.210\n",
            "6123/15750 (epoch 19), train_loss = 2.448, time/batch = 0.203\n",
            "6124/15750 (epoch 19), train_loss = 2.376, time/batch = 0.201\n",
            "6125/15750 (epoch 19), train_loss = 2.374, time/batch = 0.200\n",
            "6126/15750 (epoch 19), train_loss = 2.455, time/batch = 0.200\n",
            "6127/15750 (epoch 19), train_loss = 2.475, time/batch = 0.208\n",
            "6128/15750 (epoch 19), train_loss = 2.467, time/batch = 0.204\n",
            "6129/15750 (epoch 19), train_loss = 2.383, time/batch = 0.204\n",
            "6130/15750 (epoch 19), train_loss = 2.378, time/batch = 0.199\n",
            "6131/15750 (epoch 19), train_loss = 2.329, time/batch = 0.205\n",
            "6132/15750 (epoch 19), train_loss = 2.416, time/batch = 0.209\n",
            "6133/15750 (epoch 19), train_loss = 2.444, time/batch = 0.209\n",
            "6134/15750 (epoch 19), train_loss = 2.391, time/batch = 0.205\n",
            "6135/15750 (epoch 19), train_loss = 2.395, time/batch = 0.205\n",
            "6136/15750 (epoch 19), train_loss = 2.434, time/batch = 0.204\n",
            "6137/15750 (epoch 19), train_loss = 2.492, time/batch = 0.212\n",
            "6138/15750 (epoch 19), train_loss = 2.437, time/batch = 0.204\n",
            "6139/15750 (epoch 19), train_loss = 2.445, time/batch = 0.206\n",
            "6140/15750 (epoch 19), train_loss = 2.430, time/batch = 0.207\n",
            "6141/15750 (epoch 19), train_loss = 2.435, time/batch = 0.204\n",
            "6142/15750 (epoch 19), train_loss = 2.420, time/batch = 0.216\n",
            "6143/15750 (epoch 19), train_loss = 2.516, time/batch = 0.209\n",
            "6144/15750 (epoch 19), train_loss = 2.371, time/batch = 0.206\n",
            "6145/15750 (epoch 19), train_loss = 2.444, time/batch = 0.210\n",
            "6146/15750 (epoch 19), train_loss = 2.440, time/batch = 0.204\n",
            "6147/15750 (epoch 19), train_loss = 2.467, time/batch = 0.215\n",
            "6148/15750 (epoch 19), train_loss = 2.549, time/batch = 0.204\n",
            "6149/15750 (epoch 19), train_loss = 2.463, time/batch = 0.205\n",
            "6150/15750 (epoch 19), train_loss = 2.468, time/batch = 0.199\n",
            "6151/15750 (epoch 19), train_loss = 2.453, time/batch = 0.207\n",
            "6152/15750 (epoch 19), train_loss = 2.409, time/batch = 0.209\n",
            "6153/15750 (epoch 19), train_loss = 2.375, time/batch = 0.203\n",
            "6154/15750 (epoch 19), train_loss = 2.372, time/batch = 0.203\n",
            "6155/15750 (epoch 19), train_loss = 2.421, time/batch = 0.206\n",
            "6156/15750 (epoch 19), train_loss = 2.462, time/batch = 0.209\n",
            "6157/15750 (epoch 19), train_loss = 2.416, time/batch = 0.213\n",
            "6158/15750 (epoch 19), train_loss = 2.469, time/batch = 0.204\n",
            "6159/15750 (epoch 19), train_loss = 2.428, time/batch = 0.206\n",
            "6160/15750 (epoch 19), train_loss = 2.350, time/batch = 0.200\n",
            "6161/15750 (epoch 19), train_loss = 2.384, time/batch = 0.203\n",
            "6162/15750 (epoch 19), train_loss = 2.436, time/batch = 0.217\n",
            "6163/15750 (epoch 19), train_loss = 2.369, time/batch = 0.201\n",
            "6164/15750 (epoch 19), train_loss = 2.338, time/batch = 0.207\n",
            "6165/15750 (epoch 19), train_loss = 2.362, time/batch = 0.205\n",
            "6166/15750 (epoch 19), train_loss = 2.455, time/batch = 0.204\n",
            "6167/15750 (epoch 19), train_loss = 2.410, time/batch = 0.212\n",
            "6168/15750 (epoch 19), train_loss = 2.478, time/batch = 0.206\n",
            "6169/15750 (epoch 19), train_loss = 2.479, time/batch = 0.201\n",
            "6170/15750 (epoch 19), train_loss = 2.399, time/batch = 0.207\n",
            "6171/15750 (epoch 19), train_loss = 2.367, time/batch = 0.203\n",
            "6172/15750 (epoch 19), train_loss = 2.442, time/batch = 0.208\n",
            "6173/15750 (epoch 19), train_loss = 2.482, time/batch = 0.208\n",
            "6174/15750 (epoch 19), train_loss = 2.552, time/batch = 0.199\n",
            "6175/15750 (epoch 19), train_loss = 2.502, time/batch = 0.207\n",
            "6176/15750 (epoch 19), train_loss = 2.425, time/batch = 0.208\n",
            "6177/15750 (epoch 19), train_loss = 2.438, time/batch = 0.213\n",
            "6178/15750 (epoch 19), train_loss = 2.368, time/batch = 0.210\n",
            "6179/15750 (epoch 19), train_loss = 2.483, time/batch = 0.210\n",
            "6180/15750 (epoch 19), train_loss = 2.481, time/batch = 0.205\n",
            "6181/15750 (epoch 19), train_loss = 2.419, time/batch = 0.204\n",
            "6182/15750 (epoch 19), train_loss = 2.370, time/batch = 0.204\n",
            "6183/15750 (epoch 19), train_loss = 2.463, time/batch = 0.207\n",
            "6184/15750 (epoch 19), train_loss = 2.269, time/batch = 0.201\n",
            "6185/15750 (epoch 19), train_loss = 2.368, time/batch = 0.204\n",
            "6186/15750 (epoch 19), train_loss = 2.332, time/batch = 0.210\n",
            "6187/15750 (epoch 19), train_loss = 2.410, time/batch = 0.201\n",
            "6188/15750 (epoch 19), train_loss = 2.384, time/batch = 0.207\n",
            "6189/15750 (epoch 19), train_loss = 2.446, time/batch = 0.204\n",
            "6190/15750 (epoch 19), train_loss = 2.409, time/batch = 0.204\n",
            "6191/15750 (epoch 19), train_loss = 2.275, time/batch = 0.211\n",
            "6192/15750 (epoch 19), train_loss = 2.354, time/batch = 0.214\n",
            "6193/15750 (epoch 19), train_loss = 2.359, time/batch = 0.208\n",
            "6194/15750 (epoch 19), train_loss = 2.413, time/batch = 0.204\n",
            "6195/15750 (epoch 19), train_loss = 2.288, time/batch = 0.209\n",
            "6196/15750 (epoch 19), train_loss = 2.378, time/batch = 0.211\n",
            "6197/15750 (epoch 19), train_loss = 2.263, time/batch = 0.198\n",
            "6198/15750 (epoch 19), train_loss = 2.331, time/batch = 0.213\n",
            "6199/15750 (epoch 19), train_loss = 2.331, time/batch = 0.216\n",
            "6200/15750 (epoch 19), train_loss = 2.327, time/batch = 0.211\n",
            "6201/15750 (epoch 19), train_loss = 2.478, time/batch = 0.213\n",
            "6202/15750 (epoch 19), train_loss = 2.289, time/batch = 0.208\n",
            "6203/15750 (epoch 19), train_loss = 2.536, time/batch = 0.211\n",
            "6204/15750 (epoch 19), train_loss = 2.396, time/batch = 0.211\n",
            "6205/15750 (epoch 19), train_loss = 2.282, time/batch = 0.208\n",
            "6206/15750 (epoch 19), train_loss = 2.328, time/batch = 0.210\n",
            "6207/15750 (epoch 19), train_loss = 2.385, time/batch = 0.201\n",
            "6208/15750 (epoch 19), train_loss = 2.376, time/batch = 0.207\n",
            "6209/15750 (epoch 19), train_loss = 2.361, time/batch = 0.205\n",
            "6210/15750 (epoch 19), train_loss = 2.360, time/batch = 0.202\n",
            "6211/15750 (epoch 19), train_loss = 2.440, time/batch = 0.213\n",
            "6212/15750 (epoch 19), train_loss = 2.353, time/batch = 0.207\n",
            "6213/15750 (epoch 19), train_loss = 2.395, time/batch = 0.213\n",
            "6214/15750 (epoch 19), train_loss = 2.475, time/batch = 0.211\n",
            "6215/15750 (epoch 19), train_loss = 2.326, time/batch = 0.214\n",
            "6216/15750 (epoch 19), train_loss = 2.348, time/batch = 0.214\n",
            "6217/15750 (epoch 19), train_loss = 2.392, time/batch = 0.207\n",
            "6218/15750 (epoch 19), train_loss = 2.393, time/batch = 0.206\n",
            "6219/15750 (epoch 19), train_loss = 2.334, time/batch = 0.209\n",
            "6220/15750 (epoch 19), train_loss = 2.334, time/batch = 0.206\n",
            "6221/15750 (epoch 19), train_loss = 2.302, time/batch = 0.209\n",
            "6222/15750 (epoch 19), train_loss = 2.369, time/batch = 0.209\n",
            "6223/15750 (epoch 19), train_loss = 2.578, time/batch = 0.203\n",
            "6224/15750 (epoch 19), train_loss = 2.385, time/batch = 0.207\n",
            "6225/15750 (epoch 19), train_loss = 2.440, time/batch = 0.200\n",
            "6226/15750 (epoch 19), train_loss = 2.314, time/batch = 0.204\n",
            "6227/15750 (epoch 19), train_loss = 2.381, time/batch = 0.204\n",
            "6228/15750 (epoch 19), train_loss = 2.400, time/batch = 0.206\n",
            "6229/15750 (epoch 19), train_loss = 2.394, time/batch = 0.207\n",
            "6230/15750 (epoch 19), train_loss = 2.453, time/batch = 0.210\n",
            "6231/15750 (epoch 19), train_loss = 2.422, time/batch = 0.211\n",
            "6232/15750 (epoch 19), train_loss = 2.412, time/batch = 0.204\n",
            "6233/15750 (epoch 19), train_loss = 2.398, time/batch = 0.207\n",
            "6234/15750 (epoch 19), train_loss = 2.427, time/batch = 0.209\n",
            "6235/15750 (epoch 19), train_loss = 2.327, time/batch = 0.207\n",
            "6236/15750 (epoch 19), train_loss = 2.323, time/batch = 0.213\n",
            "6237/15750 (epoch 19), train_loss = 2.403, time/batch = 0.206\n",
            "6238/15750 (epoch 19), train_loss = 2.412, time/batch = 0.207\n",
            "6239/15750 (epoch 19), train_loss = 2.382, time/batch = 0.212\n",
            "6240/15750 (epoch 19), train_loss = 2.358, time/batch = 0.209\n",
            "6241/15750 (epoch 19), train_loss = 2.306, time/batch = 0.217\n",
            "6242/15750 (epoch 19), train_loss = 2.321, time/batch = 0.205\n",
            "6243/15750 (epoch 19), train_loss = 2.491, time/batch = 0.211\n",
            "6244/15750 (epoch 19), train_loss = 2.451, time/batch = 0.210\n",
            "6245/15750 (epoch 19), train_loss = 2.425, time/batch = 0.208\n",
            "6246/15750 (epoch 19), train_loss = 2.369, time/batch = 0.210\n",
            "6247/15750 (epoch 19), train_loss = 2.403, time/batch = 0.206\n",
            "6248/15750 (epoch 19), train_loss = 2.378, time/batch = 0.212\n",
            "6249/15750 (epoch 19), train_loss = 2.427, time/batch = 0.207\n",
            "6250/15750 (epoch 19), train_loss = 2.469, time/batch = 0.207\n",
            "6251/15750 (epoch 19), train_loss = 2.480, time/batch = 0.208\n",
            "6252/15750 (epoch 19), train_loss = 2.392, time/batch = 0.212\n",
            "6253/15750 (epoch 19), train_loss = 2.433, time/batch = 0.209\n",
            "6254/15750 (epoch 19), train_loss = 2.452, time/batch = 0.204\n",
            "6255/15750 (epoch 19), train_loss = 2.441, time/batch = 0.215\n",
            "6256/15750 (epoch 19), train_loss = 2.338, time/batch = 0.202\n",
            "6257/15750 (epoch 19), train_loss = 2.378, time/batch = 0.198\n",
            "6258/15750 (epoch 19), train_loss = 2.440, time/batch = 0.205\n",
            "6259/15750 (epoch 19), train_loss = 2.462, time/batch = 0.205\n",
            "6260/15750 (epoch 19), train_loss = 2.419, time/batch = 0.215\n",
            "6261/15750 (epoch 19), train_loss = 2.471, time/batch = 0.207\n",
            "6262/15750 (epoch 19), train_loss = 2.400, time/batch = 0.208\n",
            "6263/15750 (epoch 19), train_loss = 2.354, time/batch = 0.205\n",
            "6264/15750 (epoch 19), train_loss = 2.311, time/batch = 0.202\n",
            "6265/15750 (epoch 19), train_loss = 2.556, time/batch = 0.207\n",
            "6266/15750 (epoch 19), train_loss = 2.380, time/batch = 0.212\n",
            "6267/15750 (epoch 19), train_loss = 2.340, time/batch = 0.198\n",
            "6268/15750 (epoch 19), train_loss = 2.464, time/batch = 0.210\n",
            "6269/15750 (epoch 19), train_loss = 2.351, time/batch = 0.215\n",
            "6270/15750 (epoch 19), train_loss = 2.500, time/batch = 0.210\n",
            "6271/15750 (epoch 19), train_loss = 2.373, time/batch = 0.210\n",
            "6272/15750 (epoch 19), train_loss = 2.390, time/batch = 0.205\n",
            "6273/15750 (epoch 19), train_loss = 2.311, time/batch = 0.205\n",
            "6274/15750 (epoch 19), train_loss = 2.403, time/batch = 0.205\n",
            "6275/15750 (epoch 19), train_loss = 2.332, time/batch = 0.212\n",
            "6276/15750 (epoch 19), train_loss = 2.417, time/batch = 0.212\n",
            "6277/15750 (epoch 19), train_loss = 2.408, time/batch = 0.204\n",
            "6278/15750 (epoch 19), train_loss = 2.374, time/batch = 0.207\n",
            "6279/15750 (epoch 19), train_loss = 2.423, time/batch = 0.206\n",
            "6280/15750 (epoch 19), train_loss = 2.506, time/batch = 0.211\n",
            "6281/15750 (epoch 19), train_loss = 2.460, time/batch = 0.205\n",
            "6282/15750 (epoch 19), train_loss = 2.476, time/batch = 0.204\n",
            "6283/15750 (epoch 19), train_loss = 2.339, time/batch = 0.209\n",
            "6284/15750 (epoch 19), train_loss = 2.421, time/batch = 0.210\n",
            "6285/15750 (epoch 19), train_loss = 2.408, time/batch = 0.210\n",
            "6286/15750 (epoch 19), train_loss = 2.322, time/batch = 0.207\n",
            "6287/15750 (epoch 19), train_loss = 2.454, time/batch = 0.210\n",
            "6288/15750 (epoch 19), train_loss = 2.311, time/batch = 0.207\n",
            "6289/15750 (epoch 19), train_loss = 2.448, time/batch = 0.215\n",
            "6290/15750 (epoch 19), train_loss = 2.393, time/batch = 0.210\n",
            "6291/15750 (epoch 19), train_loss = 2.368, time/batch = 0.207\n",
            "6292/15750 (epoch 19), train_loss = 2.316, time/batch = 0.207\n",
            "6293/15750 (epoch 19), train_loss = 2.341, time/batch = 0.207\n",
            "6294/15750 (epoch 19), train_loss = 2.472, time/batch = 0.205\n",
            "6295/15750 (epoch 19), train_loss = 2.320, time/batch = 0.212\n",
            "6296/15750 (epoch 19), train_loss = 2.303, time/batch = 0.203\n",
            "6297/15750 (epoch 19), train_loss = 2.352, time/batch = 0.216\n",
            "6298/15750 (epoch 19), train_loss = 2.342, time/batch = 0.209\n",
            "6299/15750 (epoch 19), train_loss = 2.449, time/batch = 0.204\n",
            "6300/15750 (epoch 20), train_loss = 2.420, time/batch = 0.207\n",
            "6301/15750 (epoch 20), train_loss = 2.456, time/batch = 0.204\n",
            "6302/15750 (epoch 20), train_loss = 2.393, time/batch = 0.211\n",
            "6303/15750 (epoch 20), train_loss = 2.478, time/batch = 0.204\n",
            "6304/15750 (epoch 20), train_loss = 2.406, time/batch = 0.206\n",
            "6305/15750 (epoch 20), train_loss = 2.396, time/batch = 0.209\n",
            "6306/15750 (epoch 20), train_loss = 2.566, time/batch = 0.207\n",
            "6307/15750 (epoch 20), train_loss = 2.475, time/batch = 0.199\n",
            "6308/15750 (epoch 20), train_loss = 2.462, time/batch = 0.204\n",
            "6309/15750 (epoch 20), train_loss = 2.409, time/batch = 0.201\n",
            "6310/15750 (epoch 20), train_loss = 2.411, time/batch = 0.205\n",
            "6311/15750 (epoch 20), train_loss = 2.363, time/batch = 0.204\n",
            "6312/15750 (epoch 20), train_loss = 2.461, time/batch = 0.209\n",
            "6313/15750 (epoch 20), train_loss = 2.428, time/batch = 0.210\n",
            "6314/15750 (epoch 20), train_loss = 2.415, time/batch = 0.207\n",
            "6315/15750 (epoch 20), train_loss = 2.435, time/batch = 0.213\n",
            "6316/15750 (epoch 20), train_loss = 2.448, time/batch = 0.204\n",
            "6317/15750 (epoch 20), train_loss = 2.504, time/batch = 0.209\n",
            "6318/15750 (epoch 20), train_loss = 2.511, time/batch = 0.218\n",
            "6319/15750 (epoch 20), train_loss = 2.455, time/batch = 0.206\n",
            "6320/15750 (epoch 20), train_loss = 2.451, time/batch = 0.204\n",
            "6321/15750 (epoch 20), train_loss = 2.464, time/batch = 0.208\n",
            "6322/15750 (epoch 20), train_loss = 2.413, time/batch = 0.211\n",
            "6323/15750 (epoch 20), train_loss = 2.472, time/batch = 0.212\n",
            "6324/15750 (epoch 20), train_loss = 2.468, time/batch = 0.203\n",
            "6325/15750 (epoch 20), train_loss = 2.496, time/batch = 0.200\n",
            "6326/15750 (epoch 20), train_loss = 2.495, time/batch = 0.205\n",
            "6327/15750 (epoch 20), train_loss = 2.487, time/batch = 0.208\n",
            "6328/15750 (epoch 20), train_loss = 2.601, time/batch = 0.203\n",
            "6329/15750 (epoch 20), train_loss = 2.510, time/batch = 0.200\n",
            "6330/15750 (epoch 20), train_loss = 2.470, time/batch = 0.195\n",
            "6331/15750 (epoch 20), train_loss = 2.440, time/batch = 0.203\n",
            "6332/15750 (epoch 20), train_loss = 2.349, time/batch = 0.200\n",
            "6333/15750 (epoch 20), train_loss = 2.373, time/batch = 0.205\n",
            "6334/15750 (epoch 20), train_loss = 2.454, time/batch = 0.199\n",
            "6335/15750 (epoch 20), train_loss = 2.361, time/batch = 0.203\n",
            "6336/15750 (epoch 20), train_loss = 2.410, time/batch = 0.204\n",
            "6337/15750 (epoch 20), train_loss = 2.477, time/batch = 0.204\n",
            "6338/15750 (epoch 20), train_loss = 2.386, time/batch = 0.207\n",
            "6339/15750 (epoch 20), train_loss = 2.435, time/batch = 0.197\n",
            "6340/15750 (epoch 20), train_loss = 2.393, time/batch = 0.202\n",
            "6341/15750 (epoch 20), train_loss = 2.445, time/batch = 0.212\n",
            "6342/15750 (epoch 20), train_loss = 2.439, time/batch = 0.205\n",
            "6343/15750 (epoch 20), train_loss = 2.397, time/batch = 0.212\n",
            "6344/15750 (epoch 20), train_loss = 2.439, time/batch = 0.200\n",
            "6345/15750 (epoch 20), train_loss = 2.350, time/batch = 0.208\n",
            "6346/15750 (epoch 20), train_loss = 2.393, time/batch = 0.212\n",
            "6347/15750 (epoch 20), train_loss = 2.426, time/batch = 0.205\n",
            "6348/15750 (epoch 20), train_loss = 2.463, time/batch = 0.212\n",
            "6349/15750 (epoch 20), train_loss = 2.355, time/batch = 0.211\n",
            "6350/15750 (epoch 20), train_loss = 2.407, time/batch = 0.206\n",
            "6351/15750 (epoch 20), train_loss = 2.363, time/batch = 0.213\n",
            "6352/15750 (epoch 20), train_loss = 2.425, time/batch = 0.206\n",
            "6353/15750 (epoch 20), train_loss = 2.433, time/batch = 0.211\n",
            "6354/15750 (epoch 20), train_loss = 2.431, time/batch = 0.208\n",
            "6355/15750 (epoch 20), train_loss = 2.468, time/batch = 0.208\n",
            "6356/15750 (epoch 20), train_loss = 2.342, time/batch = 0.206\n",
            "6357/15750 (epoch 20), train_loss = 2.352, time/batch = 0.199\n",
            "6358/15750 (epoch 20), train_loss = 2.434, time/batch = 0.209\n",
            "6359/15750 (epoch 20), train_loss = 2.293, time/batch = 0.208\n",
            "6360/15750 (epoch 20), train_loss = 2.401, time/batch = 0.198\n",
            "6361/15750 (epoch 20), train_loss = 2.408, time/batch = 0.203\n",
            "6362/15750 (epoch 20), train_loss = 2.334, time/batch = 0.207\n",
            "6363/15750 (epoch 20), train_loss = 2.385, time/batch = 0.210\n",
            "6364/15750 (epoch 20), train_loss = 2.306, time/batch = 0.208\n",
            "6365/15750 (epoch 20), train_loss = 2.318, time/batch = 0.206\n",
            "6366/15750 (epoch 20), train_loss = 2.264, time/batch = 0.203\n",
            "6367/15750 (epoch 20), train_loss = 2.288, time/batch = 0.208\n",
            "6368/15750 (epoch 20), train_loss = 2.342, time/batch = 0.214\n",
            "6369/15750 (epoch 20), train_loss = 2.425, time/batch = 0.211\n",
            "6370/15750 (epoch 20), train_loss = 2.355, time/batch = 0.206\n",
            "6371/15750 (epoch 20), train_loss = 2.343, time/batch = 0.208\n",
            "6372/15750 (epoch 20), train_loss = 2.251, time/batch = 0.204\n",
            "6373/15750 (epoch 20), train_loss = 2.341, time/batch = 0.211\n",
            "6374/15750 (epoch 20), train_loss = 2.443, time/batch = 0.208\n",
            "6375/15750 (epoch 20), train_loss = 2.380, time/batch = 0.206\n",
            "6376/15750 (epoch 20), train_loss = 2.371, time/batch = 0.202\n",
            "6377/15750 (epoch 20), train_loss = 2.377, time/batch = 0.202\n",
            "6378/15750 (epoch 20), train_loss = 2.384, time/batch = 0.210\n",
            "6379/15750 (epoch 20), train_loss = 2.378, time/batch = 0.202\n",
            "6380/15750 (epoch 20), train_loss = 2.283, time/batch = 0.202\n",
            "6381/15750 (epoch 20), train_loss = 2.388, time/batch = 0.200\n",
            "6382/15750 (epoch 20), train_loss = 2.319, time/batch = 0.205\n",
            "6383/15750 (epoch 20), train_loss = 2.381, time/batch = 0.209\n",
            "6384/15750 (epoch 20), train_loss = 2.446, time/batch = 0.200\n",
            "6385/15750 (epoch 20), train_loss = 2.462, time/batch = 0.206\n",
            "6386/15750 (epoch 20), train_loss = 2.296, time/batch = 0.197\n",
            "6387/15750 (epoch 20), train_loss = 2.330, time/batch = 0.201\n",
            "6388/15750 (epoch 20), train_loss = 2.351, time/batch = 0.207\n",
            "6389/15750 (epoch 20), train_loss = 2.346, time/batch = 0.201\n",
            "6390/15750 (epoch 20), train_loss = 2.356, time/batch = 0.203\n",
            "6391/15750 (epoch 20), train_loss = 2.409, time/batch = 0.207\n",
            "6392/15750 (epoch 20), train_loss = 2.402, time/batch = 0.205\n",
            "6393/15750 (epoch 20), train_loss = 2.417, time/batch = 0.207\n",
            "6394/15750 (epoch 20), train_loss = 2.480, time/batch = 0.210\n",
            "6395/15750 (epoch 20), train_loss = 2.373, time/batch = 0.212\n",
            "6396/15750 (epoch 20), train_loss = 2.400, time/batch = 0.202\n",
            "6397/15750 (epoch 20), train_loss = 2.413, time/batch = 0.208\n",
            "6398/15750 (epoch 20), train_loss = 2.410, time/batch = 0.214\n",
            "6399/15750 (epoch 20), train_loss = 2.424, time/batch = 0.210\n",
            "6400/15750 (epoch 20), train_loss = 2.400, time/batch = 0.202\n",
            "6401/15750 (epoch 20), train_loss = 2.325, time/batch = 0.203\n",
            "6402/15750 (epoch 20), train_loss = 2.353, time/batch = 0.211\n",
            "6403/15750 (epoch 20), train_loss = 2.478, time/batch = 0.221\n",
            "6404/15750 (epoch 20), train_loss = 2.407, time/batch = 0.211\n",
            "6405/15750 (epoch 20), train_loss = 2.323, time/batch = 0.209\n",
            "6406/15750 (epoch 20), train_loss = 2.383, time/batch = 0.203\n",
            "6407/15750 (epoch 20), train_loss = 2.397, time/batch = 0.208\n",
            "6408/15750 (epoch 20), train_loss = 2.448, time/batch = 0.213\n",
            "6409/15750 (epoch 20), train_loss = 2.468, time/batch = 0.208\n",
            "6410/15750 (epoch 20), train_loss = 2.514, time/batch = 0.208\n",
            "6411/15750 (epoch 20), train_loss = 2.392, time/batch = 0.208\n",
            "6412/15750 (epoch 20), train_loss = 2.377, time/batch = 0.205\n",
            "6413/15750 (epoch 20), train_loss = 2.393, time/batch = 0.213\n",
            "6414/15750 (epoch 20), train_loss = 2.409, time/batch = 0.208\n",
            "6415/15750 (epoch 20), train_loss = 2.478, time/batch = 0.207\n",
            "6416/15750 (epoch 20), train_loss = 2.402, time/batch = 0.211\n",
            "6417/15750 (epoch 20), train_loss = 2.532, time/batch = 0.203\n",
            "6418/15750 (epoch 20), train_loss = 2.407, time/batch = 0.208\n",
            "6419/15750 (epoch 20), train_loss = 2.381, time/batch = 0.206\n",
            "6420/15750 (epoch 20), train_loss = 2.364, time/batch = 0.200\n",
            "6421/15750 (epoch 20), train_loss = 2.342, time/batch = 0.204\n",
            "6422/15750 (epoch 20), train_loss = 2.380, time/batch = 0.198\n",
            "6423/15750 (epoch 20), train_loss = 2.350, time/batch = 0.205\n",
            "6424/15750 (epoch 20), train_loss = 2.377, time/batch = 0.194\n",
            "6425/15750 (epoch 20), train_loss = 2.393, time/batch = 0.202\n",
            "6426/15750 (epoch 20), train_loss = 2.482, time/batch = 0.206\n",
            "6427/15750 (epoch 20), train_loss = 2.349, time/batch = 0.209\n",
            "6428/15750 (epoch 20), train_loss = 2.361, time/batch = 0.204\n",
            "6429/15750 (epoch 20), train_loss = 2.355, time/batch = 0.204\n",
            "6430/15750 (epoch 20), train_loss = 2.293, time/batch = 0.195\n",
            "6431/15750 (epoch 20), train_loss = 2.302, time/batch = 0.203\n",
            "6432/15750 (epoch 20), train_loss = 2.317, time/batch = 0.205\n",
            "6433/15750 (epoch 20), train_loss = 2.325, time/batch = 0.210\n",
            "6434/15750 (epoch 20), train_loss = 2.360, time/batch = 0.202\n",
            "6435/15750 (epoch 20), train_loss = 2.481, time/batch = 0.206\n",
            "6436/15750 (epoch 20), train_loss = 2.437, time/batch = 0.210\n",
            "6437/15750 (epoch 20), train_loss = 2.443, time/batch = 0.210\n",
            "6438/15750 (epoch 20), train_loss = 2.434, time/batch = 0.219\n",
            "6439/15750 (epoch 20), train_loss = 2.361, time/batch = 0.203\n",
            "6440/15750 (epoch 20), train_loss = 2.359, time/batch = 0.207\n",
            "6441/15750 (epoch 20), train_loss = 2.442, time/batch = 0.207\n",
            "6442/15750 (epoch 20), train_loss = 2.462, time/batch = 0.205\n",
            "6443/15750 (epoch 20), train_loss = 2.454, time/batch = 0.207\n",
            "6444/15750 (epoch 20), train_loss = 2.367, time/batch = 0.204\n",
            "6445/15750 (epoch 20), train_loss = 2.363, time/batch = 0.209\n",
            "6446/15750 (epoch 20), train_loss = 2.316, time/batch = 0.203\n",
            "6447/15750 (epoch 20), train_loss = 2.402, time/batch = 0.210\n",
            "6448/15750 (epoch 20), train_loss = 2.431, time/batch = 0.206\n",
            "6449/15750 (epoch 20), train_loss = 2.377, time/batch = 0.201\n",
            "6450/15750 (epoch 20), train_loss = 2.381, time/batch = 0.211\n",
            "6451/15750 (epoch 20), train_loss = 2.420, time/batch = 0.201\n",
            "6452/15750 (epoch 20), train_loss = 2.476, time/batch = 0.201\n",
            "6453/15750 (epoch 20), train_loss = 2.422, time/batch = 0.213\n",
            "6454/15750 (epoch 20), train_loss = 2.430, time/batch = 0.203\n",
            "6455/15750 (epoch 20), train_loss = 2.415, time/batch = 0.202\n",
            "6456/15750 (epoch 20), train_loss = 2.420, time/batch = 0.206\n",
            "6457/15750 (epoch 20), train_loss = 2.406, time/batch = 0.205\n",
            "6458/15750 (epoch 20), train_loss = 2.501, time/batch = 0.212\n",
            "6459/15750 (epoch 20), train_loss = 2.357, time/batch = 0.206\n",
            "6460/15750 (epoch 20), train_loss = 2.429, time/batch = 0.210\n",
            "6461/15750 (epoch 20), train_loss = 2.427, time/batch = 0.208\n",
            "6462/15750 (epoch 20), train_loss = 2.452, time/batch = 0.209\n",
            "6463/15750 (epoch 20), train_loss = 2.535, time/batch = 0.211\n",
            "6464/15750 (epoch 20), train_loss = 2.449, time/batch = 0.209\n",
            "6465/15750 (epoch 20), train_loss = 2.453, time/batch = 0.207\n",
            "6466/15750 (epoch 20), train_loss = 2.436, time/batch = 0.206\n",
            "6467/15750 (epoch 20), train_loss = 2.395, time/batch = 0.218\n",
            "6468/15750 (epoch 20), train_loss = 2.360, time/batch = 0.201\n",
            "6469/15750 (epoch 20), train_loss = 2.356, time/batch = 0.210\n",
            "6470/15750 (epoch 20), train_loss = 2.406, time/batch = 0.205\n",
            "6471/15750 (epoch 20), train_loss = 2.446, time/batch = 0.207\n",
            "6472/15750 (epoch 20), train_loss = 2.402, time/batch = 0.202\n",
            "6473/15750 (epoch 20), train_loss = 2.455, time/batch = 0.208\n",
            "6474/15750 (epoch 20), train_loss = 2.412, time/batch = 0.199\n",
            "6475/15750 (epoch 20), train_loss = 2.338, time/batch = 0.197\n",
            "6476/15750 (epoch 20), train_loss = 2.369, time/batch = 0.201\n",
            "6477/15750 (epoch 20), train_loss = 2.421, time/batch = 0.202\n",
            "6478/15750 (epoch 20), train_loss = 2.355, time/batch = 0.208\n",
            "6479/15750 (epoch 20), train_loss = 2.323, time/batch = 0.204\n",
            "6480/15750 (epoch 20), train_loss = 2.347, time/batch = 0.202\n",
            "6481/15750 (epoch 20), train_loss = 2.439, time/batch = 0.202\n",
            "6482/15750 (epoch 20), train_loss = 2.397, time/batch = 0.209\n",
            "6483/15750 (epoch 20), train_loss = 2.464, time/batch = 0.213\n",
            "6484/15750 (epoch 20), train_loss = 2.465, time/batch = 0.206\n",
            "6485/15750 (epoch 20), train_loss = 2.386, time/batch = 0.210\n",
            "6486/15750 (epoch 20), train_loss = 2.354, time/batch = 0.212\n",
            "6487/15750 (epoch 20), train_loss = 2.428, time/batch = 0.205\n",
            "6488/15750 (epoch 20), train_loss = 2.466, time/batch = 0.209\n",
            "6489/15750 (epoch 20), train_loss = 2.537, time/batch = 0.210\n",
            "6490/15750 (epoch 20), train_loss = 2.489, time/batch = 0.206\n",
            "6491/15750 (epoch 20), train_loss = 2.411, time/batch = 0.214\n",
            "6492/15750 (epoch 20), train_loss = 2.424, time/batch = 0.210\n",
            "6493/15750 (epoch 20), train_loss = 2.353, time/batch = 0.213\n",
            "6494/15750 (epoch 20), train_loss = 2.470, time/batch = 0.208\n",
            "6495/15750 (epoch 20), train_loss = 2.465, time/batch = 0.206\n",
            "6496/15750 (epoch 20), train_loss = 2.406, time/batch = 0.206\n",
            "6497/15750 (epoch 20), train_loss = 2.356, time/batch = 0.209\n",
            "6498/15750 (epoch 20), train_loss = 2.449, time/batch = 0.203\n",
            "6499/15750 (epoch 20), train_loss = 2.254, time/batch = 0.197\n",
            "6500/15750 (epoch 20), train_loss = 2.354, time/batch = 0.195\n",
            "6501/15750 (epoch 20), train_loss = 2.317, time/batch = 0.202\n",
            "6502/15750 (epoch 20), train_loss = 2.395, time/batch = 0.211\n",
            "6503/15750 (epoch 20), train_loss = 2.370, time/batch = 0.200\n",
            "6504/15750 (epoch 20), train_loss = 2.432, time/batch = 0.204\n",
            "6505/15750 (epoch 20), train_loss = 2.392, time/batch = 0.203\n",
            "6506/15750 (epoch 20), train_loss = 2.261, time/batch = 0.197\n",
            "6507/15750 (epoch 20), train_loss = 2.339, time/batch = 0.209\n",
            "6508/15750 (epoch 20), train_loss = 2.344, time/batch = 0.208\n",
            "6509/15750 (epoch 20), train_loss = 2.400, time/batch = 0.211\n",
            "6510/15750 (epoch 20), train_loss = 2.275, time/batch = 0.207\n",
            "6511/15750 (epoch 20), train_loss = 2.364, time/batch = 0.206\n",
            "6512/15750 (epoch 20), train_loss = 2.249, time/batch = 0.213\n",
            "6513/15750 (epoch 20), train_loss = 2.318, time/batch = 0.210\n",
            "6514/15750 (epoch 20), train_loss = 2.317, time/batch = 0.211\n",
            "6515/15750 (epoch 20), train_loss = 2.311, time/batch = 0.206\n",
            "6516/15750 (epoch 20), train_loss = 2.462, time/batch = 0.209\n",
            "6517/15750 (epoch 20), train_loss = 2.274, time/batch = 0.218\n",
            "6518/15750 (epoch 20), train_loss = 2.522, time/batch = 0.205\n",
            "6519/15750 (epoch 20), train_loss = 2.382, time/batch = 0.203\n",
            "6520/15750 (epoch 20), train_loss = 2.267, time/batch = 0.193\n",
            "6521/15750 (epoch 20), train_loss = 2.313, time/batch = 0.203\n",
            "6522/15750 (epoch 20), train_loss = 2.370, time/batch = 0.212\n",
            "6523/15750 (epoch 20), train_loss = 2.360, time/batch = 0.201\n",
            "6524/15750 (epoch 20), train_loss = 2.347, time/batch = 0.208\n",
            "6525/15750 (epoch 20), train_loss = 2.346, time/batch = 0.198\n",
            "6526/15750 (epoch 20), train_loss = 2.426, time/batch = 0.202\n",
            "6527/15750 (epoch 20), train_loss = 2.339, time/batch = 0.205\n",
            "6528/15750 (epoch 20), train_loss = 2.381, time/batch = 0.199\n",
            "6529/15750 (epoch 20), train_loss = 2.461, time/batch = 0.206\n",
            "6530/15750 (epoch 20), train_loss = 2.310, time/batch = 0.204\n",
            "6531/15750 (epoch 20), train_loss = 2.334, time/batch = 0.207\n",
            "6532/15750 (epoch 20), train_loss = 2.377, time/batch = 0.213\n",
            "6533/15750 (epoch 20), train_loss = 2.377, time/batch = 0.209\n",
            "6534/15750 (epoch 20), train_loss = 2.320, time/batch = 0.206\n",
            "6535/15750 (epoch 20), train_loss = 2.320, time/batch = 0.206\n",
            "6536/15750 (epoch 20), train_loss = 2.289, time/batch = 0.208\n",
            "6537/15750 (epoch 20), train_loss = 2.353, time/batch = 0.219\n",
            "6538/15750 (epoch 20), train_loss = 2.564, time/batch = 0.211\n",
            "6539/15750 (epoch 20), train_loss = 2.371, time/batch = 0.207\n",
            "6540/15750 (epoch 20), train_loss = 2.426, time/batch = 0.205\n",
            "6541/15750 (epoch 20), train_loss = 2.300, time/batch = 0.213\n",
            "6542/15750 (epoch 20), train_loss = 2.366, time/batch = 0.212\n",
            "6543/15750 (epoch 20), train_loss = 2.385, time/batch = 0.206\n",
            "6544/15750 (epoch 20), train_loss = 2.381, time/batch = 0.198\n",
            "6545/15750 (epoch 20), train_loss = 2.440, time/batch = 0.206\n",
            "6546/15750 (epoch 20), train_loss = 2.408, time/batch = 0.207\n",
            "6547/15750 (epoch 20), train_loss = 2.397, time/batch = 0.214\n",
            "6548/15750 (epoch 20), train_loss = 2.384, time/batch = 0.206\n",
            "6549/15750 (epoch 20), train_loss = 2.413, time/batch = 0.214\n",
            "6550/15750 (epoch 20), train_loss = 2.311, time/batch = 0.208\n",
            "6551/15750 (epoch 20), train_loss = 2.307, time/batch = 0.208\n",
            "6552/15750 (epoch 20), train_loss = 2.388, time/batch = 0.219\n",
            "6553/15750 (epoch 20), train_loss = 2.398, time/batch = 0.210\n",
            "6554/15750 (epoch 20), train_loss = 2.368, time/batch = 0.210\n",
            "6555/15750 (epoch 20), train_loss = 2.342, time/batch = 0.204\n",
            "6556/15750 (epoch 20), train_loss = 2.290, time/batch = 0.207\n",
            "6557/15750 (epoch 20), train_loss = 2.306, time/batch = 0.214\n",
            "6558/15750 (epoch 20), train_loss = 2.475, time/batch = 0.207\n",
            "6559/15750 (epoch 20), train_loss = 2.438, time/batch = 0.206\n",
            "6560/15750 (epoch 20), train_loss = 2.410, time/batch = 0.213\n",
            "6561/15750 (epoch 20), train_loss = 2.355, time/batch = 0.210\n",
            "6562/15750 (epoch 20), train_loss = 2.388, time/batch = 0.209\n",
            "6563/15750 (epoch 20), train_loss = 2.364, time/batch = 0.219\n",
            "6564/15750 (epoch 20), train_loss = 2.410, time/batch = 0.204\n",
            "6565/15750 (epoch 20), train_loss = 2.454, time/batch = 0.209\n",
            "6566/15750 (epoch 20), train_loss = 2.465, time/batch = 0.213\n",
            "6567/15750 (epoch 20), train_loss = 2.377, time/batch = 0.212\n",
            "6568/15750 (epoch 20), train_loss = 2.418, time/batch = 0.213\n",
            "6569/15750 (epoch 20), train_loss = 2.438, time/batch = 0.200\n",
            "6570/15750 (epoch 20), train_loss = 2.428, time/batch = 0.206\n",
            "6571/15750 (epoch 20), train_loss = 2.324, time/batch = 0.210\n",
            "6572/15750 (epoch 20), train_loss = 2.363, time/batch = 0.205\n",
            "6573/15750 (epoch 20), train_loss = 2.427, time/batch = 0.200\n",
            "6574/15750 (epoch 20), train_loss = 2.447, time/batch = 0.198\n",
            "6575/15750 (epoch 20), train_loss = 2.405, time/batch = 0.205\n",
            "6576/15750 (epoch 20), train_loss = 2.456, time/batch = 0.208\n",
            "6577/15750 (epoch 20), train_loss = 2.386, time/batch = 0.213\n",
            "6578/15750 (epoch 20), train_loss = 2.342, time/batch = 0.209\n",
            "6579/15750 (epoch 20), train_loss = 2.298, time/batch = 0.209\n",
            "6580/15750 (epoch 20), train_loss = 2.541, time/batch = 0.209\n",
            "6581/15750 (epoch 20), train_loss = 2.365, time/batch = 0.218\n",
            "6582/15750 (epoch 20), train_loss = 2.325, time/batch = 0.208\n",
            "6583/15750 (epoch 20), train_loss = 2.447, time/batch = 0.207\n",
            "6584/15750 (epoch 20), train_loss = 2.337, time/batch = 0.210\n",
            "6585/15750 (epoch 20), train_loss = 2.485, time/batch = 0.205\n",
            "6586/15750 (epoch 20), train_loss = 2.361, time/batch = 0.219\n",
            "6587/15750 (epoch 20), train_loss = 2.376, time/batch = 0.211\n",
            "6588/15750 (epoch 20), train_loss = 2.297, time/batch = 0.213\n",
            "6589/15750 (epoch 20), train_loss = 2.391, time/batch = 0.207\n",
            "6590/15750 (epoch 20), train_loss = 2.320, time/batch = 0.213\n",
            "6591/15750 (epoch 20), train_loss = 2.403, time/batch = 0.218\n",
            "6592/15750 (epoch 20), train_loss = 2.393, time/batch = 0.217\n",
            "6593/15750 (epoch 20), train_loss = 2.359, time/batch = 0.210\n",
            "6594/15750 (epoch 20), train_loss = 2.409, time/batch = 0.211\n",
            "6595/15750 (epoch 20), train_loss = 2.492, time/batch = 0.206\n",
            "6596/15750 (epoch 20), train_loss = 2.446, time/batch = 0.207\n",
            "6597/15750 (epoch 20), train_loss = 2.461, time/batch = 0.204\n",
            "6598/15750 (epoch 20), train_loss = 2.325, time/batch = 0.203\n",
            "6599/15750 (epoch 20), train_loss = 2.405, time/batch = 0.209\n",
            "6600/15750 (epoch 20), train_loss = 2.394, time/batch = 0.202\n",
            "6601/15750 (epoch 20), train_loss = 2.309, time/batch = 0.209\n",
            "6602/15750 (epoch 20), train_loss = 2.441, time/batch = 0.211\n",
            "6603/15750 (epoch 20), train_loss = 2.298, time/batch = 0.213\n",
            "6604/15750 (epoch 20), train_loss = 2.434, time/batch = 0.215\n",
            "6605/15750 (epoch 20), train_loss = 2.378, time/batch = 0.213\n",
            "6606/15750 (epoch 20), train_loss = 2.353, time/batch = 0.212\n",
            "6607/15750 (epoch 20), train_loss = 2.302, time/batch = 0.205\n",
            "6608/15750 (epoch 20), train_loss = 2.327, time/batch = 0.206\n",
            "6609/15750 (epoch 20), train_loss = 2.458, time/batch = 0.203\n",
            "6610/15750 (epoch 20), train_loss = 2.307, time/batch = 0.220\n",
            "6611/15750 (epoch 20), train_loss = 2.290, time/batch = 0.208\n",
            "6612/15750 (epoch 20), train_loss = 2.337, time/batch = 0.206\n",
            "6613/15750 (epoch 20), train_loss = 2.329, time/batch = 0.201\n",
            "6614/15750 (epoch 20), train_loss = 2.435, time/batch = 0.201\n",
            "6615/15750 (epoch 21), train_loss = 2.400, time/batch = 0.205\n",
            "6616/15750 (epoch 21), train_loss = 2.440, time/batch = 0.201\n",
            "6617/15750 (epoch 21), train_loss = 2.379, time/batch = 0.210\n",
            "6618/15750 (epoch 21), train_loss = 2.464, time/batch = 0.204\n",
            "6619/15750 (epoch 21), train_loss = 2.393, time/batch = 0.203\n",
            "6620/15750 (epoch 21), train_loss = 2.382, time/batch = 0.201\n",
            "6621/15750 (epoch 21), train_loss = 2.551, time/batch = 0.213\n",
            "6622/15750 (epoch 21), train_loss = 2.460, time/batch = 0.208\n",
            "6623/15750 (epoch 21), train_loss = 2.448, time/batch = 0.209\n",
            "6624/15750 (epoch 21), train_loss = 2.394, time/batch = 0.196\n",
            "6625/15750 (epoch 21), train_loss = 2.398, time/batch = 0.202\n",
            "6626/15750 (epoch 21), train_loss = 2.350, time/batch = 0.210\n",
            "6627/15750 (epoch 21), train_loss = 2.446, time/batch = 0.201\n",
            "6628/15750 (epoch 21), train_loss = 2.415, time/batch = 0.198\n",
            "6629/15750 (epoch 21), train_loss = 2.401, time/batch = 0.205\n",
            "6630/15750 (epoch 21), train_loss = 2.422, time/batch = 0.205\n",
            "6631/15750 (epoch 21), train_loss = 2.433, time/batch = 0.204\n",
            "6632/15750 (epoch 21), train_loss = 2.489, time/batch = 0.210\n",
            "6633/15750 (epoch 21), train_loss = 2.497, time/batch = 0.210\n",
            "6634/15750 (epoch 21), train_loss = 2.443, time/batch = 0.211\n",
            "6635/15750 (epoch 21), train_loss = 2.438, time/batch = 0.204\n",
            "6636/15750 (epoch 21), train_loss = 2.451, time/batch = 0.209\n",
            "6637/15750 (epoch 21), train_loss = 2.400, time/batch = 0.209\n",
            "6638/15750 (epoch 21), train_loss = 2.458, time/batch = 0.211\n",
            "6639/15750 (epoch 21), train_loss = 2.455, time/batch = 0.212\n",
            "6640/15750 (epoch 21), train_loss = 2.482, time/batch = 0.206\n",
            "6641/15750 (epoch 21), train_loss = 2.482, time/batch = 0.216\n",
            "6642/15750 (epoch 21), train_loss = 2.472, time/batch = 0.204\n",
            "6643/15750 (epoch 21), train_loss = 2.586, time/batch = 0.208\n",
            "6644/15750 (epoch 21), train_loss = 2.495, time/batch = 0.216\n",
            "6645/15750 (epoch 21), train_loss = 2.456, time/batch = 0.213\n",
            "6646/15750 (epoch 21), train_loss = 2.426, time/batch = 0.208\n",
            "6647/15750 (epoch 21), train_loss = 2.335, time/batch = 0.207\n",
            "6648/15750 (epoch 21), train_loss = 2.359, time/batch = 0.205\n",
            "6649/15750 (epoch 21), train_loss = 2.440, time/batch = 0.213\n",
            "6650/15750 (epoch 21), train_loss = 2.346, time/batch = 0.210\n",
            "6651/15750 (epoch 21), train_loss = 2.398, time/batch = 0.212\n",
            "6652/15750 (epoch 21), train_loss = 2.464, time/batch = 0.209\n",
            "6653/15750 (epoch 21), train_loss = 2.373, time/batch = 0.211\n",
            "6654/15750 (epoch 21), train_loss = 2.421, time/batch = 0.214\n",
            "6655/15750 (epoch 21), train_loss = 2.379, time/batch = 0.207\n",
            "6656/15750 (epoch 21), train_loss = 2.431, time/batch = 0.205\n",
            "6657/15750 (epoch 21), train_loss = 2.425, time/batch = 0.206\n",
            "6658/15750 (epoch 21), train_loss = 2.384, time/batch = 0.199\n",
            "6659/15750 (epoch 21), train_loss = 2.425, time/batch = 0.206\n",
            "6660/15750 (epoch 21), train_loss = 2.337, time/batch = 0.206\n",
            "6661/15750 (epoch 21), train_loss = 2.381, time/batch = 0.208\n",
            "6662/15750 (epoch 21), train_loss = 2.411, time/batch = 0.209\n",
            "6663/15750 (epoch 21), train_loss = 2.449, time/batch = 0.205\n",
            "6664/15750 (epoch 21), train_loss = 2.339, time/batch = 0.210\n",
            "6665/15750 (epoch 21), train_loss = 2.393, time/batch = 0.208\n",
            "6666/15750 (epoch 21), train_loss = 2.350, time/batch = 0.205\n",
            "6667/15750 (epoch 21), train_loss = 2.411, time/batch = 0.206\n",
            "6668/15750 (epoch 21), train_loss = 2.420, time/batch = 0.208\n",
            "6669/15750 (epoch 21), train_loss = 2.417, time/batch = 0.212\n",
            "6670/15750 (epoch 21), train_loss = 2.454, time/batch = 0.211\n",
            "6671/15750 (epoch 21), train_loss = 2.329, time/batch = 0.211\n",
            "6672/15750 (epoch 21), train_loss = 2.338, time/batch = 0.206\n",
            "6673/15750 (epoch 21), train_loss = 2.421, time/batch = 0.206\n",
            "6674/15750 (epoch 21), train_loss = 2.281, time/batch = 0.214\n",
            "6675/15750 (epoch 21), train_loss = 2.387, time/batch = 0.200\n",
            "6676/15750 (epoch 21), train_loss = 2.395, time/batch = 0.203\n",
            "6677/15750 (epoch 21), train_loss = 2.321, time/batch = 0.200\n",
            "6678/15750 (epoch 21), train_loss = 2.373, time/batch = 0.206\n",
            "6679/15750 (epoch 21), train_loss = 2.291, time/batch = 0.213\n",
            "6680/15750 (epoch 21), train_loss = 2.306, time/batch = 0.209\n",
            "6681/15750 (epoch 21), train_loss = 2.250, time/batch = 0.208\n",
            "6682/15750 (epoch 21), train_loss = 2.274, time/batch = 0.212\n",
            "6683/15750 (epoch 21), train_loss = 2.328, time/batch = 0.211\n",
            "6684/15750 (epoch 21), train_loss = 2.412, time/batch = 0.201\n",
            "6685/15750 (epoch 21), train_loss = 2.341, time/batch = 0.211\n",
            "6686/15750 (epoch 21), train_loss = 2.329, time/batch = 0.210\n",
            "6687/15750 (epoch 21), train_loss = 2.239, time/batch = 0.205\n",
            "6688/15750 (epoch 21), train_loss = 2.327, time/batch = 0.213\n",
            "6689/15750 (epoch 21), train_loss = 2.429, time/batch = 0.211\n",
            "6690/15750 (epoch 21), train_loss = 2.366, time/batch = 0.209\n",
            "6691/15750 (epoch 21), train_loss = 2.358, time/batch = 0.201\n",
            "6692/15750 (epoch 21), train_loss = 2.364, time/batch = 0.205\n",
            "6693/15750 (epoch 21), train_loss = 2.371, time/batch = 0.207\n",
            "6694/15750 (epoch 21), train_loss = 2.364, time/batch = 0.203\n",
            "6695/15750 (epoch 21), train_loss = 2.269, time/batch = 0.210\n",
            "6696/15750 (epoch 21), train_loss = 2.373, time/batch = 0.205\n",
            "6697/15750 (epoch 21), train_loss = 2.307, time/batch = 0.204\n",
            "6698/15750 (epoch 21), train_loss = 2.367, time/batch = 0.209\n",
            "6699/15750 (epoch 21), train_loss = 2.431, time/batch = 0.205\n",
            "6700/15750 (epoch 21), train_loss = 2.448, time/batch = 0.209\n",
            "6701/15750 (epoch 21), train_loss = 2.282, time/batch = 0.208\n",
            "6702/15750 (epoch 21), train_loss = 2.316, time/batch = 0.209\n",
            "6703/15750 (epoch 21), train_loss = 2.336, time/batch = 0.217\n",
            "6704/15750 (epoch 21), train_loss = 2.332, time/batch = 0.209\n",
            "6705/15750 (epoch 21), train_loss = 2.342, time/batch = 0.211\n",
            "6706/15750 (epoch 21), train_loss = 2.396, time/batch = 0.208\n",
            "6707/15750 (epoch 21), train_loss = 2.388, time/batch = 0.209\n",
            "6708/15750 (epoch 21), train_loss = 2.402, time/batch = 0.220\n",
            "6709/15750 (epoch 21), train_loss = 2.466, time/batch = 0.209\n",
            "6710/15750 (epoch 21), train_loss = 2.359, time/batch = 0.210\n",
            "6711/15750 (epoch 21), train_loss = 2.386, time/batch = 0.211\n",
            "6712/15750 (epoch 21), train_loss = 2.400, time/batch = 0.209\n",
            "6713/15750 (epoch 21), train_loss = 2.397, time/batch = 0.218\n",
            "6714/15750 (epoch 21), train_loss = 2.409, time/batch = 0.208\n",
            "6715/15750 (epoch 21), train_loss = 2.387, time/batch = 0.206\n",
            "6716/15750 (epoch 21), train_loss = 2.314, time/batch = 0.206\n",
            "6717/15750 (epoch 21), train_loss = 2.340, time/batch = 0.210\n",
            "6718/15750 (epoch 21), train_loss = 2.466, time/batch = 0.210\n",
            "6719/15750 (epoch 21), train_loss = 2.393, time/batch = 0.211\n",
            "6720/15750 (epoch 21), train_loss = 2.308, time/batch = 0.198\n",
            "6721/15750 (epoch 21), train_loss = 2.368, time/batch = 0.206\n",
            "6722/15750 (epoch 21), train_loss = 2.384, time/batch = 0.204\n",
            "6723/15750 (epoch 21), train_loss = 2.434, time/batch = 0.207\n",
            "6724/15750 (epoch 21), train_loss = 2.454, time/batch = 0.208\n",
            "6725/15750 (epoch 21), train_loss = 2.501, time/batch = 0.203\n",
            "6726/15750 (epoch 21), train_loss = 2.377, time/batch = 0.206\n",
            "6727/15750 (epoch 21), train_loss = 2.364, time/batch = 0.204\n",
            "6728/15750 (epoch 21), train_loss = 2.379, time/batch = 0.214\n",
            "6729/15750 (epoch 21), train_loss = 2.395, time/batch = 0.210\n",
            "6730/15750 (epoch 21), train_loss = 2.465, time/batch = 0.199\n",
            "6731/15750 (epoch 21), train_loss = 2.389, time/batch = 0.207\n",
            "6732/15750 (epoch 21), train_loss = 2.518, time/batch = 0.205\n",
            "6733/15750 (epoch 21), train_loss = 2.394, time/batch = 0.216\n",
            "6734/15750 (epoch 21), train_loss = 2.369, time/batch = 0.208\n",
            "6735/15750 (epoch 21), train_loss = 2.350, time/batch = 0.204\n",
            "6736/15750 (epoch 21), train_loss = 2.328, time/batch = 0.208\n",
            "6737/15750 (epoch 21), train_loss = 2.365, time/batch = 0.206\n",
            "6738/15750 (epoch 21), train_loss = 2.336, time/batch = 0.214\n",
            "6739/15750 (epoch 21), train_loss = 2.363, time/batch = 0.203\n",
            "6740/15750 (epoch 21), train_loss = 2.379, time/batch = 0.200\n",
            "6741/15750 (epoch 21), train_loss = 2.467, time/batch = 0.202\n",
            "6742/15750 (epoch 21), train_loss = 2.337, time/batch = 0.201\n",
            "6743/15750 (epoch 21), train_loss = 2.350, time/batch = 0.209\n",
            "6744/15750 (epoch 21), train_loss = 2.342, time/batch = 0.207\n",
            "6745/15750 (epoch 21), train_loss = 2.280, time/batch = 0.203\n",
            "6746/15750 (epoch 21), train_loss = 2.289, time/batch = 0.204\n",
            "6747/15750 (epoch 21), train_loss = 2.303, time/batch = 0.194\n",
            "6748/15750 (epoch 21), train_loss = 2.313, time/batch = 0.206\n",
            "6749/15750 (epoch 21), train_loss = 2.347, time/batch = 0.202\n",
            "6750/15750 (epoch 21), train_loss = 2.469, time/batch = 0.197\n",
            "6751/15750 (epoch 21), train_loss = 2.425, time/batch = 0.204\n",
            "6752/15750 (epoch 21), train_loss = 2.430, time/batch = 0.202\n",
            "6753/15750 (epoch 21), train_loss = 2.420, time/batch = 0.204\n",
            "6754/15750 (epoch 21), train_loss = 2.348, time/batch = 0.200\n",
            "6755/15750 (epoch 21), train_loss = 2.346, time/batch = 0.202\n",
            "6756/15750 (epoch 21), train_loss = 2.430, time/batch = 0.193\n",
            "6757/15750 (epoch 21), train_loss = 2.450, time/batch = 0.208\n",
            "6758/15750 (epoch 21), train_loss = 2.440, time/batch = 0.202\n",
            "6759/15750 (epoch 21), train_loss = 2.353, time/batch = 0.197\n",
            "6760/15750 (epoch 21), train_loss = 2.349, time/batch = 0.208\n",
            "6761/15750 (epoch 21), train_loss = 2.304, time/batch = 0.197\n",
            "6762/15750 (epoch 21), train_loss = 2.390, time/batch = 0.210\n",
            "6763/15750 (epoch 21), train_loss = 2.419, time/batch = 0.206\n",
            "6764/15750 (epoch 21), train_loss = 2.364, time/batch = 0.199\n",
            "6765/15750 (epoch 21), train_loss = 2.368, time/batch = 0.199\n",
            "6766/15750 (epoch 21), train_loss = 2.408, time/batch = 0.197\n",
            "6767/15750 (epoch 21), train_loss = 2.461, time/batch = 0.205\n",
            "6768/15750 (epoch 21), train_loss = 2.407, time/batch = 0.202\n",
            "6769/15750 (epoch 21), train_loss = 2.417, time/batch = 0.205\n",
            "6770/15750 (epoch 21), train_loss = 2.402, time/batch = 0.203\n",
            "6771/15750 (epoch 21), train_loss = 2.407, time/batch = 0.201\n",
            "6772/15750 (epoch 21), train_loss = 2.393, time/batch = 0.200\n",
            "6773/15750 (epoch 21), train_loss = 2.488, time/batch = 0.208\n",
            "6774/15750 (epoch 21), train_loss = 2.344, time/batch = 0.205\n",
            "6775/15750 (epoch 21), train_loss = 2.415, time/batch = 0.204\n",
            "6776/15750 (epoch 21), train_loss = 2.414, time/batch = 0.203\n",
            "6777/15750 (epoch 21), train_loss = 2.438, time/batch = 0.203\n",
            "6778/15750 (epoch 21), train_loss = 2.521, time/batch = 0.211\n",
            "6779/15750 (epoch 21), train_loss = 2.436, time/batch = 0.207\n",
            "6780/15750 (epoch 21), train_loss = 2.438, time/batch = 0.208\n",
            "6781/15750 (epoch 21), train_loss = 2.422, time/batch = 0.206\n",
            "6782/15750 (epoch 21), train_loss = 2.381, time/batch = 0.208\n",
            "6783/15750 (epoch 21), train_loss = 2.347, time/batch = 0.209\n",
            "6784/15750 (epoch 21), train_loss = 2.342, time/batch = 0.208\n",
            "6785/15750 (epoch 21), train_loss = 2.391, time/batch = 0.203\n",
            "6786/15750 (epoch 21), train_loss = 2.430, time/batch = 0.204\n",
            "6787/15750 (epoch 21), train_loss = 2.390, time/batch = 0.205\n",
            "6788/15750 (epoch 21), train_loss = 2.442, time/batch = 0.207\n",
            "6789/15750 (epoch 21), train_loss = 2.398, time/batch = 0.203\n",
            "6790/15750 (epoch 21), train_loss = 2.325, time/batch = 0.204\n",
            "6791/15750 (epoch 21), train_loss = 2.356, time/batch = 0.210\n",
            "6792/15750 (epoch 21), train_loss = 2.407, time/batch = 0.203\n",
            "6793/15750 (epoch 21), train_loss = 2.342, time/batch = 0.205\n",
            "6794/15750 (epoch 21), train_loss = 2.309, time/batch = 0.207\n",
            "6795/15750 (epoch 21), train_loss = 2.335, time/batch = 0.205\n",
            "6796/15750 (epoch 21), train_loss = 2.425, time/batch = 0.200\n",
            "6797/15750 (epoch 21), train_loss = 2.385, time/batch = 0.202\n",
            "6798/15750 (epoch 21), train_loss = 2.451, time/batch = 0.211\n",
            "6799/15750 (epoch 21), train_loss = 2.451, time/batch = 0.195\n",
            "6800/15750 (epoch 21), train_loss = 2.375, time/batch = 0.201\n",
            "6801/15750 (epoch 21), train_loss = 2.342, time/batch = 0.211\n",
            "6802/15750 (epoch 21), train_loss = 2.415, time/batch = 0.203\n",
            "6803/15750 (epoch 21), train_loss = 2.452, time/batch = 0.210\n",
            "6804/15750 (epoch 21), train_loss = 2.522, time/batch = 0.204\n",
            "6805/15750 (epoch 21), train_loss = 2.477, time/batch = 0.209\n",
            "6806/15750 (epoch 21), train_loss = 2.398, time/batch = 0.203\n",
            "6807/15750 (epoch 21), train_loss = 2.411, time/batch = 0.207\n",
            "6808/15750 (epoch 21), train_loss = 2.339, time/batch = 0.211\n",
            "6809/15750 (epoch 21), train_loss = 2.457, time/batch = 0.206\n",
            "6810/15750 (epoch 21), train_loss = 2.450, time/batch = 0.205\n",
            "6811/15750 (epoch 21), train_loss = 2.394, time/batch = 0.198\n",
            "6812/15750 (epoch 21), train_loss = 2.342, time/batch = 0.205\n",
            "6813/15750 (epoch 21), train_loss = 2.437, time/batch = 0.212\n",
            "6814/15750 (epoch 21), train_loss = 2.239, time/batch = 0.206\n",
            "6815/15750 (epoch 21), train_loss = 2.341, time/batch = 0.205\n",
            "6816/15750 (epoch 21), train_loss = 2.303, time/batch = 0.203\n",
            "6817/15750 (epoch 21), train_loss = 2.382, time/batch = 0.204\n",
            "6818/15750 (epoch 21), train_loss = 2.357, time/batch = 0.224\n",
            "6819/15750 (epoch 21), train_loss = 2.420, time/batch = 0.204\n",
            "6820/15750 (epoch 21), train_loss = 2.378, time/batch = 0.202\n",
            "6821/15750 (epoch 21), train_loss = 2.249, time/batch = 0.203\n",
            "6822/15750 (epoch 21), train_loss = 2.325, time/batch = 0.204\n",
            "6823/15750 (epoch 21), train_loss = 2.330, time/batch = 0.215\n",
            "6824/15750 (epoch 21), train_loss = 2.387, time/batch = 0.204\n",
            "6825/15750 (epoch 21), train_loss = 2.263, time/batch = 0.203\n",
            "6826/15750 (epoch 21), train_loss = 2.351, time/batch = 0.202\n",
            "6827/15750 (epoch 21), train_loss = 2.235, time/batch = 0.199\n",
            "6828/15750 (epoch 21), train_loss = 2.306, time/batch = 0.207\n",
            "6829/15750 (epoch 21), train_loss = 2.304, time/batch = 0.201\n",
            "6830/15750 (epoch 21), train_loss = 2.298, time/batch = 0.205\n",
            "6831/15750 (epoch 21), train_loss = 2.448, time/batch = 0.198\n",
            "6832/15750 (epoch 21), train_loss = 2.261, time/batch = 0.197\n",
            "6833/15750 (epoch 21), train_loss = 2.510, time/batch = 0.208\n",
            "6834/15750 (epoch 21), train_loss = 2.369, time/batch = 0.203\n",
            "6835/15750 (epoch 21), train_loss = 2.254, time/batch = 0.201\n",
            "6836/15750 (epoch 21), train_loss = 2.299, time/batch = 0.205\n",
            "6837/15750 (epoch 21), train_loss = 2.356, time/batch = 0.209\n",
            "6838/15750 (epoch 21), train_loss = 2.347, time/batch = 0.209\n",
            "6839/15750 (epoch 21), train_loss = 2.334, time/batch = 0.205\n",
            "6840/15750 (epoch 21), train_loss = 2.333, time/batch = 0.206\n",
            "6841/15750 (epoch 21), train_loss = 2.412, time/batch = 0.210\n",
            "6842/15750 (epoch 21), train_loss = 2.325, time/batch = 0.207\n",
            "6843/15750 (epoch 21), train_loss = 2.368, time/batch = 0.211\n",
            "6844/15750 (epoch 21), train_loss = 2.448, time/batch = 0.207\n",
            "6845/15750 (epoch 21), train_loss = 2.297, time/batch = 0.205\n",
            "6846/15750 (epoch 21), train_loss = 2.321, time/batch = 0.210\n",
            "6847/15750 (epoch 21), train_loss = 2.364, time/batch = 0.211\n",
            "6848/15750 (epoch 21), train_loss = 2.363, time/batch = 0.217\n",
            "6849/15750 (epoch 21), train_loss = 2.307, time/batch = 0.212\n",
            "6850/15750 (epoch 21), train_loss = 2.306, time/batch = 0.209\n",
            "6851/15750 (epoch 21), train_loss = 2.276, time/batch = 0.200\n",
            "6852/15750 (epoch 21), train_loss = 2.339, time/batch = 0.204\n",
            "6853/15750 (epoch 21), train_loss = 2.551, time/batch = 0.210\n",
            "6854/15750 (epoch 21), train_loss = 2.359, time/batch = 0.218\n",
            "6855/15750 (epoch 21), train_loss = 2.413, time/batch = 0.208\n",
            "6856/15750 (epoch 21), train_loss = 2.287, time/batch = 0.210\n",
            "6857/15750 (epoch 21), train_loss = 2.351, time/batch = 0.215\n",
            "6858/15750 (epoch 21), train_loss = 2.372, time/batch = 0.212\n",
            "6859/15750 (epoch 21), train_loss = 2.369, time/batch = 0.212\n",
            "6860/15750 (epoch 21), train_loss = 2.428, time/batch = 0.211\n",
            "6861/15750 (epoch 21), train_loss = 2.396, time/batch = 0.208\n",
            "6862/15750 (epoch 21), train_loss = 2.384, time/batch = 0.215\n",
            "6863/15750 (epoch 21), train_loss = 2.371, time/batch = 0.203\n",
            "6864/15750 (epoch 21), train_loss = 2.399, time/batch = 0.202\n",
            "6865/15750 (epoch 21), train_loss = 2.296, time/batch = 0.219\n",
            "6866/15750 (epoch 21), train_loss = 2.292, time/batch = 0.204\n",
            "6867/15750 (epoch 21), train_loss = 2.374, time/batch = 0.215\n",
            "6868/15750 (epoch 21), train_loss = 2.386, time/batch = 0.205\n",
            "6869/15750 (epoch 21), train_loss = 2.355, time/batch = 0.203\n",
            "6870/15750 (epoch 21), train_loss = 2.328, time/batch = 0.212\n",
            "6871/15750 (epoch 21), train_loss = 2.276, time/batch = 0.211\n",
            "6872/15750 (epoch 21), train_loss = 2.293, time/batch = 0.213\n",
            "6873/15750 (epoch 21), train_loss = 2.460, time/batch = 0.211\n",
            "6874/15750 (epoch 21), train_loss = 2.425, time/batch = 0.216\n",
            "6875/15750 (epoch 21), train_loss = 2.396, time/batch = 0.210\n",
            "6876/15750 (epoch 21), train_loss = 2.342, time/batch = 0.208\n",
            "6877/15750 (epoch 21), train_loss = 2.374, time/batch = 0.203\n",
            "6878/15750 (epoch 21), train_loss = 2.351, time/batch = 0.203\n",
            "6879/15750 (epoch 21), train_loss = 2.394, time/batch = 0.215\n",
            "6880/15750 (epoch 21), train_loss = 2.440, time/batch = 0.203\n",
            "6881/15750 (epoch 21), train_loss = 2.450, time/batch = 0.215\n",
            "6882/15750 (epoch 21), train_loss = 2.363, time/batch = 0.222\n",
            "6883/15750 (epoch 21), train_loss = 2.404, time/batch = 0.206\n",
            "6884/15750 (epoch 21), train_loss = 2.424, time/batch = 0.209\n",
            "6885/15750 (epoch 21), train_loss = 2.415, time/batch = 0.210\n",
            "6886/15750 (epoch 21), train_loss = 2.312, time/batch = 0.210\n",
            "6887/15750 (epoch 21), train_loss = 2.349, time/batch = 0.213\n",
            "6888/15750 (epoch 21), train_loss = 2.415, time/batch = 0.207\n",
            "6889/15750 (epoch 21), train_loss = 2.434, time/batch = 0.203\n",
            "6890/15750 (epoch 21), train_loss = 2.392, time/batch = 0.204\n",
            "6891/15750 (epoch 21), train_loss = 2.443, time/batch = 0.206\n",
            "6892/15750 (epoch 21), train_loss = 2.372, time/batch = 0.208\n",
            "6893/15750 (epoch 21), train_loss = 2.330, time/batch = 0.210\n",
            "6894/15750 (epoch 21), train_loss = 2.286, time/batch = 0.208\n",
            "6895/15750 (epoch 21), train_loss = 2.528, time/batch = 0.203\n",
            "6896/15750 (epoch 21), train_loss = 2.352, time/batch = 0.203\n",
            "6897/15750 (epoch 21), train_loss = 2.312, time/batch = 0.212\n",
            "6898/15750 (epoch 21), train_loss = 2.432, time/batch = 0.215\n",
            "6899/15750 (epoch 21), train_loss = 2.324, time/batch = 0.210\n",
            "6900/15750 (epoch 21), train_loss = 2.471, time/batch = 0.209\n",
            "6901/15750 (epoch 21), train_loss = 2.349, time/batch = 0.207\n",
            "6902/15750 (epoch 21), train_loss = 2.364, time/batch = 0.209\n",
            "6903/15750 (epoch 21), train_loss = 2.284, time/batch = 0.207\n",
            "6904/15750 (epoch 21), train_loss = 2.379, time/batch = 0.206\n",
            "6905/15750 (epoch 21), train_loss = 2.309, time/batch = 0.209\n",
            "6906/15750 (epoch 21), train_loss = 2.390, time/batch = 0.206\n",
            "6907/15750 (epoch 21), train_loss = 2.380, time/batch = 0.202\n",
            "6908/15750 (epoch 21), train_loss = 2.346, time/batch = 0.207\n",
            "6909/15750 (epoch 21), train_loss = 2.395, time/batch = 0.204\n",
            "6910/15750 (epoch 21), train_loss = 2.479, time/batch = 0.193\n",
            "6911/15750 (epoch 21), train_loss = 2.433, time/batch = 0.202\n",
            "6912/15750 (epoch 21), train_loss = 2.448, time/batch = 0.210\n",
            "6913/15750 (epoch 21), train_loss = 2.314, time/batch = 0.195\n",
            "6914/15750 (epoch 21), train_loss = 2.391, time/batch = 0.203\n",
            "6915/15750 (epoch 21), train_loss = 2.382, time/batch = 0.204\n",
            "6916/15750 (epoch 21), train_loss = 2.298, time/batch = 0.200\n",
            "6917/15750 (epoch 21), train_loss = 2.429, time/batch = 0.206\n",
            "6918/15750 (epoch 21), train_loss = 2.286, time/batch = 0.204\n",
            "6919/15750 (epoch 21), train_loss = 2.421, time/batch = 0.204\n",
            "6920/15750 (epoch 21), train_loss = 2.365, time/batch = 0.200\n",
            "6921/15750 (epoch 21), train_loss = 2.339, time/batch = 0.198\n",
            "6922/15750 (epoch 21), train_loss = 2.289, time/batch = 0.211\n",
            "6923/15750 (epoch 21), train_loss = 2.315, time/batch = 0.202\n",
            "6924/15750 (epoch 21), train_loss = 2.444, time/batch = 0.194\n",
            "6925/15750 (epoch 21), train_loss = 2.296, time/batch = 0.206\n",
            "6926/15750 (epoch 21), train_loss = 2.279, time/batch = 0.203\n",
            "6927/15750 (epoch 21), train_loss = 2.323, time/batch = 0.204\n",
            "6928/15750 (epoch 21), train_loss = 2.318, time/batch = 0.200\n",
            "6929/15750 (epoch 21), train_loss = 2.423, time/batch = 0.202\n",
            "6930/15750 (epoch 22), train_loss = 2.379, time/batch = 0.201\n",
            "6931/15750 (epoch 22), train_loss = 2.426, time/batch = 0.203\n",
            "6932/15750 (epoch 22), train_loss = 2.364, time/batch = 0.204\n",
            "6933/15750 (epoch 22), train_loss = 2.452, time/batch = 0.210\n",
            "6934/15750 (epoch 22), train_loss = 2.379, time/batch = 0.209\n",
            "6935/15750 (epoch 22), train_loss = 2.368, time/batch = 0.207\n",
            "6936/15750 (epoch 22), train_loss = 2.536, time/batch = 0.210\n",
            "6937/15750 (epoch 22), train_loss = 2.446, time/batch = 0.202\n",
            "6938/15750 (epoch 22), train_loss = 2.435, time/batch = 0.201\n",
            "6939/15750 (epoch 22), train_loss = 2.380, time/batch = 0.206\n",
            "6940/15750 (epoch 22), train_loss = 2.385, time/batch = 0.206\n",
            "6941/15750 (epoch 22), train_loss = 2.356, time/batch = 0.212\n",
            "6942/15750 (epoch 22), train_loss = 2.480, time/batch = 0.208\n",
            "6943/15750 (epoch 22), train_loss = 2.440, time/batch = 0.203\n",
            "6944/15750 (epoch 22), train_loss = 2.406, time/batch = 0.201\n",
            "6945/15750 (epoch 22), train_loss = 2.413, time/batch = 0.205\n",
            "6946/15750 (epoch 22), train_loss = 2.422, time/batch = 0.216\n",
            "6947/15750 (epoch 22), train_loss = 2.479, time/batch = 0.202\n",
            "6948/15750 (epoch 22), train_loss = 2.486, time/batch = 0.203\n",
            "6949/15750 (epoch 22), train_loss = 2.432, time/batch = 0.203\n",
            "6950/15750 (epoch 22), train_loss = 2.425, time/batch = 0.204\n",
            "6951/15750 (epoch 22), train_loss = 2.443, time/batch = 0.214\n",
            "6952/15750 (epoch 22), train_loss = 2.390, time/batch = 0.202\n",
            "6953/15750 (epoch 22), train_loss = 2.447, time/batch = 0.204\n",
            "6954/15750 (epoch 22), train_loss = 2.445, time/batch = 0.198\n",
            "6955/15750 (epoch 22), train_loss = 2.472, time/batch = 0.199\n",
            "6956/15750 (epoch 22), train_loss = 2.471, time/batch = 0.215\n",
            "6957/15750 (epoch 22), train_loss = 2.461, time/batch = 0.210\n",
            "6958/15750 (epoch 22), train_loss = 2.575, time/batch = 0.214\n",
            "6959/15750 (epoch 22), train_loss = 2.480, time/batch = 0.216\n",
            "6960/15750 (epoch 22), train_loss = 2.444, time/batch = 0.212\n",
            "6961/15750 (epoch 22), train_loss = 2.413, time/batch = 0.204\n",
            "6962/15750 (epoch 22), train_loss = 2.323, time/batch = 0.212\n",
            "6963/15750 (epoch 22), train_loss = 2.346, time/batch = 0.207\n",
            "6964/15750 (epoch 22), train_loss = 2.428, time/batch = 0.208\n",
            "6965/15750 (epoch 22), train_loss = 2.333, time/batch = 0.216\n",
            "6966/15750 (epoch 22), train_loss = 2.388, time/batch = 0.202\n",
            "6967/15750 (epoch 22), train_loss = 2.451, time/batch = 0.212\n",
            "6968/15750 (epoch 22), train_loss = 2.361, time/batch = 0.206\n",
            "6969/15750 (epoch 22), train_loss = 2.409, time/batch = 0.210\n",
            "6970/15750 (epoch 22), train_loss = 2.365, time/batch = 0.216\n",
            "6971/15750 (epoch 22), train_loss = 2.418, time/batch = 0.208\n",
            "6972/15750 (epoch 22), train_loss = 2.413, time/batch = 0.213\n",
            "6973/15750 (epoch 22), train_loss = 2.372, time/batch = 0.208\n",
            "6974/15750 (epoch 22), train_loss = 2.412, time/batch = 0.212\n",
            "6975/15750 (epoch 22), train_loss = 2.327, time/batch = 0.217\n",
            "6976/15750 (epoch 22), train_loss = 2.369, time/batch = 0.207\n",
            "6977/15750 (epoch 22), train_loss = 2.399, time/batch = 0.209\n",
            "6978/15750 (epoch 22), train_loss = 2.436, time/batch = 0.208\n",
            "6979/15750 (epoch 22), train_loss = 2.325, time/batch = 0.211\n",
            "6980/15750 (epoch 22), train_loss = 2.380, time/batch = 0.220\n",
            "6981/15750 (epoch 22), train_loss = 2.337, time/batch = 0.212\n",
            "6982/15750 (epoch 22), train_loss = 2.398, time/batch = 0.208\n",
            "6983/15750 (epoch 22), train_loss = 2.408, time/batch = 0.210\n",
            "6984/15750 (epoch 22), train_loss = 2.406, time/batch = 0.211\n",
            "6985/15750 (epoch 22), train_loss = 2.440, time/batch = 0.216\n",
            "6986/15750 (epoch 22), train_loss = 2.318, time/batch = 0.209\n",
            "6987/15750 (epoch 22), train_loss = 2.325, time/batch = 0.210\n",
            "6988/15750 (epoch 22), train_loss = 2.410, time/batch = 0.207\n",
            "6989/15750 (epoch 22), train_loss = 2.271, time/batch = 0.209\n",
            "6990/15750 (epoch 22), train_loss = 2.375, time/batch = 0.218\n",
            "6991/15750 (epoch 22), train_loss = 2.383, time/batch = 0.211\n",
            "6992/15750 (epoch 22), train_loss = 2.309, time/batch = 0.212\n",
            "6993/15750 (epoch 22), train_loss = 2.361, time/batch = 0.208\n",
            "6994/15750 (epoch 22), train_loss = 2.278, time/batch = 0.202\n",
            "6995/15750 (epoch 22), train_loss = 2.295, time/batch = 0.217\n",
            "6996/15750 (epoch 22), train_loss = 2.238, time/batch = 0.213\n",
            "6997/15750 (epoch 22), train_loss = 2.261, time/batch = 0.209\n",
            "6998/15750 (epoch 22), train_loss = 2.316, time/batch = 0.208\n",
            "6999/15750 (epoch 22), train_loss = 2.401, time/batch = 0.212\n",
            "7000/15750 (epoch 22), train_loss = 2.329, time/batch = 0.206\n",
            "model saved to ./save_star/model.ckpt\n",
            "7001/15750 (epoch 22), train_loss = 2.317, time/batch = 0.212\n",
            "7002/15750 (epoch 22), train_loss = 2.227, time/batch = 0.203\n",
            "7003/15750 (epoch 22), train_loss = 2.313, time/batch = 0.212\n",
            "7004/15750 (epoch 22), train_loss = 2.418, time/batch = 0.209\n",
            "7005/15750 (epoch 22), train_loss = 2.353, time/batch = 0.211\n",
            "7006/15750 (epoch 22), train_loss = 2.346, time/batch = 0.211\n",
            "7007/15750 (epoch 22), train_loss = 2.351, time/batch = 0.204\n",
            "7008/15750 (epoch 22), train_loss = 2.359, time/batch = 0.209\n",
            "7009/15750 (epoch 22), train_loss = 2.351, time/batch = 0.206\n",
            "7010/15750 (epoch 22), train_loss = 2.255, time/batch = 0.214\n",
            "7011/15750 (epoch 22), train_loss = 2.359, time/batch = 0.211\n",
            "7012/15750 (epoch 22), train_loss = 2.295, time/batch = 0.213\n",
            "7013/15750 (epoch 22), train_loss = 2.354, time/batch = 0.216\n",
            "7014/15750 (epoch 22), train_loss = 2.416, time/batch = 0.212\n",
            "7015/15750 (epoch 22), train_loss = 2.435, time/batch = 0.213\n",
            "7016/15750 (epoch 22), train_loss = 2.269, time/batch = 0.211\n",
            "7017/15750 (epoch 22), train_loss = 2.303, time/batch = 0.215\n",
            "7018/15750 (epoch 22), train_loss = 2.323, time/batch = 0.203\n",
            "7019/15750 (epoch 22), train_loss = 2.320, time/batch = 0.208\n",
            "7020/15750 (epoch 22), train_loss = 2.329, time/batch = 0.205\n",
            "7021/15750 (epoch 22), train_loss = 2.384, time/batch = 0.202\n",
            "7022/15750 (epoch 22), train_loss = 2.375, time/batch = 0.207\n",
            "7023/15750 (epoch 22), train_loss = 2.388, time/batch = 0.206\n",
            "7024/15750 (epoch 22), train_loss = 2.452, time/batch = 0.204\n",
            "7025/15750 (epoch 22), train_loss = 2.346, time/batch = 0.207\n",
            "7026/15750 (epoch 22), train_loss = 2.374, time/batch = 0.209\n",
            "7027/15750 (epoch 22), train_loss = 2.389, time/batch = 0.216\n",
            "7028/15750 (epoch 22), train_loss = 2.385, time/batch = 0.210\n",
            "7029/15750 (epoch 22), train_loss = 2.396, time/batch = 0.210\n",
            "7030/15750 (epoch 22), train_loss = 2.374, time/batch = 0.211\n",
            "7031/15750 (epoch 22), train_loss = 2.302, time/batch = 0.211\n",
            "7032/15750 (epoch 22), train_loss = 2.329, time/batch = 0.216\n",
            "7033/15750 (epoch 22), train_loss = 2.454, time/batch = 0.215\n",
            "7034/15750 (epoch 22), train_loss = 2.380, time/batch = 0.209\n",
            "7035/15750 (epoch 22), train_loss = 2.294, time/batch = 0.201\n",
            "7036/15750 (epoch 22), train_loss = 2.355, time/batch = 0.203\n",
            "7037/15750 (epoch 22), train_loss = 2.371, time/batch = 0.216\n",
            "7038/15750 (epoch 22), train_loss = 2.420, time/batch = 0.202\n",
            "7039/15750 (epoch 22), train_loss = 2.442, time/batch = 0.211\n",
            "7040/15750 (epoch 22), train_loss = 2.489, time/batch = 0.213\n",
            "7041/15750 (epoch 22), train_loss = 2.364, time/batch = 0.212\n",
            "7042/15750 (epoch 22), train_loss = 2.352, time/batch = 0.215\n",
            "7043/15750 (epoch 22), train_loss = 2.367, time/batch = 0.210\n",
            "7044/15750 (epoch 22), train_loss = 2.382, time/batch = 0.207\n",
            "7045/15750 (epoch 22), train_loss = 2.452, time/batch = 0.211\n",
            "7046/15750 (epoch 22), train_loss = 2.376, time/batch = 0.219\n",
            "7047/15750 (epoch 22), train_loss = 2.504, time/batch = 0.202\n",
            "7048/15750 (epoch 22), train_loss = 2.381, time/batch = 0.207\n",
            "7049/15750 (epoch 22), train_loss = 2.358, time/batch = 0.218\n",
            "7050/15750 (epoch 22), train_loss = 2.336, time/batch = 0.202\n",
            "7051/15750 (epoch 22), train_loss = 2.315, time/batch = 0.215\n",
            "7052/15750 (epoch 22), train_loss = 2.352, time/batch = 0.209\n",
            "7053/15750 (epoch 22), train_loss = 2.322, time/batch = 0.217\n",
            "7054/15750 (epoch 22), train_loss = 2.351, time/batch = 0.215\n",
            "7055/15750 (epoch 22), train_loss = 2.366, time/batch = 0.204\n",
            "7056/15750 (epoch 22), train_loss = 2.453, time/batch = 0.213\n",
            "7057/15750 (epoch 22), train_loss = 2.326, time/batch = 0.212\n",
            "7058/15750 (epoch 22), train_loss = 2.340, time/batch = 0.203\n",
            "7059/15750 (epoch 22), train_loss = 2.330, time/batch = 0.205\n",
            "7060/15750 (epoch 22), train_loss = 2.267, time/batch = 0.210\n",
            "7061/15750 (epoch 22), train_loss = 2.276, time/batch = 0.218\n",
            "7062/15750 (epoch 22), train_loss = 2.291, time/batch = 0.213\n",
            "7063/15750 (epoch 22), train_loss = 2.303, time/batch = 0.212\n",
            "7064/15750 (epoch 22), train_loss = 2.335, time/batch = 0.211\n",
            "7065/15750 (epoch 22), train_loss = 2.458, time/batch = 0.210\n",
            "7066/15750 (epoch 22), train_loss = 2.414, time/batch = 0.208\n",
            "7067/15750 (epoch 22), train_loss = 2.417, time/batch = 0.216\n",
            "7068/15750 (epoch 22), train_loss = 2.408, time/batch = 0.222\n",
            "7069/15750 (epoch 22), train_loss = 2.336, time/batch = 0.216\n",
            "7070/15750 (epoch 22), train_loss = 2.334, time/batch = 0.202\n",
            "7071/15750 (epoch 22), train_loss = 2.419, time/batch = 0.216\n",
            "7072/15750 (epoch 22), train_loss = 2.439, time/batch = 0.207\n",
            "7073/15750 (epoch 22), train_loss = 2.428, time/batch = 0.215\n",
            "7074/15750 (epoch 22), train_loss = 2.340, time/batch = 0.206\n",
            "7075/15750 (epoch 22), train_loss = 2.336, time/batch = 0.213\n",
            "7076/15750 (epoch 22), train_loss = 2.292, time/batch = 0.211\n",
            "7077/15750 (epoch 22), train_loss = 2.379, time/batch = 0.209\n",
            "7078/15750 (epoch 22), train_loss = 2.408, time/batch = 0.209\n",
            "7079/15750 (epoch 22), train_loss = 2.353, time/batch = 0.213\n",
            "7080/15750 (epoch 22), train_loss = 2.357, time/batch = 0.212\n",
            "7081/15750 (epoch 22), train_loss = 2.397, time/batch = 0.202\n",
            "7082/15750 (epoch 22), train_loss = 2.448, time/batch = 0.219\n",
            "7083/15750 (epoch 22), train_loss = 2.394, time/batch = 0.210\n",
            "7084/15750 (epoch 22), train_loss = 2.405, time/batch = 0.216\n",
            "7085/15750 (epoch 22), train_loss = 2.390, time/batch = 0.214\n",
            "7086/15750 (epoch 22), train_loss = 2.394, time/batch = 0.213\n",
            "7087/15750 (epoch 22), train_loss = 2.381, time/batch = 0.212\n",
            "7088/15750 (epoch 22), train_loss = 2.475, time/batch = 0.212\n",
            "7089/15750 (epoch 22), train_loss = 2.332, time/batch = 0.208\n",
            "7090/15750 (epoch 22), train_loss = 2.403, time/batch = 0.214\n",
            "7091/15750 (epoch 22), train_loss = 2.401, time/batch = 0.205\n",
            "7092/15750 (epoch 22), train_loss = 2.424, time/batch = 0.218\n",
            "7093/15750 (epoch 22), train_loss = 2.508, time/batch = 0.206\n",
            "7094/15750 (epoch 22), train_loss = 2.424, time/batch = 0.210\n",
            "7095/15750 (epoch 22), train_loss = 2.426, time/batch = 0.218\n",
            "7096/15750 (epoch 22), train_loss = 2.408, time/batch = 0.211\n",
            "7097/15750 (epoch 22), train_loss = 2.368, time/batch = 0.211\n",
            "7098/15750 (epoch 22), train_loss = 2.335, time/batch = 0.218\n",
            "7099/15750 (epoch 22), train_loss = 2.329, time/batch = 0.206\n",
            "7100/15750 (epoch 22), train_loss = 2.377, time/batch = 0.222\n",
            "7101/15750 (epoch 22), train_loss = 2.416, time/batch = 0.213\n",
            "7102/15750 (epoch 22), train_loss = 2.378, time/batch = 0.208\n",
            "7103/15750 (epoch 22), train_loss = 2.431, time/batch = 0.213\n",
            "7104/15750 (epoch 22), train_loss = 2.386, time/batch = 0.211\n",
            "7105/15750 (epoch 22), train_loss = 2.313, time/batch = 0.203\n",
            "7106/15750 (epoch 22), train_loss = 2.343, time/batch = 0.211\n",
            "7107/15750 (epoch 22), train_loss = 2.395, time/batch = 0.207\n",
            "7108/15750 (epoch 22), train_loss = 2.330, time/batch = 0.212\n",
            "7109/15750 (epoch 22), train_loss = 2.296, time/batch = 0.215\n",
            "7110/15750 (epoch 22), train_loss = 2.324, time/batch = 0.206\n",
            "7111/15750 (epoch 22), train_loss = 2.412, time/batch = 0.213\n",
            "7112/15750 (epoch 22), train_loss = 2.373, time/batch = 0.211\n",
            "7113/15750 (epoch 22), train_loss = 2.439, time/batch = 0.198\n",
            "7114/15750 (epoch 22), train_loss = 2.437, time/batch = 0.213\n",
            "7115/15750 (epoch 22), train_loss = 2.365, time/batch = 0.210\n",
            "7116/15750 (epoch 22), train_loss = 2.331, time/batch = 0.208\n",
            "7117/15750 (epoch 22), train_loss = 2.403, time/batch = 0.210\n",
            "7118/15750 (epoch 22), train_loss = 2.438, time/batch = 0.204\n",
            "7119/15750 (epoch 22), train_loss = 2.508, time/batch = 0.213\n",
            "7120/15750 (epoch 22), train_loss = 2.465, time/batch = 0.214\n",
            "7121/15750 (epoch 22), train_loss = 2.386, time/batch = 0.207\n",
            "7122/15750 (epoch 22), train_loss = 2.398, time/batch = 0.216\n",
            "7123/15750 (epoch 22), train_loss = 2.327, time/batch = 0.213\n",
            "7124/15750 (epoch 22), train_loss = 2.446, time/batch = 0.216\n",
            "7125/15750 (epoch 22), train_loss = 2.437, time/batch = 0.203\n",
            "7126/15750 (epoch 22), train_loss = 2.383, time/batch = 0.205\n",
            "7127/15750 (epoch 22), train_loss = 2.330, time/batch = 0.215\n",
            "7128/15750 (epoch 22), train_loss = 2.425, time/batch = 0.203\n",
            "7129/15750 (epoch 22), train_loss = 2.225, time/batch = 0.217\n",
            "7130/15750 (epoch 22), train_loss = 2.329, time/batch = 0.215\n",
            "7131/15750 (epoch 22), train_loss = 2.290, time/batch = 0.216\n",
            "7132/15750 (epoch 22), train_loss = 2.370, time/batch = 0.215\n",
            "7133/15750 (epoch 22), train_loss = 2.345, time/batch = 0.213\n",
            "7134/15750 (epoch 22), train_loss = 2.408, time/batch = 0.215\n",
            "7135/15750 (epoch 22), train_loss = 2.365, time/batch = 0.199\n",
            "7136/15750 (epoch 22), train_loss = 2.237, time/batch = 0.204\n",
            "7137/15750 (epoch 22), train_loss = 2.312, time/batch = 0.195\n",
            "7138/15750 (epoch 22), train_loss = 2.317, time/batch = 0.208\n",
            "7139/15750 (epoch 22), train_loss = 2.375, time/batch = 0.211\n",
            "7140/15750 (epoch 22), train_loss = 2.251, time/batch = 0.209\n",
            "7141/15750 (epoch 22), train_loss = 2.338, time/batch = 0.215\n",
            "7142/15750 (epoch 22), train_loss = 2.223, time/batch = 0.211\n",
            "7143/15750 (epoch 22), train_loss = 2.295, time/batch = 0.206\n",
            "7144/15750 (epoch 22), train_loss = 2.291, time/batch = 0.209\n",
            "7145/15750 (epoch 22), train_loss = 2.285, time/batch = 0.211\n",
            "7146/15750 (epoch 22), train_loss = 2.435, time/batch = 0.211\n",
            "7147/15750 (epoch 22), train_loss = 2.250, time/batch = 0.213\n",
            "7148/15750 (epoch 22), train_loss = 2.498, time/batch = 0.215\n",
            "7149/15750 (epoch 22), train_loss = 2.358, time/batch = 0.202\n",
            "7150/15750 (epoch 22), train_loss = 2.241, time/batch = 0.200\n",
            "7151/15750 (epoch 22), train_loss = 2.285, time/batch = 0.200\n",
            "7152/15750 (epoch 22), train_loss = 2.343, time/batch = 0.201\n",
            "7153/15750 (epoch 22), train_loss = 2.334, time/batch = 0.201\n",
            "7154/15750 (epoch 22), train_loss = 2.321, time/batch = 0.202\n",
            "7155/15750 (epoch 22), train_loss = 2.321, time/batch = 0.205\n",
            "7156/15750 (epoch 22), train_loss = 2.399, time/batch = 0.204\n",
            "7157/15750 (epoch 22), train_loss = 2.312, time/batch = 0.203\n",
            "7158/15750 (epoch 22), train_loss = 2.355, time/batch = 0.205\n",
            "7159/15750 (epoch 22), train_loss = 2.435, time/batch = 0.211\n",
            "7160/15750 (epoch 22), train_loss = 2.284, time/batch = 0.211\n",
            "7161/15750 (epoch 22), train_loss = 2.309, time/batch = 0.207\n",
            "7162/15750 (epoch 22), train_loss = 2.351, time/batch = 0.210\n",
            "7163/15750 (epoch 22), train_loss = 2.350, time/batch = 0.207\n",
            "7164/15750 (epoch 22), train_loss = 2.296, time/batch = 0.206\n",
            "7165/15750 (epoch 22), train_loss = 2.294, time/batch = 0.215\n",
            "7166/15750 (epoch 22), train_loss = 2.265, time/batch = 0.208\n",
            "7167/15750 (epoch 22), train_loss = 2.325, time/batch = 0.207\n",
            "7168/15750 (epoch 22), train_loss = 2.539, time/batch = 0.214\n",
            "7169/15750 (epoch 22), train_loss = 2.347, time/batch = 0.212\n",
            "7170/15750 (epoch 22), train_loss = 2.401, time/batch = 0.207\n",
            "7171/15750 (epoch 22), train_loss = 2.275, time/batch = 0.209\n",
            "7172/15750 (epoch 22), train_loss = 2.338, time/batch = 0.209\n",
            "7173/15750 (epoch 22), train_loss = 2.359, time/batch = 0.209\n",
            "7174/15750 (epoch 22), train_loss = 2.357, time/batch = 0.210\n",
            "7175/15750 (epoch 22), train_loss = 2.416, time/batch = 0.210\n",
            "7176/15750 (epoch 22), train_loss = 2.383, time/batch = 0.209\n",
            "7177/15750 (epoch 22), train_loss = 2.372, time/batch = 0.206\n",
            "7178/15750 (epoch 22), train_loss = 2.359, time/batch = 0.223\n",
            "7179/15750 (epoch 22), train_loss = 2.386, time/batch = 0.208\n",
            "7180/15750 (epoch 22), train_loss = 2.283, time/batch = 0.211\n",
            "7181/15750 (epoch 22), train_loss = 2.278, time/batch = 0.207\n",
            "7182/15750 (epoch 22), train_loss = 2.360, time/batch = 0.203\n",
            "7183/15750 (epoch 22), train_loss = 2.374, time/batch = 0.212\n",
            "7184/15750 (epoch 22), train_loss = 2.343, time/batch = 0.211\n",
            "7185/15750 (epoch 22), train_loss = 2.314, time/batch = 0.200\n",
            "7186/15750 (epoch 22), train_loss = 2.262, time/batch = 0.200\n",
            "7187/15750 (epoch 22), train_loss = 2.281, time/batch = 0.207\n",
            "7188/15750 (epoch 22), train_loss = 2.447, time/batch = 0.204\n",
            "7189/15750 (epoch 22), train_loss = 2.414, time/batch = 0.200\n",
            "7190/15750 (epoch 22), train_loss = 2.383, time/batch = 0.195\n",
            "7191/15750 (epoch 22), train_loss = 2.330, time/batch = 0.203\n",
            "7192/15750 (epoch 22), train_loss = 2.361, time/batch = 0.203\n",
            "7193/15750 (epoch 22), train_loss = 2.339, time/batch = 0.205\n",
            "7194/15750 (epoch 22), train_loss = 2.380, time/batch = 0.201\n",
            "7195/15750 (epoch 22), train_loss = 2.427, time/batch = 0.201\n",
            "7196/15750 (epoch 22), train_loss = 2.436, time/batch = 0.195\n",
            "7197/15750 (epoch 22), train_loss = 2.350, time/batch = 0.203\n",
            "7198/15750 (epoch 22), train_loss = 2.390, time/batch = 0.208\n",
            "7199/15750 (epoch 22), train_loss = 2.412, time/batch = 0.196\n",
            "7200/15750 (epoch 22), train_loss = 2.403, time/batch = 0.205\n",
            "7201/15750 (epoch 22), train_loss = 2.300, time/batch = 0.202\n",
            "7202/15750 (epoch 22), train_loss = 2.337, time/batch = 0.198\n",
            "7203/15750 (epoch 22), train_loss = 2.404, time/batch = 0.207\n",
            "7204/15750 (epoch 22), train_loss = 2.422, time/batch = 0.203\n",
            "7205/15750 (epoch 22), train_loss = 2.379, time/batch = 0.197\n",
            "7206/15750 (epoch 22), train_loss = 2.430, time/batch = 0.204\n",
            "7207/15750 (epoch 22), train_loss = 2.359, time/batch = 0.202\n",
            "7208/15750 (epoch 22), train_loss = 2.319, time/batch = 0.199\n",
            "7209/15750 (epoch 22), train_loss = 2.275, time/batch = 0.202\n",
            "7210/15750 (epoch 22), train_loss = 2.515, time/batch = 0.200\n",
            "7211/15750 (epoch 22), train_loss = 2.339, time/batch = 0.202\n",
            "7212/15750 (epoch 22), train_loss = 2.299, time/batch = 0.206\n",
            "7213/15750 (epoch 22), train_loss = 2.419, time/batch = 0.206\n",
            "7214/15750 (epoch 22), train_loss = 2.312, time/batch = 0.200\n",
            "7215/15750 (epoch 22), train_loss = 2.458, time/batch = 0.198\n",
            "7216/15750 (epoch 22), train_loss = 2.337, time/batch = 0.202\n",
            "7217/15750 (epoch 22), train_loss = 2.352, time/batch = 0.196\n",
            "7218/15750 (epoch 22), train_loss = 2.273, time/batch = 0.208\n",
            "7219/15750 (epoch 22), train_loss = 2.369, time/batch = 0.203\n",
            "7220/15750 (epoch 22), train_loss = 2.297, time/batch = 0.202\n",
            "7221/15750 (epoch 22), train_loss = 2.377, time/batch = 0.201\n",
            "7222/15750 (epoch 22), train_loss = 2.368, time/batch = 0.200\n",
            "7223/15750 (epoch 22), train_loss = 2.334, time/batch = 0.203\n",
            "7224/15750 (epoch 22), train_loss = 2.383, time/batch = 0.204\n",
            "7225/15750 (epoch 22), train_loss = 2.466, time/batch = 0.204\n",
            "7226/15750 (epoch 22), train_loss = 2.422, time/batch = 0.202\n",
            "7227/15750 (epoch 22), train_loss = 2.436, time/batch = 0.198\n",
            "7228/15750 (epoch 22), train_loss = 2.303, time/batch = 0.200\n",
            "7229/15750 (epoch 22), train_loss = 2.379, time/batch = 0.196\n",
            "7230/15750 (epoch 22), train_loss = 2.370, time/batch = 0.205\n",
            "7231/15750 (epoch 22), train_loss = 2.287, time/batch = 0.204\n",
            "7232/15750 (epoch 22), train_loss = 2.418, time/batch = 0.200\n",
            "7233/15750 (epoch 22), train_loss = 2.275, time/batch = 0.205\n",
            "7234/15750 (epoch 22), train_loss = 2.409, time/batch = 0.203\n",
            "7235/15750 (epoch 22), train_loss = 2.353, time/batch = 0.204\n",
            "7236/15750 (epoch 22), train_loss = 2.325, time/batch = 0.200\n",
            "7237/15750 (epoch 22), train_loss = 2.278, time/batch = 0.205\n",
            "7238/15750 (epoch 22), train_loss = 2.303, time/batch = 0.209\n",
            "7239/15750 (epoch 22), train_loss = 2.431, time/batch = 0.212\n",
            "7240/15750 (epoch 22), train_loss = 2.286, time/batch = 0.202\n",
            "7241/15750 (epoch 22), train_loss = 2.268, time/batch = 0.200\n",
            "7242/15750 (epoch 22), train_loss = 2.310, time/batch = 0.202\n",
            "7243/15750 (epoch 22), train_loss = 2.307, time/batch = 0.208\n",
            "7244/15750 (epoch 22), train_loss = 2.412, time/batch = 0.213\n",
            "7245/15750 (epoch 23), train_loss = 2.366, time/batch = 0.212\n",
            "7246/15750 (epoch 23), train_loss = 2.414, time/batch = 0.208\n",
            "7247/15750 (epoch 23), train_loss = 2.352, time/batch = 0.214\n",
            "7248/15750 (epoch 23), train_loss = 2.440, time/batch = 0.220\n",
            "7249/15750 (epoch 23), train_loss = 2.368, time/batch = 0.208\n",
            "7250/15750 (epoch 23), train_loss = 2.357, time/batch = 0.212\n",
            "7251/15750 (epoch 23), train_loss = 2.523, time/batch = 0.209\n",
            "7252/15750 (epoch 23), train_loss = 2.434, time/batch = 0.211\n",
            "7253/15750 (epoch 23), train_loss = 2.423, time/batch = 0.208\n",
            "7254/15750 (epoch 23), train_loss = 2.369, time/batch = 0.216\n",
            "7255/15750 (epoch 23), train_loss = 2.375, time/batch = 0.206\n",
            "7256/15750 (epoch 23), train_loss = 2.330, time/batch = 0.207\n",
            "7257/15750 (epoch 23), train_loss = 2.437, time/batch = 0.215\n",
            "7258/15750 (epoch 23), train_loss = 2.457, time/batch = 0.204\n",
            "7259/15750 (epoch 23), train_loss = 2.431, time/batch = 0.213\n",
            "7260/15750 (epoch 23), train_loss = 2.453, time/batch = 0.209\n",
            "7261/15750 (epoch 23), train_loss = 2.441, time/batch = 0.215\n",
            "7262/15750 (epoch 23), train_loss = 2.472, time/batch = 0.219\n",
            "7263/15750 (epoch 23), train_loss = 2.480, time/batch = 0.210\n",
            "7264/15750 (epoch 23), train_loss = 2.424, time/batch = 0.214\n",
            "7265/15750 (epoch 23), train_loss = 2.415, time/batch = 0.210\n",
            "7266/15750 (epoch 23), train_loss = 2.428, time/batch = 0.210\n",
            "7267/15750 (epoch 23), train_loss = 2.379, time/batch = 0.210\n",
            "7268/15750 (epoch 23), train_loss = 2.435, time/batch = 0.210\n",
            "7269/15750 (epoch 23), train_loss = 2.436, time/batch = 0.208\n",
            "7270/15750 (epoch 23), train_loss = 2.460, time/batch = 0.205\n",
            "7271/15750 (epoch 23), train_loss = 2.462, time/batch = 0.212\n",
            "7272/15750 (epoch 23), train_loss = 2.449, time/batch = 0.215\n",
            "7273/15750 (epoch 23), train_loss = 2.563, time/batch = 0.209\n",
            "7274/15750 (epoch 23), train_loss = 2.471, time/batch = 0.207\n",
            "7275/15750 (epoch 23), train_loss = 2.435, time/batch = 0.216\n",
            "7276/15750 (epoch 23), train_loss = 2.404, time/batch = 0.215\n",
            "7277/15750 (epoch 23), train_loss = 2.314, time/batch = 0.215\n",
            "7278/15750 (epoch 23), train_loss = 2.335, time/batch = 0.205\n",
            "7279/15750 (epoch 23), train_loss = 2.416, time/batch = 0.214\n",
            "7280/15750 (epoch 23), train_loss = 2.320, time/batch = 0.209\n",
            "7281/15750 (epoch 23), train_loss = 2.379, time/batch = 0.201\n",
            "7282/15750 (epoch 23), train_loss = 2.443, time/batch = 0.212\n",
            "7283/15750 (epoch 23), train_loss = 2.350, time/batch = 0.203\n",
            "7284/15750 (epoch 23), train_loss = 2.400, time/batch = 0.208\n",
            "7285/15750 (epoch 23), train_loss = 2.356, time/batch = 0.208\n",
            "7286/15750 (epoch 23), train_loss = 2.405, time/batch = 0.207\n",
            "7287/15750 (epoch 23), train_loss = 2.402, time/batch = 0.209\n",
            "7288/15750 (epoch 23), train_loss = 2.365, time/batch = 0.206\n",
            "7289/15750 (epoch 23), train_loss = 2.403, time/batch = 0.203\n",
            "7290/15750 (epoch 23), train_loss = 2.316, time/batch = 0.211\n",
            "7291/15750 (epoch 23), train_loss = 2.361, time/batch = 0.205\n",
            "7292/15750 (epoch 23), train_loss = 2.385, time/batch = 0.206\n",
            "7293/15750 (epoch 23), train_loss = 2.426, time/batch = 0.212\n",
            "7294/15750 (epoch 23), train_loss = 2.313, time/batch = 0.199\n",
            "7295/15750 (epoch 23), train_loss = 2.369, time/batch = 0.211\n",
            "7296/15750 (epoch 23), train_loss = 2.327, time/batch = 0.211\n",
            "7297/15750 (epoch 23), train_loss = 2.386, time/batch = 0.197\n",
            "7298/15750 (epoch 23), train_loss = 2.396, time/batch = 0.200\n",
            "7299/15750 (epoch 23), train_loss = 2.395, time/batch = 0.201\n",
            "7300/15750 (epoch 23), train_loss = 2.428, time/batch = 0.199\n",
            "7301/15750 (epoch 23), train_loss = 2.307, time/batch = 0.204\n",
            "7302/15750 (epoch 23), train_loss = 2.313, time/batch = 0.218\n",
            "7303/15750 (epoch 23), train_loss = 2.399, time/batch = 0.213\n",
            "7304/15750 (epoch 23), train_loss = 2.260, time/batch = 0.210\n",
            "7305/15750 (epoch 23), train_loss = 2.363, time/batch = 0.212\n",
            "7306/15750 (epoch 23), train_loss = 2.372, time/batch = 0.214\n",
            "7307/15750 (epoch 23), train_loss = 2.299, time/batch = 0.211\n",
            "7308/15750 (epoch 23), train_loss = 2.352, time/batch = 0.206\n",
            "7309/15750 (epoch 23), train_loss = 2.266, time/batch = 0.209\n",
            "7310/15750 (epoch 23), train_loss = 2.284, time/batch = 0.209\n",
            "7311/15750 (epoch 23), train_loss = 2.227, time/batch = 0.207\n",
            "7312/15750 (epoch 23), train_loss = 2.248, time/batch = 0.199\n",
            "7313/15750 (epoch 23), train_loss = 2.304, time/batch = 0.209\n",
            "7314/15750 (epoch 23), train_loss = 2.390, time/batch = 0.210\n",
            "7315/15750 (epoch 23), train_loss = 2.318, time/batch = 0.207\n",
            "7316/15750 (epoch 23), train_loss = 2.305, time/batch = 0.212\n",
            "7317/15750 (epoch 23), train_loss = 2.217, time/batch = 0.216\n",
            "7318/15750 (epoch 23), train_loss = 2.301, time/batch = 0.207\n",
            "7319/15750 (epoch 23), train_loss = 2.407, time/batch = 0.210\n",
            "7320/15750 (epoch 23), train_loss = 2.341, time/batch = 0.212\n",
            "7321/15750 (epoch 23), train_loss = 2.335, time/batch = 0.212\n",
            "7322/15750 (epoch 23), train_loss = 2.340, time/batch = 0.207\n",
            "7323/15750 (epoch 23), train_loss = 2.347, time/batch = 0.199\n",
            "7324/15750 (epoch 23), train_loss = 2.339, time/batch = 0.212\n",
            "7325/15750 (epoch 23), train_loss = 2.244, time/batch = 0.209\n",
            "7326/15750 (epoch 23), train_loss = 2.346, time/batch = 0.217\n",
            "7327/15750 (epoch 23), train_loss = 2.284, time/batch = 0.204\n",
            "7328/15750 (epoch 23), train_loss = 2.343, time/batch = 0.204\n",
            "7329/15750 (epoch 23), train_loss = 2.403, time/batch = 0.210\n",
            "7330/15750 (epoch 23), train_loss = 2.422, time/batch = 0.214\n",
            "7331/15750 (epoch 23), train_loss = 2.256, time/batch = 0.217\n",
            "7332/15750 (epoch 23), train_loss = 2.290, time/batch = 0.211\n",
            "7333/15750 (epoch 23), train_loss = 2.311, time/batch = 0.209\n",
            "7334/15750 (epoch 23), train_loss = 2.308, time/batch = 0.201\n",
            "7335/15750 (epoch 23), train_loss = 2.316, time/batch = 0.206\n",
            "7336/15750 (epoch 23), train_loss = 2.372, time/batch = 0.212\n",
            "7337/15750 (epoch 23), train_loss = 2.363, time/batch = 0.209\n",
            "7338/15750 (epoch 23), train_loss = 2.376, time/batch = 0.209\n",
            "7339/15750 (epoch 23), train_loss = 2.440, time/batch = 0.204\n",
            "7340/15750 (epoch 23), train_loss = 2.335, time/batch = 0.208\n",
            "7341/15750 (epoch 23), train_loss = 2.362, time/batch = 0.209\n",
            "7342/15750 (epoch 23), train_loss = 2.378, time/batch = 0.197\n",
            "7343/15750 (epoch 23), train_loss = 2.372, time/batch = 0.207\n",
            "7344/15750 (epoch 23), train_loss = 2.384, time/batch = 0.210\n",
            "7345/15750 (epoch 23), train_loss = 2.363, time/batch = 0.213\n",
            "7346/15750 (epoch 23), train_loss = 2.292, time/batch = 0.212\n",
            "7347/15750 (epoch 23), train_loss = 2.317, time/batch = 0.206\n",
            "7348/15750 (epoch 23), train_loss = 2.443, time/batch = 0.208\n",
            "7349/15750 (epoch 23), train_loss = 2.368, time/batch = 0.211\n",
            "7350/15750 (epoch 23), train_loss = 2.282, time/batch = 0.212\n",
            "7351/15750 (epoch 23), train_loss = 2.343, time/batch = 0.206\n",
            "7352/15750 (epoch 23), train_loss = 2.360, time/batch = 0.208\n",
            "7353/15750 (epoch 23), train_loss = 2.408, time/batch = 0.203\n",
            "7354/15750 (epoch 23), train_loss = 2.430, time/batch = 0.206\n",
            "7355/15750 (epoch 23), train_loss = 2.478, time/batch = 0.210\n",
            "7356/15750 (epoch 23), train_loss = 2.352, time/batch = 0.206\n",
            "7357/15750 (epoch 23), train_loss = 2.341, time/batch = 0.205\n",
            "7358/15750 (epoch 23), train_loss = 2.355, time/batch = 0.208\n",
            "7359/15750 (epoch 23), train_loss = 2.368, time/batch = 0.208\n",
            "7360/15750 (epoch 23), train_loss = 2.441, time/batch = 0.208\n",
            "7361/15750 (epoch 23), train_loss = 2.364, time/batch = 0.198\n",
            "7362/15750 (epoch 23), train_loss = 2.491, time/batch = 0.213\n",
            "7363/15750 (epoch 23), train_loss = 2.370, time/batch = 0.210\n",
            "7364/15750 (epoch 23), train_loss = 2.347, time/batch = 0.204\n",
            "7365/15750 (epoch 23), train_loss = 2.324, time/batch = 0.221\n",
            "7366/15750 (epoch 23), train_loss = 2.303, time/batch = 0.208\n",
            "7367/15750 (epoch 23), train_loss = 2.340, time/batch = 0.212\n",
            "7368/15750 (epoch 23), train_loss = 2.309, time/batch = 0.206\n",
            "7369/15750 (epoch 23), train_loss = 2.339, time/batch = 0.208\n",
            "7370/15750 (epoch 23), train_loss = 2.354, time/batch = 0.212\n",
            "7371/15750 (epoch 23), train_loss = 2.440, time/batch = 0.216\n",
            "7372/15750 (epoch 23), train_loss = 2.315, time/batch = 0.206\n",
            "7373/15750 (epoch 23), train_loss = 2.330, time/batch = 0.205\n",
            "7374/15750 (epoch 23), train_loss = 2.318, time/batch = 0.205\n",
            "7375/15750 (epoch 23), train_loss = 2.255, time/batch = 0.219\n",
            "7376/15750 (epoch 23), train_loss = 2.264, time/batch = 0.207\n",
            "7377/15750 (epoch 23), train_loss = 2.280, time/batch = 0.210\n",
            "7378/15750 (epoch 23), train_loss = 2.293, time/batch = 0.210\n",
            "7379/15750 (epoch 23), train_loss = 2.324, time/batch = 0.206\n",
            "7380/15750 (epoch 23), train_loss = 2.448, time/batch = 0.209\n",
            "7381/15750 (epoch 23), train_loss = 2.403, time/batch = 0.207\n",
            "7382/15750 (epoch 23), train_loss = 2.406, time/batch = 0.203\n",
            "7383/15750 (epoch 23), train_loss = 2.397, time/batch = 0.205\n",
            "7384/15750 (epoch 23), train_loss = 2.325, time/batch = 0.209\n",
            "7385/15750 (epoch 23), train_loss = 2.323, time/batch = 0.210\n",
            "7386/15750 (epoch 23), train_loss = 2.409, time/batch = 0.208\n",
            "7387/15750 (epoch 23), train_loss = 2.429, time/batch = 0.202\n",
            "7388/15750 (epoch 23), train_loss = 2.416, time/batch = 0.202\n",
            "7389/15750 (epoch 23), train_loss = 2.328, time/batch = 0.208\n",
            "7390/15750 (epoch 23), train_loss = 2.325, time/batch = 0.213\n",
            "7391/15750 (epoch 23), train_loss = 2.282, time/batch = 0.202\n",
            "7392/15750 (epoch 23), train_loss = 2.369, time/batch = 0.204\n",
            "7393/15750 (epoch 23), train_loss = 2.398, time/batch = 0.204\n",
            "7394/15750 (epoch 23), train_loss = 2.342, time/batch = 0.209\n",
            "7395/15750 (epoch 23), train_loss = 2.346, time/batch = 0.214\n",
            "7396/15750 (epoch 23), train_loss = 2.387, time/batch = 0.214\n",
            "7397/15750 (epoch 23), train_loss = 2.436, time/batch = 0.203\n",
            "7398/15750 (epoch 23), train_loss = 2.382, time/batch = 0.209\n",
            "7399/15750 (epoch 23), train_loss = 2.393, time/batch = 0.212\n",
            "7400/15750 (epoch 23), train_loss = 2.379, time/batch = 0.215\n",
            "7401/15750 (epoch 23), train_loss = 2.382, time/batch = 0.205\n",
            "7402/15750 (epoch 23), train_loss = 2.370, time/batch = 0.205\n",
            "7403/15750 (epoch 23), train_loss = 2.464, time/batch = 0.212\n",
            "7404/15750 (epoch 23), train_loss = 2.321, time/batch = 0.213\n",
            "7405/15750 (epoch 23), train_loss = 2.392, time/batch = 0.213\n",
            "7406/15750 (epoch 23), train_loss = 2.389, time/batch = 0.209\n",
            "7407/15750 (epoch 23), train_loss = 2.412, time/batch = 0.204\n",
            "7408/15750 (epoch 23), train_loss = 2.496, time/batch = 0.214\n",
            "7409/15750 (epoch 23), train_loss = 2.412, time/batch = 0.211\n",
            "7410/15750 (epoch 23), train_loss = 2.413, time/batch = 0.206\n",
            "7411/15750 (epoch 23), train_loss = 2.395, time/batch = 0.212\n",
            "7412/15750 (epoch 23), train_loss = 2.356, time/batch = 0.213\n",
            "7413/15750 (epoch 23), train_loss = 2.323, time/batch = 0.208\n",
            "7414/15750 (epoch 23), train_loss = 2.317, time/batch = 0.212\n",
            "7415/15750 (epoch 23), train_loss = 2.365, time/batch = 0.214\n",
            "7416/15750 (epoch 23), train_loss = 2.402, time/batch = 0.211\n",
            "7417/15750 (epoch 23), train_loss = 2.367, time/batch = 0.206\n",
            "7418/15750 (epoch 23), train_loss = 2.420, time/batch = 0.215\n",
            "7419/15750 (epoch 23), train_loss = 2.373, time/batch = 0.212\n",
            "7420/15750 (epoch 23), train_loss = 2.301, time/batch = 0.216\n",
            "7421/15750 (epoch 23), train_loss = 2.332, time/batch = 0.210\n",
            "7422/15750 (epoch 23), train_loss = 2.384, time/batch = 0.208\n",
            "7423/15750 (epoch 23), train_loss = 2.319, time/batch = 0.206\n",
            "7424/15750 (epoch 23), train_loss = 2.283, time/batch = 0.219\n",
            "7425/15750 (epoch 23), train_loss = 2.313, time/batch = 0.212\n",
            "7426/15750 (epoch 23), train_loss = 2.400, time/batch = 0.209\n",
            "7427/15750 (epoch 23), train_loss = 2.363, time/batch = 0.198\n",
            "7428/15750 (epoch 23), train_loss = 2.428, time/batch = 0.204\n",
            "7429/15750 (epoch 23), train_loss = 2.425, time/batch = 0.203\n",
            "7430/15750 (epoch 23), train_loss = 2.355, time/batch = 0.205\n",
            "7431/15750 (epoch 23), train_loss = 2.320, time/batch = 0.201\n",
            "7432/15750 (epoch 23), train_loss = 2.391, time/batch = 0.200\n",
            "7433/15750 (epoch 23), train_loss = 2.425, time/batch = 0.200\n",
            "7434/15750 (epoch 23), train_loss = 2.495, time/batch = 0.208\n",
            "7435/15750 (epoch 23), train_loss = 2.454, time/batch = 0.209\n",
            "7436/15750 (epoch 23), train_loss = 2.374, time/batch = 0.202\n",
            "7437/15750 (epoch 23), train_loss = 2.387, time/batch = 0.199\n",
            "7438/15750 (epoch 23), train_loss = 2.315, time/batch = 0.209\n",
            "7439/15750 (epoch 23), train_loss = 2.436, time/batch = 0.213\n",
            "7440/15750 (epoch 23), train_loss = 2.424, time/batch = 0.201\n",
            "7441/15750 (epoch 23), train_loss = 2.372, time/batch = 0.205\n",
            "7442/15750 (epoch 23), train_loss = 2.318, time/batch = 0.211\n",
            "7443/15750 (epoch 23), train_loss = 2.413, time/batch = 0.212\n",
            "7444/15750 (epoch 23), train_loss = 2.213, time/batch = 0.216\n",
            "7445/15750 (epoch 23), train_loss = 2.319, time/batch = 0.205\n",
            "7446/15750 (epoch 23), train_loss = 2.278, time/batch = 0.205\n",
            "7447/15750 (epoch 23), train_loss = 2.359, time/batch = 0.205\n",
            "7448/15750 (epoch 23), train_loss = 2.333, time/batch = 0.210\n",
            "7449/15750 (epoch 23), train_loss = 2.397, time/batch = 0.213\n",
            "7450/15750 (epoch 23), train_loss = 2.352, time/batch = 0.205\n",
            "7451/15750 (epoch 23), train_loss = 2.225, time/batch = 0.207\n",
            "7452/15750 (epoch 23), train_loss = 2.300, time/batch = 0.203\n",
            "7453/15750 (epoch 23), train_loss = 2.304, time/batch = 0.202\n",
            "7454/15750 (epoch 23), train_loss = 2.363, time/batch = 0.206\n",
            "7455/15750 (epoch 23), train_loss = 2.241, time/batch = 0.207\n",
            "7456/15750 (epoch 23), train_loss = 2.326, time/batch = 0.210\n",
            "7457/15750 (epoch 23), train_loss = 2.212, time/batch = 0.202\n",
            "7458/15750 (epoch 23), train_loss = 2.284, time/batch = 0.199\n",
            "7459/15750 (epoch 23), train_loss = 2.280, time/batch = 0.210\n",
            "7460/15750 (epoch 23), train_loss = 2.273, time/batch = 0.203\n",
            "7461/15750 (epoch 23), train_loss = 2.423, time/batch = 0.210\n",
            "7462/15750 (epoch 23), train_loss = 2.239, time/batch = 0.204\n",
            "7463/15750 (epoch 23), train_loss = 2.487, time/batch = 0.210\n",
            "7464/15750 (epoch 23), train_loss = 2.347, time/batch = 0.217\n",
            "7465/15750 (epoch 23), train_loss = 2.230, time/batch = 0.207\n",
            "7466/15750 (epoch 23), train_loss = 2.272, time/batch = 0.204\n",
            "7467/15750 (epoch 23), train_loss = 2.331, time/batch = 0.203\n",
            "7468/15750 (epoch 23), train_loss = 2.322, time/batch = 0.210\n",
            "7469/15750 (epoch 23), train_loss = 2.310, time/batch = 0.208\n",
            "7470/15750 (epoch 23), train_loss = 2.310, time/batch = 0.214\n",
            "7471/15750 (epoch 23), train_loss = 2.386, time/batch = 0.208\n",
            "7472/15750 (epoch 23), train_loss = 2.300, time/batch = 0.208\n",
            "7473/15750 (epoch 23), train_loss = 2.344, time/batch = 0.204\n",
            "7474/15750 (epoch 23), train_loss = 2.422, time/batch = 0.204\n",
            "7475/15750 (epoch 23), train_loss = 2.272, time/batch = 0.207\n",
            "7476/15750 (epoch 23), train_loss = 2.299, time/batch = 0.195\n",
            "7477/15750 (epoch 23), train_loss = 2.339, time/batch = 0.203\n",
            "7478/15750 (epoch 23), train_loss = 2.337, time/batch = 0.202\n",
            "7479/15750 (epoch 23), train_loss = 2.285, time/batch = 0.212\n",
            "7480/15750 (epoch 23), train_loss = 2.282, time/batch = 0.203\n",
            "7481/15750 (epoch 23), train_loss = 2.254, time/batch = 0.200\n",
            "7482/15750 (epoch 23), train_loss = 2.312, time/batch = 0.208\n",
            "7483/15750 (epoch 23), train_loss = 2.526, time/batch = 0.205\n",
            "7484/15750 (epoch 23), train_loss = 2.336, time/batch = 0.209\n",
            "7485/15750 (epoch 23), train_loss = 2.389, time/batch = 0.211\n",
            "7486/15750 (epoch 23), train_loss = 2.264, time/batch = 0.206\n",
            "7487/15750 (epoch 23), train_loss = 2.325, time/batch = 0.208\n",
            "7488/15750 (epoch 23), train_loss = 2.347, time/batch = 0.204\n",
            "7489/15750 (epoch 23), train_loss = 2.346, time/batch = 0.214\n",
            "7490/15750 (epoch 23), train_loss = 2.404, time/batch = 0.208\n",
            "7491/15750 (epoch 23), train_loss = 2.371, time/batch = 0.211\n",
            "7492/15750 (epoch 23), train_loss = 2.361, time/batch = 0.212\n",
            "7493/15750 (epoch 23), train_loss = 2.347, time/batch = 0.205\n",
            "7494/15750 (epoch 23), train_loss = 2.375, time/batch = 0.203\n",
            "7495/15750 (epoch 23), train_loss = 2.271, time/batch = 0.206\n",
            "7496/15750 (epoch 23), train_loss = 2.266, time/batch = 0.205\n",
            "7497/15750 (epoch 23), train_loss = 2.348, time/batch = 0.203\n",
            "7498/15750 (epoch 23), train_loss = 2.364, time/batch = 0.207\n",
            "7499/15750 (epoch 23), train_loss = 2.332, time/batch = 0.207\n",
            "7500/15750 (epoch 23), train_loss = 2.302, time/batch = 0.208\n",
            "7501/15750 (epoch 23), train_loss = 2.250, time/batch = 0.196\n",
            "7502/15750 (epoch 23), train_loss = 2.270, time/batch = 0.210\n",
            "7503/15750 (epoch 23), train_loss = 2.435, time/batch = 0.201\n",
            "7504/15750 (epoch 23), train_loss = 2.402, time/batch = 0.207\n",
            "7505/15750 (epoch 23), train_loss = 2.372, time/batch = 0.206\n",
            "7506/15750 (epoch 23), train_loss = 2.319, time/batch = 0.214\n",
            "7507/15750 (epoch 23), train_loss = 2.349, time/batch = 0.209\n",
            "7508/15750 (epoch 23), train_loss = 2.328, time/batch = 0.211\n",
            "7509/15750 (epoch 23), train_loss = 2.367, time/batch = 0.204\n",
            "7510/15750 (epoch 23), train_loss = 2.414, time/batch = 0.208\n",
            "7511/15750 (epoch 23), train_loss = 2.422, time/batch = 0.202\n",
            "7512/15750 (epoch 23), train_loss = 2.338, time/batch = 0.203\n",
            "7513/15750 (epoch 23), train_loss = 2.378, time/batch = 0.205\n",
            "7514/15750 (epoch 23), train_loss = 2.400, time/batch = 0.207\n",
            "7515/15750 (epoch 23), train_loss = 2.391, time/batch = 0.207\n",
            "7516/15750 (epoch 23), train_loss = 2.291, time/batch = 0.212\n",
            "7517/15750 (epoch 23), train_loss = 2.326, time/batch = 0.210\n",
            "7518/15750 (epoch 23), train_loss = 2.393, time/batch = 0.208\n",
            "7519/15750 (epoch 23), train_loss = 2.411, time/batch = 0.210\n",
            "7520/15750 (epoch 23), train_loss = 2.367, time/batch = 0.206\n",
            "7521/15750 (epoch 23), train_loss = 2.418, time/batch = 0.199\n",
            "7522/15750 (epoch 23), train_loss = 2.348, time/batch = 0.203\n",
            "7523/15750 (epoch 23), train_loss = 2.309, time/batch = 0.214\n",
            "7524/15750 (epoch 23), train_loss = 2.264, time/batch = 0.205\n",
            "7525/15750 (epoch 23), train_loss = 2.503, time/batch = 0.202\n",
            "7526/15750 (epoch 23), train_loss = 2.327, time/batch = 0.206\n",
            "7527/15750 (epoch 23), train_loss = 2.288, time/batch = 0.202\n",
            "7528/15750 (epoch 23), train_loss = 2.406, time/batch = 0.205\n",
            "7529/15750 (epoch 23), train_loss = 2.301, time/batch = 0.197\n",
            "7530/15750 (epoch 23), train_loss = 2.446, time/batch = 0.204\n",
            "7531/15750 (epoch 23), train_loss = 2.327, time/batch = 0.201\n",
            "7532/15750 (epoch 23), train_loss = 2.341, time/batch = 0.206\n",
            "7533/15750 (epoch 23), train_loss = 2.262, time/batch = 0.200\n",
            "7534/15750 (epoch 23), train_loss = 2.359, time/batch = 0.195\n",
            "7535/15750 (epoch 23), train_loss = 2.287, time/batch = 0.213\n",
            "7536/15750 (epoch 23), train_loss = 2.366, time/batch = 0.209\n",
            "7537/15750 (epoch 23), train_loss = 2.356, time/batch = 0.205\n",
            "7538/15750 (epoch 23), train_loss = 2.323, time/batch = 0.197\n",
            "7539/15750 (epoch 23), train_loss = 2.372, time/batch = 0.200\n",
            "7540/15750 (epoch 23), train_loss = 2.454, time/batch = 0.207\n",
            "7541/15750 (epoch 23), train_loss = 2.411, time/batch = 0.202\n",
            "7542/15750 (epoch 23), train_loss = 2.425, time/batch = 0.203\n",
            "7543/15750 (epoch 23), train_loss = 2.293, time/batch = 0.201\n",
            "7544/15750 (epoch 23), train_loss = 2.367, time/batch = 0.201\n",
            "7545/15750 (epoch 23), train_loss = 2.358, time/batch = 0.197\n",
            "7546/15750 (epoch 23), train_loss = 2.277, time/batch = 0.197\n",
            "7547/15750 (epoch 23), train_loss = 2.408, time/batch = 0.203\n",
            "7548/15750 (epoch 23), train_loss = 2.265, time/batch = 0.203\n",
            "7549/15750 (epoch 23), train_loss = 2.398, time/batch = 0.203\n",
            "7550/15750 (epoch 23), train_loss = 2.342, time/batch = 0.195\n",
            "7551/15750 (epoch 23), train_loss = 2.314, time/batch = 0.207\n",
            "7552/15750 (epoch 23), train_loss = 2.267, time/batch = 0.202\n",
            "7553/15750 (epoch 23), train_loss = 2.293, time/batch = 0.199\n",
            "7554/15750 (epoch 23), train_loss = 2.420, time/batch = 0.207\n",
            "7555/15750 (epoch 23), train_loss = 2.277, time/batch = 0.196\n",
            "7556/15750 (epoch 23), train_loss = 2.258, time/batch = 0.206\n",
            "7557/15750 (epoch 23), train_loss = 2.299, time/batch = 0.202\n",
            "7558/15750 (epoch 23), train_loss = 2.297, time/batch = 0.201\n",
            "7559/15750 (epoch 23), train_loss = 2.401, time/batch = 0.210\n",
            "7560/15750 (epoch 24), train_loss = 2.341, time/batch = 0.204\n",
            "7561/15750 (epoch 24), train_loss = 2.402, time/batch = 0.200\n",
            "7562/15750 (epoch 24), train_loss = 2.339, time/batch = 0.205\n",
            "7563/15750 (epoch 24), train_loss = 2.428, time/batch = 0.211\n",
            "7564/15750 (epoch 24), train_loss = 2.355, time/batch = 0.197\n",
            "7565/15750 (epoch 24), train_loss = 2.345, time/batch = 0.200\n",
            "7566/15750 (epoch 24), train_loss = 2.511, time/batch = 0.200\n",
            "7567/15750 (epoch 24), train_loss = 2.422, time/batch = 0.200\n",
            "7568/15750 (epoch 24), train_loss = 2.412, time/batch = 0.203\n",
            "7569/15750 (epoch 24), train_loss = 2.357, time/batch = 0.200\n",
            "7570/15750 (epoch 24), train_loss = 2.363, time/batch = 0.208\n",
            "7571/15750 (epoch 24), train_loss = 2.318, time/batch = 0.203\n",
            "7572/15750 (epoch 24), train_loss = 2.409, time/batch = 0.202\n",
            "7573/15750 (epoch 24), train_loss = 2.383, time/batch = 0.208\n",
            "7574/15750 (epoch 24), train_loss = 2.362, time/batch = 0.200\n",
            "7575/15750 (epoch 24), train_loss = 2.388, time/batch = 0.205\n",
            "7576/15750 (epoch 24), train_loss = 2.395, time/batch = 0.203\n",
            "7577/15750 (epoch 24), train_loss = 2.453, time/batch = 0.200\n",
            "7578/15750 (epoch 24), train_loss = 2.463, time/batch = 0.204\n",
            "7579/15750 (epoch 24), train_loss = 2.408, time/batch = 0.199\n",
            "7580/15750 (epoch 24), train_loss = 2.401, time/batch = 0.202\n",
            "7581/15750 (epoch 24), train_loss = 2.416, time/batch = 0.198\n",
            "7582/15750 (epoch 24), train_loss = 2.366, time/batch = 0.205\n",
            "7583/15750 (epoch 24), train_loss = 2.423, time/batch = 0.206\n",
            "7584/15750 (epoch 24), train_loss = 2.421, time/batch = 0.201\n",
            "7585/15750 (epoch 24), train_loss = 2.448, time/batch = 0.198\n",
            "7586/15750 (epoch 24), train_loss = 2.449, time/batch = 0.201\n",
            "7587/15750 (epoch 24), train_loss = 2.436, time/batch = 0.206\n",
            "7588/15750 (epoch 24), train_loss = 2.548, time/batch = 0.207\n",
            "7589/15750 (epoch 24), train_loss = 2.456, time/batch = 0.215\n",
            "7590/15750 (epoch 24), train_loss = 2.419, time/batch = 0.208\n",
            "7591/15750 (epoch 24), train_loss = 2.387, time/batch = 0.207\n",
            "7592/15750 (epoch 24), train_loss = 2.298, time/batch = 0.212\n",
            "7593/15750 (epoch 24), train_loss = 2.320, time/batch = 0.210\n",
            "7594/15750 (epoch 24), train_loss = 2.404, time/batch = 0.209\n",
            "7595/15750 (epoch 24), train_loss = 2.307, time/batch = 0.211\n",
            "7596/15750 (epoch 24), train_loss = 2.368, time/batch = 0.208\n",
            "7597/15750 (epoch 24), train_loss = 2.429, time/batch = 0.206\n",
            "7598/15750 (epoch 24), train_loss = 2.337, time/batch = 0.213\n",
            "7599/15750 (epoch 24), train_loss = 2.386, time/batch = 0.203\n",
            "7600/15750 (epoch 24), train_loss = 2.342, time/batch = 0.201\n",
            "7601/15750 (epoch 24), train_loss = 2.394, time/batch = 0.206\n",
            "7602/15750 (epoch 24), train_loss = 2.390, time/batch = 0.210\n",
            "7603/15750 (epoch 24), train_loss = 2.351, time/batch = 0.218\n",
            "7604/15750 (epoch 24), train_loss = 2.388, time/batch = 0.207\n",
            "7605/15750 (epoch 24), train_loss = 2.306, time/batch = 0.205\n",
            "7606/15750 (epoch 24), train_loss = 2.349, time/batch = 0.208\n",
            "7607/15750 (epoch 24), train_loss = 2.374, time/batch = 0.204\n",
            "7608/15750 (epoch 24), train_loss = 2.411, time/batch = 0.208\n",
            "7609/15750 (epoch 24), train_loss = 2.299, time/batch = 0.200\n",
            "7610/15750 (epoch 24), train_loss = 2.358, time/batch = 0.203\n",
            "7611/15750 (epoch 24), train_loss = 2.315, time/batch = 0.205\n",
            "7612/15750 (epoch 24), train_loss = 2.375, time/batch = 0.211\n",
            "7613/15750 (epoch 24), train_loss = 2.386, time/batch = 0.207\n",
            "7614/15750 (epoch 24), train_loss = 2.384, time/batch = 0.208\n",
            "7615/15750 (epoch 24), train_loss = 2.417, time/batch = 0.206\n",
            "7616/15750 (epoch 24), train_loss = 2.297, time/batch = 0.201\n",
            "7617/15750 (epoch 24), train_loss = 2.301, time/batch = 0.200\n",
            "7618/15750 (epoch 24), train_loss = 2.390, time/batch = 0.213\n",
            "7619/15750 (epoch 24), train_loss = 2.250, time/batch = 0.203\n",
            "7620/15750 (epoch 24), train_loss = 2.352, time/batch = 0.207\n",
            "7621/15750 (epoch 24), train_loss = 2.360, time/batch = 0.207\n",
            "7622/15750 (epoch 24), train_loss = 2.288, time/batch = 0.203\n",
            "7623/15750 (epoch 24), train_loss = 2.342, time/batch = 0.207\n",
            "7624/15750 (epoch 24), train_loss = 2.254, time/batch = 0.203\n",
            "7625/15750 (epoch 24), train_loss = 2.274, time/batch = 0.203\n",
            "7626/15750 (epoch 24), train_loss = 2.216, time/batch = 0.201\n",
            "7627/15750 (epoch 24), train_loss = 2.237, time/batch = 0.208\n",
            "7628/15750 (epoch 24), train_loss = 2.293, time/batch = 0.208\n",
            "7629/15750 (epoch 24), train_loss = 2.379, time/batch = 0.201\n",
            "7630/15750 (epoch 24), train_loss = 2.307, time/batch = 0.210\n",
            "7631/15750 (epoch 24), train_loss = 2.294, time/batch = 0.207\n",
            "7632/15750 (epoch 24), train_loss = 2.207, time/batch = 0.209\n",
            "7633/15750 (epoch 24), train_loss = 2.289, time/batch = 0.215\n",
            "7634/15750 (epoch 24), train_loss = 2.395, time/batch = 0.207\n",
            "7635/15750 (epoch 24), train_loss = 2.331, time/batch = 0.208\n",
            "7636/15750 (epoch 24), train_loss = 2.324, time/batch = 0.204\n",
            "7637/15750 (epoch 24), train_loss = 2.329, time/batch = 0.210\n",
            "7638/15750 (epoch 24), train_loss = 2.337, time/batch = 0.209\n",
            "7639/15750 (epoch 24), train_loss = 2.329, time/batch = 0.206\n",
            "7640/15750 (epoch 24), train_loss = 2.232, time/batch = 0.202\n",
            "7641/15750 (epoch 24), train_loss = 2.335, time/batch = 0.211\n",
            "7642/15750 (epoch 24), train_loss = 2.274, time/batch = 0.206\n",
            "7643/15750 (epoch 24), train_loss = 2.331, time/batch = 0.201\n",
            "7644/15750 (epoch 24), train_loss = 2.392, time/batch = 0.203\n",
            "7645/15750 (epoch 24), train_loss = 2.411, time/batch = 0.203\n",
            "7646/15750 (epoch 24), train_loss = 2.245, time/batch = 0.203\n",
            "7647/15750 (epoch 24), train_loss = 2.278, time/batch = 0.203\n",
            "7648/15750 (epoch 24), train_loss = 2.300, time/batch = 0.209\n",
            "7649/15750 (epoch 24), train_loss = 2.297, time/batch = 0.200\n",
            "7650/15750 (epoch 24), train_loss = 2.304, time/batch = 0.201\n",
            "7651/15750 (epoch 24), train_loss = 2.361, time/batch = 0.202\n",
            "7652/15750 (epoch 24), train_loss = 2.351, time/batch = 0.202\n",
            "7653/15750 (epoch 24), train_loss = 2.364, time/batch = 0.205\n",
            "7654/15750 (epoch 24), train_loss = 2.429, time/batch = 0.202\n",
            "7655/15750 (epoch 24), train_loss = 2.328, time/batch = 0.207\n",
            "7656/15750 (epoch 24), train_loss = 2.361, time/batch = 0.204\n",
            "7657/15750 (epoch 24), train_loss = 2.371, time/batch = 0.202\n",
            "7658/15750 (epoch 24), train_loss = 2.360, time/batch = 0.206\n",
            "7659/15750 (epoch 24), train_loss = 2.373, time/batch = 0.209\n",
            "7660/15750 (epoch 24), train_loss = 2.352, time/batch = 0.207\n",
            "7661/15750 (epoch 24), train_loss = 2.282, time/batch = 0.211\n",
            "7662/15750 (epoch 24), train_loss = 2.308, time/batch = 0.208\n",
            "7663/15750 (epoch 24), train_loss = 2.433, time/batch = 0.206\n",
            "7664/15750 (epoch 24), train_loss = 2.357, time/batch = 0.207\n",
            "7665/15750 (epoch 24), train_loss = 2.271, time/batch = 0.203\n",
            "7666/15750 (epoch 24), train_loss = 2.330, time/batch = 0.209\n",
            "7667/15750 (epoch 24), train_loss = 2.350, time/batch = 0.203\n",
            "7668/15750 (epoch 24), train_loss = 2.397, time/batch = 0.213\n",
            "7669/15750 (epoch 24), train_loss = 2.419, time/batch = 0.201\n",
            "7670/15750 (epoch 24), train_loss = 2.467, time/batch = 0.202\n",
            "7671/15750 (epoch 24), train_loss = 2.341, time/batch = 0.202\n",
            "7672/15750 (epoch 24), train_loss = 2.331, time/batch = 0.201\n",
            "7673/15750 (epoch 24), train_loss = 2.344, time/batch = 0.217\n",
            "7674/15750 (epoch 24), train_loss = 2.356, time/batch = 0.205\n",
            "7675/15750 (epoch 24), train_loss = 2.429, time/batch = 0.202\n",
            "7676/15750 (epoch 24), train_loss = 2.352, time/batch = 0.203\n",
            "7677/15750 (epoch 24), train_loss = 2.479, time/batch = 0.203\n",
            "7678/15750 (epoch 24), train_loss = 2.359, time/batch = 0.209\n",
            "7679/15750 (epoch 24), train_loss = 2.337, time/batch = 0.205\n",
            "7680/15750 (epoch 24), train_loss = 2.313, time/batch = 0.201\n",
            "7681/15750 (epoch 24), train_loss = 2.293, time/batch = 0.207\n",
            "7682/15750 (epoch 24), train_loss = 2.330, time/batch = 0.199\n",
            "7683/15750 (epoch 24), train_loss = 2.297, time/batch = 0.216\n",
            "7684/15750 (epoch 24), train_loss = 2.327, time/batch = 0.204\n",
            "7685/15750 (epoch 24), train_loss = 2.343, time/batch = 0.204\n",
            "7686/15750 (epoch 24), train_loss = 2.428, time/batch = 0.208\n",
            "7687/15750 (epoch 24), train_loss = 2.305, time/batch = 0.202\n",
            "7688/15750 (epoch 24), train_loss = 2.321, time/batch = 0.220\n",
            "7689/15750 (epoch 24), train_loss = 2.306, time/batch = 0.207\n",
            "7690/15750 (epoch 24), train_loss = 2.245, time/batch = 0.206\n",
            "7691/15750 (epoch 24), train_loss = 2.253, time/batch = 0.208\n",
            "7692/15750 (epoch 24), train_loss = 2.269, time/batch = 0.201\n",
            "7693/15750 (epoch 24), train_loss = 2.284, time/batch = 0.210\n",
            "7694/15750 (epoch 24), train_loss = 2.313, time/batch = 0.205\n",
            "7695/15750 (epoch 24), train_loss = 2.438, time/batch = 0.208\n",
            "7696/15750 (epoch 24), train_loss = 2.394, time/batch = 0.204\n",
            "7697/15750 (epoch 24), train_loss = 2.395, time/batch = 0.205\n",
            "7698/15750 (epoch 24), train_loss = 2.386, time/batch = 0.202\n",
            "7699/15750 (epoch 24), train_loss = 2.314, time/batch = 0.206\n",
            "7700/15750 (epoch 24), train_loss = 2.312, time/batch = 0.200\n",
            "7701/15750 (epoch 24), train_loss = 2.399, time/batch = 0.205\n",
            "7702/15750 (epoch 24), train_loss = 2.419, time/batch = 0.206\n",
            "7703/15750 (epoch 24), train_loss = 2.405, time/batch = 0.204\n",
            "7704/15750 (epoch 24), train_loss = 2.317, time/batch = 0.199\n",
            "7705/15750 (epoch 24), train_loss = 2.314, time/batch = 0.200\n",
            "7706/15750 (epoch 24), train_loss = 2.272, time/batch = 0.202\n",
            "7707/15750 (epoch 24), train_loss = 2.360, time/batch = 0.207\n",
            "7708/15750 (epoch 24), train_loss = 2.389, time/batch = 0.214\n",
            "7709/15750 (epoch 24), train_loss = 2.332, time/batch = 0.196\n",
            "7710/15750 (epoch 24), train_loss = 2.337, time/batch = 0.205\n",
            "7711/15750 (epoch 24), train_loss = 2.377, time/batch = 0.204\n",
            "7712/15750 (epoch 24), train_loss = 2.424, time/batch = 0.197\n",
            "7713/15750 (epoch 24), train_loss = 2.370, time/batch = 0.213\n",
            "7714/15750 (epoch 24), train_loss = 2.383, time/batch = 0.203\n",
            "7715/15750 (epoch 24), train_loss = 2.368, time/batch = 0.202\n",
            "7716/15750 (epoch 24), train_loss = 2.371, time/batch = 0.207\n",
            "7717/15750 (epoch 24), train_loss = 2.361, time/batch = 0.207\n",
            "7718/15750 (epoch 24), train_loss = 2.454, time/batch = 0.217\n",
            "7719/15750 (epoch 24), train_loss = 2.311, time/batch = 0.206\n",
            "7720/15750 (epoch 24), train_loss = 2.381, time/batch = 0.205\n",
            "7721/15750 (epoch 24), train_loss = 2.378, time/batch = 0.207\n",
            "7722/15750 (epoch 24), train_loss = 2.401, time/batch = 0.206\n",
            "7723/15750 (epoch 24), train_loss = 2.484, time/batch = 0.206\n",
            "7724/15750 (epoch 24), train_loss = 2.402, time/batch = 0.204\n",
            "7725/15750 (epoch 24), train_loss = 2.402, time/batch = 0.203\n",
            "7726/15750 (epoch 24), train_loss = 2.382, time/batch = 0.206\n",
            "7727/15750 (epoch 24), train_loss = 2.345, time/batch = 0.208\n",
            "7728/15750 (epoch 24), train_loss = 2.313, time/batch = 0.208\n",
            "7729/15750 (epoch 24), train_loss = 2.306, time/batch = 0.206\n",
            "7730/15750 (epoch 24), train_loss = 2.353, time/batch = 0.210\n",
            "7731/15750 (epoch 24), train_loss = 2.390, time/batch = 0.205\n",
            "7732/15750 (epoch 24), train_loss = 2.356, time/batch = 0.202\n",
            "7733/15750 (epoch 24), train_loss = 2.410, time/batch = 0.212\n",
            "7734/15750 (epoch 24), train_loss = 2.362, time/batch = 0.201\n",
            "7735/15750 (epoch 24), train_loss = 2.291, time/batch = 0.204\n",
            "7736/15750 (epoch 24), train_loss = 2.321, time/batch = 0.200\n",
            "7737/15750 (epoch 24), train_loss = 2.374, time/batch = 0.200\n",
            "7738/15750 (epoch 24), train_loss = 2.309, time/batch = 0.207\n",
            "7739/15750 (epoch 24), train_loss = 2.272, time/batch = 0.206\n",
            "7740/15750 (epoch 24), train_loss = 2.303, time/batch = 0.203\n",
            "7741/15750 (epoch 24), train_loss = 2.388, time/batch = 0.206\n",
            "7742/15750 (epoch 24), train_loss = 2.353, time/batch = 0.203\n",
            "7743/15750 (epoch 24), train_loss = 2.417, time/batch = 0.215\n",
            "7744/15750 (epoch 24), train_loss = 2.413, time/batch = 0.207\n",
            "7745/15750 (epoch 24), train_loss = 2.345, time/batch = 0.203\n",
            "7746/15750 (epoch 24), train_loss = 2.310, time/batch = 0.205\n",
            "7747/15750 (epoch 24), train_loss = 2.381, time/batch = 0.208\n",
            "7748/15750 (epoch 24), train_loss = 2.413, time/batch = 0.212\n",
            "7749/15750 (epoch 24), train_loss = 2.483, time/batch = 0.206\n",
            "7750/15750 (epoch 24), train_loss = 2.444, time/batch = 0.202\n",
            "7751/15750 (epoch 24), train_loss = 2.364, time/batch = 0.206\n",
            "7752/15750 (epoch 24), train_loss = 2.377, time/batch = 0.203\n",
            "7753/15750 (epoch 24), train_loss = 2.304, time/batch = 0.203\n",
            "7754/15750 (epoch 24), train_loss = 2.426, time/batch = 0.206\n",
            "7755/15750 (epoch 24), train_loss = 2.411, time/batch = 0.208\n",
            "7756/15750 (epoch 24), train_loss = 2.361, time/batch = 0.207\n",
            "7757/15750 (epoch 24), train_loss = 2.307, time/batch = 0.205\n",
            "7758/15750 (epoch 24), train_loss = 2.403, time/batch = 0.206\n",
            "7759/15750 (epoch 24), train_loss = 2.202, time/batch = 0.204\n",
            "7760/15750 (epoch 24), train_loss = 2.308, time/batch = 0.206\n",
            "7761/15750 (epoch 24), train_loss = 2.266, time/batch = 0.205\n",
            "7762/15750 (epoch 24), train_loss = 2.348, time/batch = 0.200\n",
            "7763/15750 (epoch 24), train_loss = 2.322, time/batch = 0.206\n",
            "7764/15750 (epoch 24), train_loss = 2.386, time/batch = 0.203\n",
            "7765/15750 (epoch 24), train_loss = 2.340, time/batch = 0.195\n",
            "7766/15750 (epoch 24), train_loss = 2.215, time/batch = 0.198\n",
            "7767/15750 (epoch 24), train_loss = 2.289, time/batch = 0.200\n",
            "7768/15750 (epoch 24), train_loss = 2.293, time/batch = 0.212\n",
            "7769/15750 (epoch 24), train_loss = 2.353, time/batch = 0.202\n",
            "7770/15750 (epoch 24), train_loss = 2.231, time/batch = 0.203\n",
            "7771/15750 (epoch 24), train_loss = 2.314, time/batch = 0.200\n",
            "7772/15750 (epoch 24), train_loss = 2.201, time/batch = 0.199\n",
            "7773/15750 (epoch 24), train_loss = 2.274, time/batch = 0.208\n",
            "7774/15750 (epoch 24), train_loss = 2.269, time/batch = 0.211\n",
            "7775/15750 (epoch 24), train_loss = 2.262, time/batch = 0.206\n",
            "7776/15750 (epoch 24), train_loss = 2.412, time/batch = 0.206\n",
            "7777/15750 (epoch 24), train_loss = 2.229, time/batch = 0.203\n",
            "7778/15750 (epoch 24), train_loss = 2.477, time/batch = 0.209\n",
            "7779/15750 (epoch 24), train_loss = 2.337, time/batch = 0.204\n",
            "7780/15750 (epoch 24), train_loss = 2.219, time/batch = 0.203\n",
            "7781/15750 (epoch 24), train_loss = 2.261, time/batch = 0.202\n",
            "7782/15750 (epoch 24), train_loss = 2.320, time/batch = 0.206\n",
            "7783/15750 (epoch 24), train_loss = 2.312, time/batch = 0.211\n",
            "7784/15750 (epoch 24), train_loss = 2.299, time/batch = 0.201\n",
            "7785/15750 (epoch 24), train_loss = 2.300, time/batch = 0.201\n",
            "7786/15750 (epoch 24), train_loss = 2.374, time/batch = 0.203\n",
            "7787/15750 (epoch 24), train_loss = 2.290, time/batch = 0.201\n",
            "7788/15750 (epoch 24), train_loss = 2.333, time/batch = 0.216\n",
            "7789/15750 (epoch 24), train_loss = 2.411, time/batch = 0.208\n",
            "7790/15750 (epoch 24), train_loss = 2.262, time/batch = 0.206\n",
            "7791/15750 (epoch 24), train_loss = 2.288, time/batch = 0.212\n",
            "7792/15750 (epoch 24), train_loss = 2.329, time/batch = 0.202\n",
            "7793/15750 (epoch 24), train_loss = 2.326, time/batch = 0.214\n",
            "7794/15750 (epoch 24), train_loss = 2.275, time/batch = 0.201\n",
            "7795/15750 (epoch 24), train_loss = 2.271, time/batch = 0.202\n",
            "7796/15750 (epoch 24), train_loss = 2.244, time/batch = 0.209\n",
            "7797/15750 (epoch 24), train_loss = 2.300, time/batch = 0.206\n",
            "7798/15750 (epoch 24), train_loss = 2.513, time/batch = 0.214\n",
            "7799/15750 (epoch 24), train_loss = 2.325, time/batch = 0.209\n",
            "7800/15750 (epoch 24), train_loss = 2.379, time/batch = 0.210\n",
            "7801/15750 (epoch 24), train_loss = 2.254, time/batch = 0.212\n",
            "7802/15750 (epoch 24), train_loss = 2.314, time/batch = 0.206\n",
            "7803/15750 (epoch 24), train_loss = 2.336, time/batch = 0.212\n",
            "7804/15750 (epoch 24), train_loss = 2.337, time/batch = 0.207\n",
            "7805/15750 (epoch 24), train_loss = 2.394, time/batch = 0.209\n",
            "7806/15750 (epoch 24), train_loss = 2.360, time/batch = 0.209\n",
            "7807/15750 (epoch 24), train_loss = 2.350, time/batch = 0.207\n",
            "7808/15750 (epoch 24), train_loss = 2.335, time/batch = 0.203\n",
            "7809/15750 (epoch 24), train_loss = 2.363, time/batch = 0.204\n",
            "7810/15750 (epoch 24), train_loss = 2.258, time/batch = 0.205\n",
            "7811/15750 (epoch 24), train_loss = 2.254, time/batch = 0.204\n",
            "7812/15750 (epoch 24), train_loss = 2.337, time/batch = 0.208\n",
            "7813/15750 (epoch 24), train_loss = 2.353, time/batch = 0.200\n",
            "7814/15750 (epoch 24), train_loss = 2.322, time/batch = 0.204\n",
            "7815/15750 (epoch 24), train_loss = 2.290, time/batch = 0.202\n",
            "7816/15750 (epoch 24), train_loss = 2.239, time/batch = 0.200\n",
            "7817/15750 (epoch 24), train_loss = 2.259, time/batch = 0.201\n",
            "7818/15750 (epoch 24), train_loss = 2.424, time/batch = 0.204\n",
            "7819/15750 (epoch 24), train_loss = 2.392, time/batch = 0.204\n",
            "7820/15750 (epoch 24), train_loss = 2.362, time/batch = 0.209\n",
            "7821/15750 (epoch 24), train_loss = 2.309, time/batch = 0.199\n",
            "7822/15750 (epoch 24), train_loss = 2.337, time/batch = 0.199\n",
            "7823/15750 (epoch 24), train_loss = 2.318, time/batch = 0.214\n",
            "7824/15750 (epoch 24), train_loss = 2.356, time/batch = 0.205\n",
            "7825/15750 (epoch 24), train_loss = 2.403, time/batch = 0.208\n",
            "7826/15750 (epoch 24), train_loss = 2.411, time/batch = 0.209\n",
            "7827/15750 (epoch 24), train_loss = 2.326, time/batch = 0.215\n",
            "7828/15750 (epoch 24), train_loss = 2.366, time/batch = 0.202\n",
            "7829/15750 (epoch 24), train_loss = 2.389, time/batch = 0.208\n",
            "7830/15750 (epoch 24), train_loss = 2.380, time/batch = 0.212\n",
            "7831/15750 (epoch 24), train_loss = 2.281, time/batch = 0.204\n",
            "7832/15750 (epoch 24), train_loss = 2.316, time/batch = 0.214\n",
            "7833/15750 (epoch 24), train_loss = 2.382, time/batch = 0.206\n",
            "7834/15750 (epoch 24), train_loss = 2.400, time/batch = 0.205\n",
            "7835/15750 (epoch 24), train_loss = 2.355, time/batch = 0.209\n",
            "7836/15750 (epoch 24), train_loss = 2.406, time/batch = 0.205\n",
            "7837/15750 (epoch 24), train_loss = 2.337, time/batch = 0.210\n",
            "7838/15750 (epoch 24), train_loss = 2.299, time/batch = 0.213\n",
            "7839/15750 (epoch 24), train_loss = 2.254, time/batch = 0.211\n",
            "7840/15750 (epoch 24), train_loss = 2.491, time/batch = 0.210\n",
            "7841/15750 (epoch 24), train_loss = 2.316, time/batch = 0.208\n",
            "7842/15750 (epoch 24), train_loss = 2.277, time/batch = 0.217\n",
            "7843/15750 (epoch 24), train_loss = 2.395, time/batch = 0.212\n",
            "7844/15750 (epoch 24), train_loss = 2.291, time/batch = 0.216\n",
            "7845/15750 (epoch 24), train_loss = 2.434, time/batch = 0.212\n",
            "7846/15750 (epoch 24), train_loss = 2.318, time/batch = 0.213\n",
            "7847/15750 (epoch 24), train_loss = 2.331, time/batch = 0.211\n",
            "7848/15750 (epoch 24), train_loss = 2.252, time/batch = 0.206\n",
            "7849/15750 (epoch 24), train_loss = 2.350, time/batch = 0.207\n",
            "7850/15750 (epoch 24), train_loss = 2.277, time/batch = 0.203\n",
            "7851/15750 (epoch 24), train_loss = 2.355, time/batch = 0.212\n",
            "7852/15750 (epoch 24), train_loss = 2.346, time/batch = 0.217\n",
            "7853/15750 (epoch 24), train_loss = 2.312, time/batch = 0.213\n",
            "7854/15750 (epoch 24), train_loss = 2.361, time/batch = 0.209\n",
            "7855/15750 (epoch 24), train_loss = 2.444, time/batch = 0.215\n",
            "7856/15750 (epoch 24), train_loss = 2.400, time/batch = 0.219\n",
            "7857/15750 (epoch 24), train_loss = 2.415, time/batch = 0.222\n",
            "7858/15750 (epoch 24), train_loss = 2.283, time/batch = 0.209\n",
            "7859/15750 (epoch 24), train_loss = 2.356, time/batch = 0.201\n",
            "7860/15750 (epoch 24), train_loss = 2.347, time/batch = 0.205\n",
            "7861/15750 (epoch 24), train_loss = 2.268, time/batch = 0.203\n",
            "7862/15750 (epoch 24), train_loss = 2.399, time/batch = 0.221\n",
            "7863/15750 (epoch 24), train_loss = 2.255, time/batch = 0.206\n",
            "7864/15750 (epoch 24), train_loss = 2.387, time/batch = 0.212\n",
            "7865/15750 (epoch 24), train_loss = 2.332, time/batch = 0.213\n",
            "7866/15750 (epoch 24), train_loss = 2.303, time/batch = 0.212\n",
            "7867/15750 (epoch 24), train_loss = 2.256, time/batch = 0.211\n",
            "7868/15750 (epoch 24), train_loss = 2.283, time/batch = 0.212\n",
            "7869/15750 (epoch 24), train_loss = 2.409, time/batch = 0.204\n",
            "7870/15750 (epoch 24), train_loss = 2.268, time/batch = 0.209\n",
            "7871/15750 (epoch 24), train_loss = 2.249, time/batch = 0.215\n",
            "7872/15750 (epoch 24), train_loss = 2.287, time/batch = 0.206\n",
            "7873/15750 (epoch 24), train_loss = 2.287, time/batch = 0.207\n",
            "7874/15750 (epoch 24), train_loss = 2.391, time/batch = 0.213\n",
            "7875/15750 (epoch 25), train_loss = 2.320, time/batch = 0.212\n",
            "7876/15750 (epoch 25), train_loss = 2.391, time/batch = 0.211\n",
            "7877/15750 (epoch 25), train_loss = 2.328, time/batch = 0.204\n",
            "7878/15750 (epoch 25), train_loss = 2.418, time/batch = 0.208\n",
            "7879/15750 (epoch 25), train_loss = 2.344, time/batch = 0.209\n",
            "7880/15750 (epoch 25), train_loss = 2.336, time/batch = 0.217\n",
            "7881/15750 (epoch 25), train_loss = 2.500, time/batch = 0.211\n",
            "7882/15750 (epoch 25), train_loss = 2.410, time/batch = 0.211\n",
            "7883/15750 (epoch 25), train_loss = 2.402, time/batch = 0.214\n",
            "7884/15750 (epoch 25), train_loss = 2.347, time/batch = 0.216\n",
            "7885/15750 (epoch 25), train_loss = 2.352, time/batch = 0.213\n",
            "7886/15750 (epoch 25), train_loss = 2.309, time/batch = 0.203\n",
            "7887/15750 (epoch 25), train_loss = 2.397, time/batch = 0.203\n",
            "7888/15750 (epoch 25), train_loss = 2.373, time/batch = 0.200\n",
            "7889/15750 (epoch 25), train_loss = 2.350, time/batch = 0.200\n",
            "7890/15750 (epoch 25), train_loss = 2.378, time/batch = 0.206\n",
            "7891/15750 (epoch 25), train_loss = 2.383, time/batch = 0.205\n",
            "7892/15750 (epoch 25), train_loss = 2.441, time/batch = 0.203\n",
            "7893/15750 (epoch 25), train_loss = 2.458, time/batch = 0.206\n",
            "7894/15750 (epoch 25), train_loss = 2.404, time/batch = 0.199\n",
            "7895/15750 (epoch 25), train_loss = 2.396, time/batch = 0.206\n",
            "7896/15750 (epoch 25), train_loss = 2.409, time/batch = 0.197\n",
            "7897/15750 (epoch 25), train_loss = 2.359, time/batch = 0.205\n",
            "7898/15750 (epoch 25), train_loss = 2.412, time/batch = 0.203\n",
            "7899/15750 (epoch 25), train_loss = 2.411, time/batch = 0.196\n",
            "7900/15750 (epoch 25), train_loss = 2.439, time/batch = 0.206\n",
            "7901/15750 (epoch 25), train_loss = 2.440, time/batch = 0.201\n",
            "7902/15750 (epoch 25), train_loss = 2.426, time/batch = 0.202\n",
            "7903/15750 (epoch 25), train_loss = 2.536, time/batch = 0.205\n",
            "7904/15750 (epoch 25), train_loss = 2.445, time/batch = 0.197\n",
            "7905/15750 (epoch 25), train_loss = 2.408, time/batch = 0.222\n",
            "7906/15750 (epoch 25), train_loss = 2.376, time/batch = 0.208\n",
            "7907/15750 (epoch 25), train_loss = 2.287, time/batch = 0.216\n",
            "7908/15750 (epoch 25), train_loss = 2.309, time/batch = 0.209\n",
            "7909/15750 (epoch 25), train_loss = 2.393, time/batch = 0.213\n",
            "7910/15750 (epoch 25), train_loss = 2.295, time/batch = 0.216\n",
            "7911/15750 (epoch 25), train_loss = 2.359, time/batch = 0.204\n",
            "7912/15750 (epoch 25), train_loss = 2.418, time/batch = 0.210\n",
            "7913/15750 (epoch 25), train_loss = 2.327, time/batch = 0.204\n",
            "7914/15750 (epoch 25), train_loss = 2.376, time/batch = 0.203\n",
            "7915/15750 (epoch 25), train_loss = 2.332, time/batch = 0.212\n",
            "7916/15750 (epoch 25), train_loss = 2.383, time/batch = 0.203\n",
            "7917/15750 (epoch 25), train_loss = 2.380, time/batch = 0.201\n",
            "7918/15750 (epoch 25), train_loss = 2.340, time/batch = 0.208\n",
            "7919/15750 (epoch 25), train_loss = 2.377, time/batch = 0.205\n",
            "7920/15750 (epoch 25), train_loss = 2.298, time/batch = 0.207\n",
            "7921/15750 (epoch 25), train_loss = 2.340, time/batch = 0.210\n",
            "7922/15750 (epoch 25), train_loss = 2.363, time/batch = 0.208\n",
            "7923/15750 (epoch 25), train_loss = 2.400, time/batch = 0.206\n",
            "7924/15750 (epoch 25), train_loss = 2.287, time/batch = 0.205\n",
            "7925/15750 (epoch 25), train_loss = 2.348, time/batch = 0.214\n",
            "7926/15750 (epoch 25), train_loss = 2.304, time/batch = 0.209\n",
            "7927/15750 (epoch 25), train_loss = 2.364, time/batch = 0.212\n",
            "7928/15750 (epoch 25), train_loss = 2.377, time/batch = 0.212\n",
            "7929/15750 (epoch 25), train_loss = 2.375, time/batch = 0.213\n",
            "7930/15750 (epoch 25), train_loss = 2.406, time/batch = 0.210\n",
            "7931/15750 (epoch 25), train_loss = 2.288, time/batch = 0.206\n",
            "7932/15750 (epoch 25), train_loss = 2.290, time/batch = 0.202\n",
            "7933/15750 (epoch 25), train_loss = 2.380, time/batch = 0.203\n",
            "7934/15750 (epoch 25), train_loss = 2.241, time/batch = 0.198\n",
            "7935/15750 (epoch 25), train_loss = 2.343, time/batch = 0.206\n",
            "7936/15750 (epoch 25), train_loss = 2.350, time/batch = 0.198\n",
            "7937/15750 (epoch 25), train_loss = 2.278, time/batch = 0.208\n",
            "7938/15750 (epoch 25), train_loss = 2.333, time/batch = 0.204\n",
            "7939/15750 (epoch 25), train_loss = 2.244, time/batch = 0.207\n",
            "7940/15750 (epoch 25), train_loss = 2.265, time/batch = 0.210\n",
            "7941/15750 (epoch 25), train_loss = 2.206, time/batch = 0.212\n",
            "7942/15750 (epoch 25), train_loss = 2.227, time/batch = 0.210\n",
            "7943/15750 (epoch 25), train_loss = 2.283, time/batch = 0.210\n",
            "7944/15750 (epoch 25), train_loss = 2.370, time/batch = 0.208\n",
            "7945/15750 (epoch 25), train_loss = 2.297, time/batch = 0.217\n",
            "7946/15750 (epoch 25), train_loss = 2.285, time/batch = 0.204\n",
            "7947/15750 (epoch 25), train_loss = 2.198, time/batch = 0.195\n",
            "7948/15750 (epoch 25), train_loss = 2.278, time/batch = 0.213\n",
            "7949/15750 (epoch 25), train_loss = 2.385, time/batch = 0.215\n",
            "7950/15750 (epoch 25), train_loss = 2.320, time/batch = 0.200\n",
            "7951/15750 (epoch 25), train_loss = 2.315, time/batch = 0.208\n",
            "7952/15750 (epoch 25), train_loss = 2.319, time/batch = 0.207\n",
            "7953/15750 (epoch 25), train_loss = 2.327, time/batch = 0.207\n",
            "7954/15750 (epoch 25), train_loss = 2.319, time/batch = 0.207\n",
            "7955/15750 (epoch 25), train_loss = 2.221, time/batch = 0.211\n",
            "7956/15750 (epoch 25), train_loss = 2.324, time/batch = 0.211\n",
            "7957/15750 (epoch 25), train_loss = 2.264, time/batch = 0.215\n",
            "7958/15750 (epoch 25), train_loss = 2.321, time/batch = 0.206\n",
            "7959/15750 (epoch 25), train_loss = 2.380, time/batch = 0.207\n",
            "7960/15750 (epoch 25), train_loss = 2.400, time/batch = 0.209\n",
            "7961/15750 (epoch 25), train_loss = 2.235, time/batch = 0.210\n",
            "7962/15750 (epoch 25), train_loss = 2.267, time/batch = 0.210\n",
            "7963/15750 (epoch 25), train_loss = 2.289, time/batch = 0.207\n",
            "7964/15750 (epoch 25), train_loss = 2.287, time/batch = 0.212\n",
            "7965/15750 (epoch 25), train_loss = 2.293, time/batch = 0.201\n",
            "7966/15750 (epoch 25), train_loss = 2.350, time/batch = 0.205\n",
            "7967/15750 (epoch 25), train_loss = 2.340, time/batch = 0.205\n",
            "7968/15750 (epoch 25), train_loss = 2.353, time/batch = 0.206\n",
            "7969/15750 (epoch 25), train_loss = 2.417, time/batch = 0.211\n",
            "7970/15750 (epoch 25), train_loss = 2.315, time/batch = 0.203\n",
            "7971/15750 (epoch 25), train_loss = 2.341, time/batch = 0.206\n",
            "7972/15750 (epoch 25), train_loss = 2.360, time/batch = 0.205\n",
            "7973/15750 (epoch 25), train_loss = 2.349, time/batch = 0.212\n",
            "7974/15750 (epoch 25), train_loss = 2.362, time/batch = 0.215\n",
            "7975/15750 (epoch 25), train_loss = 2.341, time/batch = 0.213\n",
            "7976/15750 (epoch 25), train_loss = 2.273, time/batch = 0.210\n",
            "7977/15750 (epoch 25), train_loss = 2.298, time/batch = 0.214\n",
            "7978/15750 (epoch 25), train_loss = 2.423, time/batch = 0.215\n",
            "7979/15750 (epoch 25), train_loss = 2.347, time/batch = 0.215\n",
            "7980/15750 (epoch 25), train_loss = 2.259, time/batch = 0.203\n",
            "7981/15750 (epoch 25), train_loss = 2.319, time/batch = 0.205\n",
            "7982/15750 (epoch 25), train_loss = 2.340, time/batch = 0.207\n",
            "7983/15750 (epoch 25), train_loss = 2.386, time/batch = 0.212\n",
            "7984/15750 (epoch 25), train_loss = 2.408, time/batch = 0.221\n",
            "7985/15750 (epoch 25), train_loss = 2.458, time/batch = 0.208\n",
            "7986/15750 (epoch 25), train_loss = 2.330, time/batch = 0.207\n",
            "7987/15750 (epoch 25), train_loss = 2.322, time/batch = 0.215\n",
            "7988/15750 (epoch 25), train_loss = 2.333, time/batch = 0.212\n",
            "7989/15750 (epoch 25), train_loss = 2.345, time/batch = 0.213\n",
            "7990/15750 (epoch 25), train_loss = 2.420, time/batch = 0.214\n",
            "7991/15750 (epoch 25), train_loss = 2.341, time/batch = 0.204\n",
            "7992/15750 (epoch 25), train_loss = 2.468, time/batch = 0.216\n",
            "7993/15750 (epoch 25), train_loss = 2.349, time/batch = 0.205\n",
            "7994/15750 (epoch 25), train_loss = 2.328, time/batch = 0.220\n",
            "7995/15750 (epoch 25), train_loss = 2.303, time/batch = 0.211\n",
            "7996/15750 (epoch 25), train_loss = 2.282, time/batch = 0.214\n",
            "7997/15750 (epoch 25), train_loss = 2.319, time/batch = 0.210\n",
            "7998/15750 (epoch 25), train_loss = 2.286, time/batch = 0.213\n",
            "7999/15750 (epoch 25), train_loss = 2.317, time/batch = 0.216\n",
            "8000/15750 (epoch 25), train_loss = 2.332, time/batch = 0.211\n",
            "model saved to ./save_star/model.ckpt\n",
            "8001/15750 (epoch 25), train_loss = 2.418, time/batch = 0.209\n",
            "8002/15750 (epoch 25), train_loss = 2.296, time/batch = 0.211\n",
            "8003/15750 (epoch 25), train_loss = 2.312, time/batch = 0.209\n",
            "8004/15750 (epoch 25), train_loss = 2.295, time/batch = 0.210\n",
            "8005/15750 (epoch 25), train_loss = 2.235, time/batch = 0.208\n",
            "8006/15750 (epoch 25), train_loss = 2.243, time/batch = 0.217\n",
            "8007/15750 (epoch 25), train_loss = 2.260, time/batch = 0.209\n",
            "8008/15750 (epoch 25), train_loss = 2.276, time/batch = 0.208\n",
            "8009/15750 (epoch 25), train_loss = 2.303, time/batch = 0.208\n",
            "8010/15750 (epoch 25), train_loss = 2.428, time/batch = 0.207\n",
            "8011/15750 (epoch 25), train_loss = 2.385, time/batch = 0.213\n",
            "8012/15750 (epoch 25), train_loss = 2.386, time/batch = 0.202\n",
            "8013/15750 (epoch 25), train_loss = 2.376, time/batch = 0.208\n",
            "8014/15750 (epoch 25), train_loss = 2.305, time/batch = 0.209\n",
            "8015/15750 (epoch 25), train_loss = 2.303, time/batch = 0.217\n",
            "8016/15750 (epoch 25), train_loss = 2.390, time/batch = 0.217\n",
            "8017/15750 (epoch 25), train_loss = 2.410, time/batch = 0.212\n",
            "8018/15750 (epoch 25), train_loss = 2.395, time/batch = 0.212\n",
            "8019/15750 (epoch 25), train_loss = 2.307, time/batch = 0.218\n",
            "8020/15750 (epoch 25), train_loss = 2.304, time/batch = 0.211\n",
            "8021/15750 (epoch 25), train_loss = 2.263, time/batch = 0.222\n",
            "8022/15750 (epoch 25), train_loss = 2.351, time/batch = 0.217\n",
            "8023/15750 (epoch 25), train_loss = 2.379, time/batch = 0.216\n",
            "8024/15750 (epoch 25), train_loss = 2.324, time/batch = 0.208\n",
            "8025/15750 (epoch 25), train_loss = 2.328, time/batch = 0.211\n",
            "8026/15750 (epoch 25), train_loss = 2.368, time/batch = 0.208\n",
            "8027/15750 (epoch 25), train_loss = 2.413, time/batch = 0.210\n",
            "8028/15750 (epoch 25), train_loss = 2.360, time/batch = 0.215\n",
            "8029/15750 (epoch 25), train_loss = 2.372, time/batch = 0.205\n",
            "8030/15750 (epoch 25), train_loss = 2.359, time/batch = 0.207\n",
            "8031/15750 (epoch 25), train_loss = 2.361, time/batch = 0.200\n",
            "8032/15750 (epoch 25), train_loss = 2.351, time/batch = 0.210\n",
            "8033/15750 (epoch 25), train_loss = 2.444, time/batch = 0.201\n",
            "8034/15750 (epoch 25), train_loss = 2.301, time/batch = 0.207\n",
            "8035/15750 (epoch 25), train_loss = 2.372, time/batch = 0.203\n",
            "8036/15750 (epoch 25), train_loss = 2.368, time/batch = 0.207\n",
            "8037/15750 (epoch 25), train_loss = 2.391, time/batch = 0.215\n",
            "8038/15750 (epoch 25), train_loss = 2.473, time/batch = 0.208\n",
            "8039/15750 (epoch 25), train_loss = 2.391, time/batch = 0.211\n",
            "8040/15750 (epoch 25), train_loss = 2.391, time/batch = 0.210\n",
            "8041/15750 (epoch 25), train_loss = 2.371, time/batch = 0.210\n",
            "8042/15750 (epoch 25), train_loss = 2.335, time/batch = 0.217\n",
            "8043/15750 (epoch 25), train_loss = 2.303, time/batch = 0.216\n",
            "8044/15750 (epoch 25), train_loss = 2.295, time/batch = 0.208\n",
            "8045/15750 (epoch 25), train_loss = 2.343, time/batch = 0.209\n",
            "8046/15750 (epoch 25), train_loss = 2.379, time/batch = 0.206\n",
            "8047/15750 (epoch 25), train_loss = 2.345, time/batch = 0.206\n",
            "8048/15750 (epoch 25), train_loss = 2.401, time/batch = 0.205\n",
            "8049/15750 (epoch 25), train_loss = 2.351, time/batch = 0.212\n",
            "8050/15750 (epoch 25), train_loss = 2.280, time/batch = 0.214\n",
            "8051/15750 (epoch 25), train_loss = 2.310, time/batch = 0.217\n",
            "8052/15750 (epoch 25), train_loss = 2.364, time/batch = 0.207\n",
            "8053/15750 (epoch 25), train_loss = 2.299, time/batch = 0.204\n",
            "8054/15750 (epoch 25), train_loss = 2.261, time/batch = 0.215\n",
            "8055/15750 (epoch 25), train_loss = 2.293, time/batch = 0.216\n",
            "8056/15750 (epoch 25), train_loss = 2.378, time/batch = 0.206\n",
            "8057/15750 (epoch 25), train_loss = 2.344, time/batch = 0.209\n",
            "8058/15750 (epoch 25), train_loss = 2.407, time/batch = 0.206\n",
            "8059/15750 (epoch 25), train_loss = 2.401, time/batch = 0.207\n",
            "8060/15750 (epoch 25), train_loss = 2.337, time/batch = 0.214\n",
            "8061/15750 (epoch 25), train_loss = 2.300, time/batch = 0.207\n",
            "8062/15750 (epoch 25), train_loss = 2.371, time/batch = 0.213\n",
            "8063/15750 (epoch 25), train_loss = 2.402, time/batch = 0.214\n",
            "8064/15750 (epoch 25), train_loss = 2.472, time/batch = 0.214\n",
            "8065/15750 (epoch 25), train_loss = 2.435, time/batch = 0.224\n",
            "8066/15750 (epoch 25), train_loss = 2.353, time/batch = 0.215\n",
            "8067/15750 (epoch 25), train_loss = 2.366, time/batch = 0.216\n",
            "8068/15750 (epoch 25), train_loss = 2.294, time/batch = 0.209\n",
            "8069/15750 (epoch 25), train_loss = 2.416, time/batch = 0.212\n",
            "8070/15750 (epoch 25), train_loss = 2.399, time/batch = 0.207\n",
            "8071/15750 (epoch 25), train_loss = 2.351, time/batch = 0.212\n",
            "8072/15750 (epoch 25), train_loss = 2.297, time/batch = 0.213\n",
            "8073/15750 (epoch 25), train_loss = 2.393, time/batch = 0.208\n",
            "8074/15750 (epoch 25), train_loss = 2.191, time/batch = 0.215\n",
            "8075/15750 (epoch 25), train_loss = 2.299, time/batch = 0.212\n",
            "8076/15750 (epoch 25), train_loss = 2.256, time/batch = 0.205\n",
            "8077/15750 (epoch 25), train_loss = 2.338, time/batch = 0.209\n",
            "8078/15750 (epoch 25), train_loss = 2.312, time/batch = 0.208\n",
            "8079/15750 (epoch 25), train_loss = 2.376, time/batch = 0.209\n",
            "8080/15750 (epoch 25), train_loss = 2.329, time/batch = 0.204\n",
            "8081/15750 (epoch 25), train_loss = 2.205, time/batch = 0.207\n",
            "8082/15750 (epoch 25), train_loss = 2.278, time/batch = 0.202\n",
            "8083/15750 (epoch 25), train_loss = 2.282, time/batch = 0.195\n",
            "8084/15750 (epoch 25), train_loss = 2.343, time/batch = 0.206\n",
            "8085/15750 (epoch 25), train_loss = 2.222, time/batch = 0.203\n",
            "8086/15750 (epoch 25), train_loss = 2.304, time/batch = 0.200\n",
            "8087/15750 (epoch 25), train_loss = 2.192, time/batch = 0.204\n",
            "8088/15750 (epoch 25), train_loss = 2.265, time/batch = 0.202\n",
            "8089/15750 (epoch 25), train_loss = 2.259, time/batch = 0.202\n",
            "8090/15750 (epoch 25), train_loss = 2.252, time/batch = 0.206\n",
            "8091/15750 (epoch 25), train_loss = 2.401, time/batch = 0.203\n",
            "8092/15750 (epoch 25), train_loss = 2.220, time/batch = 0.199\n",
            "8093/15750 (epoch 25), train_loss = 2.468, time/batch = 0.200\n",
            "8094/15750 (epoch 25), train_loss = 2.328, time/batch = 0.205\n",
            "8095/15750 (epoch 25), train_loss = 2.209, time/batch = 0.198\n",
            "8096/15750 (epoch 25), train_loss = 2.250, time/batch = 0.201\n",
            "8097/15750 (epoch 25), train_loss = 2.309, time/batch = 0.201\n",
            "8098/15750 (epoch 25), train_loss = 2.302, time/batch = 0.193\n",
            "8099/15750 (epoch 25), train_loss = 2.288, time/batch = 0.204\n",
            "8100/15750 (epoch 25), train_loss = 2.290, time/batch = 0.197\n",
            "8101/15750 (epoch 25), train_loss = 2.364, time/batch = 0.200\n",
            "8102/15750 (epoch 25), train_loss = 2.279, time/batch = 0.202\n",
            "8103/15750 (epoch 25), train_loss = 2.323, time/batch = 0.204\n",
            "8104/15750 (epoch 25), train_loss = 2.400, time/batch = 0.206\n",
            "8105/15750 (epoch 25), train_loss = 2.252, time/batch = 0.196\n",
            "8106/15750 (epoch 25), train_loss = 2.278, time/batch = 0.204\n",
            "8107/15750 (epoch 25), train_loss = 2.319, time/batch = 0.204\n",
            "8108/15750 (epoch 25), train_loss = 2.317, time/batch = 0.200\n",
            "8109/15750 (epoch 25), train_loss = 2.267, time/batch = 0.202\n",
            "8110/15750 (epoch 25), train_loss = 2.261, time/batch = 0.205\n",
            "8111/15750 (epoch 25), train_loss = 2.234, time/batch = 0.204\n",
            "8112/15750 (epoch 25), train_loss = 2.289, time/batch = 0.195\n",
            "8113/15750 (epoch 25), train_loss = 2.502, time/batch = 0.201\n",
            "8114/15750 (epoch 25), train_loss = 2.315, time/batch = 0.206\n",
            "8115/15750 (epoch 25), train_loss = 2.369, time/batch = 0.207\n",
            "8116/15750 (epoch 25), train_loss = 2.244, time/batch = 0.197\n",
            "8117/15750 (epoch 25), train_loss = 2.303, time/batch = 0.202\n",
            "8118/15750 (epoch 25), train_loss = 2.325, time/batch = 0.202\n",
            "8119/15750 (epoch 25), train_loss = 2.327, time/batch = 0.205\n",
            "8120/15750 (epoch 25), train_loss = 2.384, time/batch = 0.216\n",
            "8121/15750 (epoch 25), train_loss = 2.349, time/batch = 0.202\n",
            "8122/15750 (epoch 25), train_loss = 2.339, time/batch = 0.206\n",
            "8123/15750 (epoch 25), train_loss = 2.325, time/batch = 0.207\n",
            "8124/15750 (epoch 25), train_loss = 2.352, time/batch = 0.206\n",
            "8125/15750 (epoch 25), train_loss = 2.247, time/batch = 0.216\n",
            "8126/15750 (epoch 25), train_loss = 2.243, time/batch = 0.209\n",
            "8127/15750 (epoch 25), train_loss = 2.326, time/batch = 0.207\n",
            "8128/15750 (epoch 25), train_loss = 2.343, time/batch = 0.205\n",
            "8129/15750 (epoch 25), train_loss = 2.312, time/batch = 0.203\n",
            "8130/15750 (epoch 25), train_loss = 2.279, time/batch = 0.210\n",
            "8131/15750 (epoch 25), train_loss = 2.228, time/batch = 0.203\n",
            "8132/15750 (epoch 25), train_loss = 2.249, time/batch = 0.200\n",
            "8133/15750 (epoch 25), train_loss = 2.413, time/batch = 0.205\n",
            "8134/15750 (epoch 25), train_loss = 2.381, time/batch = 0.204\n",
            "8135/15750 (epoch 25), train_loss = 2.352, time/batch = 0.211\n",
            "8136/15750 (epoch 25), train_loss = 2.298, time/batch = 0.203\n",
            "8137/15750 (epoch 25), train_loss = 2.326, time/batch = 0.204\n",
            "8138/15750 (epoch 25), train_loss = 2.309, time/batch = 0.201\n",
            "8139/15750 (epoch 25), train_loss = 2.344, time/batch = 0.199\n",
            "8140/15750 (epoch 25), train_loss = 2.392, time/batch = 0.211\n",
            "8141/15750 (epoch 25), train_loss = 2.400, time/batch = 0.202\n",
            "8142/15750 (epoch 25), train_loss = 2.315, time/batch = 0.199\n",
            "8143/15750 (epoch 25), train_loss = 2.354, time/batch = 0.202\n",
            "8144/15750 (epoch 25), train_loss = 2.379, time/batch = 0.202\n",
            "8145/15750 (epoch 25), train_loss = 2.369, time/batch = 0.214\n",
            "8146/15750 (epoch 25), train_loss = 2.271, time/batch = 0.204\n",
            "8147/15750 (epoch 25), train_loss = 2.306, time/batch = 0.208\n",
            "8148/15750 (epoch 25), train_loss = 2.373, time/batch = 0.201\n",
            "8149/15750 (epoch 25), train_loss = 2.390, time/batch = 0.211\n",
            "8150/15750 (epoch 25), train_loss = 2.344, time/batch = 0.216\n",
            "8151/15750 (epoch 25), train_loss = 2.396, time/batch = 0.202\n",
            "8152/15750 (epoch 25), train_loss = 2.326, time/batch = 0.204\n",
            "8153/15750 (epoch 25), train_loss = 2.291, time/batch = 0.207\n",
            "8154/15750 (epoch 25), train_loss = 2.245, time/batch = 0.206\n",
            "8155/15750 (epoch 25), train_loss = 2.479, time/batch = 0.213\n",
            "8156/15750 (epoch 25), train_loss = 2.305, time/batch = 0.204\n",
            "8157/15750 (epoch 25), train_loss = 2.267, time/batch = 0.203\n",
            "8158/15750 (epoch 25), train_loss = 2.384, time/batch = 0.203\n",
            "8159/15750 (epoch 25), train_loss = 2.282, time/batch = 0.203\n",
            "8160/15750 (epoch 25), train_loss = 2.423, time/batch = 0.216\n",
            "8161/15750 (epoch 25), train_loss = 2.309, time/batch = 0.213\n",
            "8162/15750 (epoch 25), train_loss = 2.322, time/batch = 0.202\n",
            "8163/15750 (epoch 25), train_loss = 2.243, time/batch = 0.201\n",
            "8164/15750 (epoch 25), train_loss = 2.342, time/batch = 0.202\n",
            "8165/15750 (epoch 25), train_loss = 2.268, time/batch = 0.210\n",
            "8166/15750 (epoch 25), train_loss = 2.344, time/batch = 0.205\n",
            "8167/15750 (epoch 25), train_loss = 2.336, time/batch = 0.207\n",
            "8168/15750 (epoch 25), train_loss = 2.301, time/batch = 0.205\n",
            "8169/15750 (epoch 25), train_loss = 2.351, time/batch = 0.205\n",
            "8170/15750 (epoch 25), train_loss = 2.434, time/batch = 0.218\n",
            "8171/15750 (epoch 25), train_loss = 2.390, time/batch = 0.207\n",
            "8172/15750 (epoch 25), train_loss = 2.405, time/batch = 0.204\n",
            "8173/15750 (epoch 25), train_loss = 2.275, time/batch = 0.221\n",
            "8174/15750 (epoch 25), train_loss = 2.346, time/batch = 0.212\n",
            "8175/15750 (epoch 25), train_loss = 2.337, time/batch = 0.206\n",
            "8176/15750 (epoch 25), train_loss = 2.260, time/batch = 0.210\n",
            "8177/15750 (epoch 25), train_loss = 2.389, time/batch = 0.207\n",
            "8178/15750 (epoch 25), train_loss = 2.246, time/batch = 0.205\n",
            "8179/15750 (epoch 25), train_loss = 2.377, time/batch = 0.218\n",
            "8180/15750 (epoch 25), train_loss = 2.323, time/batch = 0.206\n",
            "8181/15750 (epoch 25), train_loss = 2.292, time/batch = 0.208\n",
            "8182/15750 (epoch 25), train_loss = 2.246, time/batch = 0.202\n",
            "8183/15750 (epoch 25), train_loss = 2.274, time/batch = 0.202\n",
            "8184/15750 (epoch 25), train_loss = 2.398, time/batch = 0.207\n",
            "8185/15750 (epoch 25), train_loss = 2.260, time/batch = 0.201\n",
            "8186/15750 (epoch 25), train_loss = 2.240, time/batch = 0.200\n",
            "8187/15750 (epoch 25), train_loss = 2.277, time/batch = 0.200\n",
            "8188/15750 (epoch 25), train_loss = 2.278, time/batch = 0.202\n",
            "8189/15750 (epoch 25), train_loss = 2.382, time/batch = 0.202\n",
            "8190/15750 (epoch 26), train_loss = 2.302, time/batch = 0.205\n",
            "8191/15750 (epoch 26), train_loss = 2.380, time/batch = 0.206\n",
            "8192/15750 (epoch 26), train_loss = 2.318, time/batch = 0.211\n",
            "8193/15750 (epoch 26), train_loss = 2.408, time/batch = 0.209\n",
            "8194/15750 (epoch 26), train_loss = 2.333, time/batch = 0.201\n",
            "8195/15750 (epoch 26), train_loss = 2.326, time/batch = 0.206\n",
            "8196/15750 (epoch 26), train_loss = 2.489, time/batch = 0.209\n",
            "8197/15750 (epoch 26), train_loss = 2.400, time/batch = 0.203\n",
            "8198/15750 (epoch 26), train_loss = 2.392, time/batch = 0.198\n",
            "8199/15750 (epoch 26), train_loss = 2.338, time/batch = 0.198\n",
            "8200/15750 (epoch 26), train_loss = 2.343, time/batch = 0.199\n",
            "8201/15750 (epoch 26), train_loss = 2.300, time/batch = 0.201\n",
            "8202/15750 (epoch 26), train_loss = 2.388, time/batch = 0.200\n",
            "8203/15750 (epoch 26), train_loss = 2.364, time/batch = 0.199\n",
            "8204/15750 (epoch 26), train_loss = 2.341, time/batch = 0.211\n",
            "8205/15750 (epoch 26), train_loss = 2.367, time/batch = 0.203\n",
            "8206/15750 (epoch 26), train_loss = 2.372, time/batch = 0.212\n",
            "8207/15750 (epoch 26), train_loss = 2.431, time/batch = 0.201\n",
            "8208/15750 (epoch 26), train_loss = 2.443, time/batch = 0.205\n",
            "8209/15750 (epoch 26), train_loss = 2.390, time/batch = 0.216\n",
            "8210/15750 (epoch 26), train_loss = 2.381, time/batch = 0.210\n",
            "8211/15750 (epoch 26), train_loss = 2.397, time/batch = 0.209\n",
            "8212/15750 (epoch 26), train_loss = 2.346, time/batch = 0.209\n",
            "8213/15750 (epoch 26), train_loss = 2.402, time/batch = 0.212\n",
            "8214/15750 (epoch 26), train_loss = 2.401, time/batch = 0.201\n",
            "8215/15750 (epoch 26), train_loss = 2.428, time/batch = 0.211\n",
            "8216/15750 (epoch 26), train_loss = 2.430, time/batch = 0.210\n",
            "8217/15750 (epoch 26), train_loss = 2.415, time/batch = 0.207\n",
            "8218/15750 (epoch 26), train_loss = 2.526, time/batch = 0.206\n",
            "8219/15750 (epoch 26), train_loss = 2.435, time/batch = 0.197\n",
            "8220/15750 (epoch 26), train_loss = 2.398, time/batch = 0.202\n",
            "8221/15750 (epoch 26), train_loss = 2.365, time/batch = 0.217\n",
            "8222/15750 (epoch 26), train_loss = 2.277, time/batch = 0.200\n",
            "8223/15750 (epoch 26), train_loss = 2.298, time/batch = 0.214\n",
            "8224/15750 (epoch 26), train_loss = 2.383, time/batch = 0.206\n",
            "8225/15750 (epoch 26), train_loss = 2.284, time/batch = 0.206\n",
            "8226/15750 (epoch 26), train_loss = 2.352, time/batch = 0.208\n",
            "8227/15750 (epoch 26), train_loss = 2.409, time/batch = 0.206\n",
            "8228/15750 (epoch 26), train_loss = 2.317, time/batch = 0.213\n",
            "8229/15750 (epoch 26), train_loss = 2.366, time/batch = 0.209\n",
            "8230/15750 (epoch 26), train_loss = 2.322, time/batch = 0.206\n",
            "8231/15750 (epoch 26), train_loss = 2.373, time/batch = 0.211\n",
            "8232/15750 (epoch 26), train_loss = 2.370, time/batch = 0.212\n",
            "8233/15750 (epoch 26), train_loss = 2.332, time/batch = 0.209\n",
            "8234/15750 (epoch 26), train_loss = 2.367, time/batch = 0.212\n",
            "8235/15750 (epoch 26), train_loss = 2.289, time/batch = 0.206\n",
            "8236/15750 (epoch 26), train_loss = 2.331, time/batch = 0.210\n",
            "8237/15750 (epoch 26), train_loss = 2.353, time/batch = 0.208\n",
            "8238/15750 (epoch 26), train_loss = 2.390, time/batch = 0.212\n",
            "8239/15750 (epoch 26), train_loss = 2.277, time/batch = 0.201\n",
            "8240/15750 (epoch 26), train_loss = 2.339, time/batch = 0.210\n",
            "8241/15750 (epoch 26), train_loss = 2.295, time/batch = 0.210\n",
            "8242/15750 (epoch 26), train_loss = 2.354, time/batch = 0.212\n",
            "8243/15750 (epoch 26), train_loss = 2.367, time/batch = 0.216\n",
            "8244/15750 (epoch 26), train_loss = 2.365, time/batch = 0.210\n",
            "8245/15750 (epoch 26), train_loss = 2.396, time/batch = 0.209\n",
            "8246/15750 (epoch 26), train_loss = 2.280, time/batch = 0.205\n",
            "8247/15750 (epoch 26), train_loss = 2.280, time/batch = 0.203\n",
            "8248/15750 (epoch 26), train_loss = 2.371, time/batch = 0.204\n",
            "8249/15750 (epoch 26), train_loss = 2.232, time/batch = 0.206\n",
            "8250/15750 (epoch 26), train_loss = 2.333, time/batch = 0.207\n",
            "8251/15750 (epoch 26), train_loss = 2.341, time/batch = 0.205\n",
            "8252/15750 (epoch 26), train_loss = 2.269, time/batch = 0.213\n",
            "8253/15750 (epoch 26), train_loss = 2.325, time/batch = 0.209\n",
            "8254/15750 (epoch 26), train_loss = 2.234, time/batch = 0.206\n",
            "8255/15750 (epoch 26), train_loss = 2.256, time/batch = 0.208\n",
            "8256/15750 (epoch 26), train_loss = 2.197, time/batch = 0.206\n",
            "8257/15750 (epoch 26), train_loss = 2.217, time/batch = 0.204\n",
            "8258/15750 (epoch 26), train_loss = 2.273, time/batch = 0.213\n",
            "8259/15750 (epoch 26), train_loss = 2.361, time/batch = 0.210\n",
            "8260/15750 (epoch 26), train_loss = 2.288, time/batch = 0.209\n",
            "8261/15750 (epoch 26), train_loss = 2.276, time/batch = 0.210\n",
            "8262/15750 (epoch 26), train_loss = 2.190, time/batch = 0.205\n",
            "8263/15750 (epoch 26), train_loss = 2.268, time/batch = 0.207\n",
            "8264/15750 (epoch 26), train_loss = 2.376, time/batch = 0.209\n",
            "8265/15750 (epoch 26), train_loss = 2.311, time/batch = 0.204\n",
            "8266/15750 (epoch 26), train_loss = 2.305, time/batch = 0.203\n",
            "8267/15750 (epoch 26), train_loss = 2.310, time/batch = 0.208\n",
            "8268/15750 (epoch 26), train_loss = 2.318, time/batch = 0.205\n",
            "8269/15750 (epoch 26), train_loss = 2.310, time/batch = 0.205\n",
            "8270/15750 (epoch 26), train_loss = 2.211, time/batch = 0.213\n",
            "8271/15750 (epoch 26), train_loss = 2.314, time/batch = 0.205\n",
            "8272/15750 (epoch 26), train_loss = 2.255, time/batch = 0.205\n",
            "8273/15750 (epoch 26), train_loss = 2.311, time/batch = 0.198\n",
            "8274/15750 (epoch 26), train_loss = 2.370, time/batch = 0.204\n",
            "8275/15750 (epoch 26), train_loss = 2.390, time/batch = 0.208\n",
            "8276/15750 (epoch 26), train_loss = 2.226, time/batch = 0.198\n",
            "8277/15750 (epoch 26), train_loss = 2.257, time/batch = 0.208\n",
            "8278/15750 (epoch 26), train_loss = 2.279, time/batch = 0.202\n",
            "8279/15750 (epoch 26), train_loss = 2.278, time/batch = 0.197\n",
            "8280/15750 (epoch 26), train_loss = 2.282, time/batch = 0.199\n",
            "8281/15750 (epoch 26), train_loss = 2.341, time/batch = 0.204\n",
            "8282/15750 (epoch 26), train_loss = 2.330, time/batch = 0.202\n",
            "8283/15750 (epoch 26), train_loss = 2.342, time/batch = 0.205\n",
            "8284/15750 (epoch 26), train_loss = 2.406, time/batch = 0.210\n",
            "8285/15750 (epoch 26), train_loss = 2.306, time/batch = 0.208\n",
            "8286/15750 (epoch 26), train_loss = 2.333, time/batch = 0.209\n",
            "8287/15750 (epoch 26), train_loss = 2.352, time/batch = 0.207\n",
            "8288/15750 (epoch 26), train_loss = 2.339, time/batch = 0.212\n",
            "8289/15750 (epoch 26), train_loss = 2.352, time/batch = 0.208\n",
            "8290/15750 (epoch 26), train_loss = 2.332, time/batch = 0.211\n",
            "8291/15750 (epoch 26), train_loss = 2.265, time/batch = 0.210\n",
            "8292/15750 (epoch 26), train_loss = 2.288, time/batch = 0.206\n",
            "8293/15750 (epoch 26), train_loss = 2.414, time/batch = 0.197\n",
            "8294/15750 (epoch 26), train_loss = 2.337, time/batch = 0.211\n",
            "8295/15750 (epoch 26), train_loss = 2.249, time/batch = 0.203\n",
            "8296/15750 (epoch 26), train_loss = 2.308, time/batch = 0.200\n",
            "8297/15750 (epoch 26), train_loss = 2.331, time/batch = 0.208\n",
            "8298/15750 (epoch 26), train_loss = 2.376, time/batch = 0.201\n",
            "8299/15750 (epoch 26), train_loss = 2.399, time/batch = 0.203\n",
            "8300/15750 (epoch 26), train_loss = 2.449, time/batch = 0.205\n",
            "8301/15750 (epoch 26), train_loss = 2.320, time/batch = 0.205\n",
            "8302/15750 (epoch 26), train_loss = 2.314, time/batch = 0.205\n",
            "8303/15750 (epoch 26), train_loss = 2.323, time/batch = 0.208\n",
            "8304/15750 (epoch 26), train_loss = 2.333, time/batch = 0.209\n",
            "8305/15750 (epoch 26), train_loss = 2.410, time/batch = 0.201\n",
            "8306/15750 (epoch 26), train_loss = 2.331, time/batch = 0.206\n",
            "8307/15750 (epoch 26), train_loss = 2.457, time/batch = 0.203\n",
            "8308/15750 (epoch 26), train_loss = 2.339, time/batch = 0.209\n",
            "8309/15750 (epoch 26), train_loss = 2.319, time/batch = 0.205\n",
            "8310/15750 (epoch 26), train_loss = 2.293, time/batch = 0.209\n",
            "8311/15750 (epoch 26), train_loss = 2.273, time/batch = 0.207\n",
            "8312/15750 (epoch 26), train_loss = 2.310, time/batch = 0.212\n",
            "8313/15750 (epoch 26), train_loss = 2.276, time/batch = 0.205\n",
            "8314/15750 (epoch 26), train_loss = 2.307, time/batch = 0.208\n",
            "8315/15750 (epoch 26), train_loss = 2.323, time/batch = 0.210\n",
            "8316/15750 (epoch 26), train_loss = 2.407, time/batch = 0.210\n",
            "8317/15750 (epoch 26), train_loss = 2.287, time/batch = 0.218\n",
            "8318/15750 (epoch 26), train_loss = 2.304, time/batch = 0.215\n",
            "8319/15750 (epoch 26), train_loss = 2.284, time/batch = 0.212\n",
            "8320/15750 (epoch 26), train_loss = 2.226, time/batch = 0.203\n",
            "8321/15750 (epoch 26), train_loss = 2.234, time/batch = 0.206\n",
            "8322/15750 (epoch 26), train_loss = 2.251, time/batch = 0.210\n",
            "8323/15750 (epoch 26), train_loss = 2.267, time/batch = 0.206\n",
            "8324/15750 (epoch 26), train_loss = 2.293, time/batch = 0.215\n",
            "8325/15750 (epoch 26), train_loss = 2.419, time/batch = 0.208\n",
            "8326/15750 (epoch 26), train_loss = 2.377, time/batch = 0.198\n",
            "8327/15750 (epoch 26), train_loss = 2.377, time/batch = 0.214\n",
            "8328/15750 (epoch 26), train_loss = 2.367, time/batch = 0.210\n",
            "8329/15750 (epoch 26), train_loss = 2.295, time/batch = 0.215\n",
            "8330/15750 (epoch 26), train_loss = 2.294, time/batch = 0.206\n",
            "8331/15750 (epoch 26), train_loss = 2.382, time/batch = 0.206\n",
            "8332/15750 (epoch 26), train_loss = 2.402, time/batch = 0.218\n",
            "8333/15750 (epoch 26), train_loss = 2.385, time/batch = 0.203\n",
            "8334/15750 (epoch 26), train_loss = 2.298, time/batch = 0.206\n",
            "8335/15750 (epoch 26), train_loss = 2.295, time/batch = 0.205\n",
            "8336/15750 (epoch 26), train_loss = 2.254, time/batch = 0.207\n",
            "8337/15750 (epoch 26), train_loss = 2.342, time/batch = 0.208\n",
            "8338/15750 (epoch 26), train_loss = 2.371, time/batch = 0.206\n",
            "8339/15750 (epoch 26), train_loss = 2.315, time/batch = 0.209\n",
            "8340/15750 (epoch 26), train_loss = 2.319, time/batch = 0.206\n",
            "8341/15750 (epoch 26), train_loss = 2.360, time/batch = 0.209\n",
            "8342/15750 (epoch 26), train_loss = 2.403, time/batch = 0.208\n",
            "8343/15750 (epoch 26), train_loss = 2.350, time/batch = 0.205\n",
            "8344/15750 (epoch 26), train_loss = 2.363, time/batch = 0.204\n",
            "8345/15750 (epoch 26), train_loss = 2.350, time/batch = 0.208\n",
            "8346/15750 (epoch 26), train_loss = 2.352, time/batch = 0.206\n",
            "8347/15750 (epoch 26), train_loss = 2.343, time/batch = 0.211\n",
            "8348/15750 (epoch 26), train_loss = 2.434, time/batch = 0.214\n",
            "8349/15750 (epoch 26), train_loss = 2.291, time/batch = 0.204\n",
            "8350/15750 (epoch 26), train_loss = 2.362, time/batch = 0.201\n",
            "8351/15750 (epoch 26), train_loss = 2.358, time/batch = 0.218\n",
            "8352/15750 (epoch 26), train_loss = 2.381, time/batch = 0.212\n",
            "8353/15750 (epoch 26), train_loss = 2.463, time/batch = 0.210\n",
            "8354/15750 (epoch 26), train_loss = 2.382, time/batch = 0.209\n",
            "8355/15750 (epoch 26), train_loss = 2.381, time/batch = 0.206\n",
            "8356/15750 (epoch 26), train_loss = 2.362, time/batch = 0.216\n",
            "8357/15750 (epoch 26), train_loss = 2.326, time/batch = 0.206\n",
            "8358/15750 (epoch 26), train_loss = 2.293, time/batch = 0.208\n",
            "8359/15750 (epoch 26), train_loss = 2.285, time/batch = 0.209\n",
            "8360/15750 (epoch 26), train_loss = 2.333, time/batch = 0.207\n",
            "8361/15750 (epoch 26), train_loss = 2.368, time/batch = 0.201\n",
            "8362/15750 (epoch 26), train_loss = 2.336, time/batch = 0.202\n",
            "8363/15750 (epoch 26), train_loss = 2.393, time/batch = 0.207\n",
            "8364/15750 (epoch 26), train_loss = 2.340, time/batch = 0.208\n",
            "8365/15750 (epoch 26), train_loss = 2.271, time/batch = 0.214\n",
            "8366/15750 (epoch 26), train_loss = 2.300, time/batch = 0.205\n",
            "8367/15750 (epoch 26), train_loss = 2.355, time/batch = 0.203\n",
            "8368/15750 (epoch 26), train_loss = 2.290, time/batch = 0.204\n",
            "8369/15750 (epoch 26), train_loss = 2.252, time/batch = 0.202\n",
            "8370/15750 (epoch 26), train_loss = 2.284, time/batch = 0.204\n",
            "8371/15750 (epoch 26), train_loss = 2.367, time/batch = 0.207\n",
            "8372/15750 (epoch 26), train_loss = 2.335, time/batch = 0.216\n",
            "8373/15750 (epoch 26), train_loss = 2.398, time/batch = 0.207\n",
            "8374/15750 (epoch 26), train_loss = 2.391, time/batch = 0.204\n",
            "8375/15750 (epoch 26), train_loss = 2.329, time/batch = 0.211\n",
            "8376/15750 (epoch 26), train_loss = 2.291, time/batch = 0.213\n",
            "8377/15750 (epoch 26), train_loss = 2.362, time/batch = 0.209\n",
            "8378/15750 (epoch 26), train_loss = 2.391, time/batch = 0.207\n",
            "8379/15750 (epoch 26), train_loss = 2.461, time/batch = 0.206\n",
            "8380/15750 (epoch 26), train_loss = 2.426, time/batch = 0.212\n",
            "8381/15750 (epoch 26), train_loss = 2.343, time/batch = 0.214\n",
            "8382/15750 (epoch 26), train_loss = 2.357, time/batch = 0.212\n",
            "8383/15750 (epoch 26), train_loss = 2.285, time/batch = 0.204\n",
            "8384/15750 (epoch 26), train_loss = 2.408, time/batch = 0.206\n",
            "8385/15750 (epoch 26), train_loss = 2.388, time/batch = 0.203\n",
            "8386/15750 (epoch 26), train_loss = 2.341, time/batch = 0.211\n",
            "8387/15750 (epoch 26), train_loss = 2.287, time/batch = 0.201\n",
            "8388/15750 (epoch 26), train_loss = 2.384, time/batch = 0.203\n",
            "8389/15750 (epoch 26), train_loss = 2.181, time/batch = 0.205\n",
            "8390/15750 (epoch 26), train_loss = 2.290, time/batch = 0.201\n",
            "8391/15750 (epoch 26), train_loss = 2.247, time/batch = 0.206\n",
            "8392/15750 (epoch 26), train_loss = 2.328, time/batch = 0.204\n",
            "8393/15750 (epoch 26), train_loss = 2.302, time/batch = 0.200\n",
            "8394/15750 (epoch 26), train_loss = 2.366, time/batch = 0.200\n",
            "8395/15750 (epoch 26), train_loss = 2.319, time/batch = 0.206\n",
            "8396/15750 (epoch 26), train_loss = 2.196, time/batch = 0.213\n",
            "8397/15750 (epoch 26), train_loss = 2.268, time/batch = 0.205\n",
            "8398/15750 (epoch 26), train_loss = 2.273, time/batch = 0.209\n",
            "8399/15750 (epoch 26), train_loss = 2.333, time/batch = 0.214\n",
            "8400/15750 (epoch 26), train_loss = 2.214, time/batch = 0.205\n",
            "8401/15750 (epoch 26), train_loss = 2.294, time/batch = 0.213\n",
            "8402/15750 (epoch 26), train_loss = 2.183, time/batch = 0.211\n",
            "8403/15750 (epoch 26), train_loss = 2.256, time/batch = 0.211\n",
            "8404/15750 (epoch 26), train_loss = 2.250, time/batch = 0.209\n",
            "8405/15750 (epoch 26), train_loss = 2.242, time/batch = 0.211\n",
            "8406/15750 (epoch 26), train_loss = 2.391, time/batch = 0.220\n",
            "8407/15750 (epoch 26), train_loss = 2.212, time/batch = 0.206\n",
            "8408/15750 (epoch 26), train_loss = 2.459, time/batch = 0.203\n",
            "8409/15750 (epoch 26), train_loss = 2.320, time/batch = 0.212\n",
            "8410/15750 (epoch 26), train_loss = 2.200, time/batch = 0.208\n",
            "8411/15750 (epoch 26), train_loss = 2.240, time/batch = 0.212\n",
            "8412/15750 (epoch 26), train_loss = 2.300, time/batch = 0.209\n",
            "8413/15750 (epoch 26), train_loss = 2.292, time/batch = 0.213\n",
            "8414/15750 (epoch 26), train_loss = 2.279, time/batch = 0.206\n",
            "8415/15750 (epoch 26), train_loss = 2.281, time/batch = 0.208\n",
            "8416/15750 (epoch 26), train_loss = 2.354, time/batch = 0.218\n",
            "8417/15750 (epoch 26), train_loss = 2.270, time/batch = 0.205\n",
            "8418/15750 (epoch 26), train_loss = 2.313, time/batch = 0.214\n",
            "8419/15750 (epoch 26), train_loss = 2.390, time/batch = 0.208\n",
            "8420/15750 (epoch 26), train_loss = 2.243, time/batch = 0.209\n",
            "8421/15750 (epoch 26), train_loss = 2.269, time/batch = 0.205\n",
            "8422/15750 (epoch 26), train_loss = 2.309, time/batch = 0.199\n",
            "8423/15750 (epoch 26), train_loss = 2.307, time/batch = 0.207\n",
            "8424/15750 (epoch 26), train_loss = 2.258, time/batch = 0.196\n",
            "8425/15750 (epoch 26), train_loss = 2.252, time/batch = 0.208\n",
            "8426/15750 (epoch 26), train_loss = 2.225, time/batch = 0.215\n",
            "8427/15750 (epoch 26), train_loss = 2.279, time/batch = 0.209\n",
            "8428/15750 (epoch 26), train_loss = 2.490, time/batch = 0.211\n",
            "8429/15750 (epoch 26), train_loss = 2.306, time/batch = 0.215\n",
            "8430/15750 (epoch 26), train_loss = 2.359, time/batch = 0.214\n",
            "8431/15750 (epoch 26), train_loss = 2.236, time/batch = 0.200\n",
            "8432/15750 (epoch 26), train_loss = 2.293, time/batch = 0.215\n",
            "8433/15750 (epoch 26), train_loss = 2.316, time/batch = 0.208\n",
            "8434/15750 (epoch 26), train_loss = 2.319, time/batch = 0.208\n",
            "8435/15750 (epoch 26), train_loss = 2.374, time/batch = 0.215\n",
            "8436/15750 (epoch 26), train_loss = 2.339, time/batch = 0.208\n",
            "8437/15750 (epoch 26), train_loss = 2.330, time/batch = 0.204\n",
            "8438/15750 (epoch 26), train_loss = 2.315, time/batch = 0.198\n",
            "8439/15750 (epoch 26), train_loss = 2.342, time/batch = 0.205\n",
            "8440/15750 (epoch 26), train_loss = 2.237, time/batch = 0.211\n",
            "8441/15750 (epoch 26), train_loss = 2.233, time/batch = 0.202\n",
            "8442/15750 (epoch 26), train_loss = 2.316, time/batch = 0.205\n",
            "8443/15750 (epoch 26), train_loss = 2.334, time/batch = 0.208\n",
            "8444/15750 (epoch 26), train_loss = 2.303, time/batch = 0.206\n",
            "8445/15750 (epoch 26), train_loss = 2.269, time/batch = 0.211\n",
            "8446/15750 (epoch 26), train_loss = 2.218, time/batch = 0.206\n",
            "8447/15750 (epoch 26), train_loss = 2.240, time/batch = 0.204\n",
            "8448/15750 (epoch 26), train_loss = 2.404, time/batch = 0.210\n",
            "8449/15750 (epoch 26), train_loss = 2.372, time/batch = 0.206\n",
            "8450/15750 (epoch 26), train_loss = 2.343, time/batch = 0.208\n",
            "8451/15750 (epoch 26), train_loss = 2.289, time/batch = 0.207\n",
            "8452/15750 (epoch 26), train_loss = 2.317, time/batch = 0.214\n",
            "8453/15750 (epoch 26), train_loss = 2.300, time/batch = 0.210\n",
            "8454/15750 (epoch 26), train_loss = 2.334, time/batch = 0.210\n",
            "8455/15750 (epoch 26), train_loss = 2.382, time/batch = 0.215\n",
            "8456/15750 (epoch 26), train_loss = 2.389, time/batch = 0.207\n",
            "8457/15750 (epoch 26), train_loss = 2.306, time/batch = 0.211\n",
            "8458/15750 (epoch 26), train_loss = 2.344, time/batch = 0.208\n",
            "8459/15750 (epoch 26), train_loss = 2.369, time/batch = 0.205\n",
            "8460/15750 (epoch 26), train_loss = 2.360, time/batch = 0.213\n",
            "8461/15750 (epoch 26), train_loss = 2.262, time/batch = 0.209\n",
            "8462/15750 (epoch 26), train_loss = 2.297, time/batch = 0.208\n",
            "8463/15750 (epoch 26), train_loss = 2.363, time/batch = 0.209\n",
            "8464/15750 (epoch 26), train_loss = 2.381, time/batch = 0.207\n",
            "8465/15750 (epoch 26), train_loss = 2.333, time/batch = 0.212\n",
            "8466/15750 (epoch 26), train_loss = 2.386, time/batch = 0.206\n",
            "8467/15750 (epoch 26), train_loss = 2.317, time/batch = 0.203\n",
            "8468/15750 (epoch 26), train_loss = 2.282, time/batch = 0.208\n",
            "8469/15750 (epoch 26), train_loss = 2.237, time/batch = 0.196\n",
            "8470/15750 (epoch 26), train_loss = 2.469, time/batch = 0.214\n",
            "8471/15750 (epoch 26), train_loss = 2.295, time/batch = 0.207\n",
            "8472/15750 (epoch 26), train_loss = 2.258, time/batch = 0.205\n",
            "8473/15750 (epoch 26), train_loss = 2.373, time/batch = 0.215\n",
            "8474/15750 (epoch 26), train_loss = 2.273, time/batch = 0.212\n",
            "8475/15750 (epoch 26), train_loss = 2.413, time/batch = 0.216\n",
            "8476/15750 (epoch 26), train_loss = 2.301, time/batch = 0.206\n",
            "8477/15750 (epoch 26), train_loss = 2.314, time/batch = 0.208\n",
            "8478/15750 (epoch 26), train_loss = 2.235, time/batch = 0.205\n",
            "8479/15750 (epoch 26), train_loss = 2.333, time/batch = 0.208\n",
            "8480/15750 (epoch 26), train_loss = 2.259, time/batch = 0.203\n",
            "8481/15750 (epoch 26), train_loss = 2.335, time/batch = 0.207\n",
            "8482/15750 (epoch 26), train_loss = 2.326, time/batch = 0.210\n",
            "8483/15750 (epoch 26), train_loss = 2.291, time/batch = 0.202\n",
            "8484/15750 (epoch 26), train_loss = 2.342, time/batch = 0.206\n",
            "8485/15750 (epoch 26), train_loss = 2.425, time/batch = 0.202\n",
            "8486/15750 (epoch 26), train_loss = 2.380, time/batch = 0.204\n",
            "8487/15750 (epoch 26), train_loss = 2.395, time/batch = 0.205\n",
            "8488/15750 (epoch 26), train_loss = 2.267, time/batch = 0.207\n",
            "8489/15750 (epoch 26), train_loss = 2.337, time/batch = 0.198\n",
            "8490/15750 (epoch 26), train_loss = 2.327, time/batch = 0.206\n",
            "8491/15750 (epoch 26), train_loss = 2.252, time/batch = 0.202\n",
            "8492/15750 (epoch 26), train_loss = 2.381, time/batch = 0.205\n",
            "8493/15750 (epoch 26), train_loss = 2.238, time/batch = 0.202\n",
            "8494/15750 (epoch 26), train_loss = 2.368, time/batch = 0.199\n",
            "8495/15750 (epoch 26), train_loss = 2.314, time/batch = 0.217\n",
            "8496/15750 (epoch 26), train_loss = 2.283, time/batch = 0.203\n",
            "8497/15750 (epoch 26), train_loss = 2.237, time/batch = 0.209\n",
            "8498/15750 (epoch 26), train_loss = 2.265, time/batch = 0.205\n",
            "8499/15750 (epoch 26), train_loss = 2.388, time/batch = 0.206\n",
            "8500/15750 (epoch 26), train_loss = 2.252, time/batch = 0.217\n",
            "8501/15750 (epoch 26), train_loss = 2.232, time/batch = 0.205\n",
            "8502/15750 (epoch 26), train_loss = 2.267, time/batch = 0.216\n",
            "8503/15750 (epoch 26), train_loss = 2.270, time/batch = 0.207\n",
            "8504/15750 (epoch 26), train_loss = 2.374, time/batch = 0.205\n",
            "8505/15750 (epoch 27), train_loss = 2.293, time/batch = 0.201\n",
            "8506/15750 (epoch 27), train_loss = 2.370, time/batch = 0.204\n",
            "8507/15750 (epoch 27), train_loss = 2.307, time/batch = 0.211\n",
            "8508/15750 (epoch 27), train_loss = 2.398, time/batch = 0.211\n",
            "8509/15750 (epoch 27), train_loss = 2.323, time/batch = 0.217\n",
            "8510/15750 (epoch 27), train_loss = 2.318, time/batch = 0.206\n",
            "8511/15750 (epoch 27), train_loss = 2.478, time/batch = 0.202\n",
            "8512/15750 (epoch 27), train_loss = 2.390, time/batch = 0.206\n",
            "8513/15750 (epoch 27), train_loss = 2.384, time/batch = 0.204\n",
            "8514/15750 (epoch 27), train_loss = 2.329, time/batch = 0.207\n",
            "8515/15750 (epoch 27), train_loss = 2.333, time/batch = 0.196\n",
            "8516/15750 (epoch 27), train_loss = 2.292, time/batch = 0.203\n",
            "8517/15750 (epoch 27), train_loss = 2.379, time/batch = 0.202\n",
            "8518/15750 (epoch 27), train_loss = 2.354, time/batch = 0.200\n",
            "8519/15750 (epoch 27), train_loss = 2.332, time/batch = 0.206\n",
            "8520/15750 (epoch 27), train_loss = 2.358, time/batch = 0.203\n",
            "8521/15750 (epoch 27), train_loss = 2.362, time/batch = 0.202\n",
            "8522/15750 (epoch 27), train_loss = 2.422, time/batch = 0.196\n",
            "8523/15750 (epoch 27), train_loss = 2.434, time/batch = 0.203\n",
            "8524/15750 (epoch 27), train_loss = 2.381, time/batch = 0.205\n",
            "8525/15750 (epoch 27), train_loss = 2.371, time/batch = 0.203\n",
            "8526/15750 (epoch 27), train_loss = 2.386, time/batch = 0.204\n",
            "8527/15750 (epoch 27), train_loss = 2.337, time/batch = 0.209\n",
            "8528/15750 (epoch 27), train_loss = 2.393, time/batch = 0.203\n",
            "8529/15750 (epoch 27), train_loss = 2.393, time/batch = 0.206\n",
            "8530/15750 (epoch 27), train_loss = 2.419, time/batch = 0.199\n",
            "8531/15750 (epoch 27), train_loss = 2.421, time/batch = 0.206\n",
            "8532/15750 (epoch 27), train_loss = 2.406, time/batch = 0.202\n",
            "8533/15750 (epoch 27), train_loss = 2.516, time/batch = 0.203\n",
            "8534/15750 (epoch 27), train_loss = 2.425, time/batch = 0.211\n",
            "8535/15750 (epoch 27), train_loss = 2.388, time/batch = 0.202\n",
            "8536/15750 (epoch 27), train_loss = 2.356, time/batch = 0.210\n",
            "8537/15750 (epoch 27), train_loss = 2.268, time/batch = 0.209\n",
            "8538/15750 (epoch 27), train_loss = 2.289, time/batch = 0.208\n",
            "8539/15750 (epoch 27), train_loss = 2.373, time/batch = 0.214\n",
            "8540/15750 (epoch 27), train_loss = 2.274, time/batch = 0.205\n",
            "8541/15750 (epoch 27), train_loss = 2.343, time/batch = 0.203\n",
            "8542/15750 (epoch 27), train_loss = 2.399, time/batch = 0.207\n",
            "8543/15750 (epoch 27), train_loss = 2.308, time/batch = 0.206\n",
            "8544/15750 (epoch 27), train_loss = 2.357, time/batch = 0.206\n",
            "8545/15750 (epoch 27), train_loss = 2.313, time/batch = 0.208\n",
            "8546/15750 (epoch 27), train_loss = 2.363, time/batch = 0.209\n",
            "8547/15750 (epoch 27), train_loss = 2.361, time/batch = 0.208\n",
            "8548/15750 (epoch 27), train_loss = 2.323, time/batch = 0.215\n",
            "8549/15750 (epoch 27), train_loss = 2.358, time/batch = 0.213\n",
            "8550/15750 (epoch 27), train_loss = 2.281, time/batch = 0.205\n",
            "8551/15750 (epoch 27), train_loss = 2.322, time/batch = 0.209\n",
            "8552/15750 (epoch 27), train_loss = 2.343, time/batch = 0.211\n",
            "8553/15750 (epoch 27), train_loss = 2.381, time/batch = 0.211\n",
            "8554/15750 (epoch 27), train_loss = 2.267, time/batch = 0.203\n",
            "8555/15750 (epoch 27), train_loss = 2.331, time/batch = 0.213\n",
            "8556/15750 (epoch 27), train_loss = 2.286, time/batch = 0.212\n",
            "8557/15750 (epoch 27), train_loss = 2.345, time/batch = 0.214\n",
            "8558/15750 (epoch 27), train_loss = 2.358, time/batch = 0.208\n",
            "8559/15750 (epoch 27), train_loss = 2.356, time/batch = 0.211\n",
            "8560/15750 (epoch 27), train_loss = 2.387, time/batch = 0.206\n",
            "8561/15750 (epoch 27), train_loss = 2.271, time/batch = 0.207\n",
            "8562/15750 (epoch 27), train_loss = 2.270, time/batch = 0.211\n",
            "8563/15750 (epoch 27), train_loss = 2.363, time/batch = 0.204\n",
            "8564/15750 (epoch 27), train_loss = 2.224, time/batch = 0.205\n",
            "8565/15750 (epoch 27), train_loss = 2.325, time/batch = 0.209\n",
            "8566/15750 (epoch 27), train_loss = 2.331, time/batch = 0.206\n",
            "8567/15750 (epoch 27), train_loss = 2.261, time/batch = 0.211\n",
            "8568/15750 (epoch 27), train_loss = 2.317, time/batch = 0.213\n",
            "8569/15750 (epoch 27), train_loss = 2.225, time/batch = 0.207\n",
            "8570/15750 (epoch 27), train_loss = 2.248, time/batch = 0.203\n",
            "8571/15750 (epoch 27), train_loss = 2.189, time/batch = 0.215\n",
            "8572/15750 (epoch 27), train_loss = 2.208, time/batch = 0.206\n",
            "8573/15750 (epoch 27), train_loss = 2.264, time/batch = 0.211\n",
            "8574/15750 (epoch 27), train_loss = 2.352, time/batch = 0.208\n",
            "8575/15750 (epoch 27), train_loss = 2.279, time/batch = 0.204\n",
            "8576/15750 (epoch 27), train_loss = 2.267, time/batch = 0.206\n",
            "8577/15750 (epoch 27), train_loss = 2.182, time/batch = 0.201\n",
            "8578/15750 (epoch 27), train_loss = 2.259, time/batch = 0.208\n",
            "8579/15750 (epoch 27), train_loss = 2.367, time/batch = 0.202\n",
            "8580/15750 (epoch 27), train_loss = 2.302, time/batch = 0.196\n",
            "8581/15750 (epoch 27), train_loss = 2.297, time/batch = 0.203\n",
            "8582/15750 (epoch 27), train_loss = 2.301, time/batch = 0.206\n",
            "8583/15750 (epoch 27), train_loss = 2.309, time/batch = 0.207\n",
            "8584/15750 (epoch 27), train_loss = 2.302, time/batch = 0.197\n",
            "8585/15750 (epoch 27), train_loss = 2.202, time/batch = 0.196\n",
            "8586/15750 (epoch 27), train_loss = 2.305, time/batch = 0.200\n",
            "8587/15750 (epoch 27), train_loss = 2.247, time/batch = 0.199\n",
            "8588/15750 (epoch 27), train_loss = 2.302, time/batch = 0.209\n",
            "8589/15750 (epoch 27), train_loss = 2.361, time/batch = 0.204\n",
            "8590/15750 (epoch 27), train_loss = 2.380, time/batch = 0.197\n",
            "8591/15750 (epoch 27), train_loss = 2.216, time/batch = 0.209\n",
            "8592/15750 (epoch 27), train_loss = 2.249, time/batch = 0.201\n",
            "8593/15750 (epoch 27), train_loss = 2.270, time/batch = 0.211\n",
            "8594/15750 (epoch 27), train_loss = 2.269, time/batch = 0.203\n",
            "8595/15750 (epoch 27), train_loss = 2.272, time/batch = 0.203\n",
            "8596/15750 (epoch 27), train_loss = 2.332, time/batch = 0.212\n",
            "8597/15750 (epoch 27), train_loss = 2.320, time/batch = 0.215\n",
            "8598/15750 (epoch 27), train_loss = 2.333, time/batch = 0.218\n",
            "8599/15750 (epoch 27), train_loss = 2.396, time/batch = 0.212\n",
            "8600/15750 (epoch 27), train_loss = 2.298, time/batch = 0.209\n",
            "8601/15750 (epoch 27), train_loss = 2.324, time/batch = 0.213\n",
            "8602/15750 (epoch 27), train_loss = 2.344, time/batch = 0.208\n",
            "8603/15750 (epoch 27), train_loss = 2.330, time/batch = 0.208\n",
            "8604/15750 (epoch 27), train_loss = 2.343, time/batch = 0.206\n",
            "8605/15750 (epoch 27), train_loss = 2.322, time/batch = 0.207\n",
            "8606/15750 (epoch 27), train_loss = 2.257, time/batch = 0.202\n",
            "8607/15750 (epoch 27), train_loss = 2.280, time/batch = 0.198\n",
            "8608/15750 (epoch 27), train_loss = 2.405, time/batch = 0.214\n",
            "8609/15750 (epoch 27), train_loss = 2.328, time/batch = 0.209\n",
            "8610/15750 (epoch 27), train_loss = 2.239, time/batch = 0.209\n",
            "8611/15750 (epoch 27), train_loss = 2.298, time/batch = 0.208\n",
            "8612/15750 (epoch 27), train_loss = 2.323, time/batch = 0.214\n",
            "8613/15750 (epoch 27), train_loss = 2.365, time/batch = 0.215\n",
            "8614/15750 (epoch 27), train_loss = 2.390, time/batch = 0.207\n",
            "8615/15750 (epoch 27), train_loss = 2.440, time/batch = 0.210\n",
            "8616/15750 (epoch 27), train_loss = 2.311, time/batch = 0.199\n",
            "8617/15750 (epoch 27), train_loss = 2.306, time/batch = 0.219\n",
            "8618/15750 (epoch 27), train_loss = 2.314, time/batch = 0.208\n",
            "8619/15750 (epoch 27), train_loss = 2.323, time/batch = 0.204\n",
            "8620/15750 (epoch 27), train_loss = 2.401, time/batch = 0.209\n",
            "8621/15750 (epoch 27), train_loss = 2.322, time/batch = 0.207\n",
            "8622/15750 (epoch 27), train_loss = 2.448, time/batch = 0.218\n",
            "8623/15750 (epoch 27), train_loss = 2.330, time/batch = 0.202\n",
            "8624/15750 (epoch 27), train_loss = 2.311, time/batch = 0.207\n",
            "8625/15750 (epoch 27), train_loss = 2.284, time/batch = 0.205\n",
            "8626/15750 (epoch 27), train_loss = 2.264, time/batch = 0.207\n",
            "8627/15750 (epoch 27), train_loss = 2.302, time/batch = 0.211\n",
            "8628/15750 (epoch 27), train_loss = 2.266, time/batch = 0.202\n",
            "8629/15750 (epoch 27), train_loss = 2.298, time/batch = 0.207\n",
            "8630/15750 (epoch 27), train_loss = 2.314, time/batch = 0.203\n",
            "8631/15750 (epoch 27), train_loss = 2.397, time/batch = 0.206\n",
            "8632/15750 (epoch 27), train_loss = 2.279, time/batch = 0.208\n",
            "8633/15750 (epoch 27), train_loss = 2.296, time/batch = 0.204\n",
            "8634/15750 (epoch 27), train_loss = 2.274, time/batch = 0.202\n",
            "8635/15750 (epoch 27), train_loss = 2.218, time/batch = 0.202\n",
            "8636/15750 (epoch 27), train_loss = 2.226, time/batch = 0.204\n",
            "8637/15750 (epoch 27), train_loss = 2.243, time/batch = 0.209\n",
            "8638/15750 (epoch 27), train_loss = 2.260, time/batch = 0.208\n",
            "8639/15750 (epoch 27), train_loss = 2.284, time/batch = 0.217\n",
            "8640/15750 (epoch 27), train_loss = 2.411, time/batch = 0.211\n",
            "8641/15750 (epoch 27), train_loss = 2.369, time/batch = 0.209\n",
            "8642/15750 (epoch 27), train_loss = 2.369, time/batch = 0.214\n",
            "8643/15750 (epoch 27), train_loss = 2.358, time/batch = 0.206\n",
            "8644/15750 (epoch 27), train_loss = 2.287, time/batch = 0.215\n",
            "8645/15750 (epoch 27), train_loss = 2.286, time/batch = 0.204\n",
            "8646/15750 (epoch 27), train_loss = 2.373, time/batch = 0.212\n",
            "8647/15750 (epoch 27), train_loss = 2.394, time/batch = 0.207\n",
            "8648/15750 (epoch 27), train_loss = 2.376, time/batch = 0.204\n",
            "8649/15750 (epoch 27), train_loss = 2.289, time/batch = 0.206\n",
            "8650/15750 (epoch 27), train_loss = 2.286, time/batch = 0.215\n",
            "8651/15750 (epoch 27), train_loss = 2.246, time/batch = 0.207\n",
            "8652/15750 (epoch 27), train_loss = 2.335, time/batch = 0.209\n",
            "8653/15750 (epoch 27), train_loss = 2.362, time/batch = 0.205\n",
            "8654/15750 (epoch 27), train_loss = 2.308, time/batch = 0.208\n",
            "8655/15750 (epoch 27), train_loss = 2.311, time/batch = 0.206\n",
            "8656/15750 (epoch 27), train_loss = 2.351, time/batch = 0.211\n",
            "8657/15750 (epoch 27), train_loss = 2.394, time/batch = 0.214\n",
            "8658/15750 (epoch 27), train_loss = 2.341, time/batch = 0.202\n",
            "8659/15750 (epoch 27), train_loss = 2.353, time/batch = 0.201\n",
            "8660/15750 (epoch 27), train_loss = 2.341, time/batch = 0.205\n",
            "8661/15750 (epoch 27), train_loss = 2.343, time/batch = 0.204\n",
            "8662/15750 (epoch 27), train_loss = 2.335, time/batch = 0.207\n",
            "8663/15750 (epoch 27), train_loss = 2.425, time/batch = 0.212\n",
            "8664/15750 (epoch 27), train_loss = 2.282, time/batch = 0.204\n",
            "8665/15750 (epoch 27), train_loss = 2.354, time/batch = 0.211\n",
            "8666/15750 (epoch 27), train_loss = 2.349, time/batch = 0.212\n",
            "8667/15750 (epoch 27), train_loss = 2.372, time/batch = 0.212\n",
            "8668/15750 (epoch 27), train_loss = 2.453, time/batch = 0.212\n",
            "8669/15750 (epoch 27), train_loss = 2.372, time/batch = 0.206\n",
            "8670/15750 (epoch 27), train_loss = 2.372, time/batch = 0.207\n",
            "8671/15750 (epoch 27), train_loss = 2.352, time/batch = 0.211\n",
            "8672/15750 (epoch 27), train_loss = 2.317, time/batch = 0.215\n",
            "8673/15750 (epoch 27), train_loss = 2.284, time/batch = 0.207\n",
            "8674/15750 (epoch 27), train_loss = 2.276, time/batch = 0.202\n",
            "8675/15750 (epoch 27), train_loss = 2.323, time/batch = 0.203\n",
            "8676/15750 (epoch 27), train_loss = 2.358, time/batch = 0.205\n",
            "8677/15750 (epoch 27), train_loss = 2.326, time/batch = 0.207\n",
            "8678/15750 (epoch 27), train_loss = 2.385, time/batch = 0.203\n",
            "8679/15750 (epoch 27), train_loss = 2.331, time/batch = 0.204\n",
            "8680/15750 (epoch 27), train_loss = 2.262, time/batch = 0.209\n",
            "8681/15750 (epoch 27), train_loss = 2.291, time/batch = 0.205\n",
            "8682/15750 (epoch 27), train_loss = 2.347, time/batch = 0.212\n",
            "8683/15750 (epoch 27), train_loss = 2.281, time/batch = 0.207\n",
            "8684/15750 (epoch 27), train_loss = 2.242, time/batch = 0.204\n",
            "8685/15750 (epoch 27), train_loss = 2.276, time/batch = 0.203\n",
            "8686/15750 (epoch 27), train_loss = 2.358, time/batch = 0.207\n",
            "8687/15750 (epoch 27), train_loss = 2.327, time/batch = 0.218\n",
            "8688/15750 (epoch 27), train_loss = 2.389, time/batch = 0.206\n",
            "8689/15750 (epoch 27), train_loss = 2.381, time/batch = 0.211\n",
            "8690/15750 (epoch 27), train_loss = 2.321, time/batch = 0.210\n",
            "8691/15750 (epoch 27), train_loss = 2.282, time/batch = 0.213\n",
            "8692/15750 (epoch 27), train_loss = 2.354, time/batch = 0.198\n",
            "8693/15750 (epoch 27), train_loss = 2.381, time/batch = 0.203\n",
            "8694/15750 (epoch 27), train_loss = 2.451, time/batch = 0.205\n",
            "8695/15750 (epoch 27), train_loss = 2.418, time/batch = 0.198\n",
            "8696/15750 (epoch 27), train_loss = 2.334, time/batch = 0.205\n",
            "8697/15750 (epoch 27), train_loss = 2.349, time/batch = 0.206\n",
            "8698/15750 (epoch 27), train_loss = 2.275, time/batch = 0.201\n",
            "8699/15750 (epoch 27), train_loss = 2.400, time/batch = 0.208\n",
            "8700/15750 (epoch 27), train_loss = 2.378, time/batch = 0.206\n",
            "8701/15750 (epoch 27), train_loss = 2.332, time/batch = 0.209\n",
            "8702/15750 (epoch 27), train_loss = 2.278, time/batch = 0.216\n",
            "8703/15750 (epoch 27), train_loss = 2.376, time/batch = 0.208\n",
            "8704/15750 (epoch 27), train_loss = 2.171, time/batch = 0.210\n",
            "8705/15750 (epoch 27), train_loss = 2.281, time/batch = 0.208\n",
            "8706/15750 (epoch 27), train_loss = 2.238, time/batch = 0.207\n",
            "8707/15750 (epoch 27), train_loss = 2.319, time/batch = 0.204\n",
            "8708/15750 (epoch 27), train_loss = 2.293, time/batch = 0.216\n",
            "8709/15750 (epoch 27), train_loss = 2.357, time/batch = 0.208\n",
            "8710/15750 (epoch 27), train_loss = 2.309, time/batch = 0.210\n",
            "8711/15750 (epoch 27), train_loss = 2.187, time/batch = 0.211\n",
            "8712/15750 (epoch 27), train_loss = 2.259, time/batch = 0.205\n",
            "8713/15750 (epoch 27), train_loss = 2.263, time/batch = 0.212\n",
            "8714/15750 (epoch 27), train_loss = 2.324, time/batch = 0.206\n",
            "8715/15750 (epoch 27), train_loss = 2.206, time/batch = 0.216\n",
            "8716/15750 (epoch 27), train_loss = 2.285, time/batch = 0.216\n",
            "8717/15750 (epoch 27), train_loss = 2.174, time/batch = 0.203\n",
            "8718/15750 (epoch 27), train_loss = 2.247, time/batch = 0.208\n",
            "8719/15750 (epoch 27), train_loss = 2.241, time/batch = 0.203\n",
            "8720/15750 (epoch 27), train_loss = 2.233, time/batch = 0.204\n",
            "8721/15750 (epoch 27), train_loss = 2.382, time/batch = 0.221\n",
            "8722/15750 (epoch 27), train_loss = 2.204, time/batch = 0.209\n",
            "8723/15750 (epoch 27), train_loss = 2.451, time/batch = 0.209\n",
            "8724/15750 (epoch 27), train_loss = 2.312, time/batch = 0.209\n",
            "8725/15750 (epoch 27), train_loss = 2.191, time/batch = 0.201\n",
            "8726/15750 (epoch 27), train_loss = 2.230, time/batch = 0.206\n",
            "8727/15750 (epoch 27), train_loss = 2.290, time/batch = 0.194\n",
            "8728/15750 (epoch 27), train_loss = 2.283, time/batch = 0.204\n",
            "8729/15750 (epoch 27), train_loss = 2.269, time/batch = 0.209\n",
            "8730/15750 (epoch 27), train_loss = 2.273, time/batch = 0.201\n",
            "8731/15750 (epoch 27), train_loss = 2.344, time/batch = 0.206\n",
            "8732/15750 (epoch 27), train_loss = 2.261, time/batch = 0.206\n",
            "8733/15750 (epoch 27), train_loss = 2.305, time/batch = 0.205\n",
            "8734/15750 (epoch 27), train_loss = 2.381, time/batch = 0.209\n",
            "8735/15750 (epoch 27), train_loss = 2.234, time/batch = 0.207\n",
            "8736/15750 (epoch 27), train_loss = 2.260, time/batch = 0.214\n",
            "8737/15750 (epoch 27), train_loss = 2.300, time/batch = 0.206\n",
            "8738/15750 (epoch 27), train_loss = 2.298, time/batch = 0.210\n",
            "8739/15750 (epoch 27), train_loss = 2.250, time/batch = 0.209\n",
            "8740/15750 (epoch 27), train_loss = 2.243, time/batch = 0.218\n",
            "8741/15750 (epoch 27), train_loss = 2.216, time/batch = 0.211\n",
            "8742/15750 (epoch 27), train_loss = 2.269, time/batch = 0.210\n",
            "8743/15750 (epoch 27), train_loss = 2.480, time/batch = 0.206\n",
            "8744/15750 (epoch 27), train_loss = 2.297, time/batch = 0.209\n",
            "8745/15750 (epoch 27), train_loss = 2.350, time/batch = 0.206\n",
            "8746/15750 (epoch 27), train_loss = 2.227, time/batch = 0.204\n",
            "8747/15750 (epoch 27), train_loss = 2.284, time/batch = 0.200\n",
            "8748/15750 (epoch 27), train_loss = 2.307, time/batch = 0.202\n",
            "8749/15750 (epoch 27), train_loss = 2.311, time/batch = 0.207\n",
            "8750/15750 (epoch 27), train_loss = 2.365, time/batch = 0.199\n",
            "8751/15750 (epoch 27), train_loss = 2.329, time/batch = 0.208\n",
            "8752/15750 (epoch 27), train_loss = 2.321, time/batch = 0.206\n",
            "8753/15750 (epoch 27), train_loss = 2.305, time/batch = 0.212\n",
            "8754/15750 (epoch 27), train_loss = 2.332, time/batch = 0.206\n",
            "8755/15750 (epoch 27), train_loss = 2.228, time/batch = 0.211\n",
            "8756/15750 (epoch 27), train_loss = 2.224, time/batch = 0.216\n",
            "8757/15750 (epoch 27), train_loss = 2.307, time/batch = 0.207\n",
            "8758/15750 (epoch 27), train_loss = 2.325, time/batch = 0.206\n",
            "8759/15750 (epoch 27), train_loss = 2.294, time/batch = 0.210\n",
            "8760/15750 (epoch 27), train_loss = 2.259, time/batch = 0.209\n",
            "8761/15750 (epoch 27), train_loss = 2.209, time/batch = 0.212\n",
            "8762/15750 (epoch 27), train_loss = 2.232, time/batch = 0.203\n",
            "8763/15750 (epoch 27), train_loss = 2.394, time/batch = 0.207\n",
            "8764/15750 (epoch 27), train_loss = 2.363, time/batch = 0.210\n",
            "8765/15750 (epoch 27), train_loss = 2.334, time/batch = 0.207\n",
            "8766/15750 (epoch 27), train_loss = 2.280, time/batch = 0.209\n",
            "8767/15750 (epoch 27), train_loss = 2.307, time/batch = 0.203\n",
            "8768/15750 (epoch 27), train_loss = 2.292, time/batch = 0.203\n",
            "8769/15750 (epoch 27), train_loss = 2.325, time/batch = 0.209\n",
            "8770/15750 (epoch 27), train_loss = 2.373, time/batch = 0.205\n",
            "8771/15750 (epoch 27), train_loss = 2.379, time/batch = 0.219\n",
            "8772/15750 (epoch 27), train_loss = 2.297, time/batch = 0.209\n",
            "8773/15750 (epoch 27), train_loss = 2.334, time/batch = 0.209\n",
            "8774/15750 (epoch 27), train_loss = 2.360, time/batch = 0.207\n",
            "8775/15750 (epoch 27), train_loss = 2.350, time/batch = 0.204\n",
            "8776/15750 (epoch 27), train_loss = 2.254, time/batch = 0.205\n",
            "8777/15750 (epoch 27), train_loss = 2.288, time/batch = 0.205\n",
            "8778/15750 (epoch 27), train_loss = 2.354, time/batch = 0.202\n",
            "8779/15750 (epoch 27), train_loss = 2.372, time/batch = 0.213\n",
            "8780/15750 (epoch 27), train_loss = 2.324, time/batch = 0.207\n",
            "8781/15750 (epoch 27), train_loss = 2.378, time/batch = 0.205\n",
            "8782/15750 (epoch 27), train_loss = 2.308, time/batch = 0.205\n",
            "8783/15750 (epoch 27), train_loss = 2.275, time/batch = 0.209\n",
            "8784/15750 (epoch 27), train_loss = 2.229, time/batch = 0.209\n",
            "8785/15750 (epoch 27), train_loss = 2.458, time/batch = 0.211\n",
            "8786/15750 (epoch 27), train_loss = 2.286, time/batch = 0.203\n",
            "8787/15750 (epoch 27), train_loss = 2.248, time/batch = 0.211\n",
            "8788/15750 (epoch 27), train_loss = 2.364, time/batch = 0.209\n",
            "8789/15750 (epoch 27), train_loss = 2.265, time/batch = 0.204\n",
            "8790/15750 (epoch 27), train_loss = 2.403, time/batch = 0.218\n",
            "8791/15750 (epoch 27), train_loss = 2.293, time/batch = 0.207\n",
            "8792/15750 (epoch 27), train_loss = 2.306, time/batch = 0.207\n",
            "8793/15750 (epoch 27), train_loss = 2.227, time/batch = 0.211\n",
            "8794/15750 (epoch 27), train_loss = 2.325, time/batch = 0.212\n",
            "8795/15750 (epoch 27), train_loss = 2.251, time/batch = 0.213\n",
            "8796/15750 (epoch 27), train_loss = 2.325, time/batch = 0.201\n",
            "8797/15750 (epoch 27), train_loss = 2.318, time/batch = 0.204\n",
            "8798/15750 (epoch 27), train_loss = 2.282, time/batch = 0.208\n",
            "8799/15750 (epoch 27), train_loss = 2.333, time/batch = 0.195\n",
            "8800/15750 (epoch 27), train_loss = 2.416, time/batch = 0.214\n",
            "8801/15750 (epoch 27), train_loss = 2.371, time/batch = 0.208\n",
            "8802/15750 (epoch 27), train_loss = 2.387, time/batch = 0.205\n",
            "8803/15750 (epoch 27), train_loss = 2.260, time/batch = 0.213\n",
            "8804/15750 (epoch 27), train_loss = 2.328, time/batch = 0.209\n",
            "8805/15750 (epoch 27), train_loss = 2.318, time/batch = 0.211\n",
            "8806/15750 (epoch 27), train_loss = 2.245, time/batch = 0.207\n",
            "8807/15750 (epoch 27), train_loss = 2.373, time/batch = 0.207\n",
            "8808/15750 (epoch 27), train_loss = 2.230, time/batch = 0.206\n",
            "8809/15750 (epoch 27), train_loss = 2.359, time/batch = 0.204\n",
            "8810/15750 (epoch 27), train_loss = 2.306, time/batch = 0.216\n",
            "8811/15750 (epoch 27), train_loss = 2.274, time/batch = 0.206\n",
            "8812/15750 (epoch 27), train_loss = 2.228, time/batch = 0.203\n",
            "8813/15750 (epoch 27), train_loss = 2.257, time/batch = 0.203\n",
            "8814/15750 (epoch 27), train_loss = 2.379, time/batch = 0.202\n",
            "8815/15750 (epoch 27), train_loss = 2.244, time/batch = 0.211\n",
            "8816/15750 (epoch 27), train_loss = 2.224, time/batch = 0.215\n",
            "8817/15750 (epoch 27), train_loss = 2.259, time/batch = 0.204\n",
            "8818/15750 (epoch 27), train_loss = 2.262, time/batch = 0.207\n",
            "8819/15750 (epoch 27), train_loss = 2.365, time/batch = 0.209\n",
            "8820/15750 (epoch 28), train_loss = 2.274, time/batch = 0.204\n",
            "8821/15750 (epoch 28), train_loss = 2.362, time/batch = 0.203\n",
            "8822/15750 (epoch 28), train_loss = 2.297, time/batch = 0.201\n",
            "8823/15750 (epoch 28), train_loss = 2.390, time/batch = 0.207\n",
            "8824/15750 (epoch 28), train_loss = 2.313, time/batch = 0.208\n",
            "8825/15750 (epoch 28), train_loss = 2.308, time/batch = 0.194\n",
            "8826/15750 (epoch 28), train_loss = 2.467, time/batch = 0.202\n",
            "8827/15750 (epoch 28), train_loss = 2.381, time/batch = 0.201\n",
            "8828/15750 (epoch 28), train_loss = 2.375, time/batch = 0.203\n",
            "8829/15750 (epoch 28), train_loss = 2.320, time/batch = 0.210\n",
            "8830/15750 (epoch 28), train_loss = 2.325, time/batch = 0.199\n",
            "8831/15750 (epoch 28), train_loss = 2.284, time/batch = 0.203\n",
            "8832/15750 (epoch 28), train_loss = 2.370, time/batch = 0.202\n",
            "8833/15750 (epoch 28), train_loss = 2.347, time/batch = 0.199\n",
            "8834/15750 (epoch 28), train_loss = 2.323, time/batch = 0.206\n",
            "8835/15750 (epoch 28), train_loss = 2.349, time/batch = 0.201\n",
            "8836/15750 (epoch 28), train_loss = 2.352, time/batch = 0.213\n",
            "8837/15750 (epoch 28), train_loss = 2.413, time/batch = 0.204\n",
            "8838/15750 (epoch 28), train_loss = 2.426, time/batch = 0.209\n",
            "8839/15750 (epoch 28), train_loss = 2.373, time/batch = 0.212\n",
            "8840/15750 (epoch 28), train_loss = 2.363, time/batch = 0.211\n",
            "8841/15750 (epoch 28), train_loss = 2.377, time/batch = 0.209\n",
            "8842/15750 (epoch 28), train_loss = 2.327, time/batch = 0.207\n",
            "8843/15750 (epoch 28), train_loss = 2.384, time/batch = 0.207\n",
            "8844/15750 (epoch 28), train_loss = 2.385, time/batch = 0.215\n",
            "8845/15750 (epoch 28), train_loss = 2.410, time/batch = 0.208\n",
            "8846/15750 (epoch 28), train_loss = 2.414, time/batch = 0.210\n",
            "8847/15750 (epoch 28), train_loss = 2.397, time/batch = 0.209\n",
            "8848/15750 (epoch 28), train_loss = 2.507, time/batch = 0.206\n",
            "8849/15750 (epoch 28), train_loss = 2.416, time/batch = 0.209\n",
            "8850/15750 (epoch 28), train_loss = 2.379, time/batch = 0.206\n",
            "8851/15750 (epoch 28), train_loss = 2.346, time/batch = 0.217\n",
            "8852/15750 (epoch 28), train_loss = 2.259, time/batch = 0.214\n",
            "8853/15750 (epoch 28), train_loss = 2.279, time/batch = 0.206\n",
            "8854/15750 (epoch 28), train_loss = 2.364, time/batch = 0.214\n",
            "8855/15750 (epoch 28), train_loss = 2.264, time/batch = 0.214\n",
            "8856/15750 (epoch 28), train_loss = 2.336, time/batch = 0.210\n",
            "8857/15750 (epoch 28), train_loss = 2.390, time/batch = 0.212\n",
            "8858/15750 (epoch 28), train_loss = 2.300, time/batch = 0.206\n",
            "8859/15750 (epoch 28), train_loss = 2.349, time/batch = 0.204\n",
            "8860/15750 (epoch 28), train_loss = 2.305, time/batch = 0.208\n",
            "8861/15750 (epoch 28), train_loss = 2.354, time/batch = 0.206\n",
            "8862/15750 (epoch 28), train_loss = 2.353, time/batch = 0.202\n",
            "8863/15750 (epoch 28), train_loss = 2.315, time/batch = 0.210\n",
            "8864/15750 (epoch 28), train_loss = 2.349, time/batch = 0.207\n",
            "8865/15750 (epoch 28), train_loss = 2.274, time/batch = 0.205\n",
            "8866/15750 (epoch 28), train_loss = 2.314, time/batch = 0.211\n",
            "8867/15750 (epoch 28), train_loss = 2.334, time/batch = 0.208\n",
            "8868/15750 (epoch 28), train_loss = 2.373, time/batch = 0.214\n",
            "8869/15750 (epoch 28), train_loss = 2.258, time/batch = 0.206\n",
            "8870/15750 (epoch 28), train_loss = 2.323, time/batch = 0.206\n",
            "8871/15750 (epoch 28), train_loss = 2.278, time/batch = 0.202\n",
            "8872/15750 (epoch 28), train_loss = 2.336, time/batch = 0.211\n",
            "8873/15750 (epoch 28), train_loss = 2.350, time/batch = 0.210\n",
            "8874/15750 (epoch 28), train_loss = 2.348, time/batch = 0.204\n",
            "8875/15750 (epoch 28), train_loss = 2.378, time/batch = 0.203\n",
            "8876/15750 (epoch 28), train_loss = 2.264, time/batch = 0.203\n",
            "8877/15750 (epoch 28), train_loss = 2.261, time/batch = 0.202\n",
            "8878/15750 (epoch 28), train_loss = 2.356, time/batch = 0.210\n",
            "8879/15750 (epoch 28), train_loss = 2.216, time/batch = 0.209\n",
            "8880/15750 (epoch 28), train_loss = 2.317, time/batch = 0.205\n",
            "8881/15750 (epoch 28), train_loss = 2.323, time/batch = 0.211\n",
            "8882/15750 (epoch 28), train_loss = 2.253, time/batch = 0.205\n",
            "8883/15750 (epoch 28), train_loss = 2.311, time/batch = 0.209\n",
            "8884/15750 (epoch 28), train_loss = 2.217, time/batch = 0.205\n",
            "8885/15750 (epoch 28), train_loss = 2.241, time/batch = 0.204\n",
            "8886/15750 (epoch 28), train_loss = 2.181, time/batch = 0.214\n",
            "8887/15750 (epoch 28), train_loss = 2.199, time/batch = 0.207\n",
            "8888/15750 (epoch 28), train_loss = 2.255, time/batch = 0.217\n",
            "8889/15750 (epoch 28), train_loss = 2.345, time/batch = 0.208\n",
            "8890/15750 (epoch 28), train_loss = 2.270, time/batch = 0.209\n",
            "8891/15750 (epoch 28), train_loss = 2.259, time/batch = 0.207\n",
            "8892/15750 (epoch 28), train_loss = 2.175, time/batch = 0.209\n",
            "8893/15750 (epoch 28), train_loss = 2.250, time/batch = 0.212\n",
            "8894/15750 (epoch 28), train_loss = 2.359, time/batch = 0.213\n",
            "8895/15750 (epoch 28), train_loss = 2.294, time/batch = 0.205\n",
            "8896/15750 (epoch 28), train_loss = 2.289, time/batch = 0.207\n",
            "8897/15750 (epoch 28), train_loss = 2.292, time/batch = 0.200\n",
            "8898/15750 (epoch 28), train_loss = 2.301, time/batch = 0.209\n",
            "8899/15750 (epoch 28), train_loss = 2.294, time/batch = 0.201\n",
            "8900/15750 (epoch 28), train_loss = 2.194, time/batch = 0.206\n",
            "8901/15750 (epoch 28), train_loss = 2.296, time/batch = 0.206\n",
            "8902/15750 (epoch 28), train_loss = 2.239, time/batch = 0.212\n",
            "8903/15750 (epoch 28), train_loss = 2.294, time/batch = 0.217\n",
            "8904/15750 (epoch 28), train_loss = 2.352, time/batch = 0.219\n",
            "8905/15750 (epoch 28), train_loss = 2.371, time/batch = 0.212\n",
            "8906/15750 (epoch 28), train_loss = 2.208, time/batch = 0.210\n",
            "8907/15750 (epoch 28), train_loss = 2.241, time/batch = 0.210\n",
            "8908/15750 (epoch 28), train_loss = 2.261, time/batch = 0.201\n",
            "8909/15750 (epoch 28), train_loss = 2.262, time/batch = 0.204\n",
            "8910/15750 (epoch 28), train_loss = 2.262, time/batch = 0.211\n",
            "8911/15750 (epoch 28), train_loss = 2.323, time/batch = 0.205\n",
            "8912/15750 (epoch 28), train_loss = 2.311, time/batch = 0.196\n",
            "8913/15750 (epoch 28), train_loss = 2.324, time/batch = 0.207\n",
            "8914/15750 (epoch 28), train_loss = 2.387, time/batch = 0.205\n",
            "8915/15750 (epoch 28), train_loss = 2.290, time/batch = 0.213\n",
            "8916/15750 (epoch 28), train_loss = 2.316, time/batch = 0.203\n",
            "8917/15750 (epoch 28), train_loss = 2.337, time/batch = 0.218\n",
            "8918/15750 (epoch 28), train_loss = 2.321, time/batch = 0.205\n",
            "8919/15750 (epoch 28), train_loss = 2.335, time/batch = 0.208\n",
            "8920/15750 (epoch 28), train_loss = 2.314, time/batch = 0.206\n",
            "8921/15750 (epoch 28), train_loss = 2.250, time/batch = 0.206\n",
            "8922/15750 (epoch 28), train_loss = 2.271, time/batch = 0.208\n",
            "8923/15750 (epoch 28), train_loss = 2.396, time/batch = 0.212\n",
            "8924/15750 (epoch 28), train_loss = 2.319, time/batch = 0.209\n",
            "8925/15750 (epoch 28), train_loss = 2.230, time/batch = 0.201\n",
            "8926/15750 (epoch 28), train_loss = 2.289, time/batch = 0.203\n",
            "8927/15750 (epoch 28), train_loss = 2.315, time/batch = 0.215\n",
            "8928/15750 (epoch 28), train_loss = 2.356, time/batch = 0.205\n",
            "8929/15750 (epoch 28), train_loss = 2.381, time/batch = 0.202\n",
            "8930/15750 (epoch 28), train_loss = 2.431, time/batch = 0.204\n",
            "8931/15750 (epoch 28), train_loss = 2.302, time/batch = 0.201\n",
            "8932/15750 (epoch 28), train_loss = 2.299, time/batch = 0.204\n",
            "8933/15750 (epoch 28), train_loss = 2.305, time/batch = 0.199\n",
            "8934/15750 (epoch 28), train_loss = 2.313, time/batch = 0.206\n",
            "8935/15750 (epoch 28), train_loss = 2.393, time/batch = 0.205\n",
            "8936/15750 (epoch 28), train_loss = 2.314, time/batch = 0.199\n",
            "8937/15750 (epoch 28), train_loss = 2.438, time/batch = 0.206\n",
            "8938/15750 (epoch 28), train_loss = 2.321, time/batch = 0.207\n",
            "8939/15750 (epoch 28), train_loss = 2.303, time/batch = 0.212\n",
            "8940/15750 (epoch 28), train_loss = 2.276, time/batch = 0.208\n",
            "8941/15750 (epoch 28), train_loss = 2.255, time/batch = 0.208\n",
            "8942/15750 (epoch 28), train_loss = 2.294, time/batch = 0.214\n",
            "8943/15750 (epoch 28), train_loss = 2.257, time/batch = 0.209\n",
            "8944/15750 (epoch 28), train_loss = 2.289, time/batch = 0.208\n",
            "8945/15750 (epoch 28), train_loss = 2.305, time/batch = 0.206\n",
            "8946/15750 (epoch 28), train_loss = 2.388, time/batch = 0.210\n",
            "8947/15750 (epoch 28), train_loss = 2.271, time/batch = 0.211\n",
            "8948/15750 (epoch 28), train_loss = 2.289, time/batch = 0.207\n",
            "8949/15750 (epoch 28), train_loss = 2.265, time/batch = 0.206\n",
            "8950/15750 (epoch 28), train_loss = 2.210, time/batch = 0.205\n",
            "8951/15750 (epoch 28), train_loss = 2.219, time/batch = 0.205\n",
            "8952/15750 (epoch 28), train_loss = 2.234, time/batch = 0.208\n",
            "8953/15750 (epoch 28), train_loss = 2.253, time/batch = 0.203\n",
            "8954/15750 (epoch 28), train_loss = 2.276, time/batch = 0.200\n",
            "8955/15750 (epoch 28), train_loss = 2.403, time/batch = 0.201\n",
            "8956/15750 (epoch 28), train_loss = 2.362, time/batch = 0.199\n",
            "8957/15750 (epoch 28), train_loss = 2.362, time/batch = 0.204\n",
            "8958/15750 (epoch 28), train_loss = 2.350, time/batch = 0.198\n",
            "8959/15750 (epoch 28), train_loss = 2.278, time/batch = 0.204\n",
            "8960/15750 (epoch 28), train_loss = 2.278, time/batch = 0.198\n",
            "8961/15750 (epoch 28), train_loss = 2.365, time/batch = 0.201\n",
            "8962/15750 (epoch 28), train_loss = 2.386, time/batch = 0.207\n",
            "8963/15750 (epoch 28), train_loss = 2.367, time/batch = 0.200\n",
            "8964/15750 (epoch 28), train_loss = 2.281, time/batch = 0.199\n",
            "8965/15750 (epoch 28), train_loss = 2.278, time/batch = 0.199\n",
            "8966/15750 (epoch 28), train_loss = 2.239, time/batch = 0.206\n",
            "8967/15750 (epoch 28), train_loss = 2.329, time/batch = 0.206\n",
            "8968/15750 (epoch 28), train_loss = 2.355, time/batch = 0.193\n",
            "8969/15750 (epoch 28), train_loss = 2.301, time/batch = 0.202\n",
            "8970/15750 (epoch 28), train_loss = 2.303, time/batch = 0.200\n",
            "8971/15750 (epoch 28), train_loss = 2.343, time/batch = 0.200\n",
            "8972/15750 (epoch 28), train_loss = 2.385, time/batch = 0.206\n",
            "8973/15750 (epoch 28), train_loss = 2.332, time/batch = 0.198\n",
            "8974/15750 (epoch 28), train_loss = 2.344, time/batch = 0.202\n",
            "8975/15750 (epoch 28), train_loss = 2.334, time/batch = 0.207\n",
            "8976/15750 (epoch 28), train_loss = 2.335, time/batch = 0.202\n",
            "8977/15750 (epoch 28), train_loss = 2.327, time/batch = 0.203\n",
            "8978/15750 (epoch 28), train_loss = 2.417, time/batch = 0.203\n",
            "8979/15750 (epoch 28), train_loss = 2.274, time/batch = 0.200\n",
            "8980/15750 (epoch 28), train_loss = 2.346, time/batch = 0.200\n",
            "8981/15750 (epoch 28), train_loss = 2.340, time/batch = 0.206\n",
            "8982/15750 (epoch 28), train_loss = 2.364, time/batch = 0.198\n",
            "8983/15750 (epoch 28), train_loss = 2.443, time/batch = 0.203\n",
            "8984/15750 (epoch 28), train_loss = 2.364, time/batch = 0.204\n",
            "8985/15750 (epoch 28), train_loss = 2.363, time/batch = 0.200\n",
            "8986/15750 (epoch 28), train_loss = 2.343, time/batch = 0.209\n",
            "8987/15750 (epoch 28), train_loss = 2.308, time/batch = 0.201\n",
            "8988/15750 (epoch 28), train_loss = 2.276, time/batch = 0.201\n",
            "8989/15750 (epoch 28), train_loss = 2.267, time/batch = 0.201\n",
            "8990/15750 (epoch 28), train_loss = 2.315, time/batch = 0.200\n",
            "8991/15750 (epoch 28), train_loss = 2.349, time/batch = 0.198\n",
            "8992/15750 (epoch 28), train_loss = 2.317, time/batch = 0.202\n",
            "8993/15750 (epoch 28), train_loss = 2.378, time/batch = 0.195\n",
            "8994/15750 (epoch 28), train_loss = 2.322, time/batch = 0.202\n",
            "8995/15750 (epoch 28), train_loss = 2.253, time/batch = 0.200\n",
            "8996/15750 (epoch 28), train_loss = 2.282, time/batch = 0.210\n",
            "8997/15750 (epoch 28), train_loss = 2.339, time/batch = 0.207\n",
            "8998/15750 (epoch 28), train_loss = 2.273, time/batch = 0.199\n",
            "8999/15750 (epoch 28), train_loss = 2.234, time/batch = 0.201\n",
            "9000/15750 (epoch 28), train_loss = 2.268, time/batch = 0.203\n",
            "model saved to ./save_star/model.ckpt\n",
            "9001/15750 (epoch 28), train_loss = 2.349, time/batch = 0.206\n",
            "9002/15750 (epoch 28), train_loss = 2.319, time/batch = 0.209\n",
            "9003/15750 (epoch 28), train_loss = 2.381, time/batch = 0.208\n",
            "9004/15750 (epoch 28), train_loss = 2.372, time/batch = 0.201\n",
            "9005/15750 (epoch 28), train_loss = 2.314, time/batch = 0.208\n",
            "9006/15750 (epoch 28), train_loss = 2.274, time/batch = 0.213\n",
            "9007/15750 (epoch 28), train_loss = 2.346, time/batch = 0.206\n",
            "9008/15750 (epoch 28), train_loss = 2.372, time/batch = 0.204\n",
            "9009/15750 (epoch 28), train_loss = 2.441, time/batch = 0.210\n",
            "9010/15750 (epoch 28), train_loss = 2.410, time/batch = 0.201\n",
            "9011/15750 (epoch 28), train_loss = 2.325, time/batch = 0.213\n",
            "9012/15750 (epoch 28), train_loss = 2.341, time/batch = 0.203\n",
            "9013/15750 (epoch 28), train_loss = 2.267, time/batch = 0.208\n",
            "9014/15750 (epoch 28), train_loss = 2.392, time/batch = 0.203\n",
            "9015/15750 (epoch 28), train_loss = 2.368, time/batch = 0.204\n",
            "9016/15750 (epoch 28), train_loss = 2.323, time/batch = 0.204\n",
            "9017/15750 (epoch 28), train_loss = 2.269, time/batch = 0.204\n",
            "9018/15750 (epoch 28), train_loss = 2.368, time/batch = 0.202\n",
            "9019/15750 (epoch 28), train_loss = 2.163, time/batch = 0.197\n",
            "9020/15750 (epoch 28), train_loss = 2.273, time/batch = 0.203\n",
            "9021/15750 (epoch 28), train_loss = 2.231, time/batch = 0.206\n",
            "9022/15750 (epoch 28), train_loss = 2.311, time/batch = 0.195\n",
            "9023/15750 (epoch 28), train_loss = 2.285, time/batch = 0.200\n",
            "9024/15750 (epoch 28), train_loss = 2.349, time/batch = 0.207\n",
            "9025/15750 (epoch 28), train_loss = 2.299, time/batch = 0.199\n",
            "9026/15750 (epoch 28), train_loss = 2.178, time/batch = 0.206\n",
            "9027/15750 (epoch 28), train_loss = 2.250, time/batch = 0.200\n",
            "9028/15750 (epoch 28), train_loss = 2.255, time/batch = 0.196\n",
            "9029/15750 (epoch 28), train_loss = 2.316, time/batch = 0.206\n",
            "9030/15750 (epoch 28), train_loss = 2.198, time/batch = 0.197\n",
            "9031/15750 (epoch 28), train_loss = 2.276, time/batch = 0.206\n",
            "9032/15750 (epoch 28), train_loss = 2.167, time/batch = 0.199\n",
            "9033/15750 (epoch 28), train_loss = 2.239, time/batch = 0.202\n",
            "9034/15750 (epoch 28), train_loss = 2.232, time/batch = 0.204\n",
            "9035/15750 (epoch 28), train_loss = 2.224, time/batch = 0.197\n",
            "9036/15750 (epoch 28), train_loss = 2.373, time/batch = 0.211\n",
            "9037/15750 (epoch 28), train_loss = 2.196, time/batch = 0.202\n",
            "9038/15750 (epoch 28), train_loss = 2.443, time/batch = 0.204\n",
            "9039/15750 (epoch 28), train_loss = 2.304, time/batch = 0.210\n",
            "9040/15750 (epoch 28), train_loss = 2.183, time/batch = 0.208\n",
            "9041/15750 (epoch 28), train_loss = 2.221, time/batch = 0.211\n",
            "9042/15750 (epoch 28), train_loss = 2.282, time/batch = 0.206\n",
            "9043/15750 (epoch 28), train_loss = 2.274, time/batch = 0.206\n",
            "9044/15750 (epoch 28), train_loss = 2.261, time/batch = 0.205\n",
            "9045/15750 (epoch 28), train_loss = 2.265, time/batch = 0.203\n",
            "9046/15750 (epoch 28), train_loss = 2.335, time/batch = 0.208\n",
            "9047/15750 (epoch 28), train_loss = 2.253, time/batch = 0.207\n",
            "9048/15750 (epoch 28), train_loss = 2.297, time/batch = 0.208\n",
            "9049/15750 (epoch 28), train_loss = 2.373, time/batch = 0.202\n",
            "9050/15750 (epoch 28), train_loss = 2.227, time/batch = 0.215\n",
            "9051/15750 (epoch 28), train_loss = 2.252, time/batch = 0.214\n",
            "9052/15750 (epoch 28), train_loss = 2.292, time/batch = 0.200\n",
            "9053/15750 (epoch 28), train_loss = 2.290, time/batch = 0.205\n",
            "9054/15750 (epoch 28), train_loss = 2.242, time/batch = 0.206\n",
            "9055/15750 (epoch 28), train_loss = 2.234, time/batch = 0.204\n",
            "9056/15750 (epoch 28), train_loss = 2.208, time/batch = 0.207\n",
            "9057/15750 (epoch 28), train_loss = 2.260, time/batch = 0.196\n",
            "9058/15750 (epoch 28), train_loss = 2.469, time/batch = 0.201\n",
            "9059/15750 (epoch 28), train_loss = 2.288, time/batch = 0.202\n",
            "9060/15750 (epoch 28), train_loss = 2.342, time/batch = 0.204\n",
            "9061/15750 (epoch 28), train_loss = 2.220, time/batch = 0.207\n",
            "9062/15750 (epoch 28), train_loss = 2.275, time/batch = 0.202\n",
            "9063/15750 (epoch 28), train_loss = 2.299, time/batch = 0.203\n",
            "9064/15750 (epoch 28), train_loss = 2.303, time/batch = 0.201\n",
            "9065/15750 (epoch 28), train_loss = 2.356, time/batch = 0.200\n",
            "9066/15750 (epoch 28), train_loss = 2.320, time/batch = 0.201\n",
            "9067/15750 (epoch 28), train_loss = 2.312, time/batch = 0.200\n",
            "9068/15750 (epoch 28), train_loss = 2.297, time/batch = 0.202\n",
            "9069/15750 (epoch 28), train_loss = 2.323, time/batch = 0.202\n",
            "9070/15750 (epoch 28), train_loss = 2.219, time/batch = 0.202\n",
            "9071/15750 (epoch 28), train_loss = 2.215, time/batch = 0.208\n",
            "9072/15750 (epoch 28), train_loss = 2.299, time/batch = 0.197\n",
            "9073/15750 (epoch 28), train_loss = 2.317, time/batch = 0.200\n",
            "9074/15750 (epoch 28), train_loss = 2.286, time/batch = 0.206\n",
            "9075/15750 (epoch 28), train_loss = 2.251, time/batch = 0.202\n",
            "9076/15750 (epoch 28), train_loss = 2.200, time/batch = 0.204\n",
            "9077/15750 (epoch 28), train_loss = 2.224, time/batch = 0.199\n",
            "9078/15750 (epoch 28), train_loss = 2.385, time/batch = 0.200\n",
            "9079/15750 (epoch 28), train_loss = 2.355, time/batch = 0.202\n",
            "9080/15750 (epoch 28), train_loss = 2.326, time/batch = 0.199\n",
            "9081/15750 (epoch 28), train_loss = 2.272, time/batch = 0.207\n",
            "9082/15750 (epoch 28), train_loss = 2.299, time/batch = 0.203\n",
            "9083/15750 (epoch 28), train_loss = 2.285, time/batch = 0.202\n",
            "9084/15750 (epoch 28), train_loss = 2.316, time/batch = 0.198\n",
            "9085/15750 (epoch 28), train_loss = 2.363, time/batch = 0.199\n",
            "9086/15750 (epoch 28), train_loss = 2.370, time/batch = 0.207\n",
            "9087/15750 (epoch 28), train_loss = 2.288, time/batch = 0.197\n",
            "9088/15750 (epoch 28), train_loss = 2.325, time/batch = 0.201\n",
            "9089/15750 (epoch 28), train_loss = 2.352, time/batch = 0.200\n",
            "9090/15750 (epoch 28), train_loss = 2.341, time/batch = 0.204\n",
            "9091/15750 (epoch 28), train_loss = 2.246, time/batch = 0.203\n",
            "9092/15750 (epoch 28), train_loss = 2.281, time/batch = 0.204\n",
            "9093/15750 (epoch 28), train_loss = 2.346, time/batch = 0.200\n",
            "9094/15750 (epoch 28), train_loss = 2.363, time/batch = 0.201\n",
            "9095/15750 (epoch 28), train_loss = 2.315, time/batch = 0.206\n",
            "9096/15750 (epoch 28), train_loss = 2.369, time/batch = 0.206\n",
            "9097/15750 (epoch 28), train_loss = 2.300, time/batch = 0.202\n",
            "9098/15750 (epoch 28), train_loss = 2.268, time/batch = 0.206\n",
            "9099/15750 (epoch 28), train_loss = 2.221, time/batch = 0.204\n",
            "9100/15750 (epoch 28), train_loss = 2.449, time/batch = 0.196\n",
            "9101/15750 (epoch 28), train_loss = 2.277, time/batch = 0.206\n",
            "9102/15750 (epoch 28), train_loss = 2.240, time/batch = 0.205\n",
            "9103/15750 (epoch 28), train_loss = 2.355, time/batch = 0.199\n",
            "9104/15750 (epoch 28), train_loss = 2.257, time/batch = 0.198\n",
            "9105/15750 (epoch 28), train_loss = 2.394, time/batch = 0.201\n",
            "9106/15750 (epoch 28), train_loss = 2.286, time/batch = 0.211\n",
            "9107/15750 (epoch 28), train_loss = 2.299, time/batch = 0.200\n",
            "9108/15750 (epoch 28), train_loss = 2.220, time/batch = 0.202\n",
            "9109/15750 (epoch 28), train_loss = 2.317, time/batch = 0.199\n",
            "9110/15750 (epoch 28), train_loss = 2.244, time/batch = 0.197\n",
            "9111/15750 (epoch 28), train_loss = 2.317, time/batch = 0.206\n",
            "9112/15750 (epoch 28), train_loss = 2.310, time/batch = 0.200\n",
            "9113/15750 (epoch 28), train_loss = 2.272, time/batch = 0.202\n",
            "9114/15750 (epoch 28), train_loss = 2.325, time/batch = 0.200\n",
            "9115/15750 (epoch 28), train_loss = 2.407, time/batch = 0.202\n",
            "9116/15750 (epoch 28), train_loss = 2.361, time/batch = 0.207\n",
            "9117/15750 (epoch 28), train_loss = 2.378, time/batch = 0.201\n",
            "9118/15750 (epoch 28), train_loss = 2.252, time/batch = 0.200\n",
            "9119/15750 (epoch 28), train_loss = 2.320, time/batch = 0.200\n",
            "9120/15750 (epoch 28), train_loss = 2.309, time/batch = 0.198\n",
            "9121/15750 (epoch 28), train_loss = 2.238, time/batch = 0.203\n",
            "9122/15750 (epoch 28), train_loss = 2.365, time/batch = 0.202\n",
            "9123/15750 (epoch 28), train_loss = 2.222, time/batch = 0.202\n",
            "9124/15750 (epoch 28), train_loss = 2.351, time/batch = 0.201\n",
            "9125/15750 (epoch 28), train_loss = 2.299, time/batch = 0.200\n",
            "9126/15750 (epoch 28), train_loss = 2.266, time/batch = 0.201\n",
            "9127/15750 (epoch 28), train_loss = 2.219, time/batch = 0.196\n",
            "9128/15750 (epoch 28), train_loss = 2.249, time/batch = 0.201\n",
            "9129/15750 (epoch 28), train_loss = 2.369, time/batch = 0.203\n",
            "9130/15750 (epoch 28), train_loss = 2.237, time/batch = 0.201\n",
            "9131/15750 (epoch 28), train_loss = 2.217, time/batch = 0.199\n",
            "9132/15750 (epoch 28), train_loss = 2.251, time/batch = 0.204\n",
            "9133/15750 (epoch 28), train_loss = 2.255, time/batch = 0.206\n",
            "9134/15750 (epoch 28), train_loss = 2.358, time/batch = 0.198\n",
            "9135/15750 (epoch 29), train_loss = 2.260, time/batch = 0.204\n",
            "9136/15750 (epoch 29), train_loss = 2.352, time/batch = 0.212\n",
            "9137/15750 (epoch 29), train_loss = 2.288, time/batch = 0.202\n",
            "9138/15750 (epoch 29), train_loss = 2.381, time/batch = 0.208\n",
            "9139/15750 (epoch 29), train_loss = 2.305, time/batch = 0.205\n",
            "9140/15750 (epoch 29), train_loss = 2.301, time/batch = 0.199\n",
            "9141/15750 (epoch 29), train_loss = 2.458, time/batch = 0.217\n",
            "9142/15750 (epoch 29), train_loss = 2.373, time/batch = 0.207\n",
            "9143/15750 (epoch 29), train_loss = 2.366, time/batch = 0.202\n",
            "9144/15750 (epoch 29), train_loss = 2.313, time/batch = 0.199\n",
            "9145/15750 (epoch 29), train_loss = 2.317, time/batch = 0.206\n",
            "9146/15750 (epoch 29), train_loss = 2.278, time/batch = 0.209\n",
            "9147/15750 (epoch 29), train_loss = 2.362, time/batch = 0.201\n",
            "9148/15750 (epoch 29), train_loss = 2.338, time/batch = 0.206\n",
            "9149/15750 (epoch 29), train_loss = 2.314, time/batch = 0.201\n",
            "9150/15750 (epoch 29), train_loss = 2.341, time/batch = 0.202\n",
            "9151/15750 (epoch 29), train_loss = 2.343, time/batch = 0.205\n",
            "9152/15750 (epoch 29), train_loss = 2.405, time/batch = 0.199\n",
            "9153/15750 (epoch 29), train_loss = 2.418, time/batch = 0.202\n",
            "9154/15750 (epoch 29), train_loss = 2.365, time/batch = 0.203\n",
            "9155/15750 (epoch 29), train_loss = 2.354, time/batch = 0.199\n",
            "9156/15750 (epoch 29), train_loss = 2.368, time/batch = 0.204\n",
            "9157/15750 (epoch 29), train_loss = 2.320, time/batch = 0.194\n",
            "9158/15750 (epoch 29), train_loss = 2.375, time/batch = 0.206\n",
            "9159/15750 (epoch 29), train_loss = 2.377, time/batch = 0.203\n",
            "9160/15750 (epoch 29), train_loss = 2.402, time/batch = 0.198\n",
            "9161/15750 (epoch 29), train_loss = 2.405, time/batch = 0.207\n",
            "9162/15750 (epoch 29), train_loss = 2.388, time/batch = 0.202\n",
            "9163/15750 (epoch 29), train_loss = 2.498, time/batch = 0.196\n",
            "9164/15750 (epoch 29), train_loss = 2.408, time/batch = 0.199\n",
            "9165/15750 (epoch 29), train_loss = 2.370, time/batch = 0.200\n",
            "9166/15750 (epoch 29), train_loss = 2.338, time/batch = 0.206\n",
            "9167/15750 (epoch 29), train_loss = 2.251, time/batch = 0.205\n",
            "9168/15750 (epoch 29), train_loss = 2.270, time/batch = 0.200\n",
            "9169/15750 (epoch 29), train_loss = 2.355, time/batch = 0.195\n",
            "9170/15750 (epoch 29), train_loss = 2.255, time/batch = 0.203\n",
            "9171/15750 (epoch 29), train_loss = 2.329, time/batch = 0.209\n",
            "9172/15750 (epoch 29), train_loss = 2.381, time/batch = 0.199\n",
            "9173/15750 (epoch 29), train_loss = 2.292, time/batch = 0.201\n",
            "9174/15750 (epoch 29), train_loss = 2.341, time/batch = 0.203\n",
            "9175/15750 (epoch 29), train_loss = 2.297, time/batch = 0.202\n",
            "9176/15750 (epoch 29), train_loss = 2.346, time/batch = 0.211\n",
            "9177/15750 (epoch 29), train_loss = 2.345, time/batch = 0.210\n",
            "9178/15750 (epoch 29), train_loss = 2.308, time/batch = 0.205\n",
            "9179/15750 (epoch 29), train_loss = 2.341, time/batch = 0.204\n",
            "9180/15750 (epoch 29), train_loss = 2.266, time/batch = 0.207\n",
            "9181/15750 (epoch 29), train_loss = 2.307, time/batch = 0.214\n",
            "9182/15750 (epoch 29), train_loss = 2.326, time/batch = 0.208\n",
            "9183/15750 (epoch 29), train_loss = 2.365, time/batch = 0.209\n",
            "9184/15750 (epoch 29), train_loss = 2.249, time/batch = 0.208\n",
            "9185/15750 (epoch 29), train_loss = 2.316, time/batch = 0.205\n",
            "9186/15750 (epoch 29), train_loss = 2.270, time/batch = 0.214\n",
            "9187/15750 (epoch 29), train_loss = 2.328, time/batch = 0.203\n",
            "9188/15750 (epoch 29), train_loss = 2.342, time/batch = 0.203\n",
            "9189/15750 (epoch 29), train_loss = 2.340, time/batch = 0.208\n",
            "9190/15750 (epoch 29), train_loss = 2.370, time/batch = 0.207\n",
            "9191/15750 (epoch 29), train_loss = 2.256, time/batch = 0.207\n",
            "9192/15750 (epoch 29), train_loss = 2.253, time/batch = 0.205\n",
            "9193/15750 (epoch 29), train_loss = 2.348, time/batch = 0.201\n",
            "9194/15750 (epoch 29), train_loss = 2.208, time/batch = 0.203\n",
            "9195/15750 (epoch 29), train_loss = 2.310, time/batch = 0.195\n",
            "9196/15750 (epoch 29), train_loss = 2.315, time/batch = 0.206\n",
            "9197/15750 (epoch 29), train_loss = 2.245, time/batch = 0.198\n",
            "9198/15750 (epoch 29), train_loss = 2.304, time/batch = 0.203\n",
            "9199/15750 (epoch 29), train_loss = 2.210, time/batch = 0.200\n",
            "9200/15750 (epoch 29), train_loss = 2.233, time/batch = 0.201\n",
            "9201/15750 (epoch 29), train_loss = 2.173, time/batch = 0.208\n",
            "9202/15750 (epoch 29), train_loss = 2.191, time/batch = 0.201\n",
            "9203/15750 (epoch 29), train_loss = 2.247, time/batch = 0.201\n",
            "9204/15750 (epoch 29), train_loss = 2.337, time/batch = 0.204\n",
            "9205/15750 (epoch 29), train_loss = 2.262, time/batch = 0.203\n",
            "9206/15750 (epoch 29), train_loss = 2.251, time/batch = 0.207\n",
            "9207/15750 (epoch 29), train_loss = 2.168, time/batch = 0.200\n",
            "9208/15750 (epoch 29), train_loss = 2.241, time/batch = 0.200\n",
            "9209/15750 (epoch 29), train_loss = 2.351, time/batch = 0.201\n",
            "9210/15750 (epoch 29), train_loss = 2.286, time/batch = 0.196\n",
            "9211/15750 (epoch 29), train_loss = 2.281, time/batch = 0.204\n",
            "9212/15750 (epoch 29), train_loss = 2.284, time/batch = 0.201\n",
            "9213/15750 (epoch 29), train_loss = 2.293, time/batch = 0.202\n",
            "9214/15750 (epoch 29), train_loss = 2.286, time/batch = 0.200\n",
            "9215/15750 (epoch 29), train_loss = 2.187, time/batch = 0.205\n",
            "9216/15750 (epoch 29), train_loss = 2.288, time/batch = 0.206\n",
            "9217/15750 (epoch 29), train_loss = 2.231, time/batch = 0.201\n",
            "9218/15750 (epoch 29), train_loss = 2.285, time/batch = 0.199\n",
            "9219/15750 (epoch 29), train_loss = 2.343, time/batch = 0.202\n",
            "9220/15750 (epoch 29), train_loss = 2.362, time/batch = 0.200\n",
            "9221/15750 (epoch 29), train_loss = 2.199, time/batch = 0.208\n",
            "9222/15750 (epoch 29), train_loss = 2.233, time/batch = 0.209\n",
            "9223/15750 (epoch 29), train_loss = 2.252, time/batch = 0.202\n",
            "9224/15750 (epoch 29), train_loss = 2.254, time/batch = 0.197\n",
            "9225/15750 (epoch 29), train_loss = 2.253, time/batch = 0.201\n",
            "9226/15750 (epoch 29), train_loss = 2.315, time/batch = 0.204\n",
            "9227/15750 (epoch 29), train_loss = 2.303, time/batch = 0.197\n",
            "9228/15750 (epoch 29), train_loss = 2.315, time/batch = 0.201\n",
            "9229/15750 (epoch 29), train_loss = 2.378, time/batch = 0.203\n",
            "9230/15750 (epoch 29), train_loss = 2.282, time/batch = 0.204\n",
            "9231/15750 (epoch 29), train_loss = 2.309, time/batch = 0.204\n",
            "9232/15750 (epoch 29), train_loss = 2.330, time/batch = 0.196\n",
            "9233/15750 (epoch 29), train_loss = 2.312, time/batch = 0.202\n",
            "9234/15750 (epoch 29), train_loss = 2.327, time/batch = 0.202\n",
            "9235/15750 (epoch 29), train_loss = 2.306, time/batch = 0.208\n",
            "9236/15750 (epoch 29), train_loss = 2.243, time/batch = 0.204\n",
            "9237/15750 (epoch 29), train_loss = 2.263, time/batch = 0.204\n",
            "9238/15750 (epoch 29), train_loss = 2.388, time/batch = 0.202\n",
            "9239/15750 (epoch 29), train_loss = 2.311, time/batch = 0.196\n",
            "9240/15750 (epoch 29), train_loss = 2.222, time/batch = 0.199\n",
            "9241/15750 (epoch 29), train_loss = 2.280, time/batch = 0.205\n",
            "9242/15750 (epoch 29), train_loss = 2.307, time/batch = 0.202\n",
            "9243/15750 (epoch 29), train_loss = 2.347, time/batch = 0.203\n",
            "9244/15750 (epoch 29), train_loss = 2.373, time/batch = 0.201\n",
            "9245/15750 (epoch 29), train_loss = 2.424, time/batch = 0.204\n",
            "9246/15750 (epoch 29), train_loss = 2.294, time/batch = 0.205\n",
            "9247/15750 (epoch 29), train_loss = 2.292, time/batch = 0.204\n",
            "9248/15750 (epoch 29), train_loss = 2.296, time/batch = 0.198\n",
            "9249/15750 (epoch 29), train_loss = 2.304, time/batch = 0.202\n",
            "9250/15750 (epoch 29), train_loss = 2.384, time/batch = 0.200\n",
            "9251/15750 (epoch 29), train_loss = 2.306, time/batch = 0.201\n",
            "9252/15750 (epoch 29), train_loss = 2.429, time/batch = 0.200\n",
            "9253/15750 (epoch 29), train_loss = 2.314, time/batch = 0.201\n",
            "9254/15750 (epoch 29), train_loss = 2.296, time/batch = 0.206\n",
            "9255/15750 (epoch 29), train_loss = 2.268, time/batch = 0.200\n",
            "9256/15750 (epoch 29), train_loss = 2.248, time/batch = 0.198\n",
            "9257/15750 (epoch 29), train_loss = 2.286, time/batch = 0.198\n",
            "9258/15750 (epoch 29), train_loss = 2.249, time/batch = 0.207\n",
            "9259/15750 (epoch 29), train_loss = 2.281, time/batch = 0.203\n",
            "9260/15750 (epoch 29), train_loss = 2.296, time/batch = 0.201\n",
            "9261/15750 (epoch 29), train_loss = 2.379, time/batch = 0.203\n",
            "9262/15750 (epoch 29), train_loss = 2.264, time/batch = 0.194\n",
            "9263/15750 (epoch 29), train_loss = 2.282, time/batch = 0.199\n",
            "9264/15750 (epoch 29), train_loss = 2.256, time/batch = 0.200\n",
            "9265/15750 (epoch 29), train_loss = 2.202, time/batch = 0.201\n",
            "9266/15750 (epoch 29), train_loss = 2.212, time/batch = 0.204\n",
            "9267/15750 (epoch 29), train_loss = 2.227, time/batch = 0.207\n",
            "9268/15750 (epoch 29), train_loss = 2.246, time/batch = 0.199\n",
            "9269/15750 (epoch 29), train_loss = 2.268, time/batch = 0.205\n",
            "9270/15750 (epoch 29), train_loss = 2.395, time/batch = 0.204\n",
            "9271/15750 (epoch 29), train_loss = 2.355, time/batch = 0.200\n",
            "9272/15750 (epoch 29), train_loss = 2.355, time/batch = 0.210\n",
            "9273/15750 (epoch 29), train_loss = 2.343, time/batch = 0.203\n",
            "9274/15750 (epoch 29), train_loss = 2.270, time/batch = 0.201\n",
            "9275/15750 (epoch 29), train_loss = 2.270, time/batch = 0.197\n",
            "9276/15750 (epoch 29), train_loss = 2.358, time/batch = 0.200\n",
            "9277/15750 (epoch 29), train_loss = 2.380, time/batch = 0.209\n",
            "9278/15750 (epoch 29), train_loss = 2.359, time/batch = 0.202\n",
            "9279/15750 (epoch 29), train_loss = 2.273, time/batch = 0.198\n",
            "9280/15750 (epoch 29), train_loss = 2.270, time/batch = 0.198\n",
            "9281/15750 (epoch 29), train_loss = 2.232, time/batch = 0.197\n",
            "9282/15750 (epoch 29), train_loss = 2.322, time/batch = 0.207\n",
            "9283/15750 (epoch 29), train_loss = 2.348, time/batch = 0.204\n",
            "9284/15750 (epoch 29), train_loss = 2.295, time/batch = 0.201\n",
            "9285/15750 (epoch 29), train_loss = 2.295, time/batch = 0.200\n",
            "9286/15750 (epoch 29), train_loss = 2.336, time/batch = 0.205\n",
            "9287/15750 (epoch 29), train_loss = 2.377, time/batch = 0.205\n",
            "9288/15750 (epoch 29), train_loss = 2.324, time/batch = 0.200\n",
            "9289/15750 (epoch 29), train_loss = 2.336, time/batch = 0.206\n",
            "9290/15750 (epoch 29), train_loss = 2.326, time/batch = 0.205\n",
            "9291/15750 (epoch 29), train_loss = 2.328, time/batch = 0.207\n",
            "9292/15750 (epoch 29), train_loss = 2.320, time/batch = 0.211\n",
            "9293/15750 (epoch 29), train_loss = 2.409, time/batch = 0.204\n",
            "9294/15750 (epoch 29), train_loss = 2.266, time/batch = 0.203\n",
            "9295/15750 (epoch 29), train_loss = 2.338, time/batch = 0.203\n",
            "9296/15750 (epoch 29), train_loss = 2.332, time/batch = 0.202\n",
            "9297/15750 (epoch 29), train_loss = 2.356, time/batch = 0.210\n",
            "9298/15750 (epoch 29), train_loss = 2.434, time/batch = 0.203\n",
            "9299/15750 (epoch 29), train_loss = 2.356, time/batch = 0.203\n",
            "9300/15750 (epoch 29), train_loss = 2.354, time/batch = 0.208\n",
            "9301/15750 (epoch 29), train_loss = 2.335, time/batch = 0.209\n",
            "9302/15750 (epoch 29), train_loss = 2.300, time/batch = 0.213\n",
            "9303/15750 (epoch 29), train_loss = 2.268, time/batch = 0.205\n",
            "9304/15750 (epoch 29), train_loss = 2.260, time/batch = 0.203\n",
            "9305/15750 (epoch 29), train_loss = 2.307, time/batch = 0.205\n",
            "9306/15750 (epoch 29), train_loss = 2.340, time/batch = 0.208\n",
            "9307/15750 (epoch 29), train_loss = 2.309, time/batch = 0.211\n",
            "9308/15750 (epoch 29), train_loss = 2.371, time/batch = 0.201\n",
            "9309/15750 (epoch 29), train_loss = 2.313, time/batch = 0.203\n",
            "9310/15750 (epoch 29), train_loss = 2.245, time/batch = 0.203\n",
            "9311/15750 (epoch 29), train_loss = 2.273, time/batch = 0.202\n",
            "9312/15750 (epoch 29), train_loss = 2.331, time/batch = 0.208\n",
            "9313/15750 (epoch 29), train_loss = 2.266, time/batch = 0.203\n",
            "9314/15750 (epoch 29), train_loss = 2.226, time/batch = 0.200\n",
            "9315/15750 (epoch 29), train_loss = 2.260, time/batch = 0.201\n",
            "9316/15750 (epoch 29), train_loss = 2.341, time/batch = 0.200\n",
            "9317/15750 (epoch 29), train_loss = 2.311, time/batch = 0.207\n",
            "9318/15750 (epoch 29), train_loss = 2.374, time/batch = 0.203\n",
            "9319/15750 (epoch 29), train_loss = 2.363, time/batch = 0.204\n",
            "9320/15750 (epoch 29), train_loss = 2.308, time/batch = 0.199\n",
            "9321/15750 (epoch 29), train_loss = 2.267, time/batch = 0.205\n",
            "9322/15750 (epoch 29), train_loss = 2.338, time/batch = 0.207\n",
            "9323/15750 (epoch 29), train_loss = 2.363, time/batch = 0.202\n",
            "9324/15750 (epoch 29), train_loss = 2.432, time/batch = 0.199\n",
            "9325/15750 (epoch 29), train_loss = 2.403, time/batch = 0.208\n",
            "9326/15750 (epoch 29), train_loss = 2.317, time/batch = 0.205\n",
            "9327/15750 (epoch 29), train_loss = 2.333, time/batch = 0.210\n",
            "9328/15750 (epoch 29), train_loss = 2.259, time/batch = 0.203\n",
            "9329/15750 (epoch 29), train_loss = 2.384, time/batch = 0.201\n",
            "9330/15750 (epoch 29), train_loss = 2.359, time/batch = 0.206\n",
            "9331/15750 (epoch 29), train_loss = 2.315, time/batch = 0.203\n",
            "9332/15750 (epoch 29), train_loss = 2.260, time/batch = 0.212\n",
            "9333/15750 (epoch 29), train_loss = 2.361, time/batch = 0.209\n",
            "9334/15750 (epoch 29), train_loss = 2.154, time/batch = 0.206\n",
            "9335/15750 (epoch 29), train_loss = 2.266, time/batch = 0.211\n",
            "9336/15750 (epoch 29), train_loss = 2.223, time/batch = 0.203\n",
            "9337/15750 (epoch 29), train_loss = 2.303, time/batch = 0.219\n",
            "9338/15750 (epoch 29), train_loss = 2.277, time/batch = 0.207\n",
            "9339/15750 (epoch 29), train_loss = 2.341, time/batch = 0.207\n",
            "9340/15750 (epoch 29), train_loss = 2.290, time/batch = 0.206\n",
            "9341/15750 (epoch 29), train_loss = 2.170, time/batch = 0.210\n",
            "9342/15750 (epoch 29), train_loss = 2.242, time/batch = 0.211\n",
            "9343/15750 (epoch 29), train_loss = 2.246, time/batch = 0.204\n",
            "9344/15750 (epoch 29), train_loss = 2.307, time/batch = 0.203\n",
            "9345/15750 (epoch 29), train_loss = 2.191, time/batch = 0.204\n",
            "9346/15750 (epoch 29), train_loss = 2.268, time/batch = 0.204\n",
            "9347/15750 (epoch 29), train_loss = 2.159, time/batch = 0.211\n",
            "9348/15750 (epoch 29), train_loss = 2.232, time/batch = 0.203\n",
            "9349/15750 (epoch 29), train_loss = 2.224, time/batch = 0.209\n",
            "9350/15750 (epoch 29), train_loss = 2.216, time/batch = 0.205\n",
            "9351/15750 (epoch 29), train_loss = 2.365, time/batch = 0.203\n",
            "9352/15750 (epoch 29), train_loss = 2.189, time/batch = 0.210\n",
            "9353/15750 (epoch 29), train_loss = 2.435, time/batch = 0.205\n",
            "9354/15750 (epoch 29), train_loss = 2.297, time/batch = 0.208\n",
            "9355/15750 (epoch 29), train_loss = 2.176, time/batch = 0.206\n",
            "9356/15750 (epoch 29), train_loss = 2.213, time/batch = 0.204\n",
            "9357/15750 (epoch 29), train_loss = 2.274, time/batch = 0.208\n",
            "9358/15750 (epoch 29), train_loss = 2.266, time/batch = 0.201\n",
            "9359/15750 (epoch 29), train_loss = 2.252, time/batch = 0.203\n",
            "9360/15750 (epoch 29), train_loss = 2.258, time/batch = 0.202\n",
            "9361/15750 (epoch 29), train_loss = 2.327, time/batch = 0.202\n",
            "9362/15750 (epoch 29), train_loss = 2.245, time/batch = 0.208\n",
            "9363/15750 (epoch 29), train_loss = 2.288, time/batch = 0.205\n",
            "9364/15750 (epoch 29), train_loss = 2.365, time/batch = 0.201\n",
            "9365/15750 (epoch 29), train_loss = 2.219, time/batch = 0.206\n",
            "9366/15750 (epoch 29), train_loss = 2.244, time/batch = 0.209\n",
            "9367/15750 (epoch 29), train_loss = 2.284, time/batch = 0.218\n",
            "9368/15750 (epoch 29), train_loss = 2.283, time/batch = 0.203\n",
            "9369/15750 (epoch 29), train_loss = 2.236, time/batch = 0.213\n",
            "9370/15750 (epoch 29), train_loss = 2.227, time/batch = 0.201\n",
            "9371/15750 (epoch 29), train_loss = 2.201, time/batch = 0.196\n",
            "9372/15750 (epoch 29), train_loss = 2.251, time/batch = 0.211\n",
            "9373/15750 (epoch 29), train_loss = 2.459, time/batch = 0.197\n",
            "9374/15750 (epoch 29), train_loss = 2.280, time/batch = 0.203\n",
            "9375/15750 (epoch 29), train_loss = 2.334, time/batch = 0.201\n",
            "9376/15750 (epoch 29), train_loss = 2.212, time/batch = 0.200\n",
            "9377/15750 (epoch 29), train_loss = 2.266, time/batch = 0.212\n",
            "9378/15750 (epoch 29), train_loss = 2.290, time/batch = 0.200\n",
            "9379/15750 (epoch 29), train_loss = 2.295, time/batch = 0.199\n",
            "9380/15750 (epoch 29), train_loss = 2.349, time/batch = 0.200\n",
            "9381/15750 (epoch 29), train_loss = 2.311, time/batch = 0.203\n",
            "9382/15750 (epoch 29), train_loss = 2.304, time/batch = 0.203\n",
            "9383/15750 (epoch 29), train_loss = 2.288, time/batch = 0.199\n",
            "9384/15750 (epoch 29), train_loss = 2.314, time/batch = 0.205\n",
            "9385/15750 (epoch 29), train_loss = 2.211, time/batch = 0.198\n",
            "9386/15750 (epoch 29), train_loss = 2.207, time/batch = 0.204\n",
            "9387/15750 (epoch 29), train_loss = 2.291, time/batch = 0.207\n",
            "9388/15750 (epoch 29), train_loss = 2.309, time/batch = 0.202\n",
            "9389/15750 (epoch 29), train_loss = 2.278, time/batch = 0.199\n",
            "9390/15750 (epoch 29), train_loss = 2.243, time/batch = 0.194\n",
            "9391/15750 (epoch 29), train_loss = 2.192, time/batch = 0.204\n",
            "9392/15750 (epoch 29), train_loss = 2.216, time/batch = 0.202\n",
            "9393/15750 (epoch 29), train_loss = 2.377, time/batch = 0.202\n",
            "9394/15750 (epoch 29), train_loss = 2.347, time/batch = 0.201\n",
            "9395/15750 (epoch 29), train_loss = 2.319, time/batch = 0.201\n",
            "9396/15750 (epoch 29), train_loss = 2.264, time/batch = 0.203\n",
            "9397/15750 (epoch 29), train_loss = 2.291, time/batch = 0.205\n",
            "9398/15750 (epoch 29), train_loss = 2.278, time/batch = 0.203\n",
            "9399/15750 (epoch 29), train_loss = 2.307, time/batch = 0.200\n",
            "9400/15750 (epoch 29), train_loss = 2.355, time/batch = 0.203\n",
            "9401/15750 (epoch 29), train_loss = 2.361, time/batch = 0.202\n",
            "9402/15750 (epoch 29), train_loss = 2.280, time/batch = 0.203\n",
            "9403/15750 (epoch 29), train_loss = 2.316, time/batch = 0.197\n",
            "9404/15750 (epoch 29), train_loss = 2.344, time/batch = 0.197\n",
            "9405/15750 (epoch 29), train_loss = 2.333, time/batch = 0.203\n",
            "9406/15750 (epoch 29), train_loss = 2.239, time/batch = 0.199\n",
            "9407/15750 (epoch 29), train_loss = 2.274, time/batch = 0.203\n",
            "9408/15750 (epoch 29), train_loss = 2.338, time/batch = 0.201\n",
            "9409/15750 (epoch 29), train_loss = 2.355, time/batch = 0.199\n",
            "9410/15750 (epoch 29), train_loss = 2.306, time/batch = 0.202\n",
            "9411/15750 (epoch 29), train_loss = 2.362, time/batch = 0.202\n",
            "9412/15750 (epoch 29), train_loss = 2.292, time/batch = 0.204\n",
            "9413/15750 (epoch 29), train_loss = 2.261, time/batch = 0.202\n",
            "9414/15750 (epoch 29), train_loss = 2.214, time/batch = 0.202\n",
            "9415/15750 (epoch 29), train_loss = 2.440, time/batch = 0.203\n",
            "9416/15750 (epoch 29), train_loss = 2.268, time/batch = 0.201\n",
            "9417/15750 (epoch 29), train_loss = 2.232, time/batch = 0.207\n",
            "9418/15750 (epoch 29), train_loss = 2.347, time/batch = 0.201\n",
            "9419/15750 (epoch 29), train_loss = 2.249, time/batch = 0.197\n",
            "9420/15750 (epoch 29), train_loss = 2.385, time/batch = 0.207\n",
            "9421/15750 (epoch 29), train_loss = 2.279, time/batch = 0.199\n",
            "9422/15750 (epoch 29), train_loss = 2.292, time/batch = 0.208\n",
            "9423/15750 (epoch 29), train_loss = 2.213, time/batch = 0.201\n",
            "9424/15750 (epoch 29), train_loss = 2.309, time/batch = 0.198\n",
            "9425/15750 (epoch 29), train_loss = 2.236, time/batch = 0.198\n",
            "9426/15750 (epoch 29), train_loss = 2.309, time/batch = 0.207\n",
            "9427/15750 (epoch 29), train_loss = 2.303, time/batch = 0.206\n",
            "9428/15750 (epoch 29), train_loss = 2.264, time/batch = 0.207\n",
            "9429/15750 (epoch 29), train_loss = 2.317, time/batch = 0.208\n",
            "9430/15750 (epoch 29), train_loss = 2.399, time/batch = 0.209\n",
            "9431/15750 (epoch 29), train_loss = 2.352, time/batch = 0.210\n",
            "9432/15750 (epoch 29), train_loss = 2.369, time/batch = 0.209\n",
            "9433/15750 (epoch 29), train_loss = 2.246, time/batch = 0.207\n",
            "9434/15750 (epoch 29), train_loss = 2.312, time/batch = 0.208\n",
            "9435/15750 (epoch 29), train_loss = 2.300, time/batch = 0.204\n",
            "9436/15750 (epoch 29), train_loss = 2.231, time/batch = 0.206\n",
            "9437/15750 (epoch 29), train_loss = 2.358, time/batch = 0.212\n",
            "9438/15750 (epoch 29), train_loss = 2.215, time/batch = 0.205\n",
            "9439/15750 (epoch 29), train_loss = 2.343, time/batch = 0.216\n",
            "9440/15750 (epoch 29), train_loss = 2.292, time/batch = 0.204\n",
            "9441/15750 (epoch 29), train_loss = 2.259, time/batch = 0.206\n",
            "9442/15750 (epoch 29), train_loss = 2.211, time/batch = 0.213\n",
            "9443/15750 (epoch 29), train_loss = 2.242, time/batch = 0.204\n",
            "9444/15750 (epoch 29), train_loss = 2.361, time/batch = 0.201\n",
            "9445/15750 (epoch 29), train_loss = 2.230, time/batch = 0.199\n",
            "9446/15750 (epoch 29), train_loss = 2.210, time/batch = 0.198\n",
            "9447/15750 (epoch 29), train_loss = 2.243, time/batch = 0.206\n",
            "9448/15750 (epoch 29), train_loss = 2.249, time/batch = 0.204\n",
            "9449/15750 (epoch 29), train_loss = 2.351, time/batch = 0.204\n",
            "9450/15750 (epoch 30), train_loss = 2.241, time/batch = 0.201\n",
            "9451/15750 (epoch 30), train_loss = 2.344, time/batch = 0.212\n",
            "9452/15750 (epoch 30), train_loss = 2.279, time/batch = 0.210\n",
            "9453/15750 (epoch 30), train_loss = 2.374, time/batch = 0.205\n",
            "9454/15750 (epoch 30), train_loss = 2.297, time/batch = 0.200\n",
            "9455/15750 (epoch 30), train_loss = 2.293, time/batch = 0.201\n",
            "9456/15750 (epoch 30), train_loss = 2.449, time/batch = 0.207\n",
            "9457/15750 (epoch 30), train_loss = 2.365, time/batch = 0.201\n",
            "9458/15750 (epoch 30), train_loss = 2.359, time/batch = 0.199\n",
            "9459/15750 (epoch 30), train_loss = 2.305, time/batch = 0.199\n",
            "9460/15750 (epoch 30), train_loss = 2.309, time/batch = 0.201\n",
            "9461/15750 (epoch 30), train_loss = 2.272, time/batch = 0.205\n",
            "9462/15750 (epoch 30), train_loss = 2.354, time/batch = 0.204\n",
            "9463/15750 (epoch 30), train_loss = 2.331, time/batch = 0.204\n",
            "9464/15750 (epoch 30), train_loss = 2.307, time/batch = 0.208\n",
            "9465/15750 (epoch 30), train_loss = 2.333, time/batch = 0.197\n",
            "9466/15750 (epoch 30), train_loss = 2.335, time/batch = 0.206\n",
            "9467/15750 (epoch 30), train_loss = 2.397, time/batch = 0.197\n",
            "9468/15750 (epoch 30), train_loss = 2.410, time/batch = 0.200\n",
            "9469/15750 (epoch 30), train_loss = 2.358, time/batch = 0.206\n",
            "9470/15750 (epoch 30), train_loss = 2.346, time/batch = 0.195\n",
            "9471/15750 (epoch 30), train_loss = 2.360, time/batch = 0.212\n",
            "9472/15750 (epoch 30), train_loss = 2.311, time/batch = 0.200\n",
            "9473/15750 (epoch 30), train_loss = 2.367, time/batch = 0.203\n",
            "9474/15750 (epoch 30), train_loss = 2.370, time/batch = 0.205\n",
            "9475/15750 (epoch 30), train_loss = 2.393, time/batch = 0.199\n",
            "9476/15750 (epoch 30), train_loss = 2.397, time/batch = 0.206\n",
            "9477/15750 (epoch 30), train_loss = 2.379, time/batch = 0.212\n",
            "9478/15750 (epoch 30), train_loss = 2.490, time/batch = 0.205\n",
            "9479/15750 (epoch 30), train_loss = 2.400, time/batch = 0.210\n",
            "9480/15750 (epoch 30), train_loss = 2.362, time/batch = 0.205\n",
            "9481/15750 (epoch 30), train_loss = 2.329, time/batch = 0.217\n",
            "9482/15750 (epoch 30), train_loss = 2.243, time/batch = 0.203\n",
            "9483/15750 (epoch 30), train_loss = 2.261, time/batch = 0.207\n",
            "9484/15750 (epoch 30), train_loss = 2.347, time/batch = 0.211\n",
            "9485/15750 (epoch 30), train_loss = 2.246, time/batch = 0.204\n",
            "9486/15750 (epoch 30), train_loss = 2.322, time/batch = 0.208\n",
            "9487/15750 (epoch 30), train_loss = 2.373, time/batch = 0.208\n",
            "9488/15750 (epoch 30), train_loss = 2.284, time/batch = 0.206\n",
            "9489/15750 (epoch 30), train_loss = 2.333, time/batch = 0.205\n",
            "9490/15750 (epoch 30), train_loss = 2.290, time/batch = 0.203\n",
            "9491/15750 (epoch 30), train_loss = 2.337, time/batch = 0.208\n",
            "9492/15750 (epoch 30), train_loss = 2.337, time/batch = 0.202\n",
            "9493/15750 (epoch 30), train_loss = 2.300, time/batch = 0.205\n",
            "9494/15750 (epoch 30), train_loss = 2.333, time/batch = 0.204\n",
            "9495/15750 (epoch 30), train_loss = 2.260, time/batch = 0.203\n",
            "9496/15750 (epoch 30), train_loss = 2.299, time/batch = 0.209\n",
            "9497/15750 (epoch 30), train_loss = 2.318, time/batch = 0.214\n",
            "9498/15750 (epoch 30), train_loss = 2.358, time/batch = 0.210\n",
            "9499/15750 (epoch 30), train_loss = 2.241, time/batch = 0.206\n",
            "9500/15750 (epoch 30), train_loss = 2.308, time/batch = 0.206\n",
            "9501/15750 (epoch 30), train_loss = 2.263, time/batch = 0.209\n",
            "9502/15750 (epoch 30), train_loss = 2.319, time/batch = 0.204\n",
            "9503/15750 (epoch 30), train_loss = 2.335, time/batch = 0.212\n",
            "9504/15750 (epoch 30), train_loss = 2.332, time/batch = 0.203\n",
            "9505/15750 (epoch 30), train_loss = 2.362, time/batch = 0.204\n",
            "9506/15750 (epoch 30), train_loss = 2.249, time/batch = 0.212\n",
            "9507/15750 (epoch 30), train_loss = 2.244, time/batch = 0.204\n",
            "9508/15750 (epoch 30), train_loss = 2.341, time/batch = 0.206\n",
            "9509/15750 (epoch 30), train_loss = 2.201, time/batch = 0.202\n",
            "9510/15750 (epoch 30), train_loss = 2.303, time/batch = 0.201\n",
            "9511/15750 (epoch 30), train_loss = 2.308, time/batch = 0.210\n",
            "9512/15750 (epoch 30), train_loss = 2.238, time/batch = 0.203\n",
            "9513/15750 (epoch 30), train_loss = 2.297, time/batch = 0.208\n",
            "9514/15750 (epoch 30), train_loss = 2.202, time/batch = 0.210\n",
            "9515/15750 (epoch 30), train_loss = 2.226, time/batch = 0.209\n",
            "9516/15750 (epoch 30), train_loss = 2.166, time/batch = 0.215\n",
            "9517/15750 (epoch 30), train_loss = 2.184, time/batch = 0.199\n",
            "9518/15750 (epoch 30), train_loss = 2.239, time/batch = 0.201\n",
            "9519/15750 (epoch 30), train_loss = 2.330, time/batch = 0.201\n",
            "9520/15750 (epoch 30), train_loss = 2.254, time/batch = 0.202\n",
            "9521/15750 (epoch 30), train_loss = 2.244, time/batch = 0.213\n",
            "9522/15750 (epoch 30), train_loss = 2.162, time/batch = 0.207\n",
            "9523/15750 (epoch 30), train_loss = 2.233, time/batch = 0.202\n",
            "9524/15750 (epoch 30), train_loss = 2.344, time/batch = 0.206\n",
            "9525/15750 (epoch 30), train_loss = 2.280, time/batch = 0.206\n",
            "9526/15750 (epoch 30), train_loss = 2.274, time/batch = 0.214\n",
            "9527/15750 (epoch 30), train_loss = 2.276, time/batch = 0.203\n",
            "9528/15750 (epoch 30), train_loss = 2.285, time/batch = 0.203\n",
            "9529/15750 (epoch 30), train_loss = 2.279, time/batch = 0.208\n",
            "9530/15750 (epoch 30), train_loss = 2.179, time/batch = 0.201\n",
            "9531/15750 (epoch 30), train_loss = 2.281, time/batch = 0.209\n",
            "9532/15750 (epoch 30), train_loss = 2.224, time/batch = 0.213\n",
            "9533/15750 (epoch 30), train_loss = 2.277, time/batch = 0.209\n",
            "9534/15750 (epoch 30), train_loss = 2.335, time/batch = 0.208\n",
            "9535/15750 (epoch 30), train_loss = 2.354, time/batch = 0.204\n",
            "9536/15750 (epoch 30), train_loss = 2.192, time/batch = 0.204\n",
            "9537/15750 (epoch 30), train_loss = 2.226, time/batch = 0.206\n",
            "9538/15750 (epoch 30), train_loss = 2.244, time/batch = 0.201\n",
            "9539/15750 (epoch 30), train_loss = 2.247, time/batch = 0.203\n",
            "9540/15750 (epoch 30), train_loss = 2.245, time/batch = 0.208\n",
            "9541/15750 (epoch 30), train_loss = 2.307, time/batch = 0.202\n",
            "9542/15750 (epoch 30), train_loss = 2.295, time/batch = 0.203\n",
            "9543/15750 (epoch 30), train_loss = 2.307, time/batch = 0.200\n",
            "9544/15750 (epoch 30), train_loss = 2.370, time/batch = 0.200\n",
            "9545/15750 (epoch 30), train_loss = 2.275, time/batch = 0.200\n",
            "9546/15750 (epoch 30), train_loss = 2.303, time/batch = 0.205\n",
            "9547/15750 (epoch 30), train_loss = 2.323, time/batch = 0.203\n",
            "9548/15750 (epoch 30), train_loss = 2.304, time/batch = 0.200\n",
            "9549/15750 (epoch 30), train_loss = 2.320, time/batch = 0.201\n",
            "9550/15750 (epoch 30), train_loss = 2.298, time/batch = 0.206\n",
            "9551/15750 (epoch 30), train_loss = 2.237, time/batch = 0.204\n",
            "9552/15750 (epoch 30), train_loss = 2.256, time/batch = 0.203\n",
            "9553/15750 (epoch 30), train_loss = 2.380, time/batch = 0.209\n",
            "9554/15750 (epoch 30), train_loss = 2.303, time/batch = 0.202\n",
            "9555/15750 (epoch 30), train_loss = 2.213, time/batch = 0.201\n",
            "9556/15750 (epoch 30), train_loss = 2.272, time/batch = 0.213\n",
            "9557/15750 (epoch 30), train_loss = 2.300, time/batch = 0.200\n",
            "9558/15750 (epoch 30), train_loss = 2.338, time/batch = 0.203\n",
            "9559/15750 (epoch 30), train_loss = 2.366, time/batch = 0.200\n",
            "9560/15750 (epoch 30), train_loss = 2.417, time/batch = 0.204\n",
            "9561/15750 (epoch 30), train_loss = 2.286, time/batch = 0.210\n",
            "9562/15750 (epoch 30), train_loss = 2.286, time/batch = 0.208\n",
            "9563/15750 (epoch 30), train_loss = 2.288, time/batch = 0.205\n",
            "9564/15750 (epoch 30), train_loss = 2.295, time/batch = 0.203\n",
            "9565/15750 (epoch 30), train_loss = 2.377, time/batch = 0.203\n",
            "9566/15750 (epoch 30), train_loss = 2.298, time/batch = 0.209\n",
            "9567/15750 (epoch 30), train_loss = 2.421, time/batch = 0.205\n",
            "9568/15750 (epoch 30), train_loss = 2.306, time/batch = 0.204\n",
            "9569/15750 (epoch 30), train_loss = 2.289, time/batch = 0.210\n",
            "9570/15750 (epoch 30), train_loss = 2.261, time/batch = 0.209\n",
            "9571/15750 (epoch 30), train_loss = 2.241, time/batch = 0.210\n",
            "9572/15750 (epoch 30), train_loss = 2.279, time/batch = 0.203\n",
            "9573/15750 (epoch 30), train_loss = 2.240, time/batch = 0.204\n",
            "9574/15750 (epoch 30), train_loss = 2.273, time/batch = 0.204\n",
            "9575/15750 (epoch 30), train_loss = 2.289, time/batch = 0.201\n",
            "9576/15750 (epoch 30), train_loss = 2.372, time/batch = 0.212\n",
            "9577/15750 (epoch 30), train_loss = 2.257, time/batch = 0.203\n",
            "9578/15750 (epoch 30), train_loss = 2.276, time/batch = 0.201\n",
            "9579/15750 (epoch 30), train_loss = 2.248, time/batch = 0.200\n",
            "9580/15750 (epoch 30), train_loss = 2.196, time/batch = 0.206\n",
            "9581/15750 (epoch 30), train_loss = 2.205, time/batch = 0.208\n",
            "9582/15750 (epoch 30), train_loss = 2.219, time/batch = 0.206\n",
            "9583/15750 (epoch 30), train_loss = 2.240, time/batch = 0.204\n",
            "9584/15750 (epoch 30), train_loss = 2.261, time/batch = 0.211\n",
            "9585/15750 (epoch 30), train_loss = 2.388, time/batch = 0.210\n",
            "9586/15750 (epoch 30), train_loss = 2.348, time/batch = 0.211\n",
            "9587/15750 (epoch 30), train_loss = 2.348, time/batch = 0.208\n",
            "9588/15750 (epoch 30), train_loss = 2.336, time/batch = 0.208\n",
            "9589/15750 (epoch 30), train_loss = 2.263, time/batch = 0.213\n",
            "9590/15750 (epoch 30), train_loss = 2.263, time/batch = 0.205\n",
            "9591/15750 (epoch 30), train_loss = 2.351, time/batch = 0.205\n",
            "9592/15750 (epoch 30), train_loss = 2.373, time/batch = 0.206\n",
            "9593/15750 (epoch 30), train_loss = 2.351, time/batch = 0.208\n",
            "9594/15750 (epoch 30), train_loss = 2.266, time/batch = 0.202\n",
            "9595/15750 (epoch 30), train_loss = 2.262, time/batch = 0.200\n",
            "9596/15750 (epoch 30), train_loss = 2.225, time/batch = 0.202\n",
            "9597/15750 (epoch 30), train_loss = 2.316, time/batch = 0.208\n",
            "9598/15750 (epoch 30), train_loss = 2.342, time/batch = 0.201\n",
            "9599/15750 (epoch 30), train_loss = 2.289, time/batch = 0.202\n",
            "9600/15750 (epoch 30), train_loss = 2.287, time/batch = 0.202\n",
            "9601/15750 (epoch 30), train_loss = 2.329, time/batch = 0.203\n",
            "9602/15750 (epoch 30), train_loss = 2.370, time/batch = 0.203\n",
            "9603/15750 (epoch 30), train_loss = 2.316, time/batch = 0.202\n",
            "9604/15750 (epoch 30), train_loss = 2.328, time/batch = 0.205\n",
            "9605/15750 (epoch 30), train_loss = 2.319, time/batch = 0.204\n",
            "9606/15750 (epoch 30), train_loss = 2.320, time/batch = 0.210\n",
            "9607/15750 (epoch 30), train_loss = 2.313, time/batch = 0.198\n",
            "9608/15750 (epoch 30), train_loss = 2.402, time/batch = 0.196\n",
            "9609/15750 (epoch 30), train_loss = 2.259, time/batch = 0.203\n",
            "9610/15750 (epoch 30), train_loss = 2.331, time/batch = 0.207\n",
            "9611/15750 (epoch 30), train_loss = 2.324, time/batch = 0.205\n",
            "9612/15750 (epoch 30), train_loss = 2.348, time/batch = 0.203\n",
            "9613/15750 (epoch 30), train_loss = 2.425, time/batch = 0.206\n",
            "9614/15750 (epoch 30), train_loss = 2.348, time/batch = 0.207\n",
            "9615/15750 (epoch 30), train_loss = 2.346, time/batch = 0.209\n",
            "9616/15750 (epoch 30), train_loss = 2.327, time/batch = 0.214\n",
            "9617/15750 (epoch 30), train_loss = 2.293, time/batch = 0.204\n",
            "9618/15750 (epoch 30), train_loss = 2.260, time/batch = 0.205\n",
            "9619/15750 (epoch 30), train_loss = 2.252, time/batch = 0.208\n",
            "9620/15750 (epoch 30), train_loss = 2.299, time/batch = 0.204\n",
            "9621/15750 (epoch 30), train_loss = 2.332, time/batch = 0.219\n",
            "9622/15750 (epoch 30), train_loss = 2.301, time/batch = 0.206\n",
            "9623/15750 (epoch 30), train_loss = 2.364, time/batch = 0.208\n",
            "9624/15750 (epoch 30), train_loss = 2.305, time/batch = 0.206\n",
            "9625/15750 (epoch 30), train_loss = 2.237, time/batch = 0.205\n",
            "9626/15750 (epoch 30), train_loss = 2.265, time/batch = 0.206\n",
            "9627/15750 (epoch 30), train_loss = 2.324, time/batch = 0.202\n",
            "9628/15750 (epoch 30), train_loss = 2.259, time/batch = 0.207\n",
            "9629/15750 (epoch 30), train_loss = 2.218, time/batch = 0.206\n",
            "9630/15750 (epoch 30), train_loss = 2.253, time/batch = 0.199\n",
            "9631/15750 (epoch 30), train_loss = 2.333, time/batch = 0.218\n",
            "9632/15750 (epoch 30), train_loss = 2.304, time/batch = 0.204\n",
            "9633/15750 (epoch 30), train_loss = 2.367, time/batch = 0.203\n",
            "9634/15750 (epoch 30), train_loss = 2.354, time/batch = 0.206\n",
            "9635/15750 (epoch 30), train_loss = 2.301, time/batch = 0.206\n",
            "9636/15750 (epoch 30), train_loss = 2.259, time/batch = 0.211\n",
            "9637/15750 (epoch 30), train_loss = 2.331, time/batch = 0.210\n",
            "9638/15750 (epoch 30), train_loss = 2.355, time/batch = 0.208\n",
            "9639/15750 (epoch 30), train_loss = 2.423, time/batch = 0.208\n",
            "9640/15750 (epoch 30), train_loss = 2.396, time/batch = 0.207\n",
            "9641/15750 (epoch 30), train_loss = 2.309, time/batch = 0.203\n",
            "9642/15750 (epoch 30), train_loss = 2.326, time/batch = 0.203\n",
            "9643/15750 (epoch 30), train_loss = 2.251, time/batch = 0.208\n",
            "9644/15750 (epoch 30), train_loss = 2.377, time/batch = 0.205\n",
            "9645/15750 (epoch 30), train_loss = 2.351, time/batch = 0.203\n",
            "9646/15750 (epoch 30), train_loss = 2.307, time/batch = 0.204\n",
            "9647/15750 (epoch 30), train_loss = 2.253, time/batch = 0.204\n",
            "9648/15750 (epoch 30), train_loss = 2.354, time/batch = 0.206\n",
            "9649/15750 (epoch 30), train_loss = 2.146, time/batch = 0.205\n",
            "9650/15750 (epoch 30), train_loss = 2.258, time/batch = 0.202\n",
            "9651/15750 (epoch 30), train_loss = 2.217, time/batch = 0.207\n",
            "9652/15750 (epoch 30), train_loss = 2.296, time/batch = 0.202\n",
            "9653/15750 (epoch 30), train_loss = 2.269, time/batch = 0.202\n",
            "9654/15750 (epoch 30), train_loss = 2.334, time/batch = 0.200\n",
            "9655/15750 (epoch 30), train_loss = 2.282, time/batch = 0.200\n",
            "9656/15750 (epoch 30), train_loss = 2.163, time/batch = 0.207\n",
            "9657/15750 (epoch 30), train_loss = 2.235, time/batch = 0.200\n",
            "9658/15750 (epoch 30), train_loss = 2.238, time/batch = 0.203\n",
            "9659/15750 (epoch 30), train_loss = 2.300, time/batch = 0.201\n",
            "9660/15750 (epoch 30), train_loss = 2.184, time/batch = 0.197\n",
            "9661/15750 (epoch 30), train_loss = 2.260, time/batch = 0.220\n",
            "9662/15750 (epoch 30), train_loss = 2.152, time/batch = 0.202\n",
            "9663/15750 (epoch 30), train_loss = 2.225, time/batch = 0.203\n",
            "9664/15750 (epoch 30), train_loss = 2.217, time/batch = 0.205\n",
            "9665/15750 (epoch 30), train_loss = 2.207, time/batch = 0.209\n",
            "9666/15750 (epoch 30), train_loss = 2.357, time/batch = 0.199\n",
            "9667/15750 (epoch 30), train_loss = 2.182, time/batch = 0.204\n",
            "9668/15750 (epoch 30), train_loss = 2.428, time/batch = 0.205\n",
            "9669/15750 (epoch 30), train_loss = 2.290, time/batch = 0.205\n",
            "9670/15750 (epoch 30), train_loss = 2.169, time/batch = 0.204\n",
            "9671/15750 (epoch 30), train_loss = 2.205, time/batch = 0.206\n",
            "9672/15750 (epoch 30), train_loss = 2.266, time/batch = 0.206\n",
            "9673/15750 (epoch 30), train_loss = 2.258, time/batch = 0.206\n",
            "9674/15750 (epoch 30), train_loss = 2.244, time/batch = 0.202\n",
            "9675/15750 (epoch 30), train_loss = 2.251, time/batch = 0.204\n",
            "9676/15750 (epoch 30), train_loss = 2.319, time/batch = 0.211\n",
            "9677/15750 (epoch 30), train_loss = 2.237, time/batch = 0.206\n",
            "9678/15750 (epoch 30), train_loss = 2.281, time/batch = 0.203\n",
            "9679/15750 (epoch 30), train_loss = 2.358, time/batch = 0.200\n",
            "9680/15750 (epoch 30), train_loss = 2.213, time/batch = 0.204\n",
            "9681/15750 (epoch 30), train_loss = 2.236, time/batch = 0.210\n",
            "9682/15750 (epoch 30), train_loss = 2.276, time/batch = 0.204\n",
            "9683/15750 (epoch 30), train_loss = 2.276, time/batch = 0.205\n",
            "9684/15750 (epoch 30), train_loss = 2.229, time/batch = 0.202\n",
            "9685/15750 (epoch 30), train_loss = 2.220, time/batch = 0.203\n",
            "9686/15750 (epoch 30), train_loss = 2.193, time/batch = 0.203\n",
            "9687/15750 (epoch 30), train_loss = 2.243, time/batch = 0.204\n",
            "9688/15750 (epoch 30), train_loss = 2.450, time/batch = 0.204\n",
            "9689/15750 (epoch 30), train_loss = 2.273, time/batch = 0.205\n",
            "9690/15750 (epoch 30), train_loss = 2.327, time/batch = 0.206\n",
            "9691/15750 (epoch 30), train_loss = 2.205, time/batch = 0.207\n",
            "9692/15750 (epoch 30), train_loss = 2.259, time/batch = 0.200\n",
            "9693/15750 (epoch 30), train_loss = 2.282, time/batch = 0.200\n",
            "9694/15750 (epoch 30), train_loss = 2.288, time/batch = 0.195\n",
            "9695/15750 (epoch 30), train_loss = 2.342, time/batch = 0.200\n",
            "9696/15750 (epoch 30), train_loss = 2.303, time/batch = 0.207\n",
            "9697/15750 (epoch 30), train_loss = 2.296, time/batch = 0.202\n",
            "9698/15750 (epoch 30), train_loss = 2.279, time/batch = 0.202\n",
            "9699/15750 (epoch 30), train_loss = 2.306, time/batch = 0.202\n",
            "9700/15750 (epoch 30), train_loss = 2.204, time/batch = 0.203\n",
            "9701/15750 (epoch 30), train_loss = 2.198, time/batch = 0.206\n",
            "9702/15750 (epoch 30), train_loss = 2.284, time/batch = 0.199\n",
            "9703/15750 (epoch 30), train_loss = 2.302, time/batch = 0.200\n",
            "9704/15750 (epoch 30), train_loss = 2.271, time/batch = 0.200\n",
            "9705/15750 (epoch 30), train_loss = 2.235, time/batch = 0.202\n",
            "9706/15750 (epoch 30), train_loss = 2.185, time/batch = 0.206\n",
            "9707/15750 (epoch 30), train_loss = 2.210, time/batch = 0.198\n",
            "9708/15750 (epoch 30), train_loss = 2.369, time/batch = 0.203\n",
            "9709/15750 (epoch 30), train_loss = 2.339, time/batch = 0.204\n",
            "9710/15750 (epoch 30), train_loss = 2.311, time/batch = 0.199\n",
            "9711/15750 (epoch 30), train_loss = 2.257, time/batch = 0.208\n",
            "9712/15750 (epoch 30), train_loss = 2.283, time/batch = 0.209\n",
            "9713/15750 (epoch 30), train_loss = 2.271, time/batch = 0.206\n",
            "9714/15750 (epoch 30), train_loss = 2.298, time/batch = 0.210\n",
            "9715/15750 (epoch 30), train_loss = 2.347, time/batch = 0.208\n",
            "9716/15750 (epoch 30), train_loss = 2.352, time/batch = 0.212\n",
            "9717/15750 (epoch 30), train_loss = 2.273, time/batch = 0.203\n",
            "9718/15750 (epoch 30), train_loss = 2.307, time/batch = 0.202\n",
            "9719/15750 (epoch 30), train_loss = 2.337, time/batch = 0.204\n",
            "9720/15750 (epoch 30), train_loss = 2.325, time/batch = 0.205\n",
            "9721/15750 (epoch 30), train_loss = 2.231, time/batch = 0.208\n",
            "9722/15750 (epoch 30), train_loss = 2.267, time/batch = 0.206\n",
            "9723/15750 (epoch 30), train_loss = 2.330, time/batch = 0.204\n",
            "9724/15750 (epoch 30), train_loss = 2.347, time/batch = 0.206\n",
            "9725/15750 (epoch 30), train_loss = 2.296, time/batch = 0.203\n",
            "9726/15750 (epoch 30), train_loss = 2.354, time/batch = 0.207\n",
            "9727/15750 (epoch 30), train_loss = 2.285, time/batch = 0.202\n",
            "9728/15750 (epoch 30), train_loss = 2.255, time/batch = 0.210\n",
            "9729/15750 (epoch 30), train_loss = 2.207, time/batch = 0.209\n",
            "9730/15750 (epoch 30), train_loss = 2.431, time/batch = 0.206\n",
            "9731/15750 (epoch 30), train_loss = 2.260, time/batch = 0.212\n",
            "9732/15750 (epoch 30), train_loss = 2.224, time/batch = 0.206\n",
            "9733/15750 (epoch 30), train_loss = 2.338, time/batch = 0.203\n",
            "9734/15750 (epoch 30), train_loss = 2.241, time/batch = 0.202\n",
            "9735/15750 (epoch 30), train_loss = 2.377, time/batch = 0.202\n",
            "9736/15750 (epoch 30), train_loss = 2.273, time/batch = 0.212\n",
            "9737/15750 (epoch 30), train_loss = 2.286, time/batch = 0.209\n",
            "9738/15750 (epoch 30), train_loss = 2.207, time/batch = 0.206\n",
            "9739/15750 (epoch 30), train_loss = 2.302, time/batch = 0.204\n",
            "9740/15750 (epoch 30), train_loss = 2.229, time/batch = 0.208\n",
            "9741/15750 (epoch 30), train_loss = 2.301, time/batch = 0.215\n",
            "9742/15750 (epoch 30), train_loss = 2.295, time/batch = 0.204\n",
            "9743/15750 (epoch 30), train_loss = 2.256, time/batch = 0.204\n",
            "9744/15750 (epoch 30), train_loss = 2.310, time/batch = 0.205\n",
            "9745/15750 (epoch 30), train_loss = 2.391, time/batch = 0.208\n",
            "9746/15750 (epoch 30), train_loss = 2.344, time/batch = 0.210\n",
            "9747/15750 (epoch 30), train_loss = 2.362, time/batch = 0.201\n",
            "9748/15750 (epoch 30), train_loss = 2.239, time/batch = 0.203\n",
            "9749/15750 (epoch 30), train_loss = 2.304, time/batch = 0.205\n",
            "9750/15750 (epoch 30), train_loss = 2.292, time/batch = 0.201\n",
            "9751/15750 (epoch 30), train_loss = 2.224, time/batch = 0.211\n",
            "9752/15750 (epoch 30), train_loss = 2.351, time/batch = 0.199\n",
            "9753/15750 (epoch 30), train_loss = 2.208, time/batch = 0.200\n",
            "9754/15750 (epoch 30), train_loss = 2.335, time/batch = 0.202\n",
            "9755/15750 (epoch 30), train_loss = 2.285, time/batch = 0.202\n",
            "9756/15750 (epoch 30), train_loss = 2.252, time/batch = 0.210\n",
            "9757/15750 (epoch 30), train_loss = 2.204, time/batch = 0.198\n",
            "9758/15750 (epoch 30), train_loss = 2.235, time/batch = 0.206\n",
            "9759/15750 (epoch 30), train_loss = 2.353, time/batch = 0.195\n",
            "9760/15750 (epoch 30), train_loss = 2.223, time/batch = 0.202\n",
            "9761/15750 (epoch 30), train_loss = 2.203, time/batch = 0.211\n",
            "9762/15750 (epoch 30), train_loss = 2.235, time/batch = 0.203\n",
            "9763/15750 (epoch 30), train_loss = 2.243, time/batch = 0.210\n",
            "9764/15750 (epoch 30), train_loss = 2.344, time/batch = 0.208\n",
            "9765/15750 (epoch 31), train_loss = 2.224, time/batch = 0.214\n",
            "9766/15750 (epoch 31), train_loss = 2.336, time/batch = 0.201\n",
            "9767/15750 (epoch 31), train_loss = 2.270, time/batch = 0.202\n",
            "9768/15750 (epoch 31), train_loss = 2.366, time/batch = 0.197\n",
            "9769/15750 (epoch 31), train_loss = 2.289, time/batch = 0.205\n",
            "9770/15750 (epoch 31), train_loss = 2.286, time/batch = 0.204\n",
            "9771/15750 (epoch 31), train_loss = 2.441, time/batch = 0.199\n",
            "9772/15750 (epoch 31), train_loss = 2.359, time/batch = 0.205\n",
            "9773/15750 (epoch 31), train_loss = 2.351, time/batch = 0.202\n",
            "9774/15750 (epoch 31), train_loss = 2.298, time/batch = 0.203\n",
            "9775/15750 (epoch 31), train_loss = 2.302, time/batch = 0.210\n",
            "9776/15750 (epoch 31), train_loss = 2.265, time/batch = 0.205\n",
            "9777/15750 (epoch 31), train_loss = 2.347, time/batch = 0.206\n",
            "9778/15750 (epoch 31), train_loss = 2.324, time/batch = 0.207\n",
            "9779/15750 (epoch 31), train_loss = 2.299, time/batch = 0.207\n",
            "9780/15750 (epoch 31), train_loss = 2.325, time/batch = 0.208\n",
            "9781/15750 (epoch 31), train_loss = 2.328, time/batch = 0.204\n",
            "9782/15750 (epoch 31), train_loss = 2.389, time/batch = 0.203\n",
            "9783/15750 (epoch 31), train_loss = 2.403, time/batch = 0.208\n",
            "9784/15750 (epoch 31), train_loss = 2.350, time/batch = 0.209\n",
            "9785/15750 (epoch 31), train_loss = 2.338, time/batch = 0.208\n",
            "9786/15750 (epoch 31), train_loss = 2.352, time/batch = 0.204\n",
            "9787/15750 (epoch 31), train_loss = 2.303, time/batch = 0.207\n",
            "9788/15750 (epoch 31), train_loss = 2.359, time/batch = 0.210\n",
            "9789/15750 (epoch 31), train_loss = 2.362, time/batch = 0.208\n",
            "9790/15750 (epoch 31), train_loss = 2.386, time/batch = 0.214\n",
            "9791/15750 (epoch 31), train_loss = 2.390, time/batch = 0.207\n",
            "9792/15750 (epoch 31), train_loss = 2.371, time/batch = 0.207\n",
            "9793/15750 (epoch 31), train_loss = 2.482, time/batch = 0.200\n",
            "9794/15750 (epoch 31), train_loss = 2.393, time/batch = 0.204\n",
            "9795/15750 (epoch 31), train_loss = 2.354, time/batch = 0.207\n",
            "9796/15750 (epoch 31), train_loss = 2.322, time/batch = 0.201\n",
            "9797/15750 (epoch 31), train_loss = 2.235, time/batch = 0.203\n",
            "9798/15750 (epoch 31), train_loss = 2.254, time/batch = 0.198\n",
            "9799/15750 (epoch 31), train_loss = 2.339, time/batch = 0.204\n",
            "9800/15750 (epoch 31), train_loss = 2.238, time/batch = 0.208\n",
            "9801/15750 (epoch 31), train_loss = 2.316, time/batch = 0.202\n",
            "9802/15750 (epoch 31), train_loss = 2.366, time/batch = 0.203\n",
            "9803/15750 (epoch 31), train_loss = 2.277, time/batch = 0.204\n",
            "9804/15750 (epoch 31), train_loss = 2.326, time/batch = 0.207\n",
            "9805/15750 (epoch 31), train_loss = 2.283, time/batch = 0.202\n",
            "9806/15750 (epoch 31), train_loss = 2.329, time/batch = 0.199\n",
            "9807/15750 (epoch 31), train_loss = 2.330, time/batch = 0.198\n",
            "9808/15750 (epoch 31), train_loss = 2.293, time/batch = 0.204\n",
            "9809/15750 (epoch 31), train_loss = 2.326, time/batch = 0.200\n",
            "9810/15750 (epoch 31), train_loss = 2.253, time/batch = 0.205\n",
            "9811/15750 (epoch 31), train_loss = 2.293, time/batch = 0.205\n",
            "9812/15750 (epoch 31), train_loss = 2.311, time/batch = 0.209\n",
            "9813/15750 (epoch 31), train_loss = 2.350, time/batch = 0.206\n",
            "9814/15750 (epoch 31), train_loss = 2.234, time/batch = 0.209\n",
            "9815/15750 (epoch 31), train_loss = 2.301, time/batch = 0.212\n",
            "9816/15750 (epoch 31), train_loss = 2.255, time/batch = 0.206\n",
            "9817/15750 (epoch 31), train_loss = 2.312, time/batch = 0.206\n",
            "9818/15750 (epoch 31), train_loss = 2.328, time/batch = 0.210\n",
            "9819/15750 (epoch 31), train_loss = 2.324, time/batch = 0.209\n",
            "9820/15750 (epoch 31), train_loss = 2.355, time/batch = 0.221\n",
            "9821/15750 (epoch 31), train_loss = 2.243, time/batch = 0.208\n",
            "9822/15750 (epoch 31), train_loss = 2.236, time/batch = 0.204\n",
            "9823/15750 (epoch 31), train_loss = 2.335, time/batch = 0.204\n",
            "9824/15750 (epoch 31), train_loss = 2.195, time/batch = 0.203\n",
            "9825/15750 (epoch 31), train_loss = 2.296, time/batch = 0.208\n",
            "9826/15750 (epoch 31), train_loss = 2.301, time/batch = 0.205\n",
            "9827/15750 (epoch 31), train_loss = 2.231, time/batch = 0.206\n",
            "9828/15750 (epoch 31), train_loss = 2.291, time/batch = 0.204\n",
            "9829/15750 (epoch 31), train_loss = 2.196, time/batch = 0.200\n",
            "9830/15750 (epoch 31), train_loss = 2.221, time/batch = 0.211\n",
            "9831/15750 (epoch 31), train_loss = 2.160, time/batch = 0.202\n",
            "9832/15750 (epoch 31), train_loss = 2.177, time/batch = 0.207\n",
            "9833/15750 (epoch 31), train_loss = 2.231, time/batch = 0.205\n",
            "9834/15750 (epoch 31), train_loss = 2.323, time/batch = 0.206\n",
            "9835/15750 (epoch 31), train_loss = 2.247, time/batch = 0.209\n",
            "9836/15750 (epoch 31), train_loss = 2.237, time/batch = 0.202\n",
            "9837/15750 (epoch 31), train_loss = 2.156, time/batch = 0.203\n",
            "9838/15750 (epoch 31), train_loss = 2.225, time/batch = 0.208\n",
            "9839/15750 (epoch 31), train_loss = 2.338, time/batch = 0.206\n",
            "9840/15750 (epoch 31), train_loss = 2.273, time/batch = 0.217\n",
            "9841/15750 (epoch 31), train_loss = 2.267, time/batch = 0.200\n",
            "9842/15750 (epoch 31), train_loss = 2.269, time/batch = 0.206\n",
            "9843/15750 (epoch 31), train_loss = 2.278, time/batch = 0.209\n",
            "9844/15750 (epoch 31), train_loss = 2.271, time/batch = 0.208\n",
            "9845/15750 (epoch 31), train_loss = 2.173, time/batch = 0.208\n",
            "9846/15750 (epoch 31), train_loss = 2.274, time/batch = 0.207\n",
            "9847/15750 (epoch 31), train_loss = 2.217, time/batch = 0.204\n",
            "9848/15750 (epoch 31), train_loss = 2.270, time/batch = 0.201\n",
            "9849/15750 (epoch 31), train_loss = 2.328, time/batch = 0.198\n",
            "9850/15750 (epoch 31), train_loss = 2.346, time/batch = 0.220\n",
            "9851/15750 (epoch 31), train_loss = 2.184, time/batch = 0.200\n",
            "9852/15750 (epoch 31), train_loss = 2.219, time/batch = 0.203\n",
            "9853/15750 (epoch 31), train_loss = 2.237, time/batch = 0.200\n",
            "9854/15750 (epoch 31), train_loss = 2.240, time/batch = 0.199\n",
            "9855/15750 (epoch 31), train_loss = 2.237, time/batch = 0.211\n",
            "9856/15750 (epoch 31), train_loss = 2.299, time/batch = 0.202\n",
            "9857/15750 (epoch 31), train_loss = 2.287, time/batch = 0.206\n",
            "9858/15750 (epoch 31), train_loss = 2.299, time/batch = 0.202\n",
            "9859/15750 (epoch 31), train_loss = 2.362, time/batch = 0.209\n",
            "9860/15750 (epoch 31), train_loss = 2.269, time/batch = 0.210\n",
            "9861/15750 (epoch 31), train_loss = 2.296, time/batch = 0.200\n",
            "9862/15750 (epoch 31), train_loss = 2.316, time/batch = 0.211\n",
            "9863/15750 (epoch 31), train_loss = 2.297, time/batch = 0.204\n",
            "9864/15750 (epoch 31), train_loss = 2.313, time/batch = 0.211\n",
            "9865/15750 (epoch 31), train_loss = 2.290, time/batch = 0.213\n",
            "9866/15750 (epoch 31), train_loss = 2.231, time/batch = 0.204\n",
            "9867/15750 (epoch 31), train_loss = 2.249, time/batch = 0.207\n",
            "9868/15750 (epoch 31), train_loss = 2.373, time/batch = 0.206\n",
            "9869/15750 (epoch 31), train_loss = 2.296, time/batch = 0.204\n",
            "9870/15750 (epoch 31), train_loss = 2.205, time/batch = 0.210\n",
            "9871/15750 (epoch 31), train_loss = 2.264, time/batch = 0.205\n",
            "9872/15750 (epoch 31), train_loss = 2.293, time/batch = 0.206\n",
            "9873/15750 (epoch 31), train_loss = 2.331, time/batch = 0.203\n",
            "9874/15750 (epoch 31), train_loss = 2.358, time/batch = 0.204\n",
            "9875/15750 (epoch 31), train_loss = 2.411, time/batch = 0.212\n",
            "9876/15750 (epoch 31), train_loss = 2.279, time/batch = 0.200\n",
            "9877/15750 (epoch 31), train_loss = 2.280, time/batch = 0.205\n",
            "9878/15750 (epoch 31), train_loss = 2.281, time/batch = 0.200\n",
            "9879/15750 (epoch 31), train_loss = 2.288, time/batch = 0.202\n",
            "9880/15750 (epoch 31), train_loss = 2.370, time/batch = 0.209\n",
            "9881/15750 (epoch 31), train_loss = 2.291, time/batch = 0.207\n",
            "9882/15750 (epoch 31), train_loss = 2.413, time/batch = 0.204\n",
            "9883/15750 (epoch 31), train_loss = 2.298, time/batch = 0.207\n",
            "9884/15750 (epoch 31), train_loss = 2.283, time/batch = 0.212\n",
            "9885/15750 (epoch 31), train_loss = 2.255, time/batch = 0.207\n",
            "9886/15750 (epoch 31), train_loss = 2.234, time/batch = 0.205\n",
            "9887/15750 (epoch 31), train_loss = 2.273, time/batch = 0.205\n",
            "9888/15750 (epoch 31), train_loss = 2.232, time/batch = 0.204\n",
            "9889/15750 (epoch 31), train_loss = 2.265, time/batch = 0.206\n",
            "9890/15750 (epoch 31), train_loss = 2.281, time/batch = 0.208\n",
            "9891/15750 (epoch 31), train_loss = 2.364, time/batch = 0.206\n",
            "9892/15750 (epoch 31), train_loss = 2.251, time/batch = 0.207\n",
            "9893/15750 (epoch 31), train_loss = 2.270, time/batch = 0.202\n",
            "9894/15750 (epoch 31), train_loss = 2.240, time/batch = 0.202\n",
            "9895/15750 (epoch 31), train_loss = 2.189, time/batch = 0.199\n",
            "9896/15750 (epoch 31), train_loss = 2.199, time/batch = 0.203\n",
            "9897/15750 (epoch 31), train_loss = 2.212, time/batch = 0.200\n",
            "9898/15750 (epoch 31), train_loss = 2.233, time/batch = 0.201\n",
            "9899/15750 (epoch 31), train_loss = 2.253, time/batch = 0.204\n",
            "9900/15750 (epoch 31), train_loss = 2.382, time/batch = 0.202\n",
            "9901/15750 (epoch 31), train_loss = 2.342, time/batch = 0.201\n",
            "9902/15750 (epoch 31), train_loss = 2.342, time/batch = 0.201\n",
            "9903/15750 (epoch 31), train_loss = 2.330, time/batch = 0.205\n",
            "9904/15750 (epoch 31), train_loss = 2.256, time/batch = 0.201\n",
            "9905/15750 (epoch 31), train_loss = 2.256, time/batch = 0.212\n",
            "9906/15750 (epoch 31), train_loss = 2.345, time/batch = 0.201\n",
            "9907/15750 (epoch 31), train_loss = 2.366, time/batch = 0.200\n",
            "9908/15750 (epoch 31), train_loss = 2.344, time/batch = 0.202\n",
            "9909/15750 (epoch 31), train_loss = 2.259, time/batch = 0.201\n",
            "9910/15750 (epoch 31), train_loss = 2.255, time/batch = 0.209\n",
            "9911/15750 (epoch 31), train_loss = 2.219, time/batch = 0.203\n",
            "9912/15750 (epoch 31), train_loss = 2.311, time/batch = 0.201\n",
            "9913/15750 (epoch 31), train_loss = 2.336, time/batch = 0.202\n",
            "9914/15750 (epoch 31), train_loss = 2.283, time/batch = 0.202\n",
            "9915/15750 (epoch 31), train_loss = 2.280, time/batch = 0.210\n",
            "9916/15750 (epoch 31), train_loss = 2.322, time/batch = 0.208\n",
            "9917/15750 (epoch 31), train_loss = 2.362, time/batch = 0.202\n",
            "9918/15750 (epoch 31), train_loss = 2.309, time/batch = 0.201\n",
            "9919/15750 (epoch 31), train_loss = 2.321, time/batch = 0.201\n",
            "9920/15750 (epoch 31), train_loss = 2.312, time/batch = 0.207\n",
            "9921/15750 (epoch 31), train_loss = 2.313, time/batch = 0.196\n",
            "9922/15750 (epoch 31), train_loss = 2.307, time/batch = 0.200\n",
            "9923/15750 (epoch 31), train_loss = 2.394, time/batch = 0.204\n",
            "9924/15750 (epoch 31), train_loss = 2.252, time/batch = 0.198\n",
            "9925/15750 (epoch 31), train_loss = 2.325, time/batch = 0.208\n",
            "9926/15750 (epoch 31), train_loss = 2.317, time/batch = 0.196\n",
            "9927/15750 (epoch 31), train_loss = 2.341, time/batch = 0.203\n",
            "9928/15750 (epoch 31), train_loss = 2.417, time/batch = 0.203\n",
            "9929/15750 (epoch 31), train_loss = 2.340, time/batch = 0.207\n",
            "9930/15750 (epoch 31), train_loss = 2.338, time/batch = 0.210\n",
            "9931/15750 (epoch 31), train_loss = 2.319, time/batch = 0.206\n",
            "9932/15750 (epoch 31), train_loss = 2.286, time/batch = 0.206\n",
            "9933/15750 (epoch 31), train_loss = 2.253, time/batch = 0.205\n",
            "9934/15750 (epoch 31), train_loss = 2.245, time/batch = 0.208\n",
            "9935/15750 (epoch 31), train_loss = 2.291, time/batch = 0.212\n",
            "9936/15750 (epoch 31), train_loss = 2.324, time/batch = 0.205\n",
            "9937/15750 (epoch 31), train_loss = 2.294, time/batch = 0.205\n",
            "9938/15750 (epoch 31), train_loss = 2.358, time/batch = 0.209\n",
            "9939/15750 (epoch 31), train_loss = 2.298, time/batch = 0.209\n",
            "9940/15750 (epoch 31), train_loss = 2.230, time/batch = 0.215\n",
            "9941/15750 (epoch 31), train_loss = 2.258, time/batch = 0.203\n",
            "9942/15750 (epoch 31), train_loss = 2.317, time/batch = 0.201\n",
            "9943/15750 (epoch 31), train_loss = 2.252, time/batch = 0.203\n",
            "9944/15750 (epoch 31), train_loss = 2.211, time/batch = 0.202\n",
            "9945/15750 (epoch 31), train_loss = 2.246, time/batch = 0.212\n",
            "9946/15750 (epoch 31), train_loss = 2.325, time/batch = 0.198\n",
            "9947/15750 (epoch 31), train_loss = 2.297, time/batch = 0.199\n",
            "9948/15750 (epoch 31), train_loss = 2.360, time/batch = 0.202\n",
            "9949/15750 (epoch 31), train_loss = 2.346, time/batch = 0.203\n",
            "9950/15750 (epoch 31), train_loss = 2.295, time/batch = 0.213\n",
            "9951/15750 (epoch 31), train_loss = 2.252, time/batch = 0.198\n",
            "9952/15750 (epoch 31), train_loss = 2.324, time/batch = 0.207\n",
            "9953/15750 (epoch 31), train_loss = 2.347, time/batch = 0.198\n",
            "9954/15750 (epoch 31), train_loss = 2.416, time/batch = 0.208\n",
            "9955/15750 (epoch 31), train_loss = 2.389, time/batch = 0.207\n",
            "9956/15750 (epoch 31), train_loss = 2.301, time/batch = 0.203\n",
            "9957/15750 (epoch 31), train_loss = 2.319, time/batch = 0.205\n",
            "9958/15750 (epoch 31), train_loss = 2.244, time/batch = 0.206\n",
            "9959/15750 (epoch 31), train_loss = 2.370, time/batch = 0.205\n",
            "9960/15750 (epoch 31), train_loss = 2.343, time/batch = 0.211\n",
            "9961/15750 (epoch 31), train_loss = 2.300, time/batch = 0.204\n",
            "9962/15750 (epoch 31), train_loss = 2.245, time/batch = 0.207\n",
            "9963/15750 (epoch 31), train_loss = 2.348, time/batch = 0.207\n",
            "9964/15750 (epoch 31), train_loss = 2.139, time/batch = 0.212\n",
            "9965/15750 (epoch 31), train_loss = 2.251, time/batch = 0.223\n",
            "9966/15750 (epoch 31), train_loss = 2.210, time/batch = 0.203\n",
            "9967/15750 (epoch 31), train_loss = 2.289, time/batch = 0.205\n",
            "9968/15750 (epoch 31), train_loss = 2.262, time/batch = 0.205\n",
            "9969/15750 (epoch 31), train_loss = 2.327, time/batch = 0.202\n",
            "9970/15750 (epoch 31), train_loss = 2.274, time/batch = 0.210\n",
            "9971/15750 (epoch 31), train_loss = 2.156, time/batch = 0.205\n",
            "9972/15750 (epoch 31), train_loss = 2.227, time/batch = 0.205\n",
            "9973/15750 (epoch 31), train_loss = 2.231, time/batch = 0.204\n",
            "9974/15750 (epoch 31), train_loss = 2.293, time/batch = 0.203\n",
            "9975/15750 (epoch 31), train_loss = 2.177, time/batch = 0.217\n",
            "9976/15750 (epoch 31), train_loss = 2.253, time/batch = 0.207\n",
            "9977/15750 (epoch 31), train_loss = 2.146, time/batch = 0.202\n",
            "9978/15750 (epoch 31), train_loss = 2.218, time/batch = 0.201\n",
            "9979/15750 (epoch 31), train_loss = 2.210, time/batch = 0.211\n",
            "9980/15750 (epoch 31), train_loss = 2.200, time/batch = 0.213\n",
            "9981/15750 (epoch 31), train_loss = 2.350, time/batch = 0.207\n",
            "9982/15750 (epoch 31), train_loss = 2.175, time/batch = 0.204\n",
            "9983/15750 (epoch 31), train_loss = 2.421, time/batch = 0.209\n",
            "9984/15750 (epoch 31), train_loss = 2.284, time/batch = 0.209\n",
            "9985/15750 (epoch 31), train_loss = 2.163, time/batch = 0.204\n",
            "9986/15750 (epoch 31), train_loss = 2.198, time/batch = 0.205\n",
            "9987/15750 (epoch 31), train_loss = 2.259, time/batch = 0.202\n",
            "9988/15750 (epoch 31), train_loss = 2.251, time/batch = 0.203\n",
            "9989/15750 (epoch 31), train_loss = 2.236, time/batch = 0.202\n",
            "9990/15750 (epoch 31), train_loss = 2.244, time/batch = 0.207\n",
            "9991/15750 (epoch 31), train_loss = 2.312, time/batch = 0.202\n",
            "9992/15750 (epoch 31), train_loss = 2.230, time/batch = 0.199\n",
            "9993/15750 (epoch 31), train_loss = 2.274, time/batch = 0.202\n",
            "9994/15750 (epoch 31), train_loss = 2.352, time/batch = 0.200\n",
            "9995/15750 (epoch 31), train_loss = 2.206, time/batch = 0.216\n",
            "9996/15750 (epoch 31), train_loss = 2.229, time/batch = 0.208\n",
            "9997/15750 (epoch 31), train_loss = 2.269, time/batch = 0.205\n",
            "9998/15750 (epoch 31), train_loss = 2.269, time/batch = 0.205\n",
            "9999/15750 (epoch 31), train_loss = 2.223, time/batch = 0.208\n",
            "10000/15750 (epoch 31), train_loss = 2.213, time/batch = 0.205\n",
            "model saved to ./save_star/model.ckpt\n",
            "10001/15750 (epoch 31), train_loss = 2.186, time/batch = 0.210\n",
            "10002/15750 (epoch 31), train_loss = 2.234, time/batch = 0.208\n",
            "10003/15750 (epoch 31), train_loss = 2.442, time/batch = 0.210\n",
            "10004/15750 (epoch 31), train_loss = 2.265, time/batch = 0.207\n",
            "10005/15750 (epoch 31), train_loss = 2.320, time/batch = 0.206\n",
            "10006/15750 (epoch 31), train_loss = 2.198, time/batch = 0.207\n",
            "10007/15750 (epoch 31), train_loss = 2.251, time/batch = 0.208\n",
            "10008/15750 (epoch 31), train_loss = 2.275, time/batch = 0.217\n",
            "10009/15750 (epoch 31), train_loss = 2.281, time/batch = 0.200\n",
            "10010/15750 (epoch 31), train_loss = 2.335, time/batch = 0.205\n",
            "10011/15750 (epoch 31), train_loss = 2.295, time/batch = 0.206\n",
            "10012/15750 (epoch 31), train_loss = 2.290, time/batch = 0.202\n",
            "10013/15750 (epoch 31), train_loss = 2.271, time/batch = 0.210\n",
            "10014/15750 (epoch 31), train_loss = 2.298, time/batch = 0.200\n",
            "10015/15750 (epoch 31), train_loss = 2.197, time/batch = 0.200\n",
            "10016/15750 (epoch 31), train_loss = 2.191, time/batch = 0.210\n",
            "10017/15750 (epoch 31), train_loss = 2.277, time/batch = 0.208\n",
            "10018/15750 (epoch 31), train_loss = 2.295, time/batch = 0.212\n",
            "10019/15750 (epoch 31), train_loss = 2.264, time/batch = 0.207\n",
            "10020/15750 (epoch 31), train_loss = 2.229, time/batch = 0.205\n",
            "10021/15750 (epoch 31), train_loss = 2.178, time/batch = 0.210\n",
            "10022/15750 (epoch 31), train_loss = 2.203, time/batch = 0.206\n",
            "10023/15750 (epoch 31), train_loss = 2.361, time/batch = 0.209\n",
            "10024/15750 (epoch 31), train_loss = 2.332, time/batch = 0.209\n",
            "10025/15750 (epoch 31), train_loss = 2.305, time/batch = 0.206\n",
            "10026/15750 (epoch 31), train_loss = 2.250, time/batch = 0.207\n",
            "10027/15750 (epoch 31), train_loss = 2.275, time/batch = 0.206\n",
            "10028/15750 (epoch 31), train_loss = 2.265, time/batch = 0.219\n",
            "10029/15750 (epoch 31), train_loss = 2.291, time/batch = 0.205\n",
            "10030/15750 (epoch 31), train_loss = 2.339, time/batch = 0.200\n",
            "10031/15750 (epoch 31), train_loss = 2.344, time/batch = 0.201\n",
            "10032/15750 (epoch 31), train_loss = 2.265, time/batch = 0.200\n",
            "10033/15750 (epoch 31), train_loss = 2.299, time/batch = 0.217\n",
            "10034/15750 (epoch 31), train_loss = 2.330, time/batch = 0.204\n",
            "10035/15750 (epoch 31), train_loss = 2.317, time/batch = 0.203\n",
            "10036/15750 (epoch 31), train_loss = 2.225, time/batch = 0.207\n",
            "10037/15750 (epoch 31), train_loss = 2.261, time/batch = 0.204\n",
            "10038/15750 (epoch 31), train_loss = 2.323, time/batch = 0.205\n",
            "10039/15750 (epoch 31), train_loss = 2.340, time/batch = 0.203\n",
            "10040/15750 (epoch 31), train_loss = 2.288, time/batch = 0.200\n",
            "10041/15750 (epoch 31), train_loss = 2.346, time/batch = 0.205\n",
            "10042/15750 (epoch 31), train_loss = 2.278, time/batch = 0.202\n",
            "10043/15750 (epoch 31), train_loss = 2.249, time/batch = 0.210\n",
            "10044/15750 (epoch 31), train_loss = 2.201, time/batch = 0.207\n",
            "10045/15750 (epoch 31), train_loss = 2.423, time/batch = 0.209\n",
            "10046/15750 (epoch 31), train_loss = 2.252, time/batch = 0.203\n",
            "10047/15750 (epoch 31), train_loss = 2.218, time/batch = 0.205\n",
            "10048/15750 (epoch 31), train_loss = 2.331, time/batch = 0.208\n",
            "10049/15750 (epoch 31), train_loss = 2.234, time/batch = 0.205\n",
            "10050/15750 (epoch 31), train_loss = 2.369, time/batch = 0.202\n",
            "10051/15750 (epoch 31), train_loss = 2.268, time/batch = 0.203\n",
            "10052/15750 (epoch 31), train_loss = 2.280, time/batch = 0.206\n",
            "10053/15750 (epoch 31), train_loss = 2.201, time/batch = 0.212\n",
            "10054/15750 (epoch 31), train_loss = 2.295, time/batch = 0.200\n",
            "10055/15750 (epoch 31), train_loss = 2.223, time/batch = 0.206\n",
            "10056/15750 (epoch 31), train_loss = 2.293, time/batch = 0.205\n",
            "10057/15750 (epoch 31), train_loss = 2.289, time/batch = 0.201\n",
            "10058/15750 (epoch 31), train_loss = 2.249, time/batch = 0.214\n",
            "10059/15750 (epoch 31), train_loss = 2.303, time/batch = 0.203\n",
            "10060/15750 (epoch 31), train_loss = 2.383, time/batch = 0.204\n",
            "10061/15750 (epoch 31), train_loss = 2.335, time/batch = 0.202\n",
            "10062/15750 (epoch 31), train_loss = 2.354, time/batch = 0.203\n",
            "10063/15750 (epoch 31), train_loss = 2.232, time/batch = 0.212\n",
            "10064/15750 (epoch 31), train_loss = 2.297, time/batch = 0.202\n",
            "10065/15750 (epoch 31), train_loss = 2.284, time/batch = 0.198\n",
            "10066/15750 (epoch 31), train_loss = 2.218, time/batch = 0.201\n",
            "10067/15750 (epoch 31), train_loss = 2.345, time/batch = 0.205\n",
            "10068/15750 (epoch 31), train_loss = 2.201, time/batch = 0.204\n",
            "10069/15750 (epoch 31), train_loss = 2.328, time/batch = 0.199\n",
            "10070/15750 (epoch 31), train_loss = 2.278, time/batch = 0.201\n",
            "10071/15750 (epoch 31), train_loss = 2.245, time/batch = 0.199\n",
            "10072/15750 (epoch 31), train_loss = 2.196, time/batch = 0.203\n",
            "10073/15750 (epoch 31), train_loss = 2.228, time/batch = 0.204\n",
            "10074/15750 (epoch 31), train_loss = 2.346, time/batch = 0.199\n",
            "10075/15750 (epoch 31), train_loss = 2.216, time/batch = 0.201\n",
            "10076/15750 (epoch 31), train_loss = 2.196, time/batch = 0.199\n",
            "10077/15750 (epoch 31), train_loss = 2.228, time/batch = 0.203\n",
            "10078/15750 (epoch 31), train_loss = 2.237, time/batch = 0.206\n",
            "10079/15750 (epoch 31), train_loss = 2.337, time/batch = 0.199\n",
            "10080/15750 (epoch 32), train_loss = 2.212, time/batch = 0.209\n",
            "10081/15750 (epoch 32), train_loss = 2.329, time/batch = 0.204\n",
            "10082/15750 (epoch 32), train_loss = 2.262, time/batch = 0.207\n",
            "10083/15750 (epoch 32), train_loss = 2.359, time/batch = 0.210\n",
            "10084/15750 (epoch 32), train_loss = 2.282, time/batch = 0.217\n",
            "10085/15750 (epoch 32), train_loss = 2.280, time/batch = 0.196\n",
            "10086/15750 (epoch 32), train_loss = 2.434, time/batch = 0.202\n",
            "10087/15750 (epoch 32), train_loss = 2.351, time/batch = 0.204\n",
            "10088/15750 (epoch 32), train_loss = 2.345, time/batch = 0.198\n",
            "10089/15750 (epoch 32), train_loss = 2.291, time/batch = 0.202\n",
            "10090/15750 (epoch 32), train_loss = 2.295, time/batch = 0.194\n",
            "10091/15750 (epoch 32), train_loss = 2.259, time/batch = 0.201\n",
            "10092/15750 (epoch 32), train_loss = 2.340, time/batch = 0.208\n",
            "10093/15750 (epoch 32), train_loss = 2.317, time/batch = 0.205\n",
            "10094/15750 (epoch 32), train_loss = 2.292, time/batch = 0.198\n",
            "10095/15750 (epoch 32), train_loss = 2.318, time/batch = 0.205\n",
            "10096/15750 (epoch 32), train_loss = 2.321, time/batch = 0.201\n",
            "10097/15750 (epoch 32), train_loss = 2.382, time/batch = 0.205\n",
            "10098/15750 (epoch 32), train_loss = 2.396, time/batch = 0.201\n",
            "10099/15750 (epoch 32), train_loss = 2.344, time/batch = 0.197\n",
            "10100/15750 (epoch 32), train_loss = 2.332, time/batch = 0.206\n",
            "10101/15750 (epoch 32), train_loss = 2.346, time/batch = 0.204\n",
            "10102/15750 (epoch 32), train_loss = 2.296, time/batch = 0.207\n",
            "10103/15750 (epoch 32), train_loss = 2.351, time/batch = 0.207\n",
            "10104/15750 (epoch 32), train_loss = 2.355, time/batch = 0.203\n",
            "10105/15750 (epoch 32), train_loss = 2.381, time/batch = 0.207\n",
            "10106/15750 (epoch 32), train_loss = 2.383, time/batch = 0.209\n",
            "10107/15750 (epoch 32), train_loss = 2.366, time/batch = 0.216\n",
            "10108/15750 (epoch 32), train_loss = 2.478, time/batch = 0.208\n",
            "10109/15750 (epoch 32), train_loss = 2.387, time/batch = 0.204\n",
            "10110/15750 (epoch 32), train_loss = 2.348, time/batch = 0.207\n",
            "10111/15750 (epoch 32), train_loss = 2.316, time/batch = 0.206\n",
            "10112/15750 (epoch 32), train_loss = 2.229, time/batch = 0.215\n",
            "10113/15750 (epoch 32), train_loss = 2.245, time/batch = 0.206\n",
            "10114/15750 (epoch 32), train_loss = 2.331, time/batch = 0.205\n",
            "10115/15750 (epoch 32), train_loss = 2.230, time/batch = 0.210\n",
            "10116/15750 (epoch 32), train_loss = 2.311, time/batch = 0.205\n",
            "10117/15750 (epoch 32), train_loss = 2.358, time/batch = 0.206\n",
            "10118/15750 (epoch 32), train_loss = 2.270, time/batch = 0.205\n",
            "10119/15750 (epoch 32), train_loss = 2.319, time/batch = 0.203\n",
            "10120/15750 (epoch 32), train_loss = 2.276, time/batch = 0.205\n",
            "10121/15750 (epoch 32), train_loss = 2.322, time/batch = 0.201\n",
            "10122/15750 (epoch 32), train_loss = 2.323, time/batch = 0.202\n",
            "10123/15750 (epoch 32), train_loss = 2.286, time/batch = 0.201\n",
            "10124/15750 (epoch 32), train_loss = 2.319, time/batch = 0.198\n",
            "10125/15750 (epoch 32), train_loss = 2.247, time/batch = 0.197\n",
            "10126/15750 (epoch 32), train_loss = 2.286, time/batch = 0.206\n",
            "10127/15750 (epoch 32), train_loss = 2.304, time/batch = 0.210\n",
            "10128/15750 (epoch 32), train_loss = 2.344, time/batch = 0.202\n",
            "10129/15750 (epoch 32), train_loss = 2.227, time/batch = 0.200\n",
            "10130/15750 (epoch 32), train_loss = 2.295, time/batch = 0.208\n",
            "10131/15750 (epoch 32), train_loss = 2.248, time/batch = 0.207\n",
            "10132/15750 (epoch 32), train_loss = 2.304, time/batch = 0.207\n",
            "10133/15750 (epoch 32), train_loss = 2.320, time/batch = 0.202\n",
            "10134/15750 (epoch 32), train_loss = 2.317, time/batch = 0.205\n",
            "10135/15750 (epoch 32), train_loss = 2.348, time/batch = 0.206\n",
            "10136/15750 (epoch 32), train_loss = 2.236, time/batch = 0.203\n",
            "10137/15750 (epoch 32), train_loss = 2.229, time/batch = 0.207\n",
            "10138/15750 (epoch 32), train_loss = 2.328, time/batch = 0.201\n",
            "10139/15750 (epoch 32), train_loss = 2.189, time/batch = 0.205\n",
            "10140/15750 (epoch 32), train_loss = 2.290, time/batch = 0.205\n",
            "10141/15750 (epoch 32), train_loss = 2.295, time/batch = 0.204\n",
            "10142/15750 (epoch 32), train_loss = 2.224, time/batch = 0.214\n",
            "10143/15750 (epoch 32), train_loss = 2.284, time/batch = 0.207\n",
            "10144/15750 (epoch 32), train_loss = 2.189, time/batch = 0.204\n",
            "10145/15750 (epoch 32), train_loss = 2.213, time/batch = 0.202\n",
            "10146/15750 (epoch 32), train_loss = 2.152, time/batch = 0.202\n",
            "10147/15750 (epoch 32), train_loss = 2.170, time/batch = 0.209\n",
            "10148/15750 (epoch 32), train_loss = 2.225, time/batch = 0.201\n",
            "10149/15750 (epoch 32), train_loss = 2.318, time/batch = 0.212\n",
            "10150/15750 (epoch 32), train_loss = 2.241, time/batch = 0.208\n",
            "10151/15750 (epoch 32), train_loss = 2.230, time/batch = 0.204\n",
            "10152/15750 (epoch 32), train_loss = 2.150, time/batch = 0.214\n",
            "10153/15750 (epoch 32), train_loss = 2.217, time/batch = 0.198\n",
            "10154/15750 (epoch 32), train_loss = 2.332, time/batch = 0.205\n",
            "10155/15750 (epoch 32), train_loss = 2.266, time/batch = 0.207\n",
            "10156/15750 (epoch 32), train_loss = 2.261, time/batch = 0.207\n",
            "10157/15750 (epoch 32), train_loss = 2.262, time/batch = 0.212\n",
            "10158/15750 (epoch 32), train_loss = 2.271, time/batch = 0.205\n",
            "10159/15750 (epoch 32), train_loss = 2.264, time/batch = 0.209\n",
            "10160/15750 (epoch 32), train_loss = 2.165, time/batch = 0.205\n",
            "10161/15750 (epoch 32), train_loss = 2.267, time/batch = 0.206\n",
            "10162/15750 (epoch 32), train_loss = 2.210, time/batch = 0.217\n",
            "10163/15750 (epoch 32), train_loss = 2.263, time/batch = 0.206\n",
            "10164/15750 (epoch 32), train_loss = 2.321, time/batch = 0.205\n",
            "10165/15750 (epoch 32), train_loss = 2.339, time/batch = 0.208\n",
            "10166/15750 (epoch 32), train_loss = 2.177, time/batch = 0.209\n",
            "10167/15750 (epoch 32), train_loss = 2.213, time/batch = 0.209\n",
            "10168/15750 (epoch 32), train_loss = 2.229, time/batch = 0.199\n",
            "10169/15750 (epoch 32), train_loss = 2.233, time/batch = 0.202\n",
            "10170/15750 (epoch 32), train_loss = 2.229, time/batch = 0.202\n",
            "10171/15750 (epoch 32), train_loss = 2.292, time/batch = 0.205\n",
            "10172/15750 (epoch 32), train_loss = 2.280, time/batch = 0.208\n",
            "10173/15750 (epoch 32), train_loss = 2.292, time/batch = 0.206\n",
            "10174/15750 (epoch 32), train_loss = 2.354, time/batch = 0.207\n",
            "10175/15750 (epoch 32), train_loss = 2.263, time/batch = 0.201\n",
            "10176/15750 (epoch 32), train_loss = 2.290, time/batch = 0.197\n",
            "10177/15750 (epoch 32), train_loss = 2.309, time/batch = 0.205\n",
            "10178/15750 (epoch 32), train_loss = 2.290, time/batch = 0.201\n",
            "10179/15750 (epoch 32), train_loss = 2.306, time/batch = 0.200\n",
            "10180/15750 (epoch 32), train_loss = 2.283, time/batch = 0.200\n",
            "10181/15750 (epoch 32), train_loss = 2.225, time/batch = 0.203\n",
            "10182/15750 (epoch 32), train_loss = 2.242, time/batch = 0.208\n",
            "10183/15750 (epoch 32), train_loss = 2.366, time/batch = 0.197\n",
            "10184/15750 (epoch 32), train_loss = 2.290, time/batch = 0.200\n",
            "10185/15750 (epoch 32), train_loss = 2.198, time/batch = 0.198\n",
            "10186/15750 (epoch 32), train_loss = 2.257, time/batch = 0.201\n",
            "10187/15750 (epoch 32), train_loss = 2.288, time/batch = 0.204\n",
            "10188/15750 (epoch 32), train_loss = 2.323, time/batch = 0.199\n",
            "10189/15750 (epoch 32), train_loss = 2.351, time/batch = 0.200\n",
            "10190/15750 (epoch 32), train_loss = 2.404, time/batch = 0.203\n",
            "10191/15750 (epoch 32), train_loss = 2.272, time/batch = 0.203\n",
            "10192/15750 (epoch 32), train_loss = 2.275, time/batch = 0.205\n",
            "10193/15750 (epoch 32), train_loss = 2.274, time/batch = 0.207\n",
            "10194/15750 (epoch 32), train_loss = 2.281, time/batch = 0.202\n",
            "10195/15750 (epoch 32), train_loss = 2.363, time/batch = 0.201\n",
            "10196/15750 (epoch 32), train_loss = 2.284, time/batch = 0.207\n",
            "10197/15750 (epoch 32), train_loss = 2.406, time/batch = 0.205\n",
            "10198/15750 (epoch 32), train_loss = 2.291, time/batch = 0.200\n",
            "10199/15750 (epoch 32), train_loss = 2.276, time/batch = 0.203\n",
            "10200/15750 (epoch 32), train_loss = 2.248, time/batch = 0.199\n",
            "10201/15750 (epoch 32), train_loss = 2.228, time/batch = 0.198\n",
            "10202/15750 (epoch 32), train_loss = 2.267, time/batch = 0.204\n",
            "10203/15750 (epoch 32), train_loss = 2.224, time/batch = 0.198\n",
            "10204/15750 (epoch 32), train_loss = 2.258, time/batch = 0.200\n",
            "10205/15750 (epoch 32), train_loss = 2.274, time/batch = 0.200\n",
            "10206/15750 (epoch 32), train_loss = 2.357, time/batch = 0.203\n",
            "10207/15750 (epoch 32), train_loss = 2.244, time/batch = 0.205\n",
            "10208/15750 (epoch 32), train_loss = 2.264, time/batch = 0.199\n",
            "10209/15750 (epoch 32), train_loss = 2.233, time/batch = 0.198\n",
            "10210/15750 (epoch 32), train_loss = 2.183, time/batch = 0.202\n",
            "10211/15750 (epoch 32), train_loss = 2.194, time/batch = 0.203\n",
            "10212/15750 (epoch 32), train_loss = 2.206, time/batch = 0.204\n",
            "10213/15750 (epoch 32), train_loss = 2.227, time/batch = 0.197\n",
            "10214/15750 (epoch 32), train_loss = 2.247, time/batch = 0.201\n",
            "10215/15750 (epoch 32), train_loss = 2.375, time/batch = 0.203\n",
            "10216/15750 (epoch 32), train_loss = 2.336, time/batch = 0.198\n",
            "10217/15750 (epoch 32), train_loss = 2.336, time/batch = 0.205\n",
            "10218/15750 (epoch 32), train_loss = 2.324, time/batch = 0.204\n",
            "10219/15750 (epoch 32), train_loss = 2.250, time/batch = 0.200\n",
            "10220/15750 (epoch 32), train_loss = 2.250, time/batch = 0.201\n",
            "10221/15750 (epoch 32), train_loss = 2.340, time/batch = 0.204\n",
            "10222/15750 (epoch 32), train_loss = 2.360, time/batch = 0.207\n",
            "10223/15750 (epoch 32), train_loss = 2.337, time/batch = 0.198\n",
            "10224/15750 (epoch 32), train_loss = 2.252, time/batch = 0.200\n",
            "10225/15750 (epoch 32), train_loss = 2.248, time/batch = 0.199\n",
            "10226/15750 (epoch 32), train_loss = 2.213, time/batch = 0.203\n",
            "10227/15750 (epoch 32), train_loss = 2.305, time/batch = 0.207\n",
            "10228/15750 (epoch 32), train_loss = 2.330, time/batch = 0.200\n",
            "10229/15750 (epoch 32), train_loss = 2.278, time/batch = 0.200\n",
            "10230/15750 (epoch 32), train_loss = 2.273, time/batch = 0.199\n",
            "10231/15750 (epoch 32), train_loss = 2.315, time/batch = 0.200\n",
            "10232/15750 (epoch 32), train_loss = 2.355, time/batch = 0.205\n",
            "10233/15750 (epoch 32), train_loss = 2.302, time/batch = 0.199\n",
            "10234/15750 (epoch 32), train_loss = 2.314, time/batch = 0.200\n",
            "10235/15750 (epoch 32), train_loss = 2.306, time/batch = 0.201\n",
            "10236/15750 (epoch 32), train_loss = 2.306, time/batch = 0.203\n",
            "10237/15750 (epoch 32), train_loss = 2.301, time/batch = 0.204\n",
            "10238/15750 (epoch 32), train_loss = 2.387, time/batch = 0.200\n",
            "10239/15750 (epoch 32), train_loss = 2.245, time/batch = 0.200\n",
            "10240/15750 (epoch 32), train_loss = 2.318, time/batch = 0.205\n",
            "10241/15750 (epoch 32), train_loss = 2.310, time/batch = 0.204\n",
            "10242/15750 (epoch 32), train_loss = 2.334, time/batch = 0.201\n",
            "10243/15750 (epoch 32), train_loss = 2.409, time/batch = 0.199\n",
            "10244/15750 (epoch 32), train_loss = 2.333, time/batch = 0.203\n",
            "10245/15750 (epoch 32), train_loss = 2.331, time/batch = 0.207\n",
            "10246/15750 (epoch 32), train_loss = 2.312, time/batch = 0.197\n",
            "10247/15750 (epoch 32), train_loss = 2.280, time/batch = 0.203\n",
            "10248/15750 (epoch 32), train_loss = 2.246, time/batch = 0.194\n",
            "10249/15750 (epoch 32), train_loss = 2.238, time/batch = 0.200\n",
            "10250/15750 (epoch 32), train_loss = 2.283, time/batch = 0.206\n",
            "10251/15750 (epoch 32), train_loss = 2.316, time/batch = 0.206\n",
            "10252/15750 (epoch 32), train_loss = 2.287, time/batch = 0.200\n",
            "10253/15750 (epoch 32), train_loss = 2.353, time/batch = 0.204\n",
            "10254/15750 (epoch 32), train_loss = 2.290, time/batch = 0.202\n",
            "10255/15750 (epoch 32), train_loss = 2.224, time/batch = 0.207\n",
            "10256/15750 (epoch 32), train_loss = 2.250, time/batch = 0.203\n",
            "10257/15750 (epoch 32), train_loss = 2.311, time/batch = 0.200\n",
            "10258/15750 (epoch 32), train_loss = 2.246, time/batch = 0.208\n",
            "10259/15750 (epoch 32), train_loss = 2.204, time/batch = 0.197\n",
            "10260/15750 (epoch 32), train_loss = 2.240, time/batch = 0.203\n",
            "10261/15750 (epoch 32), train_loss = 2.317, time/batch = 0.201\n",
            "10262/15750 (epoch 32), train_loss = 2.291, time/batch = 0.203\n",
            "10263/15750 (epoch 32), train_loss = 2.353, time/batch = 0.210\n",
            "10264/15750 (epoch 32), train_loss = 2.338, time/batch = 0.199\n",
            "10265/15750 (epoch 32), train_loss = 2.289, time/batch = 0.199\n",
            "10266/15750 (epoch 32), train_loss = 2.246, time/batch = 0.207\n",
            "10267/15750 (epoch 32), train_loss = 2.317, time/batch = 0.200\n",
            "10268/15750 (epoch 32), train_loss = 2.340, time/batch = 0.205\n",
            "10269/15750 (epoch 32), train_loss = 2.408, time/batch = 0.200\n",
            "10270/15750 (epoch 32), train_loss = 2.383, time/batch = 0.209\n",
            "10271/15750 (epoch 32), train_loss = 2.295, time/batch = 0.203\n",
            "10272/15750 (epoch 32), train_loss = 2.313, time/batch = 0.203\n",
            "10273/15750 (epoch 32), train_loss = 2.237, time/batch = 0.209\n",
            "10274/15750 (epoch 32), train_loss = 2.364, time/batch = 0.207\n",
            "10275/15750 (epoch 32), train_loss = 2.336, time/batch = 0.207\n",
            "10276/15750 (epoch 32), train_loss = 2.293, time/batch = 0.200\n",
            "10277/15750 (epoch 32), train_loss = 2.239, time/batch = 0.208\n",
            "10278/15750 (epoch 32), train_loss = 2.341, time/batch = 0.209\n",
            "10279/15750 (epoch 32), train_loss = 2.132, time/batch = 0.204\n",
            "10280/15750 (epoch 32), train_loss = 2.245, time/batch = 0.206\n",
            "10281/15750 (epoch 32), train_loss = 2.204, time/batch = 0.201\n",
            "10282/15750 (epoch 32), train_loss = 2.282, time/batch = 0.203\n",
            "10283/15750 (epoch 32), train_loss = 2.255, time/batch = 0.205\n",
            "10284/15750 (epoch 32), train_loss = 2.321, time/batch = 0.200\n",
            "10285/15750 (epoch 32), train_loss = 2.266, time/batch = 0.203\n",
            "10286/15750 (epoch 32), train_loss = 2.149, time/batch = 0.205\n",
            "10287/15750 (epoch 32), train_loss = 2.220, time/batch = 0.202\n",
            "10288/15750 (epoch 32), train_loss = 2.224, time/batch = 0.206\n",
            "10289/15750 (epoch 32), train_loss = 2.286, time/batch = 0.205\n",
            "10290/15750 (epoch 32), train_loss = 2.171, time/batch = 0.205\n",
            "10291/15750 (epoch 32), train_loss = 2.247, time/batch = 0.207\n",
            "10292/15750 (epoch 32), train_loss = 2.140, time/batch = 0.207\n",
            "10293/15750 (epoch 32), train_loss = 2.212, time/batch = 0.214\n",
            "10294/15750 (epoch 32), train_loss = 2.203, time/batch = 0.201\n",
            "10295/15750 (epoch 32), train_loss = 2.192, time/batch = 0.202\n",
            "10296/15750 (epoch 32), train_loss = 2.344, time/batch = 0.199\n",
            "10297/15750 (epoch 32), train_loss = 2.169, time/batch = 0.204\n",
            "10298/15750 (epoch 32), train_loss = 2.414, time/batch = 0.209\n",
            "10299/15750 (epoch 32), train_loss = 2.278, time/batch = 0.203\n",
            "10300/15750 (epoch 32), train_loss = 2.157, time/batch = 0.201\n",
            "10301/15750 (epoch 32), train_loss = 2.192, time/batch = 0.197\n",
            "10302/15750 (epoch 32), train_loss = 2.253, time/batch = 0.203\n",
            "10303/15750 (epoch 32), train_loss = 2.244, time/batch = 0.203\n",
            "10304/15750 (epoch 32), train_loss = 2.229, time/batch = 0.201\n",
            "10305/15750 (epoch 32), train_loss = 2.238, time/batch = 0.200\n",
            "10306/15750 (epoch 32), train_loss = 2.305, time/batch = 0.204\n",
            "10307/15750 (epoch 32), train_loss = 2.223, time/batch = 0.203\n",
            "10308/15750 (epoch 32), train_loss = 2.268, time/batch = 0.208\n",
            "10309/15750 (epoch 32), train_loss = 2.346, time/batch = 0.198\n",
            "10310/15750 (epoch 32), train_loss = 2.201, time/batch = 0.201\n",
            "10311/15750 (epoch 32), train_loss = 2.222, time/batch = 0.202\n",
            "10312/15750 (epoch 32), train_loss = 2.263, time/batch = 0.203\n",
            "10313/15750 (epoch 32), train_loss = 2.263, time/batch = 0.208\n",
            "10314/15750 (epoch 32), train_loss = 2.216, time/batch = 0.201\n",
            "10315/15750 (epoch 32), train_loss = 2.206, time/batch = 0.199\n",
            "10316/15750 (epoch 32), train_loss = 2.179, time/batch = 0.200\n",
            "10317/15750 (epoch 32), train_loss = 2.227, time/batch = 0.203\n",
            "10318/15750 (epoch 32), train_loss = 2.434, time/batch = 0.207\n",
            "10319/15750 (epoch 32), train_loss = 2.258, time/batch = 0.200\n",
            "10320/15750 (epoch 32), train_loss = 2.313, time/batch = 0.200\n",
            "10321/15750 (epoch 32), train_loss = 2.192, time/batch = 0.199\n",
            "10322/15750 (epoch 32), train_loss = 2.244, time/batch = 0.201\n",
            "10323/15750 (epoch 32), train_loss = 2.268, time/batch = 0.205\n",
            "10324/15750 (epoch 32), train_loss = 2.274, time/batch = 0.201\n",
            "10325/15750 (epoch 32), train_loss = 2.329, time/batch = 0.198\n",
            "10326/15750 (epoch 32), train_loss = 2.287, time/batch = 0.201\n",
            "10327/15750 (epoch 32), train_loss = 2.284, time/batch = 0.207\n",
            "10328/15750 (epoch 32), train_loss = 2.263, time/batch = 0.208\n",
            "10329/15750 (epoch 32), train_loss = 2.290, time/batch = 0.202\n",
            "10330/15750 (epoch 32), train_loss = 2.190, time/batch = 0.201\n",
            "10331/15750 (epoch 32), train_loss = 2.184, time/batch = 0.199\n",
            "10332/15750 (epoch 32), train_loss = 2.270, time/batch = 0.199\n",
            "10333/15750 (epoch 32), train_loss = 2.288, time/batch = 0.206\n",
            "10334/15750 (epoch 32), train_loss = 2.257, time/batch = 0.201\n",
            "10335/15750 (epoch 32), train_loss = 2.222, time/batch = 0.198\n",
            "10336/15750 (epoch 32), train_loss = 2.171, time/batch = 0.199\n",
            "10337/15750 (epoch 32), train_loss = 2.197, time/batch = 0.198\n",
            "10338/15750 (epoch 32), train_loss = 2.354, time/batch = 0.204\n",
            "10339/15750 (epoch 32), train_loss = 2.326, time/batch = 0.205\n",
            "10340/15750 (epoch 32), train_loss = 2.298, time/batch = 0.203\n",
            "10341/15750 (epoch 32), train_loss = 2.244, time/batch = 0.205\n",
            "10342/15750 (epoch 32), train_loss = 2.268, time/batch = 0.204\n",
            "10343/15750 (epoch 32), train_loss = 2.259, time/batch = 0.204\n",
            "10344/15750 (epoch 32), train_loss = 2.283, time/batch = 0.202\n",
            "10345/15750 (epoch 32), train_loss = 2.332, time/batch = 0.200\n",
            "10346/15750 (epoch 32), train_loss = 2.336, time/batch = 0.197\n",
            "10347/15750 (epoch 32), train_loss = 2.258, time/batch = 0.199\n",
            "10348/15750 (epoch 32), train_loss = 2.292, time/batch = 0.208\n",
            "10349/15750 (epoch 32), train_loss = 2.323, time/batch = 0.203\n",
            "10350/15750 (epoch 32), train_loss = 2.310, time/batch = 0.200\n",
            "10351/15750 (epoch 32), train_loss = 2.219, time/batch = 0.203\n",
            "10352/15750 (epoch 32), train_loss = 2.255, time/batch = 0.197\n",
            "10353/15750 (epoch 32), train_loss = 2.317, time/batch = 0.203\n",
            "10354/15750 (epoch 32), train_loss = 2.333, time/batch = 0.205\n",
            "10355/15750 (epoch 32), train_loss = 2.280, time/batch = 0.205\n",
            "10356/15750 (epoch 32), train_loss = 2.339, time/batch = 0.209\n",
            "10357/15750 (epoch 32), train_loss = 2.272, time/batch = 0.202\n",
            "10358/15750 (epoch 32), train_loss = 2.243, time/batch = 0.206\n",
            "10359/15750 (epoch 32), train_loss = 2.195, time/batch = 0.206\n",
            "10360/15750 (epoch 32), train_loss = 2.416, time/batch = 0.200\n",
            "10361/15750 (epoch 32), train_loss = 2.245, time/batch = 0.205\n",
            "10362/15750 (epoch 32), train_loss = 2.211, time/batch = 0.206\n",
            "10363/15750 (epoch 32), train_loss = 2.323, time/batch = 0.211\n",
            "10364/15750 (epoch 32), train_loss = 2.228, time/batch = 0.206\n",
            "10365/15750 (epoch 32), train_loss = 2.362, time/batch = 0.206\n",
            "10366/15750 (epoch 32), train_loss = 2.262, time/batch = 0.204\n",
            "10367/15750 (epoch 32), train_loss = 2.274, time/batch = 0.206\n",
            "10368/15750 (epoch 32), train_loss = 2.195, time/batch = 0.204\n",
            "10369/15750 (epoch 32), train_loss = 2.289, time/batch = 0.203\n",
            "10370/15750 (epoch 32), train_loss = 2.216, time/batch = 0.206\n",
            "10371/15750 (epoch 32), train_loss = 2.287, time/batch = 0.208\n",
            "10372/15750 (epoch 32), train_loss = 2.283, time/batch = 0.200\n",
            "10373/15750 (epoch 32), train_loss = 2.242, time/batch = 0.203\n",
            "10374/15750 (epoch 32), train_loss = 2.297, time/batch = 0.206\n",
            "10375/15750 (epoch 32), train_loss = 2.375, time/batch = 0.199\n",
            "10376/15750 (epoch 32), train_loss = 2.327, time/batch = 0.200\n",
            "10377/15750 (epoch 32), train_loss = 2.347, time/batch = 0.198\n",
            "10378/15750 (epoch 32), train_loss = 2.226, time/batch = 0.212\n",
            "10379/15750 (epoch 32), train_loss = 2.290, time/batch = 0.203\n",
            "10380/15750 (epoch 32), train_loss = 2.278, time/batch = 0.204\n",
            "10381/15750 (epoch 32), train_loss = 2.213, time/batch = 0.203\n",
            "10382/15750 (epoch 32), train_loss = 2.339, time/batch = 0.201\n",
            "10383/15750 (epoch 32), train_loss = 2.195, time/batch = 0.203\n",
            "10384/15750 (epoch 32), train_loss = 2.321, time/batch = 0.201\n",
            "10385/15750 (epoch 32), train_loss = 2.272, time/batch = 0.200\n",
            "10386/15750 (epoch 32), train_loss = 2.239, time/batch = 0.202\n",
            "10387/15750 (epoch 32), train_loss = 2.190, time/batch = 0.198\n",
            "10388/15750 (epoch 32), train_loss = 2.222, time/batch = 0.203\n",
            "10389/15750 (epoch 32), train_loss = 2.339, time/batch = 0.199\n",
            "10390/15750 (epoch 32), train_loss = 2.210, time/batch = 0.201\n",
            "10391/15750 (epoch 32), train_loss = 2.190, time/batch = 0.202\n",
            "10392/15750 (epoch 32), train_loss = 2.222, time/batch = 0.203\n",
            "10393/15750 (epoch 32), train_loss = 2.231, time/batch = 0.213\n",
            "10394/15750 (epoch 32), train_loss = 2.331, time/batch = 0.202\n",
            "10395/15750 (epoch 33), train_loss = 2.198, time/batch = 0.197\n",
            "10396/15750 (epoch 33), train_loss = 2.322, time/batch = 0.201\n",
            "10397/15750 (epoch 33), train_loss = 2.254, time/batch = 0.204\n",
            "10398/15750 (epoch 33), train_loss = 2.353, time/batch = 0.204\n",
            "10399/15750 (epoch 33), train_loss = 2.276, time/batch = 0.199\n",
            "10400/15750 (epoch 33), train_loss = 2.273, time/batch = 0.199\n",
            "10401/15750 (epoch 33), train_loss = 2.426, time/batch = 0.207\n",
            "10402/15750 (epoch 33), train_loss = 2.345, time/batch = 0.205\n",
            "10403/15750 (epoch 33), train_loss = 2.338, time/batch = 0.196\n",
            "10404/15750 (epoch 33), train_loss = 2.285, time/batch = 0.202\n",
            "10405/15750 (epoch 33), train_loss = 2.288, time/batch = 0.203\n",
            "10406/15750 (epoch 33), train_loss = 2.253, time/batch = 0.199\n",
            "10407/15750 (epoch 33), train_loss = 2.333, time/batch = 0.204\n",
            "10408/15750 (epoch 33), train_loss = 2.312, time/batch = 0.195\n",
            "10409/15750 (epoch 33), train_loss = 2.286, time/batch = 0.204\n",
            "10410/15750 (epoch 33), train_loss = 2.310, time/batch = 0.202\n",
            "10411/15750 (epoch 33), train_loss = 2.314, time/batch = 0.201\n",
            "10412/15750 (epoch 33), train_loss = 2.375, time/batch = 0.200\n",
            "10413/15750 (epoch 33), train_loss = 2.390, time/batch = 0.213\n",
            "10414/15750 (epoch 33), train_loss = 2.337, time/batch = 0.203\n",
            "10415/15750 (epoch 33), train_loss = 2.324, time/batch = 0.202\n",
            "10416/15750 (epoch 33), train_loss = 2.338, time/batch = 0.201\n",
            "10417/15750 (epoch 33), train_loss = 2.288, time/batch = 0.203\n",
            "10418/15750 (epoch 33), train_loss = 2.344, time/batch = 0.204\n",
            "10419/15750 (epoch 33), train_loss = 2.348, time/batch = 0.200\n",
            "10420/15750 (epoch 33), train_loss = 2.371, time/batch = 0.198\n",
            "10421/15750 (epoch 33), train_loss = 2.376, time/batch = 0.203\n",
            "10422/15750 (epoch 33), train_loss = 2.357, time/batch = 0.201\n",
            "10423/15750 (epoch 33), train_loss = 2.467, time/batch = 0.203\n",
            "10424/15750 (epoch 33), train_loss = 2.379, time/batch = 0.197\n",
            "10425/15750 (epoch 33), train_loss = 2.340, time/batch = 0.203\n",
            "10426/15750 (epoch 33), train_loss = 2.307, time/batch = 0.203\n",
            "10427/15750 (epoch 33), train_loss = 2.222, time/batch = 0.201\n",
            "10428/15750 (epoch 33), train_loss = 2.239, time/batch = 0.206\n",
            "10429/15750 (epoch 33), train_loss = 2.324, time/batch = 0.202\n",
            "10430/15750 (epoch 33), train_loss = 2.223, time/batch = 0.202\n",
            "10431/15750 (epoch 33), train_loss = 2.305, time/batch = 0.199\n",
            "10432/15750 (epoch 33), train_loss = 2.352, time/batch = 0.198\n",
            "10433/15750 (epoch 33), train_loss = 2.264, time/batch = 0.208\n",
            "10434/15750 (epoch 33), train_loss = 2.311, time/batch = 0.203\n",
            "10435/15750 (epoch 33), train_loss = 2.270, time/batch = 0.202\n",
            "10436/15750 (epoch 33), train_loss = 2.315, time/batch = 0.202\n",
            "10437/15750 (epoch 33), train_loss = 2.317, time/batch = 0.203\n",
            "10438/15750 (epoch 33), train_loss = 2.280, time/batch = 0.205\n",
            "10439/15750 (epoch 33), train_loss = 2.313, time/batch = 0.199\n",
            "10440/15750 (epoch 33), train_loss = 2.242, time/batch = 0.200\n",
            "10441/15750 (epoch 33), train_loss = 2.280, time/batch = 0.199\n",
            "10442/15750 (epoch 33), train_loss = 2.298, time/batch = 0.202\n",
            "10443/15750 (epoch 33), train_loss = 2.337, time/batch = 0.203\n",
            "10444/15750 (epoch 33), train_loss = 2.220, time/batch = 0.203\n",
            "10445/15750 (epoch 33), train_loss = 2.289, time/batch = 0.201\n",
            "10446/15750 (epoch 33), train_loss = 2.242, time/batch = 0.201\n",
            "10447/15750 (epoch 33), train_loss = 2.297, time/batch = 0.200\n",
            "10448/15750 (epoch 33), train_loss = 2.313, time/batch = 0.203\n",
            "10449/15750 (epoch 33), train_loss = 2.310, time/batch = 0.202\n",
            "10450/15750 (epoch 33), train_loss = 2.342, time/batch = 0.202\n",
            "10451/15750 (epoch 33), train_loss = 2.230, time/batch = 0.203\n",
            "10452/15750 (epoch 33), train_loss = 2.223, time/batch = 0.200\n",
            "10453/15750 (epoch 33), train_loss = 2.322, time/batch = 0.207\n",
            "10454/15750 (epoch 33), train_loss = 2.183, time/batch = 0.201\n",
            "10455/15750 (epoch 33), train_loss = 2.284, time/batch = 0.201\n",
            "10456/15750 (epoch 33), train_loss = 2.289, time/batch = 0.200\n",
            "10457/15750 (epoch 33), train_loss = 2.218, time/batch = 0.201\n",
            "10458/15750 (epoch 33), train_loss = 2.278, time/batch = 0.206\n",
            "10459/15750 (epoch 33), train_loss = 2.182, time/batch = 0.201\n",
            "10460/15750 (epoch 33), train_loss = 2.207, time/batch = 0.200\n",
            "10461/15750 (epoch 33), train_loss = 2.146, time/batch = 0.200\n",
            "10462/15750 (epoch 33), train_loss = 2.163, time/batch = 0.201\n",
            "10463/15750 (epoch 33), train_loss = 2.218, time/batch = 0.204\n",
            "10464/15750 (epoch 33), train_loss = 2.312, time/batch = 0.201\n",
            "10465/15750 (epoch 33), train_loss = 2.234, time/batch = 0.199\n",
            "10466/15750 (epoch 33), train_loss = 2.224, time/batch = 0.200\n",
            "10467/15750 (epoch 33), train_loss = 2.144, time/batch = 0.200\n",
            "10468/15750 (epoch 33), train_loss = 2.210, time/batch = 0.203\n",
            "10469/15750 (epoch 33), train_loss = 2.326, time/batch = 0.203\n",
            "10470/15750 (epoch 33), train_loss = 2.260, time/batch = 0.200\n",
            "10471/15750 (epoch 33), train_loss = 2.255, time/batch = 0.200\n",
            "10472/15750 (epoch 33), train_loss = 2.256, time/batch = 0.201\n",
            "10473/15750 (epoch 33), train_loss = 2.265, time/batch = 0.207\n",
            "10474/15750 (epoch 33), train_loss = 2.257, time/batch = 0.201\n",
            "10475/15750 (epoch 33), train_loss = 2.158, time/batch = 0.199\n",
            "10476/15750 (epoch 33), train_loss = 2.260, time/batch = 0.201\n",
            "10477/15750 (epoch 33), train_loss = 2.204, time/batch = 0.200\n",
            "10478/15750 (epoch 33), train_loss = 2.257, time/batch = 0.204\n",
            "10479/15750 (epoch 33), train_loss = 2.314, time/batch = 0.201\n",
            "10480/15750 (epoch 33), train_loss = 2.333, time/batch = 0.200\n",
            "10481/15750 (epoch 33), train_loss = 2.170, time/batch = 0.202\n",
            "10482/15750 (epoch 33), train_loss = 2.207, time/batch = 0.202\n",
            "10483/15750 (epoch 33), train_loss = 2.223, time/batch = 0.197\n",
            "10484/15750 (epoch 33), train_loss = 2.227, time/batch = 0.198\n",
            "10485/15750 (epoch 33), train_loss = 2.222, time/batch = 0.206\n",
            "10486/15750 (epoch 33), train_loss = 2.285, time/batch = 0.206\n",
            "10487/15750 (epoch 33), train_loss = 2.273, time/batch = 0.199\n",
            "10488/15750 (epoch 33), train_loss = 2.285, time/batch = 0.202\n",
            "10489/15750 (epoch 33), train_loss = 2.346, time/batch = 0.202\n",
            "10490/15750 (epoch 33), train_loss = 2.257, time/batch = 0.201\n",
            "10491/15750 (epoch 33), train_loss = 2.285, time/batch = 0.200\n",
            "10492/15750 (epoch 33), train_loss = 2.304, time/batch = 0.204\n",
            "10493/15750 (epoch 33), train_loss = 2.283, time/batch = 0.201\n",
            "10494/15750 (epoch 33), train_loss = 2.299, time/batch = 0.206\n",
            "10495/15750 (epoch 33), train_loss = 2.275, time/batch = 0.199\n",
            "10496/15750 (epoch 33), train_loss = 2.219, time/batch = 0.204\n",
            "10497/15750 (epoch 33), train_loss = 2.235, time/batch = 0.202\n",
            "10498/15750 (epoch 33), train_loss = 2.359, time/batch = 0.200\n",
            "10499/15750 (epoch 33), train_loss = 2.283, time/batch = 0.205\n",
            "10500/15750 (epoch 33), train_loss = 2.191, time/batch = 0.204\n",
            "10501/15750 (epoch 33), train_loss = 2.251, time/batch = 0.204\n",
            "10502/15750 (epoch 33), train_loss = 2.281, time/batch = 0.202\n",
            "10503/15750 (epoch 33), train_loss = 2.316, time/batch = 0.199\n",
            "10504/15750 (epoch 33), train_loss = 2.344, time/batch = 0.206\n",
            "10505/15750 (epoch 33), train_loss = 2.398, time/batch = 0.202\n",
            "10506/15750 (epoch 33), train_loss = 2.265, time/batch = 0.203\n",
            "10507/15750 (epoch 33), train_loss = 2.270, time/batch = 0.200\n",
            "10508/15750 (epoch 33), train_loss = 2.268, time/batch = 0.200\n",
            "10509/15750 (epoch 33), train_loss = 2.274, time/batch = 0.208\n",
            "10510/15750 (epoch 33), train_loss = 2.357, time/batch = 0.203\n",
            "10511/15750 (epoch 33), train_loss = 2.278, time/batch = 0.203\n",
            "10512/15750 (epoch 33), train_loss = 2.399, time/batch = 0.200\n",
            "10513/15750 (epoch 33), train_loss = 2.284, time/batch = 0.202\n",
            "10514/15750 (epoch 33), train_loss = 2.270, time/batch = 0.205\n",
            "10515/15750 (epoch 33), train_loss = 2.242, time/batch = 0.198\n",
            "10516/15750 (epoch 33), train_loss = 2.222, time/batch = 0.199\n",
            "10517/15750 (epoch 33), train_loss = 2.262, time/batch = 0.202\n",
            "10518/15750 (epoch 33), train_loss = 2.217, time/batch = 0.202\n",
            "10519/15750 (epoch 33), train_loss = 2.250, time/batch = 0.206\n",
            "10520/15750 (epoch 33), train_loss = 2.267, time/batch = 0.199\n",
            "10521/15750 (epoch 33), train_loss = 2.350, time/batch = 0.202\n",
            "10522/15750 (epoch 33), train_loss = 2.237, time/batch = 0.200\n",
            "10523/15750 (epoch 33), train_loss = 2.259, time/batch = 0.201\n",
            "10524/15750 (epoch 33), train_loss = 2.226, time/batch = 0.204\n",
            "10525/15750 (epoch 33), train_loss = 2.178, time/batch = 0.202\n",
            "10526/15750 (epoch 33), train_loss = 2.189, time/batch = 0.202\n",
            "10527/15750 (epoch 33), train_loss = 2.200, time/batch = 0.199\n",
            "10528/15750 (epoch 33), train_loss = 2.221, time/batch = 0.201\n",
            "10529/15750 (epoch 33), train_loss = 2.241, time/batch = 0.206\n",
            "10530/15750 (epoch 33), train_loss = 2.368, time/batch = 0.201\n",
            "10531/15750 (epoch 33), train_loss = 2.329, time/batch = 0.201\n",
            "10532/15750 (epoch 33), train_loss = 2.330, time/batch = 0.200\n",
            "10533/15750 (epoch 33), train_loss = 2.319, time/batch = 0.201\n",
            "10534/15750 (epoch 33), train_loss = 2.244, time/batch = 0.206\n",
            "10535/15750 (epoch 33), train_loss = 2.245, time/batch = 0.200\n",
            "10536/15750 (epoch 33), train_loss = 2.335, time/batch = 0.201\n",
            "10537/15750 (epoch 33), train_loss = 2.354, time/batch = 0.201\n",
            "10538/15750 (epoch 33), train_loss = 2.330, time/batch = 0.202\n",
            "10539/15750 (epoch 33), train_loss = 2.246, time/batch = 0.204\n",
            "10540/15750 (epoch 33), train_loss = 2.242, time/batch = 0.204\n",
            "10541/15750 (epoch 33), train_loss = 2.207, time/batch = 0.203\n",
            "10542/15750 (epoch 33), train_loss = 2.299, time/batch = 0.199\n",
            "10543/15750 (epoch 33), train_loss = 2.325, time/batch = 0.202\n",
            "10544/15750 (epoch 33), train_loss = 2.272, time/batch = 0.206\n",
            "10545/15750 (epoch 33), train_loss = 2.266, time/batch = 0.203\n",
            "10546/15750 (epoch 33), train_loss = 2.308, time/batch = 0.200\n",
            "10547/15750 (epoch 33), train_loss = 2.348, time/batch = 0.203\n",
            "10548/15750 (epoch 33), train_loss = 2.294, time/batch = 0.199\n",
            "10549/15750 (epoch 33), train_loss = 2.307, time/batch = 0.210\n",
            "10550/15750 (epoch 33), train_loss = 2.299, time/batch = 0.204\n",
            "10551/15750 (epoch 33), train_loss = 2.300, time/batch = 0.201\n",
            "10552/15750 (epoch 33), train_loss = 2.295, time/batch = 0.201\n",
            "10553/15750 (epoch 33), train_loss = 2.381, time/batch = 0.201\n",
            "10554/15750 (epoch 33), train_loss = 2.239, time/batch = 0.206\n",
            "10555/15750 (epoch 33), train_loss = 2.313, time/batch = 0.203\n",
            "10556/15750 (epoch 33), train_loss = 2.303, time/batch = 0.198\n",
            "10557/15750 (epoch 33), train_loss = 2.327, time/batch = 0.204\n",
            "10558/15750 (epoch 33), train_loss = 2.401, time/batch = 0.204\n",
            "10559/15750 (epoch 33), train_loss = 2.325, time/batch = 0.207\n",
            "10560/15750 (epoch 33), train_loss = 2.324, time/batch = 0.202\n",
            "10561/15750 (epoch 33), train_loss = 2.305, time/batch = 0.200\n",
            "10562/15750 (epoch 33), train_loss = 2.274, time/batch = 0.200\n",
            "10563/15750 (epoch 33), train_loss = 2.239, time/batch = 0.198\n",
            "10564/15750 (epoch 33), train_loss = 2.232, time/batch = 0.201\n",
            "10565/15750 (epoch 33), train_loss = 2.276, time/batch = 0.196\n",
            "10566/15750 (epoch 33), train_loss = 2.309, time/batch = 0.200\n",
            "10567/15750 (epoch 33), train_loss = 2.280, time/batch = 0.202\n",
            "10568/15750 (epoch 33), train_loss = 2.347, time/batch = 0.202\n",
            "10569/15750 (epoch 33), train_loss = 2.284, time/batch = 0.207\n",
            "10570/15750 (epoch 33), train_loss = 2.217, time/batch = 0.208\n",
            "10571/15750 (epoch 33), train_loss = 2.243, time/batch = 0.198\n",
            "10572/15750 (epoch 33), train_loss = 2.304, time/batch = 0.200\n",
            "10573/15750 (epoch 33), train_loss = 2.240, time/batch = 0.203\n",
            "10574/15750 (epoch 33), train_loss = 2.198, time/batch = 0.204\n",
            "10575/15750 (epoch 33), train_loss = 2.233, time/batch = 0.200\n",
            "10576/15750 (epoch 33), train_loss = 2.311, time/batch = 0.200\n",
            "10577/15750 (epoch 33), train_loss = 2.285, time/batch = 0.202\n",
            "10578/15750 (epoch 33), train_loss = 2.347, time/batch = 0.202\n",
            "10579/15750 (epoch 33), train_loss = 2.331, time/batch = 0.199\n",
            "10580/15750 (epoch 33), train_loss = 2.283, time/batch = 0.196\n",
            "10581/15750 (epoch 33), train_loss = 2.240, time/batch = 0.202\n",
            "10582/15750 (epoch 33), train_loss = 2.310, time/batch = 0.199\n",
            "10583/15750 (epoch 33), train_loss = 2.334, time/batch = 0.199\n",
            "10584/15750 (epoch 33), train_loss = 2.400, time/batch = 0.202\n",
            "10585/15750 (epoch 33), train_loss = 2.378, time/batch = 0.209\n",
            "10586/15750 (epoch 33), train_loss = 2.288, time/batch = 0.203\n",
            "10587/15750 (epoch 33), train_loss = 2.306, time/batch = 0.199\n",
            "10588/15750 (epoch 33), train_loss = 2.230, time/batch = 0.201\n",
            "10589/15750 (epoch 33), train_loss = 2.357, time/batch = 0.199\n",
            "10590/15750 (epoch 33), train_loss = 2.329, time/batch = 0.206\n",
            "10591/15750 (epoch 33), train_loss = 2.287, time/batch = 0.202\n",
            "10592/15750 (epoch 33), train_loss = 2.232, time/batch = 0.201\n",
            "10593/15750 (epoch 33), train_loss = 2.336, time/batch = 0.198\n",
            "10594/15750 (epoch 33), train_loss = 2.125, time/batch = 0.200\n",
            "10595/15750 (epoch 33), train_loss = 2.238, time/batch = 0.205\n",
            "10596/15750 (epoch 33), train_loss = 2.198, time/batch = 0.197\n",
            "10597/15750 (epoch 33), train_loss = 2.276, time/batch = 0.200\n",
            "10598/15750 (epoch 33), train_loss = 2.249, time/batch = 0.203\n",
            "10599/15750 (epoch 33), train_loss = 2.315, time/batch = 0.200\n",
            "10600/15750 (epoch 33), train_loss = 2.259, time/batch = 0.207\n",
            "10601/15750 (epoch 33), train_loss = 2.143, time/batch = 0.204\n",
            "10602/15750 (epoch 33), train_loss = 2.214, time/batch = 0.203\n",
            "10603/15750 (epoch 33), train_loss = 2.218, time/batch = 0.202\n",
            "10604/15750 (epoch 33), train_loss = 2.280, time/batch = 0.198\n",
            "10605/15750 (epoch 33), train_loss = 2.165, time/batch = 0.205\n",
            "10606/15750 (epoch 33), train_loss = 2.241, time/batch = 0.198\n",
            "10607/15750 (epoch 33), train_loss = 2.134, time/batch = 0.202\n",
            "10608/15750 (epoch 33), train_loss = 2.206, time/batch = 0.202\n",
            "10609/15750 (epoch 33), train_loss = 2.196, time/batch = 0.206\n",
            "10610/15750 (epoch 33), train_loss = 2.186, time/batch = 0.207\n",
            "10611/15750 (epoch 33), train_loss = 2.338, time/batch = 0.198\n",
            "10612/15750 (epoch 33), train_loss = 2.163, time/batch = 0.202\n",
            "10613/15750 (epoch 33), train_loss = 2.408, time/batch = 0.202\n",
            "10614/15750 (epoch 33), train_loss = 2.272, time/batch = 0.201\n",
            "10615/15750 (epoch 33), train_loss = 2.151, time/batch = 0.206\n",
            "10616/15750 (epoch 33), train_loss = 2.185, time/batch = 0.200\n",
            "10617/15750 (epoch 33), train_loss = 2.247, time/batch = 0.201\n",
            "10618/15750 (epoch 33), train_loss = 2.237, time/batch = 0.202\n",
            "10619/15750 (epoch 33), train_loss = 2.222, time/batch = 0.201\n",
            "10620/15750 (epoch 33), train_loss = 2.231, time/batch = 0.209\n",
            "10621/15750 (epoch 33), train_loss = 2.298, time/batch = 0.194\n",
            "10622/15750 (epoch 33), train_loss = 2.217, time/batch = 0.198\n",
            "10623/15750 (epoch 33), train_loss = 2.261, time/batch = 0.200\n",
            "10624/15750 (epoch 33), train_loss = 2.340, time/batch = 0.200\n",
            "10625/15750 (epoch 33), train_loss = 2.195, time/batch = 0.204\n",
            "10626/15750 (epoch 33), train_loss = 2.216, time/batch = 0.200\n",
            "10627/15750 (epoch 33), train_loss = 2.256, time/batch = 0.199\n",
            "10628/15750 (epoch 33), train_loss = 2.257, time/batch = 0.198\n",
            "10629/15750 (epoch 33), train_loss = 2.210, time/batch = 0.200\n",
            "10630/15750 (epoch 33), train_loss = 2.200, time/batch = 0.206\n",
            "10631/15750 (epoch 33), train_loss = 2.173, time/batch = 0.198\n",
            "10632/15750 (epoch 33), train_loss = 2.220, time/batch = 0.198\n",
            "10633/15750 (epoch 33), train_loss = 2.426, time/batch = 0.200\n",
            "10634/15750 (epoch 33), train_loss = 2.251, time/batch = 0.207\n",
            "10635/15750 (epoch 33), train_loss = 2.307, time/batch = 0.206\n",
            "10636/15750 (epoch 33), train_loss = 2.186, time/batch = 0.198\n",
            "10637/15750 (epoch 33), train_loss = 2.237, time/batch = 0.200\n",
            "10638/15750 (epoch 33), train_loss = 2.261, time/batch = 0.200\n",
            "10639/15750 (epoch 33), train_loss = 2.268, time/batch = 0.200\n",
            "10640/15750 (epoch 33), train_loss = 2.323, time/batch = 0.202\n",
            "10641/15750 (epoch 33), train_loss = 2.280, time/batch = 0.198\n",
            "10642/15750 (epoch 33), train_loss = 2.277, time/batch = 0.200\n",
            "10643/15750 (epoch 33), train_loss = 2.256, time/batch = 0.198\n",
            "10644/15750 (epoch 33), train_loss = 2.283, time/batch = 0.206\n",
            "10645/15750 (epoch 33), train_loss = 2.183, time/batch = 0.203\n",
            "10646/15750 (epoch 33), train_loss = 2.177, time/batch = 0.201\n",
            "10647/15750 (epoch 33), train_loss = 2.264, time/batch = 0.199\n",
            "10648/15750 (epoch 33), train_loss = 2.282, time/batch = 0.198\n",
            "10649/15750 (epoch 33), train_loss = 2.251, time/batch = 0.200\n",
            "10650/15750 (epoch 33), train_loss = 2.216, time/batch = 0.205\n",
            "10651/15750 (epoch 33), train_loss = 2.165, time/batch = 0.204\n",
            "10652/15750 (epoch 33), train_loss = 2.192, time/batch = 0.201\n",
            "10653/15750 (epoch 33), train_loss = 2.347, time/batch = 0.207\n",
            "10654/15750 (epoch 33), train_loss = 2.320, time/batch = 0.206\n",
            "10655/15750 (epoch 33), train_loss = 2.292, time/batch = 0.203\n",
            "10656/15750 (epoch 33), train_loss = 2.238, time/batch = 0.205\n",
            "10657/15750 (epoch 33), train_loss = 2.262, time/batch = 0.201\n",
            "10658/15750 (epoch 33), train_loss = 2.252, time/batch = 0.203\n",
            "10659/15750 (epoch 33), train_loss = 2.276, time/batch = 0.203\n",
            "10660/15750 (epoch 33), train_loss = 2.325, time/batch = 0.202\n",
            "10661/15750 (epoch 33), train_loss = 2.328, time/batch = 0.208\n",
            "10662/15750 (epoch 33), train_loss = 2.252, time/batch = 0.201\n",
            "10663/15750 (epoch 33), train_loss = 2.285, time/batch = 0.199\n",
            "10664/15750 (epoch 33), train_loss = 2.317, time/batch = 0.199\n",
            "10665/15750 (epoch 33), train_loss = 2.303, time/batch = 0.200\n",
            "10666/15750 (epoch 33), train_loss = 2.213, time/batch = 0.208\n",
            "10667/15750 (epoch 33), train_loss = 2.249, time/batch = 0.199\n",
            "10668/15750 (epoch 33), train_loss = 2.311, time/batch = 0.199\n",
            "10669/15750 (epoch 33), train_loss = 2.327, time/batch = 0.201\n",
            "10670/15750 (epoch 33), train_loss = 2.273, time/batch = 0.203\n",
            "10671/15750 (epoch 33), train_loss = 2.333, time/batch = 0.205\n",
            "10672/15750 (epoch 33), train_loss = 2.266, time/batch = 0.200\n",
            "10673/15750 (epoch 33), train_loss = 2.238, time/batch = 0.201\n",
            "10674/15750 (epoch 33), train_loss = 2.190, time/batch = 0.201\n",
            "10675/15750 (epoch 33), train_loss = 2.409, time/batch = 0.211\n",
            "10676/15750 (epoch 33), train_loss = 2.237, time/batch = 0.203\n",
            "10677/15750 (epoch 33), train_loss = 2.205, time/batch = 0.199\n",
            "10678/15750 (epoch 33), train_loss = 2.316, time/batch = 0.202\n",
            "10679/15750 (epoch 33), train_loss = 2.221, time/batch = 0.202\n",
            "10680/15750 (epoch 33), train_loss = 2.355, time/batch = 0.200\n",
            "10681/15750 (epoch 33), train_loss = 2.257, time/batch = 0.204\n",
            "10682/15750 (epoch 33), train_loss = 2.269, time/batch = 0.196\n",
            "10683/15750 (epoch 33), train_loss = 2.189, time/batch = 0.198\n",
            "10684/15750 (epoch 33), train_loss = 2.283, time/batch = 0.200\n",
            "10685/15750 (epoch 33), train_loss = 2.210, time/batch = 0.203\n",
            "10686/15750 (epoch 33), train_loss = 2.280, time/batch = 0.207\n",
            "10687/15750 (epoch 33), train_loss = 2.277, time/batch = 0.202\n",
            "10688/15750 (epoch 33), train_loss = 2.235, time/batch = 0.201\n",
            "10689/15750 (epoch 33), train_loss = 2.290, time/batch = 0.207\n",
            "10690/15750 (epoch 33), train_loss = 2.368, time/batch = 0.200\n",
            "10691/15750 (epoch 33), train_loss = 2.320, time/batch = 0.206\n",
            "10692/15750 (epoch 33), train_loss = 2.341, time/batch = 0.197\n",
            "10693/15750 (epoch 33), train_loss = 2.220, time/batch = 0.202\n",
            "10694/15750 (epoch 33), train_loss = 2.284, time/batch = 0.200\n",
            "10695/15750 (epoch 33), train_loss = 2.271, time/batch = 0.202\n",
            "10696/15750 (epoch 33), train_loss = 2.208, time/batch = 0.203\n",
            "10697/15750 (epoch 33), train_loss = 2.334, time/batch = 0.200\n",
            "10698/15750 (epoch 33), train_loss = 2.189, time/batch = 0.201\n",
            "10699/15750 (epoch 33), train_loss = 2.314, time/batch = 0.205\n",
            "10700/15750 (epoch 33), train_loss = 2.267, time/batch = 0.201\n",
            "10701/15750 (epoch 33), train_loss = 2.233, time/batch = 0.205\n",
            "10702/15750 (epoch 33), train_loss = 2.183, time/batch = 0.200\n",
            "10703/15750 (epoch 33), train_loss = 2.216, time/batch = 0.202\n",
            "10704/15750 (epoch 33), train_loss = 2.332, time/batch = 0.203\n",
            "10705/15750 (epoch 33), train_loss = 2.204, time/batch = 0.201\n",
            "10706/15750 (epoch 33), train_loss = 2.183, time/batch = 0.207\n",
            "10707/15750 (epoch 33), train_loss = 2.216, time/batch = 0.199\n",
            "10708/15750 (epoch 33), train_loss = 2.226, time/batch = 0.199\n",
            "10709/15750 (epoch 33), train_loss = 2.325, time/batch = 0.200\n",
            "10710/15750 (epoch 34), train_loss = 2.189, time/batch = 0.205\n",
            "10711/15750 (epoch 34), train_loss = 2.315, time/batch = 0.200\n",
            "10712/15750 (epoch 34), train_loss = 2.248, time/batch = 0.202\n",
            "10713/15750 (epoch 34), train_loss = 2.347, time/batch = 0.195\n",
            "10714/15750 (epoch 34), train_loss = 2.270, time/batch = 0.203\n",
            "10715/15750 (epoch 34), train_loss = 2.267, time/batch = 0.207\n",
            "10716/15750 (epoch 34), train_loss = 2.420, time/batch = 0.202\n",
            "10717/15750 (epoch 34), train_loss = 2.338, time/batch = 0.193\n",
            "10718/15750 (epoch 34), train_loss = 2.332, time/batch = 0.204\n",
            "10719/15750 (epoch 34), train_loss = 2.279, time/batch = 0.203\n",
            "10720/15750 (epoch 34), train_loss = 2.282, time/batch = 0.204\n",
            "10721/15750 (epoch 34), train_loss = 2.247, time/batch = 0.197\n",
            "10722/15750 (epoch 34), train_loss = 2.328, time/batch = 0.202\n",
            "10723/15750 (epoch 34), train_loss = 2.307, time/batch = 0.201\n",
            "10724/15750 (epoch 34), train_loss = 2.280, time/batch = 0.202\n",
            "10725/15750 (epoch 34), train_loss = 2.304, time/batch = 0.204\n",
            "10726/15750 (epoch 34), train_loss = 2.308, time/batch = 0.196\n",
            "10727/15750 (epoch 34), train_loss = 2.369, time/batch = 0.201\n",
            "10728/15750 (epoch 34), train_loss = 2.383, time/batch = 0.202\n",
            "10729/15750 (epoch 34), train_loss = 2.332, time/batch = 0.201\n",
            "10730/15750 (epoch 34), train_loss = 2.317, time/batch = 0.202\n",
            "10731/15750 (epoch 34), train_loss = 2.332, time/batch = 0.212\n",
            "10732/15750 (epoch 34), train_loss = 2.281, time/batch = 0.201\n",
            "10733/15750 (epoch 34), train_loss = 2.338, time/batch = 0.203\n",
            "10734/15750 (epoch 34), train_loss = 2.342, time/batch = 0.200\n",
            "10735/15750 (epoch 34), train_loss = 2.365, time/batch = 0.203\n",
            "10736/15750 (epoch 34), train_loss = 2.370, time/batch = 0.208\n",
            "10737/15750 (epoch 34), train_loss = 2.350, time/batch = 0.203\n",
            "10738/15750 (epoch 34), train_loss = 2.460, time/batch = 0.199\n",
            "10739/15750 (epoch 34), train_loss = 2.372, time/batch = 0.199\n",
            "10740/15750 (epoch 34), train_loss = 2.334, time/batch = 0.203\n",
            "10741/15750 (epoch 34), train_loss = 2.300, time/batch = 0.205\n",
            "10742/15750 (epoch 34), train_loss = 2.216, time/batch = 0.203\n",
            "10743/15750 (epoch 34), train_loss = 2.231, time/batch = 0.202\n",
            "10744/15750 (epoch 34), train_loss = 2.317, time/batch = 0.202\n",
            "10745/15750 (epoch 34), train_loss = 2.216, time/batch = 0.202\n",
            "10746/15750 (epoch 34), train_loss = 2.299, time/batch = 0.206\n",
            "10747/15750 (epoch 34), train_loss = 2.346, time/batch = 0.202\n",
            "10748/15750 (epoch 34), train_loss = 2.258, time/batch = 0.199\n",
            "10749/15750 (epoch 34), train_loss = 2.305, time/batch = 0.201\n",
            "10750/15750 (epoch 34), train_loss = 2.264, time/batch = 0.203\n",
            "10751/15750 (epoch 34), train_loss = 2.310, time/batch = 0.206\n",
            "10752/15750 (epoch 34), train_loss = 2.310, time/batch = 0.204\n",
            "10753/15750 (epoch 34), train_loss = 2.274, time/batch = 0.200\n",
            "10754/15750 (epoch 34), train_loss = 2.307, time/batch = 0.199\n",
            "10755/15750 (epoch 34), train_loss = 2.236, time/batch = 0.200\n",
            "10756/15750 (epoch 34), train_loss = 2.275, time/batch = 0.205\n",
            "10757/15750 (epoch 34), train_loss = 2.291, time/batch = 0.205\n",
            "10758/15750 (epoch 34), train_loss = 2.330, time/batch = 0.197\n",
            "10759/15750 (epoch 34), train_loss = 2.215, time/batch = 0.202\n",
            "10760/15750 (epoch 34), train_loss = 2.284, time/batch = 0.202\n",
            "10761/15750 (epoch 34), train_loss = 2.236, time/batch = 0.206\n",
            "10762/15750 (epoch 34), train_loss = 2.290, time/batch = 0.198\n",
            "10763/15750 (epoch 34), train_loss = 2.307, time/batch = 0.199\n",
            "10764/15750 (epoch 34), train_loss = 2.303, time/batch = 0.201\n",
            "10765/15750 (epoch 34), train_loss = 2.336, time/batch = 0.202\n",
            "10766/15750 (epoch 34), train_loss = 2.224, time/batch = 0.207\n",
            "10767/15750 (epoch 34), train_loss = 2.216, time/batch = 0.202\n",
            "10768/15750 (epoch 34), train_loss = 2.316, time/batch = 0.199\n",
            "10769/15750 (epoch 34), train_loss = 2.177, time/batch = 0.200\n",
            "10770/15750 (epoch 34), train_loss = 2.279, time/batch = 0.202\n",
            "10771/15750 (epoch 34), train_loss = 2.283, time/batch = 0.203\n",
            "10772/15750 (epoch 34), train_loss = 2.212, time/batch = 0.200\n",
            "10773/15750 (epoch 34), train_loss = 2.272, time/batch = 0.200\n",
            "10774/15750 (epoch 34), train_loss = 2.176, time/batch = 0.201\n",
            "10775/15750 (epoch 34), train_loss = 2.200, time/batch = 0.201\n",
            "10776/15750 (epoch 34), train_loss = 2.139, time/batch = 0.207\n",
            "10777/15750 (epoch 34), train_loss = 2.157, time/batch = 0.201\n",
            "10778/15750 (epoch 34), train_loss = 2.212, time/batch = 0.200\n",
            "10779/15750 (epoch 34), train_loss = 2.307, time/batch = 0.198\n",
            "10780/15750 (epoch 34), train_loss = 2.229, time/batch = 0.199\n",
            "10781/15750 (epoch 34), train_loss = 2.218, time/batch = 0.207\n",
            "10782/15750 (epoch 34), train_loss = 2.138, time/batch = 0.203\n",
            "10783/15750 (epoch 34), train_loss = 2.204, time/batch = 0.201\n",
            "10784/15750 (epoch 34), train_loss = 2.320, time/batch = 0.200\n",
            "10785/15750 (epoch 34), train_loss = 2.255, time/batch = 0.200\n",
            "10786/15750 (epoch 34), train_loss = 2.249, time/batch = 0.201\n",
            "10787/15750 (epoch 34), train_loss = 2.250, time/batch = 0.199\n",
            "10788/15750 (epoch 34), train_loss = 2.259, time/batch = 0.201\n",
            "10789/15750 (epoch 34), train_loss = 2.251, time/batch = 0.203\n",
            "10790/15750 (epoch 34), train_loss = 2.152, time/batch = 0.200\n",
            "10791/15750 (epoch 34), train_loss = 2.253, time/batch = 0.205\n",
            "10792/15750 (epoch 34), train_loss = 2.198, time/batch = 0.203\n",
            "10793/15750 (epoch 34), train_loss = 2.250, time/batch = 0.199\n",
            "10794/15750 (epoch 34), train_loss = 2.307, time/batch = 0.199\n",
            "10795/15750 (epoch 34), train_loss = 2.326, time/batch = 0.202\n",
            "10796/15750 (epoch 34), train_loss = 2.164, time/batch = 0.201\n",
            "10797/15750 (epoch 34), train_loss = 2.201, time/batch = 0.200\n",
            "10798/15750 (epoch 34), train_loss = 2.217, time/batch = 0.203\n",
            "10799/15750 (epoch 34), train_loss = 2.221, time/batch = 0.198\n",
            "10800/15750 (epoch 34), train_loss = 2.215, time/batch = 0.203\n",
            "10801/15750 (epoch 34), train_loss = 2.278, time/batch = 0.200\n",
            "10802/15750 (epoch 34), train_loss = 2.266, time/batch = 0.201\n",
            "10803/15750 (epoch 34), train_loss = 2.278, time/batch = 0.200\n",
            "10804/15750 (epoch 34), train_loss = 2.340, time/batch = 0.203\n",
            "10805/15750 (epoch 34), train_loss = 2.252, time/batch = 0.204\n",
            "10806/15750 (epoch 34), train_loss = 2.279, time/batch = 0.204\n",
            "10807/15750 (epoch 34), train_loss = 2.298, time/batch = 0.211\n",
            "10808/15750 (epoch 34), train_loss = 2.277, time/batch = 0.204\n",
            "10809/15750 (epoch 34), train_loss = 2.292, time/batch = 0.200\n",
            "10810/15750 (epoch 34), train_loss = 2.268, time/batch = 0.201\n",
            "10811/15750 (epoch 34), train_loss = 2.213, time/batch = 0.202\n",
            "10812/15750 (epoch 34), train_loss = 2.229, time/batch = 0.212\n",
            "10813/15750 (epoch 34), train_loss = 2.353, time/batch = 0.198\n",
            "10814/15750 (epoch 34), train_loss = 2.277, time/batch = 0.201\n",
            "10815/15750 (epoch 34), train_loss = 2.184, time/batch = 0.201\n",
            "10816/15750 (epoch 34), train_loss = 2.245, time/batch = 0.203\n",
            "10817/15750 (epoch 34), train_loss = 2.275, time/batch = 0.208\n",
            "10818/15750 (epoch 34), train_loss = 2.309, time/batch = 0.201\n",
            "10819/15750 (epoch 34), train_loss = 2.337, time/batch = 0.203\n",
            "10820/15750 (epoch 34), train_loss = 2.392, time/batch = 0.202\n",
            "10821/15750 (epoch 34), train_loss = 2.258, time/batch = 0.201\n",
            "10822/15750 (epoch 34), train_loss = 2.264, time/batch = 0.206\n",
            "10823/15750 (epoch 34), train_loss = 2.261, time/batch = 0.198\n",
            "10824/15750 (epoch 34), train_loss = 2.268, time/batch = 0.201\n",
            "10825/15750 (epoch 34), train_loss = 2.351, time/batch = 0.200\n",
            "10826/15750 (epoch 34), train_loss = 2.273, time/batch = 0.198\n",
            "10827/15750 (epoch 34), train_loss = 2.392, time/batch = 0.203\n",
            "10828/15750 (epoch 34), train_loss = 2.277, time/batch = 0.201\n",
            "10829/15750 (epoch 34), train_loss = 2.263, time/batch = 0.196\n",
            "10830/15750 (epoch 34), train_loss = 2.236, time/batch = 0.202\n",
            "10831/15750 (epoch 34), train_loss = 2.216, time/batch = 0.201\n",
            "10832/15750 (epoch 34), train_loss = 2.257, time/batch = 0.210\n",
            "10833/15750 (epoch 34), train_loss = 2.210, time/batch = 0.200\n",
            "10834/15750 (epoch 34), train_loss = 2.244, time/batch = 0.199\n",
            "10835/15750 (epoch 34), train_loss = 2.261, time/batch = 0.199\n",
            "10836/15750 (epoch 34), train_loss = 2.344, time/batch = 0.204\n",
            "10837/15750 (epoch 34), train_loss = 2.231, time/batch = 0.216\n",
            "10838/15750 (epoch 34), train_loss = 2.253, time/batch = 0.199\n",
            "10839/15750 (epoch 34), train_loss = 2.219, time/batch = 0.200\n",
            "10840/15750 (epoch 34), train_loss = 2.172, time/batch = 0.200\n",
            "10841/15750 (epoch 34), train_loss = 2.184, time/batch = 0.203\n",
            "10842/15750 (epoch 34), train_loss = 2.194, time/batch = 0.206\n",
            "10843/15750 (epoch 34), train_loss = 2.216, time/batch = 0.199\n",
            "10844/15750 (epoch 34), train_loss = 2.235, time/batch = 0.200\n",
            "10845/15750 (epoch 34), train_loss = 2.362, time/batch = 0.204\n",
            "10846/15750 (epoch 34), train_loss = 2.323, time/batch = 0.203\n",
            "10847/15750 (epoch 34), train_loss = 2.324, time/batch = 0.206\n",
            "10848/15750 (epoch 34), train_loss = 2.313, time/batch = 0.203\n",
            "10849/15750 (epoch 34), train_loss = 2.238, time/batch = 0.200\n",
            "10850/15750 (epoch 34), train_loss = 2.240, time/batch = 0.202\n",
            "10851/15750 (epoch 34), train_loss = 2.331, time/batch = 0.200\n",
            "10852/15750 (epoch 34), train_loss = 2.348, time/batch = 0.208\n",
            "10853/15750 (epoch 34), train_loss = 2.323, time/batch = 0.200\n",
            "10854/15750 (epoch 34), train_loss = 2.239, time/batch = 0.199\n",
            "10855/15750 (epoch 34), train_loss = 2.234, time/batch = 0.202\n",
            "10856/15750 (epoch 34), train_loss = 2.201, time/batch = 0.202\n",
            "10857/15750 (epoch 34), train_loss = 2.293, time/batch = 0.207\n",
            "10858/15750 (epoch 34), train_loss = 2.320, time/batch = 0.201\n",
            "10859/15750 (epoch 34), train_loss = 2.267, time/batch = 0.201\n",
            "10860/15750 (epoch 34), train_loss = 2.260, time/batch = 0.200\n",
            "10861/15750 (epoch 34), train_loss = 2.302, time/batch = 0.204\n",
            "10862/15750 (epoch 34), train_loss = 2.341, time/batch = 0.205\n",
            "10863/15750 (epoch 34), train_loss = 2.288, time/batch = 0.197\n",
            "10864/15750 (epoch 34), train_loss = 2.300, time/batch = 0.199\n",
            "10865/15750 (epoch 34), train_loss = 2.294, time/batch = 0.200\n",
            "10866/15750 (epoch 34), train_loss = 2.294, time/batch = 0.201\n",
            "10867/15750 (epoch 34), train_loss = 2.289, time/batch = 0.204\n",
            "10868/15750 (epoch 34), train_loss = 2.374, time/batch = 0.202\n",
            "10869/15750 (epoch 34), train_loss = 2.233, time/batch = 0.200\n",
            "10870/15750 (epoch 34), train_loss = 2.307, time/batch = 0.200\n",
            "10871/15750 (epoch 34), train_loss = 2.296, time/batch = 0.202\n",
            "10872/15750 (epoch 34), train_loss = 2.320, time/batch = 0.205\n",
            "10873/15750 (epoch 34), train_loss = 2.394, time/batch = 0.200\n",
            "10874/15750 (epoch 34), train_loss = 2.318, time/batch = 0.199\n",
            "10875/15750 (epoch 34), train_loss = 2.317, time/batch = 0.200\n",
            "10876/15750 (epoch 34), train_loss = 2.298, time/batch = 0.202\n",
            "10877/15750 (epoch 34), train_loss = 2.268, time/batch = 0.204\n",
            "10878/15750 (epoch 34), train_loss = 2.233, time/batch = 0.199\n",
            "10879/15750 (epoch 34), train_loss = 2.226, time/batch = 0.202\n",
            "10880/15750 (epoch 34), train_loss = 2.269, time/batch = 0.202\n",
            "10881/15750 (epoch 34), train_loss = 2.302, time/batch = 0.204\n",
            "10882/15750 (epoch 34), train_loss = 2.274, time/batch = 0.203\n",
            "10883/15750 (epoch 34), train_loss = 2.341, time/batch = 0.198\n",
            "10884/15750 (epoch 34), train_loss = 2.277, time/batch = 0.200\n",
            "10885/15750 (epoch 34), train_loss = 2.211, time/batch = 0.201\n",
            "10886/15750 (epoch 34), train_loss = 2.237, time/batch = 0.201\n",
            "10887/15750 (epoch 34), train_loss = 2.299, time/batch = 0.202\n",
            "10888/15750 (epoch 34), train_loss = 2.234, time/batch = 0.206\n",
            "10889/15750 (epoch 34), train_loss = 2.192, time/batch = 0.201\n",
            "10890/15750 (epoch 34), train_loss = 2.228, time/batch = 0.202\n",
            "10891/15750 (epoch 34), train_loss = 2.305, time/batch = 0.204\n",
            "10892/15750 (epoch 34), train_loss = 2.279, time/batch = 0.203\n",
            "10893/15750 (epoch 34), train_loss = 2.341, time/batch = 0.208\n",
            "10894/15750 (epoch 34), train_loss = 2.324, time/batch = 0.200\n",
            "10895/15750 (epoch 34), train_loss = 2.278, time/batch = 0.201\n",
            "10896/15750 (epoch 34), train_loss = 2.234, time/batch = 0.203\n",
            "10897/15750 (epoch 34), train_loss = 2.304, time/batch = 0.199\n",
            "10898/15750 (epoch 34), train_loss = 2.328, time/batch = 0.205\n",
            "10899/15750 (epoch 34), train_loss = 2.394, time/batch = 0.198\n",
            "10900/15750 (epoch 34), train_loss = 2.372, time/batch = 0.202\n",
            "10901/15750 (epoch 34), train_loss = 2.282, time/batch = 0.200\n",
            "10902/15750 (epoch 34), train_loss = 2.300, time/batch = 0.199\n",
            "10903/15750 (epoch 34), train_loss = 2.224, time/batch = 0.205\n",
            "10904/15750 (epoch 34), train_loss = 2.351, time/batch = 0.201\n",
            "10905/15750 (epoch 34), train_loss = 2.323, time/batch = 0.200\n",
            "10906/15750 (epoch 34), train_loss = 2.281, time/batch = 0.205\n",
            "10907/15750 (epoch 34), train_loss = 2.226, time/batch = 0.200\n",
            "10908/15750 (epoch 34), train_loss = 2.330, time/batch = 0.206\n",
            "10909/15750 (epoch 34), train_loss = 2.118, time/batch = 0.202\n",
            "10910/15750 (epoch 34), train_loss = 2.233, time/batch = 0.202\n",
            "10911/15750 (epoch 34), train_loss = 2.193, time/batch = 0.201\n",
            "10912/15750 (epoch 34), train_loss = 2.269, time/batch = 0.200\n",
            "10913/15750 (epoch 34), train_loss = 2.243, time/batch = 0.206\n",
            "10914/15750 (epoch 34), train_loss = 2.310, time/batch = 0.200\n",
            "10915/15750 (epoch 34), train_loss = 2.253, time/batch = 0.201\n",
            "10916/15750 (epoch 34), train_loss = 2.137, time/batch = 0.201\n",
            "10917/15750 (epoch 34), train_loss = 2.207, time/batch = 0.201\n",
            "10918/15750 (epoch 34), train_loss = 2.211, time/batch = 0.204\n",
            "10919/15750 (epoch 34), train_loss = 2.274, time/batch = 0.201\n",
            "10920/15750 (epoch 34), train_loss = 2.160, time/batch = 0.199\n",
            "10921/15750 (epoch 34), train_loss = 2.235, time/batch = 0.202\n",
            "10922/15750 (epoch 34), train_loss = 2.128, time/batch = 0.202\n",
            "10923/15750 (epoch 34), train_loss = 2.200, time/batch = 0.208\n",
            "10924/15750 (epoch 34), train_loss = 2.191, time/batch = 0.199\n",
            "10925/15750 (epoch 34), train_loss = 2.179, time/batch = 0.203\n",
            "10926/15750 (epoch 34), train_loss = 2.332, time/batch = 0.197\n",
            "10927/15750 (epoch 34), train_loss = 2.157, time/batch = 0.201\n",
            "10928/15750 (epoch 34), train_loss = 2.402, time/batch = 0.207\n",
            "10929/15750 (epoch 34), train_loss = 2.267, time/batch = 0.197\n",
            "10930/15750 (epoch 34), train_loss = 2.146, time/batch = 0.203\n",
            "10931/15750 (epoch 34), train_loss = 2.179, time/batch = 0.201\n",
            "10932/15750 (epoch 34), train_loss = 2.241, time/batch = 0.200\n",
            "10933/15750 (epoch 34), train_loss = 2.231, time/batch = 0.207\n",
            "10934/15750 (epoch 34), train_loss = 2.216, time/batch = 0.202\n",
            "10935/15750 (epoch 34), train_loss = 2.225, time/batch = 0.194\n",
            "10936/15750 (epoch 34), train_loss = 2.291, time/batch = 0.199\n",
            "10937/15750 (epoch 34), train_loss = 2.210, time/batch = 0.200\n",
            "10938/15750 (epoch 34), train_loss = 2.255, time/batch = 0.205\n",
            "10939/15750 (epoch 34), train_loss = 2.335, time/batch = 0.202\n",
            "10940/15750 (epoch 34), train_loss = 2.190, time/batch = 0.200\n",
            "10941/15750 (epoch 34), train_loss = 2.209, time/batch = 0.200\n",
            "10942/15750 (epoch 34), train_loss = 2.250, time/batch = 0.202\n",
            "10943/15750 (epoch 34), train_loss = 2.252, time/batch = 0.204\n",
            "10944/15750 (epoch 34), train_loss = 2.205, time/batch = 0.204\n",
            "10945/15750 (epoch 34), train_loss = 2.194, time/batch = 0.203\n",
            "10946/15750 (epoch 34), train_loss = 2.167, time/batch = 0.201\n",
            "10947/15750 (epoch 34), train_loss = 2.213, time/batch = 0.201\n",
            "10948/15750 (epoch 34), train_loss = 2.418, time/batch = 0.207\n",
            "10949/15750 (epoch 34), train_loss = 2.244, time/batch = 0.202\n",
            "10950/15750 (epoch 34), train_loss = 2.301, time/batch = 0.202\n",
            "10951/15750 (epoch 34), train_loss = 2.180, time/batch = 0.196\n",
            "10952/15750 (epoch 34), train_loss = 2.231, time/batch = 0.200\n",
            "10953/15750 (epoch 34), train_loss = 2.254, time/batch = 0.207\n",
            "10954/15750 (epoch 34), train_loss = 2.262, time/batch = 0.197\n",
            "10955/15750 (epoch 34), train_loss = 2.317, time/batch = 0.201\n",
            "10956/15750 (epoch 34), train_loss = 2.274, time/batch = 0.202\n",
            "10957/15750 (epoch 34), train_loss = 2.272, time/batch = 0.200\n",
            "10958/15750 (epoch 34), train_loss = 2.249, time/batch = 0.200\n",
            "10959/15750 (epoch 34), train_loss = 2.276, time/batch = 0.196\n",
            "10960/15750 (epoch 34), train_loss = 2.177, time/batch = 0.203\n",
            "10961/15750 (epoch 34), train_loss = 2.171, time/batch = 0.200\n",
            "10962/15750 (epoch 34), train_loss = 2.258, time/batch = 0.200\n",
            "10963/15750 (epoch 34), train_loss = 2.276, time/batch = 0.202\n",
            "10964/15750 (epoch 34), train_loss = 2.245, time/batch = 0.200\n",
            "10965/15750 (epoch 34), train_loss = 2.210, time/batch = 0.204\n",
            "10966/15750 (epoch 34), train_loss = 2.160, time/batch = 0.200\n",
            "10967/15750 (epoch 34), train_loss = 2.186, time/batch = 0.205\n",
            "10968/15750 (epoch 34), train_loss = 2.341, time/batch = 0.200\n",
            "10969/15750 (epoch 34), train_loss = 2.314, time/batch = 0.204\n",
            "10970/15750 (epoch 34), train_loss = 2.286, time/batch = 0.199\n",
            "10971/15750 (epoch 34), train_loss = 2.232, time/batch = 0.198\n",
            "10972/15750 (epoch 34), train_loss = 2.256, time/batch = 0.206\n",
            "10973/15750 (epoch 34), train_loss = 2.246, time/batch = 0.203\n",
            "10974/15750 (epoch 34), train_loss = 2.269, time/batch = 0.207\n",
            "10975/15750 (epoch 34), train_loss = 2.319, time/batch = 0.200\n",
            "10976/15750 (epoch 34), train_loss = 2.321, time/batch = 0.204\n",
            "10977/15750 (epoch 34), train_loss = 2.246, time/batch = 0.200\n",
            "10978/15750 (epoch 34), train_loss = 2.278, time/batch = 0.201\n",
            "10979/15750 (epoch 34), train_loss = 2.311, time/batch = 0.204\n",
            "10980/15750 (epoch 34), train_loss = 2.297, time/batch = 0.203\n",
            "10981/15750 (epoch 34), train_loss = 2.207, time/batch = 0.201\n",
            "10982/15750 (epoch 34), train_loss = 2.243, time/batch = 0.201\n",
            "10983/15750 (epoch 34), train_loss = 2.305, time/batch = 0.200\n",
            "10984/15750 (epoch 34), train_loss = 2.320, time/batch = 0.205\n",
            "10985/15750 (epoch 34), train_loss = 2.265, time/batch = 0.203\n",
            "10986/15750 (epoch 34), train_loss = 2.326, time/batch = 0.207\n",
            "10987/15750 (epoch 34), train_loss = 2.260, time/batch = 0.199\n",
            "10988/15750 (epoch 34), train_loss = 2.233, time/batch = 0.200\n",
            "10989/15750 (epoch 34), train_loss = 2.184, time/batch = 0.205\n",
            "10990/15750 (epoch 34), train_loss = 2.402, time/batch = 0.197\n",
            "10991/15750 (epoch 34), train_loss = 2.231, time/batch = 0.200\n",
            "10992/15750 (epoch 34), train_loss = 2.200, time/batch = 0.201\n",
            "10993/15750 (epoch 34), train_loss = 2.309, time/batch = 0.201\n",
            "10994/15750 (epoch 34), train_loss = 2.215, time/batch = 0.208\n",
            "10995/15750 (epoch 34), train_loss = 2.349, time/batch = 0.199\n",
            "10996/15750 (epoch 34), train_loss = 2.252, time/batch = 0.201\n",
            "10997/15750 (epoch 34), train_loss = 2.264, time/batch = 0.202\n",
            "10998/15750 (epoch 34), train_loss = 2.184, time/batch = 0.200\n",
            "10999/15750 (epoch 34), train_loss = 2.277, time/batch = 0.204\n",
            "11000/15750 (epoch 34), train_loss = 2.204, time/batch = 0.204\n",
            "model saved to ./save_star/model.ckpt\n",
            "11001/15750 (epoch 34), train_loss = 2.273, time/batch = 0.204\n",
            "11002/15750 (epoch 34), train_loss = 2.271, time/batch = 0.204\n",
            "11003/15750 (epoch 34), train_loss = 2.229, time/batch = 0.199\n",
            "11004/15750 (epoch 34), train_loss = 2.284, time/batch = 0.203\n",
            "11005/15750 (epoch 34), train_loss = 2.362, time/batch = 0.205\n",
            "11006/15750 (epoch 34), train_loss = 2.312, time/batch = 0.204\n",
            "11007/15750 (epoch 34), train_loss = 2.335, time/batch = 0.205\n",
            "11008/15750 (epoch 34), train_loss = 2.214, time/batch = 0.201\n",
            "11009/15750 (epoch 34), train_loss = 2.278, time/batch = 0.206\n",
            "11010/15750 (epoch 34), train_loss = 2.265, time/batch = 0.200\n",
            "11011/15750 (epoch 34), train_loss = 2.203, time/batch = 0.204\n",
            "11012/15750 (epoch 34), train_loss = 2.328, time/batch = 0.204\n",
            "11013/15750 (epoch 34), train_loss = 2.183, time/batch = 0.204\n",
            "11014/15750 (epoch 34), train_loss = 2.308, time/batch = 0.207\n",
            "11015/15750 (epoch 34), train_loss = 2.261, time/batch = 0.199\n",
            "11016/15750 (epoch 34), train_loss = 2.228, time/batch = 0.203\n",
            "11017/15750 (epoch 34), train_loss = 2.177, time/batch = 0.211\n",
            "11018/15750 (epoch 34), train_loss = 2.211, time/batch = 0.200\n",
            "11019/15750 (epoch 34), train_loss = 2.326, time/batch = 0.200\n",
            "11020/15750 (epoch 34), train_loss = 2.199, time/batch = 0.203\n",
            "11021/15750 (epoch 34), train_loss = 2.177, time/batch = 0.201\n",
            "11022/15750 (epoch 34), train_loss = 2.210, time/batch = 0.205\n",
            "11023/15750 (epoch 34), train_loss = 2.221, time/batch = 0.202\n",
            "11024/15750 (epoch 34), train_loss = 2.319, time/batch = 0.200\n",
            "11025/15750 (epoch 35), train_loss = 2.178, time/batch = 0.200\n",
            "11026/15750 (epoch 35), train_loss = 2.311, time/batch = 0.199\n",
            "11027/15750 (epoch 35), train_loss = 2.240, time/batch = 0.210\n",
            "11028/15750 (epoch 35), train_loss = 2.340, time/batch = 0.205\n",
            "11029/15750 (epoch 35), train_loss = 2.264, time/batch = 0.201\n",
            "11030/15750 (epoch 35), train_loss = 2.261, time/batch = 0.200\n",
            "11031/15750 (epoch 35), train_loss = 2.413, time/batch = 0.202\n",
            "11032/15750 (epoch 35), train_loss = 2.332, time/batch = 0.209\n",
            "11033/15750 (epoch 35), train_loss = 2.326, time/batch = 0.202\n",
            "11034/15750 (epoch 35), train_loss = 2.274, time/batch = 0.203\n",
            "11035/15750 (epoch 35), train_loss = 2.275, time/batch = 0.199\n",
            "11036/15750 (epoch 35), train_loss = 2.241, time/batch = 0.203\n",
            "11037/15750 (epoch 35), train_loss = 2.321, time/batch = 0.210\n",
            "11038/15750 (epoch 35), train_loss = 2.301, time/batch = 0.198\n",
            "11039/15750 (epoch 35), train_loss = 2.274, time/batch = 0.202\n",
            "11040/15750 (epoch 35), train_loss = 2.297, time/batch = 0.205\n",
            "11041/15750 (epoch 35), train_loss = 2.301, time/batch = 0.205\n",
            "11042/15750 (epoch 35), train_loss = 2.362, time/batch = 0.207\n",
            "11043/15750 (epoch 35), train_loss = 2.377, time/batch = 0.201\n",
            "11044/15750 (epoch 35), train_loss = 2.325, time/batch = 0.204\n",
            "11045/15750 (epoch 35), train_loss = 2.311, time/batch = 0.200\n",
            "11046/15750 (epoch 35), train_loss = 2.325, time/batch = 0.201\n",
            "11047/15750 (epoch 35), train_loss = 2.274, time/batch = 0.210\n",
            "11048/15750 (epoch 35), train_loss = 2.330, time/batch = 0.201\n",
            "11049/15750 (epoch 35), train_loss = 2.336, time/batch = 0.200\n",
            "11050/15750 (epoch 35), train_loss = 2.358, time/batch = 0.205\n",
            "11051/15750 (epoch 35), train_loss = 2.364, time/batch = 0.202\n",
            "11052/15750 (epoch 35), train_loss = 2.343, time/batch = 0.212\n",
            "11053/15750 (epoch 35), train_loss = 2.453, time/batch = 0.200\n",
            "11054/15750 (epoch 35), train_loss = 2.366, time/batch = 0.200\n",
            "11055/15750 (epoch 35), train_loss = 2.327, time/batch = 0.202\n",
            "11056/15750 (epoch 35), train_loss = 2.294, time/batch = 0.202\n",
            "11057/15750 (epoch 35), train_loss = 2.209, time/batch = 0.208\n",
            "11058/15750 (epoch 35), train_loss = 2.224, time/batch = 0.205\n",
            "11059/15750 (epoch 35), train_loss = 2.310, time/batch = 0.206\n",
            "11060/15750 (epoch 35), train_loss = 2.209, time/batch = 0.200\n",
            "11061/15750 (epoch 35), train_loss = 2.294, time/batch = 0.202\n",
            "11062/15750 (epoch 35), train_loss = 2.340, time/batch = 0.209\n",
            "11063/15750 (epoch 35), train_loss = 2.252, time/batch = 0.199\n",
            "11064/15750 (epoch 35), train_loss = 2.299, time/batch = 0.199\n",
            "11065/15750 (epoch 35), train_loss = 2.258, time/batch = 0.201\n",
            "11066/15750 (epoch 35), train_loss = 2.304, time/batch = 0.199\n",
            "11067/15750 (epoch 35), train_loss = 2.304, time/batch = 0.207\n",
            "11068/15750 (epoch 35), train_loss = 2.269, time/batch = 0.203\n",
            "11069/15750 (epoch 35), train_loss = 2.301, time/batch = 0.204\n",
            "11070/15750 (epoch 35), train_loss = 2.231, time/batch = 0.204\n",
            "11071/15750 (epoch 35), train_loss = 2.269, time/batch = 0.200\n",
            "11072/15750 (epoch 35), train_loss = 2.285, time/batch = 0.210\n",
            "11073/15750 (epoch 35), train_loss = 2.324, time/batch = 0.200\n",
            "11074/15750 (epoch 35), train_loss = 2.209, time/batch = 0.200\n",
            "11075/15750 (epoch 35), train_loss = 2.279, time/batch = 0.201\n",
            "11076/15750 (epoch 35), train_loss = 2.230, time/batch = 0.203\n",
            "11077/15750 (epoch 35), train_loss = 2.284, time/batch = 0.204\n",
            "11078/15750 (epoch 35), train_loss = 2.301, time/batch = 0.199\n",
            "11079/15750 (epoch 35), train_loss = 2.297, time/batch = 0.201\n",
            "11080/15750 (epoch 35), train_loss = 2.330, time/batch = 0.201\n",
            "11081/15750 (epoch 35), train_loss = 2.218, time/batch = 0.201\n",
            "11082/15750 (epoch 35), train_loss = 2.210, time/batch = 0.206\n",
            "11083/15750 (epoch 35), train_loss = 2.311, time/batch = 0.202\n",
            "11084/15750 (epoch 35), train_loss = 2.172, time/batch = 0.202\n",
            "11085/15750 (epoch 35), train_loss = 2.273, time/batch = 0.202\n",
            "11086/15750 (epoch 35), train_loss = 2.278, time/batch = 0.202\n",
            "11087/15750 (epoch 35), train_loss = 2.206, time/batch = 0.204\n",
            "11088/15750 (epoch 35), train_loss = 2.266, time/batch = 0.200\n",
            "11089/15750 (epoch 35), train_loss = 2.170, time/batch = 0.199\n",
            "11090/15750 (epoch 35), train_loss = 2.194, time/batch = 0.202\n",
            "11091/15750 (epoch 35), train_loss = 2.133, time/batch = 0.202\n",
            "11092/15750 (epoch 35), train_loss = 2.151, time/batch = 0.206\n",
            "11093/15750 (epoch 35), train_loss = 2.206, time/batch = 0.199\n",
            "11094/15750 (epoch 35), train_loss = 2.302, time/batch = 0.201\n",
            "11095/15750 (epoch 35), train_loss = 2.223, time/batch = 0.203\n",
            "11096/15750 (epoch 35), train_loss = 2.212, time/batch = 0.202\n",
            "11097/15750 (epoch 35), train_loss = 2.133, time/batch = 0.203\n",
            "11098/15750 (epoch 35), train_loss = 2.197, time/batch = 0.201\n",
            "11099/15750 (epoch 35), train_loss = 2.315, time/batch = 0.202\n",
            "11100/15750 (epoch 35), train_loss = 2.249, time/batch = 0.203\n",
            "11101/15750 (epoch 35), train_loss = 2.244, time/batch = 0.201\n",
            "11102/15750 (epoch 35), train_loss = 2.244, time/batch = 0.205\n",
            "11103/15750 (epoch 35), train_loss = 2.253, time/batch = 0.201\n",
            "11104/15750 (epoch 35), train_loss = 2.245, time/batch = 0.202\n",
            "11105/15750 (epoch 35), train_loss = 2.145, time/batch = 0.201\n",
            "11106/15750 (epoch 35), train_loss = 2.247, time/batch = 0.200\n",
            "11107/15750 (epoch 35), train_loss = 2.192, time/batch = 0.205\n",
            "11108/15750 (epoch 35), train_loss = 2.244, time/batch = 0.202\n",
            "11109/15750 (epoch 35), train_loss = 2.300, time/batch = 0.198\n",
            "11110/15750 (epoch 35), train_loss = 2.320, time/batch = 0.200\n",
            "11111/15750 (epoch 35), train_loss = 2.157, time/batch = 0.200\n",
            "11112/15750 (epoch 35), train_loss = 2.195, time/batch = 0.209\n",
            "11113/15750 (epoch 35), train_loss = 2.211, time/batch = 0.198\n",
            "11114/15750 (epoch 35), train_loss = 2.216, time/batch = 0.203\n",
            "11115/15750 (epoch 35), train_loss = 2.208, time/batch = 0.199\n",
            "11116/15750 (epoch 35), train_loss = 2.272, time/batch = 0.200\n",
            "11117/15750 (epoch 35), train_loss = 2.259, time/batch = 0.211\n",
            "11118/15750 (epoch 35), train_loss = 2.271, time/batch = 0.201\n",
            "11119/15750 (epoch 35), train_loss = 2.333, time/batch = 0.200\n",
            "11120/15750 (epoch 35), train_loss = 2.247, time/batch = 0.202\n",
            "11121/15750 (epoch 35), train_loss = 2.274, time/batch = 0.198\n",
            "11122/15750 (epoch 35), train_loss = 2.293, time/batch = 0.205\n",
            "11123/15750 (epoch 35), train_loss = 2.271, time/batch = 0.199\n",
            "11124/15750 (epoch 35), train_loss = 2.285, time/batch = 0.203\n",
            "11125/15750 (epoch 35), train_loss = 2.262, time/batch = 0.202\n",
            "11126/15750 (epoch 35), train_loss = 2.207, time/batch = 0.201\n",
            "11127/15750 (epoch 35), train_loss = 2.222, time/batch = 0.199\n",
            "11128/15750 (epoch 35), train_loss = 2.346, time/batch = 0.200\n",
            "11129/15750 (epoch 35), train_loss = 2.271, time/batch = 0.203\n",
            "11130/15750 (epoch 35), train_loss = 2.178, time/batch = 0.198\n",
            "11131/15750 (epoch 35), train_loss = 2.240, time/batch = 0.204\n",
            "11132/15750 (epoch 35), train_loss = 2.270, time/batch = 0.203\n",
            "11133/15750 (epoch 35), train_loss = 2.302, time/batch = 0.205\n",
            "11134/15750 (epoch 35), train_loss = 2.330, time/batch = 0.201\n",
            "11135/15750 (epoch 35), train_loss = 2.386, time/batch = 0.205\n",
            "11136/15750 (epoch 35), train_loss = 2.251, time/batch = 0.201\n",
            "11137/15750 (epoch 35), train_loss = 2.259, time/batch = 0.201\n",
            "11138/15750 (epoch 35), train_loss = 2.256, time/batch = 0.206\n",
            "11139/15750 (epoch 35), train_loss = 2.262, time/batch = 0.202\n",
            "11140/15750 (epoch 35), train_loss = 2.346, time/batch = 0.207\n",
            "11141/15750 (epoch 35), train_loss = 2.268, time/batch = 0.199\n",
            "11142/15750 (epoch 35), train_loss = 2.386, time/batch = 0.200\n",
            "11143/15750 (epoch 35), train_loss = 2.270, time/batch = 0.209\n",
            "11144/15750 (epoch 35), train_loss = 2.257, time/batch = 0.199\n",
            "11145/15750 (epoch 35), train_loss = 2.230, time/batch = 0.202\n",
            "11146/15750 (epoch 35), train_loss = 2.210, time/batch = 0.202\n",
            "11147/15750 (epoch 35), train_loss = 2.251, time/batch = 0.200\n",
            "11148/15750 (epoch 35), train_loss = 2.204, time/batch = 0.205\n",
            "11149/15750 (epoch 35), train_loss = 2.238, time/batch = 0.202\n",
            "11150/15750 (epoch 35), train_loss = 2.256, time/batch = 0.201\n",
            "11151/15750 (epoch 35), train_loss = 2.338, time/batch = 0.201\n",
            "11152/15750 (epoch 35), train_loss = 2.225, time/batch = 0.202\n",
            "11153/15750 (epoch 35), train_loss = 2.247, time/batch = 0.205\n",
            "11154/15750 (epoch 35), train_loss = 2.213, time/batch = 0.194\n",
            "11155/15750 (epoch 35), train_loss = 2.167, time/batch = 0.203\n",
            "11156/15750 (epoch 35), train_loss = 2.179, time/batch = 0.200\n",
            "11157/15750 (epoch 35), train_loss = 2.189, time/batch = 0.198\n",
            "11158/15750 (epoch 35), train_loss = 2.211, time/batch = 0.207\n",
            "11159/15750 (epoch 35), train_loss = 2.230, time/batch = 0.203\n",
            "11160/15750 (epoch 35), train_loss = 2.357, time/batch = 0.206\n",
            "11161/15750 (epoch 35), train_loss = 2.317, time/batch = 0.199\n",
            "11162/15750 (epoch 35), train_loss = 2.317, time/batch = 0.200\n",
            "11163/15750 (epoch 35), train_loss = 2.307, time/batch = 0.202\n",
            "11164/15750 (epoch 35), train_loss = 2.233, time/batch = 0.202\n",
            "11165/15750 (epoch 35), train_loss = 2.234, time/batch = 0.199\n",
            "11166/15750 (epoch 35), train_loss = 2.326, time/batch = 0.200\n",
            "11167/15750 (epoch 35), train_loss = 2.343, time/batch = 0.200\n",
            "11168/15750 (epoch 35), train_loss = 2.317, time/batch = 0.206\n",
            "11169/15750 (epoch 35), train_loss = 2.233, time/batch = 0.197\n",
            "11170/15750 (epoch 35), train_loss = 2.229, time/batch = 0.201\n",
            "11171/15750 (epoch 35), train_loss = 2.195, time/batch = 0.200\n",
            "11172/15750 (epoch 35), train_loss = 2.287, time/batch = 0.202\n",
            "11173/15750 (epoch 35), train_loss = 2.314, time/batch = 0.206\n",
            "11174/15750 (epoch 35), train_loss = 2.262, time/batch = 0.202\n",
            "11175/15750 (epoch 35), train_loss = 2.254, time/batch = 0.204\n",
            "11176/15750 (epoch 35), train_loss = 2.296, time/batch = 0.203\n",
            "11177/15750 (epoch 35), train_loss = 2.334, time/batch = 0.202\n",
            "11178/15750 (epoch 35), train_loss = 2.282, time/batch = 0.205\n",
            "11179/15750 (epoch 35), train_loss = 2.293, time/batch = 0.202\n",
            "11180/15750 (epoch 35), train_loss = 2.288, time/batch = 0.202\n",
            "11181/15750 (epoch 35), train_loss = 2.289, time/batch = 0.199\n",
            "11182/15750 (epoch 35), train_loss = 2.283, time/batch = 0.199\n",
            "11183/15750 (epoch 35), train_loss = 2.368, time/batch = 0.209\n",
            "11184/15750 (epoch 35), train_loss = 2.228, time/batch = 0.203\n",
            "11185/15750 (epoch 35), train_loss = 2.302, time/batch = 0.204\n",
            "11186/15750 (epoch 35), train_loss = 2.290, time/batch = 0.201\n",
            "11187/15750 (epoch 35), train_loss = 2.314, time/batch = 0.203\n",
            "11188/15750 (epoch 35), train_loss = 2.387, time/batch = 0.206\n",
            "11189/15750 (epoch 35), train_loss = 2.312, time/batch = 0.201\n",
            "11190/15750 (epoch 35), train_loss = 2.310, time/batch = 0.201\n",
            "11191/15750 (epoch 35), train_loss = 2.293, time/batch = 0.203\n",
            "11192/15750 (epoch 35), train_loss = 2.262, time/batch = 0.202\n",
            "11193/15750 (epoch 35), train_loss = 2.228, time/batch = 0.205\n",
            "11194/15750 (epoch 35), train_loss = 2.221, time/batch = 0.202\n",
            "11195/15750 (epoch 35), train_loss = 2.263, time/batch = 0.203\n",
            "11196/15750 (epoch 35), train_loss = 2.296, time/batch = 0.199\n",
            "11197/15750 (epoch 35), train_loss = 2.268, time/batch = 0.201\n",
            "11198/15750 (epoch 35), train_loss = 2.335, time/batch = 0.204\n",
            "11199/15750 (epoch 35), train_loss = 2.271, time/batch = 0.202\n",
            "11200/15750 (epoch 35), train_loss = 2.205, time/batch = 0.203\n",
            "11201/15750 (epoch 35), train_loss = 2.231, time/batch = 0.197\n",
            "11202/15750 (epoch 35), train_loss = 2.293, time/batch = 0.198\n",
            "11203/15750 (epoch 35), train_loss = 2.228, time/batch = 0.206\n",
            "11204/15750 (epoch 35), train_loss = 2.187, time/batch = 0.202\n",
            "11205/15750 (epoch 35), train_loss = 2.222, time/batch = 0.200\n",
            "11206/15750 (epoch 35), train_loss = 2.299, time/batch = 0.198\n",
            "11207/15750 (epoch 35), train_loss = 2.274, time/batch = 0.200\n",
            "11208/15750 (epoch 35), train_loss = 2.336, time/batch = 0.202\n",
            "11209/15750 (epoch 35), train_loss = 2.318, time/batch = 0.195\n",
            "11210/15750 (epoch 35), train_loss = 2.273, time/batch = 0.198\n",
            "11211/15750 (epoch 35), train_loss = 2.229, time/batch = 0.205\n",
            "11212/15750 (epoch 35), train_loss = 2.299, time/batch = 0.202\n",
            "11213/15750 (epoch 35), train_loss = 2.323, time/batch = 0.205\n",
            "11214/15750 (epoch 35), train_loss = 2.388, time/batch = 0.201\n",
            "11215/15750 (epoch 35), train_loss = 2.367, time/batch = 0.202\n",
            "11216/15750 (epoch 35), train_loss = 2.276, time/batch = 0.202\n",
            "11217/15750 (epoch 35), train_loss = 2.294, time/batch = 0.203\n",
            "11218/15750 (epoch 35), train_loss = 2.219, time/batch = 0.197\n",
            "11219/15750 (epoch 35), train_loss = 2.346, time/batch = 0.216\n",
            "11220/15750 (epoch 35), train_loss = 2.317, time/batch = 0.202\n",
            "11221/15750 (epoch 35), train_loss = 2.275, time/batch = 0.199\n",
            "11222/15750 (epoch 35), train_loss = 2.220, time/batch = 0.199\n",
            "11223/15750 (epoch 35), train_loss = 2.325, time/batch = 0.202\n",
            "11224/15750 (epoch 35), train_loss = 2.112, time/batch = 0.205\n",
            "11225/15750 (epoch 35), train_loss = 2.227, time/batch = 0.203\n",
            "11226/15750 (epoch 35), train_loss = 2.188, time/batch = 0.201\n",
            "11227/15750 (epoch 35), train_loss = 2.264, time/batch = 0.201\n",
            "11228/15750 (epoch 35), train_loss = 2.237, time/batch = 0.204\n",
            "11229/15750 (epoch 35), train_loss = 2.305, time/batch = 0.208\n",
            "11230/15750 (epoch 35), train_loss = 2.246, time/batch = 0.201\n",
            "11231/15750 (epoch 35), train_loss = 2.132, time/batch = 0.203\n",
            "11232/15750 (epoch 35), train_loss = 2.201, time/batch = 0.203\n",
            "11233/15750 (epoch 35), train_loss = 2.205, time/batch = 0.202\n",
            "11234/15750 (epoch 35), train_loss = 2.268, time/batch = 0.209\n",
            "11235/15750 (epoch 35), train_loss = 2.155, time/batch = 0.196\n",
            "11236/15750 (epoch 35), train_loss = 2.230, time/batch = 0.198\n",
            "11237/15750 (epoch 35), train_loss = 2.123, time/batch = 0.200\n",
            "11238/15750 (epoch 35), train_loss = 2.194, time/batch = 0.203\n",
            "11239/15750 (epoch 35), train_loss = 2.185, time/batch = 0.207\n",
            "11240/15750 (epoch 35), train_loss = 2.172, time/batch = 0.197\n",
            "11241/15750 (epoch 35), train_loss = 2.326, time/batch = 0.199\n",
            "11242/15750 (epoch 35), train_loss = 2.152, time/batch = 0.201\n",
            "11243/15750 (epoch 35), train_loss = 2.397, time/batch = 0.202\n",
            "11244/15750 (epoch 35), train_loss = 2.261, time/batch = 0.203\n",
            "11245/15750 (epoch 35), train_loss = 2.141, time/batch = 0.201\n",
            "11246/15750 (epoch 35), train_loss = 2.173, time/batch = 0.199\n",
            "11247/15750 (epoch 35), train_loss = 2.236, time/batch = 0.199\n",
            "11248/15750 (epoch 35), train_loss = 2.225, time/batch = 0.203\n",
            "11249/15750 (epoch 35), train_loss = 2.210, time/batch = 0.208\n",
            "11250/15750 (epoch 35), train_loss = 2.220, time/batch = 0.203\n",
            "11251/15750 (epoch 35), train_loss = 2.285, time/batch = 0.198\n",
            "11252/15750 (epoch 35), train_loss = 2.204, time/batch = 0.202\n",
            "11253/15750 (epoch 35), train_loss = 2.250, time/batch = 0.202\n",
            "11254/15750 (epoch 35), train_loss = 2.330, time/batch = 0.207\n",
            "11255/15750 (epoch 35), train_loss = 2.185, time/batch = 0.201\n",
            "11256/15750 (epoch 35), train_loss = 2.204, time/batch = 0.194\n",
            "11257/15750 (epoch 35), train_loss = 2.245, time/batch = 0.202\n",
            "11258/15750 (epoch 35), train_loss = 2.246, time/batch = 0.202\n",
            "11259/15750 (epoch 35), train_loss = 2.200, time/batch = 0.209\n",
            "11260/15750 (epoch 35), train_loss = 2.188, time/batch = 0.201\n",
            "11261/15750 (epoch 35), train_loss = 2.161, time/batch = 0.193\n",
            "11262/15750 (epoch 35), train_loss = 2.207, time/batch = 0.201\n",
            "11263/15750 (epoch 35), train_loss = 2.411, time/batch = 0.203\n",
            "11264/15750 (epoch 35), train_loss = 2.239, time/batch = 0.207\n",
            "11265/15750 (epoch 35), train_loss = 2.295, time/batch = 0.199\n",
            "11266/15750 (epoch 35), train_loss = 2.174, time/batch = 0.202\n",
            "11267/15750 (epoch 35), train_loss = 2.225, time/batch = 0.203\n",
            "11268/15750 (epoch 35), train_loss = 2.248, time/batch = 0.203\n",
            "11269/15750 (epoch 35), train_loss = 2.256, time/batch = 0.205\n",
            "11270/15750 (epoch 35), train_loss = 2.311, time/batch = 0.195\n",
            "11271/15750 (epoch 35), train_loss = 2.267, time/batch = 0.199\n",
            "11272/15750 (epoch 35), train_loss = 2.266, time/batch = 0.199\n",
            "11273/15750 (epoch 35), train_loss = 2.242, time/batch = 0.201\n",
            "11274/15750 (epoch 35), train_loss = 2.270, time/batch = 0.204\n",
            "11275/15750 (epoch 35), train_loss = 2.171, time/batch = 0.200\n",
            "11276/15750 (epoch 35), train_loss = 2.165, time/batch = 0.201\n",
            "11277/15750 (epoch 35), train_loss = 2.253, time/batch = 0.202\n",
            "11278/15750 (epoch 35), train_loss = 2.270, time/batch = 0.201\n",
            "11279/15750 (epoch 35), train_loss = 2.239, time/batch = 0.208\n",
            "11280/15750 (epoch 35), train_loss = 2.204, time/batch = 0.206\n",
            "11281/15750 (epoch 35), train_loss = 2.154, time/batch = 0.201\n",
            "11282/15750 (epoch 35), train_loss = 2.181, time/batch = 0.201\n",
            "11283/15750 (epoch 35), train_loss = 2.335, time/batch = 0.203\n",
            "11284/15750 (epoch 35), train_loss = 2.308, time/batch = 0.206\n",
            "11285/15750 (epoch 35), train_loss = 2.281, time/batch = 0.197\n",
            "11286/15750 (epoch 35), train_loss = 2.227, time/batch = 0.201\n",
            "11287/15750 (epoch 35), train_loss = 2.250, time/batch = 0.201\n",
            "11288/15750 (epoch 35), train_loss = 2.241, time/batch = 0.200\n",
            "11289/15750 (epoch 35), train_loss = 2.262, time/batch = 0.203\n",
            "11290/15750 (epoch 35), train_loss = 2.312, time/batch = 0.197\n",
            "11291/15750 (epoch 35), train_loss = 2.314, time/batch = 0.202\n",
            "11292/15750 (epoch 35), train_loss = 2.239, time/batch = 0.200\n",
            "11293/15750 (epoch 35), train_loss = 2.272, time/batch = 0.202\n",
            "11294/15750 (epoch 35), train_loss = 2.305, time/batch = 0.201\n",
            "11295/15750 (epoch 35), train_loss = 2.291, time/batch = 0.200\n",
            "11296/15750 (epoch 35), train_loss = 2.202, time/batch = 0.200\n",
            "11297/15750 (epoch 35), train_loss = 2.238, time/batch = 0.202\n",
            "11298/15750 (epoch 35), train_loss = 2.299, time/batch = 0.200\n",
            "11299/15750 (epoch 35), train_loss = 2.314, time/batch = 0.204\n",
            "11300/15750 (epoch 35), train_loss = 2.258, time/batch = 0.216\n",
            "11301/15750 (epoch 35), train_loss = 2.320, time/batch = 0.202\n",
            "11302/15750 (epoch 35), train_loss = 2.254, time/batch = 0.202\n",
            "11303/15750 (epoch 35), train_loss = 2.228, time/batch = 0.202\n",
            "11304/15750 (epoch 35), train_loss = 2.179, time/batch = 0.203\n",
            "11305/15750 (epoch 35), train_loss = 2.395, time/batch = 0.208\n",
            "11306/15750 (epoch 35), train_loss = 2.224, time/batch = 0.201\n",
            "11307/15750 (epoch 35), train_loss = 2.195, time/batch = 0.200\n",
            "11308/15750 (epoch 35), train_loss = 2.303, time/batch = 0.204\n",
            "11309/15750 (epoch 35), train_loss = 2.209, time/batch = 0.203\n",
            "11310/15750 (epoch 35), train_loss = 2.342, time/batch = 0.204\n",
            "11311/15750 (epoch 35), train_loss = 2.247, time/batch = 0.201\n",
            "11312/15750 (epoch 35), train_loss = 2.258, time/batch = 0.200\n",
            "11313/15750 (epoch 35), train_loss = 2.179, time/batch = 0.200\n",
            "11314/15750 (epoch 35), train_loss = 2.271, time/batch = 0.200\n",
            "11315/15750 (epoch 35), train_loss = 2.198, time/batch = 0.206\n",
            "11316/15750 (epoch 35), train_loss = 2.266, time/batch = 0.203\n",
            "11317/15750 (epoch 35), train_loss = 2.266, time/batch = 0.200\n",
            "11318/15750 (epoch 35), train_loss = 2.223, time/batch = 0.198\n",
            "11319/15750 (epoch 35), train_loss = 2.278, time/batch = 0.202\n",
            "11320/15750 (epoch 35), train_loss = 2.355, time/batch = 0.204\n",
            "11321/15750 (epoch 35), train_loss = 2.305, time/batch = 0.198\n",
            "11322/15750 (epoch 35), train_loss = 2.329, time/batch = 0.198\n",
            "11323/15750 (epoch 35), train_loss = 2.209, time/batch = 0.200\n",
            "11324/15750 (epoch 35), train_loss = 2.273, time/batch = 0.201\n",
            "11325/15750 (epoch 35), train_loss = 2.259, time/batch = 0.206\n",
            "11326/15750 (epoch 35), train_loss = 2.199, time/batch = 0.200\n",
            "11327/15750 (epoch 35), train_loss = 2.324, time/batch = 0.201\n",
            "11328/15750 (epoch 35), train_loss = 2.177, time/batch = 0.202\n",
            "11329/15750 (epoch 35), train_loss = 2.303, time/batch = 0.204\n",
            "11330/15750 (epoch 35), train_loss = 2.256, time/batch = 0.205\n",
            "11331/15750 (epoch 35), train_loss = 2.223, time/batch = 0.202\n",
            "11332/15750 (epoch 35), train_loss = 2.171, time/batch = 0.202\n",
            "11333/15750 (epoch 35), train_loss = 2.205, time/batch = 0.199\n",
            "11334/15750 (epoch 35), train_loss = 2.321, time/batch = 0.201\n",
            "11335/15750 (epoch 35), train_loss = 2.194, time/batch = 0.204\n",
            "11336/15750 (epoch 35), train_loss = 2.171, time/batch = 0.203\n",
            "11337/15750 (epoch 35), train_loss = 2.204, time/batch = 0.199\n",
            "11338/15750 (epoch 35), train_loss = 2.216, time/batch = 0.201\n",
            "11339/15750 (epoch 35), train_loss = 2.314, time/batch = 0.200\n",
            "11340/15750 (epoch 36), train_loss = 2.169, time/batch = 0.202\n",
            "11341/15750 (epoch 36), train_loss = 2.304, time/batch = 0.200\n",
            "11342/15750 (epoch 36), train_loss = 2.234, time/batch = 0.200\n",
            "11343/15750 (epoch 36), train_loss = 2.335, time/batch = 0.203\n",
            "11344/15750 (epoch 36), train_loss = 2.259, time/batch = 0.207\n",
            "11345/15750 (epoch 36), train_loss = 2.256, time/batch = 0.198\n",
            "11346/15750 (epoch 36), train_loss = 2.407, time/batch = 0.202\n",
            "11347/15750 (epoch 36), train_loss = 2.327, time/batch = 0.201\n",
            "11348/15750 (epoch 36), train_loss = 2.320, time/batch = 0.199\n",
            "11349/15750 (epoch 36), train_loss = 2.268, time/batch = 0.204\n",
            "11350/15750 (epoch 36), train_loss = 2.269, time/batch = 0.203\n",
            "11351/15750 (epoch 36), train_loss = 2.236, time/batch = 0.202\n",
            "11352/15750 (epoch 36), train_loss = 2.315, time/batch = 0.202\n",
            "11353/15750 (epoch 36), train_loss = 2.296, time/batch = 0.198\n",
            "11354/15750 (epoch 36), train_loss = 2.269, time/batch = 0.206\n",
            "11355/15750 (epoch 36), train_loss = 2.291, time/batch = 0.202\n",
            "11356/15750 (epoch 36), train_loss = 2.296, time/batch = 0.201\n",
            "11357/15750 (epoch 36), train_loss = 2.356, time/batch = 0.198\n",
            "11358/15750 (epoch 36), train_loss = 2.371, time/batch = 0.199\n",
            "11359/15750 (epoch 36), train_loss = 2.320, time/batch = 0.203\n",
            "11360/15750 (epoch 36), train_loss = 2.306, time/batch = 0.199\n",
            "11361/15750 (epoch 36), train_loss = 2.318, time/batch = 0.198\n",
            "11362/15750 (epoch 36), train_loss = 2.267, time/batch = 0.204\n",
            "11363/15750 (epoch 36), train_loss = 2.325, time/batch = 0.202\n",
            "11364/15750 (epoch 36), train_loss = 2.329, time/batch = 0.203\n",
            "11365/15750 (epoch 36), train_loss = 2.352, time/batch = 0.194\n",
            "11366/15750 (epoch 36), train_loss = 2.359, time/batch = 0.202\n",
            "11367/15750 (epoch 36), train_loss = 2.337, time/batch = 0.202\n",
            "11368/15750 (epoch 36), train_loss = 2.447, time/batch = 0.201\n",
            "11369/15750 (epoch 36), train_loss = 2.360, time/batch = 0.202\n",
            "11370/15750 (epoch 36), train_loss = 2.321, time/batch = 0.201\n",
            "11371/15750 (epoch 36), train_loss = 2.288, time/batch = 0.202\n",
            "11372/15750 (epoch 36), train_loss = 2.203, time/batch = 0.203\n",
            "11373/15750 (epoch 36), train_loss = 2.218, time/batch = 0.200\n",
            "11374/15750 (epoch 36), train_loss = 2.304, time/batch = 0.202\n",
            "11375/15750 (epoch 36), train_loss = 2.203, time/batch = 0.202\n",
            "11376/15750 (epoch 36), train_loss = 2.288, time/batch = 0.200\n",
            "11377/15750 (epoch 36), train_loss = 2.335, time/batch = 0.201\n",
            "11378/15750 (epoch 36), train_loss = 2.246, time/batch = 0.201\n",
            "11379/15750 (epoch 36), train_loss = 2.294, time/batch = 0.202\n",
            "11380/15750 (epoch 36), train_loss = 2.252, time/batch = 0.209\n",
            "11381/15750 (epoch 36), train_loss = 2.300, time/batch = 0.201\n",
            "11382/15750 (epoch 36), train_loss = 2.298, time/batch = 0.204\n",
            "11383/15750 (epoch 36), train_loss = 2.264, time/batch = 0.203\n",
            "11384/15750 (epoch 36), train_loss = 2.295, time/batch = 0.201\n",
            "11385/15750 (epoch 36), train_loss = 2.226, time/batch = 0.206\n",
            "11386/15750 (epoch 36), train_loss = 2.264, time/batch = 0.204\n",
            "11387/15750 (epoch 36), train_loss = 2.279, time/batch = 0.200\n",
            "11388/15750 (epoch 36), train_loss = 2.319, time/batch = 0.199\n",
            "11389/15750 (epoch 36), train_loss = 2.203, time/batch = 0.199\n",
            "11390/15750 (epoch 36), train_loss = 2.274, time/batch = 0.205\n",
            "11391/15750 (epoch 36), train_loss = 2.224, time/batch = 0.200\n",
            "11392/15750 (epoch 36), train_loss = 2.278, time/batch = 0.203\n",
            "11393/15750 (epoch 36), train_loss = 2.295, time/batch = 0.198\n",
            "11394/15750 (epoch 36), train_loss = 2.292, time/batch = 0.202\n",
            "11395/15750 (epoch 36), train_loss = 2.324, time/batch = 0.206\n",
            "11396/15750 (epoch 36), train_loss = 2.213, time/batch = 0.200\n",
            "11397/15750 (epoch 36), train_loss = 2.204, time/batch = 0.199\n",
            "11398/15750 (epoch 36), train_loss = 2.305, time/batch = 0.200\n",
            "11399/15750 (epoch 36), train_loss = 2.167, time/batch = 0.203\n",
            "11400/15750 (epoch 36), train_loss = 2.268, time/batch = 0.205\n",
            "11401/15750 (epoch 36), train_loss = 2.274, time/batch = 0.199\n",
            "11402/15750 (epoch 36), train_loss = 2.201, time/batch = 0.203\n",
            "11403/15750 (epoch 36), train_loss = 2.260, time/batch = 0.202\n",
            "11404/15750 (epoch 36), train_loss = 2.164, time/batch = 0.202\n",
            "11405/15750 (epoch 36), train_loss = 2.188, time/batch = 0.204\n",
            "11406/15750 (epoch 36), train_loss = 2.127, time/batch = 0.202\n",
            "11407/15750 (epoch 36), train_loss = 2.145, time/batch = 0.203\n",
            "11408/15750 (epoch 36), train_loss = 2.200, time/batch = 0.201\n",
            "11409/15750 (epoch 36), train_loss = 2.297, time/batch = 0.201\n",
            "11410/15750 (epoch 36), train_loss = 2.218, time/batch = 0.205\n",
            "11411/15750 (epoch 36), train_loss = 2.206, time/batch = 0.203\n",
            "11412/15750 (epoch 36), train_loss = 2.129, time/batch = 0.202\n",
            "11413/15750 (epoch 36), train_loss = 2.191, time/batch = 0.201\n",
            "11414/15750 (epoch 36), train_loss = 2.310, time/batch = 0.203\n",
            "11415/15750 (epoch 36), train_loss = 2.244, time/batch = 0.204\n",
            "11416/15750 (epoch 36), train_loss = 2.238, time/batch = 0.196\n",
            "11417/15750 (epoch 36), train_loss = 2.238, time/batch = 0.198\n",
            "11418/15750 (epoch 36), train_loss = 2.247, time/batch = 0.199\n",
            "11419/15750 (epoch 36), train_loss = 2.239, time/batch = 0.202\n",
            "11420/15750 (epoch 36), train_loss = 2.139, time/batch = 0.205\n",
            "11421/15750 (epoch 36), train_loss = 2.241, time/batch = 0.202\n",
            "11422/15750 (epoch 36), train_loss = 2.187, time/batch = 0.203\n",
            "11423/15750 (epoch 36), train_loss = 2.238, time/batch = 0.199\n",
            "11424/15750 (epoch 36), train_loss = 2.294, time/batch = 0.202\n",
            "11425/15750 (epoch 36), train_loss = 2.313, time/batch = 0.205\n",
            "11426/15750 (epoch 36), train_loss = 2.151, time/batch = 0.199\n",
            "11427/15750 (epoch 36), train_loss = 2.190, time/batch = 0.203\n",
            "11428/15750 (epoch 36), train_loss = 2.205, time/batch = 0.205\n",
            "11429/15750 (epoch 36), train_loss = 2.211, time/batch = 0.195\n",
            "11430/15750 (epoch 36), train_loss = 2.202, time/batch = 0.199\n",
            "11431/15750 (epoch 36), train_loss = 2.266, time/batch = 0.200\n",
            "11432/15750 (epoch 36), train_loss = 2.253, time/batch = 0.200\n",
            "11433/15750 (epoch 36), train_loss = 2.264, time/batch = 0.201\n",
            "11434/15750 (epoch 36), train_loss = 2.326, time/batch = 0.203\n",
            "11435/15750 (epoch 36), train_loss = 2.241, time/batch = 0.209\n",
            "11436/15750 (epoch 36), train_loss = 2.269, time/batch = 0.199\n",
            "11437/15750 (epoch 36), train_loss = 2.288, time/batch = 0.201\n",
            "11438/15750 (epoch 36), train_loss = 2.266, time/batch = 0.200\n",
            "11439/15750 (epoch 36), train_loss = 2.279, time/batch = 0.202\n",
            "11440/15750 (epoch 36), train_loss = 2.256, time/batch = 0.203\n",
            "11441/15750 (epoch 36), train_loss = 2.201, time/batch = 0.199\n",
            "11442/15750 (epoch 36), train_loss = 2.216, time/batch = 0.205\n",
            "11443/15750 (epoch 36), train_loss = 2.340, time/batch = 0.207\n",
            "11444/15750 (epoch 36), train_loss = 2.265, time/batch = 0.202\n",
            "11445/15750 (epoch 36), train_loss = 2.172, time/batch = 0.202\n",
            "11446/15750 (epoch 36), train_loss = 2.235, time/batch = 0.200\n",
            "11447/15750 (epoch 36), train_loss = 2.265, time/batch = 0.202\n",
            "11448/15750 (epoch 36), train_loss = 2.297, time/batch = 0.202\n",
            "11449/15750 (epoch 36), train_loss = 2.324, time/batch = 0.201\n",
            "11450/15750 (epoch 36), train_loss = 2.381, time/batch = 0.201\n",
            "11451/15750 (epoch 36), train_loss = 2.245, time/batch = 0.198\n",
            "11452/15750 (epoch 36), train_loss = 2.254, time/batch = 0.200\n",
            "11453/15750 (epoch 36), train_loss = 2.250, time/batch = 0.204\n",
            "11454/15750 (epoch 36), train_loss = 2.255, time/batch = 0.205\n",
            "11455/15750 (epoch 36), train_loss = 2.340, time/batch = 0.203\n",
            "11456/15750 (epoch 36), train_loss = 2.263, time/batch = 0.206\n",
            "11457/15750 (epoch 36), train_loss = 2.380, time/batch = 0.201\n",
            "11458/15750 (epoch 36), train_loss = 2.264, time/batch = 0.202\n",
            "11459/15750 (epoch 36), train_loss = 2.252, time/batch = 0.201\n",
            "11460/15750 (epoch 36), train_loss = 2.224, time/batch = 0.202\n",
            "11461/15750 (epoch 36), train_loss = 2.204, time/batch = 0.203\n",
            "11462/15750 (epoch 36), train_loss = 2.246, time/batch = 0.203\n",
            "11463/15750 (epoch 36), train_loss = 2.199, time/batch = 0.203\n",
            "11464/15750 (epoch 36), train_loss = 2.233, time/batch = 0.201\n",
            "11465/15750 (epoch 36), train_loss = 2.250, time/batch = 0.199\n",
            "11466/15750 (epoch 36), train_loss = 2.333, time/batch = 0.207\n",
            "11467/15750 (epoch 36), train_loss = 2.220, time/batch = 0.201\n",
            "11468/15750 (epoch 36), train_loss = 2.242, time/batch = 0.201\n",
            "11469/15750 (epoch 36), train_loss = 2.207, time/batch = 0.201\n",
            "11470/15750 (epoch 36), train_loss = 2.161, time/batch = 0.202\n",
            "11471/15750 (epoch 36), train_loss = 2.174, time/batch = 0.210\n",
            "11472/15750 (epoch 36), train_loss = 2.184, time/batch = 0.202\n",
            "11473/15750 (epoch 36), train_loss = 2.206, time/batch = 0.200\n",
            "11474/15750 (epoch 36), train_loss = 2.225, time/batch = 0.202\n",
            "11475/15750 (epoch 36), train_loss = 2.351, time/batch = 0.202\n",
            "11476/15750 (epoch 36), train_loss = 2.312, time/batch = 0.203\n",
            "11477/15750 (epoch 36), train_loss = 2.312, time/batch = 0.201\n",
            "11478/15750 (epoch 36), train_loss = 2.301, time/batch = 0.200\n",
            "11479/15750 (epoch 36), train_loss = 2.227, time/batch = 0.205\n",
            "11480/15750 (epoch 36), train_loss = 2.229, time/batch = 0.202\n",
            "11481/15750 (epoch 36), train_loss = 2.320, time/batch = 0.209\n",
            "11482/15750 (epoch 36), train_loss = 2.337, time/batch = 0.195\n",
            "11483/15750 (epoch 36), train_loss = 2.311, time/batch = 0.201\n",
            "11484/15750 (epoch 36), train_loss = 2.228, time/batch = 0.199\n",
            "11485/15750 (epoch 36), train_loss = 2.223, time/batch = 0.199\n",
            "11486/15750 (epoch 36), train_loss = 2.189, time/batch = 0.205\n",
            "11487/15750 (epoch 36), train_loss = 2.282, time/batch = 0.202\n",
            "11488/15750 (epoch 36), train_loss = 2.310, time/batch = 0.201\n",
            "11489/15750 (epoch 36), train_loss = 2.257, time/batch = 0.199\n",
            "11490/15750 (epoch 36), train_loss = 2.248, time/batch = 0.203\n",
            "11491/15750 (epoch 36), train_loss = 2.291, time/batch = 0.208\n",
            "11492/15750 (epoch 36), train_loss = 2.328, time/batch = 0.200\n",
            "11493/15750 (epoch 36), train_loss = 2.276, time/batch = 0.200\n",
            "11494/15750 (epoch 36), train_loss = 2.287, time/batch = 0.200\n",
            "11495/15750 (epoch 36), train_loss = 2.283, time/batch = 0.202\n",
            "11496/15750 (epoch 36), train_loss = 2.283, time/batch = 0.207\n",
            "11497/15750 (epoch 36), train_loss = 2.277, time/batch = 0.201\n",
            "11498/15750 (epoch 36), train_loss = 2.362, time/batch = 0.201\n",
            "11499/15750 (epoch 36), train_loss = 2.222, time/batch = 0.203\n",
            "11500/15750 (epoch 36), train_loss = 2.297, time/batch = 0.198\n",
            "11501/15750 (epoch 36), train_loss = 2.284, time/batch = 0.207\n",
            "11502/15750 (epoch 36), train_loss = 2.308, time/batch = 0.200\n",
            "11503/15750 (epoch 36), train_loss = 2.381, time/batch = 0.201\n",
            "11504/15750 (epoch 36), train_loss = 2.305, time/batch = 0.200\n",
            "11505/15750 (epoch 36), train_loss = 2.304, time/batch = 0.201\n",
            "11506/15750 (epoch 36), train_loss = 2.287, time/batch = 0.207\n",
            "11507/15750 (epoch 36), train_loss = 2.257, time/batch = 0.199\n",
            "11508/15750 (epoch 36), train_loss = 2.222, time/batch = 0.200\n",
            "11509/15750 (epoch 36), train_loss = 2.215, time/batch = 0.199\n",
            "11510/15750 (epoch 36), train_loss = 2.257, time/batch = 0.198\n",
            "11511/15750 (epoch 36), train_loss = 2.290, time/batch = 0.209\n",
            "11512/15750 (epoch 36), train_loss = 2.262, time/batch = 0.202\n",
            "11513/15750 (epoch 36), train_loss = 2.330, time/batch = 0.202\n",
            "11514/15750 (epoch 36), train_loss = 2.266, time/batch = 0.202\n",
            "11515/15750 (epoch 36), train_loss = 2.200, time/batch = 0.201\n",
            "11516/15750 (epoch 36), train_loss = 2.225, time/batch = 0.203\n",
            "11517/15750 (epoch 36), train_loss = 2.287, time/batch = 0.199\n",
            "11518/15750 (epoch 36), train_loss = 2.223, time/batch = 0.199\n",
            "11519/15750 (epoch 36), train_loss = 2.181, time/batch = 0.202\n",
            "11520/15750 (epoch 36), train_loss = 2.217, time/batch = 0.202\n",
            "11521/15750 (epoch 36), train_loss = 2.293, time/batch = 0.205\n",
            "11522/15750 (epoch 36), train_loss = 2.269, time/batch = 0.199\n",
            "11523/15750 (epoch 36), train_loss = 2.331, time/batch = 0.203\n",
            "11524/15750 (epoch 36), train_loss = 2.311, time/batch = 0.199\n",
            "11525/15750 (epoch 36), train_loss = 2.268, time/batch = 0.199\n",
            "11526/15750 (epoch 36), train_loss = 2.224, time/batch = 0.204\n",
            "11527/15750 (epoch 36), train_loss = 2.293, time/batch = 0.195\n",
            "11528/15750 (epoch 36), train_loss = 2.317, time/batch = 0.206\n",
            "11529/15750 (epoch 36), train_loss = 2.381, time/batch = 0.204\n",
            "11530/15750 (epoch 36), train_loss = 2.362, time/batch = 0.199\n",
            "11531/15750 (epoch 36), train_loss = 2.270, time/batch = 0.202\n",
            "11532/15750 (epoch 36), train_loss = 2.288, time/batch = 0.198\n",
            "11533/15750 (epoch 36), train_loss = 2.213, time/batch = 0.203\n",
            "11534/15750 (epoch 36), train_loss = 2.341, time/batch = 0.204\n",
            "11535/15750 (epoch 36), train_loss = 2.312, time/batch = 0.206\n",
            "11536/15750 (epoch 36), train_loss = 2.269, time/batch = 0.203\n",
            "11537/15750 (epoch 36), train_loss = 2.214, time/batch = 0.200\n",
            "11538/15750 (epoch 36), train_loss = 2.320, time/batch = 0.202\n",
            "11539/15750 (epoch 36), train_loss = 2.106, time/batch = 0.201\n",
            "11540/15750 (epoch 36), train_loss = 2.221, time/batch = 0.204\n",
            "11541/15750 (epoch 36), train_loss = 2.184, time/batch = 0.205\n",
            "11542/15750 (epoch 36), train_loss = 2.258, time/batch = 0.205\n",
            "11543/15750 (epoch 36), train_loss = 2.232, time/batch = 0.201\n",
            "11544/15750 (epoch 36), train_loss = 2.299, time/batch = 0.200\n",
            "11545/15750 (epoch 36), train_loss = 2.240, time/batch = 0.199\n",
            "11546/15750 (epoch 36), train_loss = 2.127, time/batch = 0.204\n",
            "11547/15750 (epoch 36), train_loss = 2.195, time/batch = 0.205\n",
            "11548/15750 (epoch 36), train_loss = 2.200, time/batch = 0.201\n",
            "11549/15750 (epoch 36), train_loss = 2.262, time/batch = 0.198\n",
            "11550/15750 (epoch 36), train_loss = 2.151, time/batch = 0.202\n",
            "11551/15750 (epoch 36), train_loss = 2.225, time/batch = 0.201\n",
            "11552/15750 (epoch 36), train_loss = 2.118, time/batch = 0.209\n",
            "11553/15750 (epoch 36), train_loss = 2.189, time/batch = 0.201\n",
            "11554/15750 (epoch 36), train_loss = 2.179, time/batch = 0.203\n",
            "11555/15750 (epoch 36), train_loss = 2.166, time/batch = 0.203\n",
            "11556/15750 (epoch 36), train_loss = 2.321, time/batch = 0.200\n",
            "11557/15750 (epoch 36), train_loss = 2.146, time/batch = 0.206\n",
            "11558/15750 (epoch 36), train_loss = 2.391, time/batch = 0.203\n",
            "11559/15750 (epoch 36), train_loss = 2.256, time/batch = 0.201\n",
            "11560/15750 (epoch 36), train_loss = 2.136, time/batch = 0.200\n",
            "11561/15750 (epoch 36), train_loss = 2.168, time/batch = 0.205\n",
            "11562/15750 (epoch 36), train_loss = 2.230, time/batch = 0.206\n",
            "11563/15750 (epoch 36), train_loss = 2.220, time/batch = 0.201\n",
            "11564/15750 (epoch 36), train_loss = 2.204, time/batch = 0.202\n",
            "11565/15750 (epoch 36), train_loss = 2.215, time/batch = 0.198\n",
            "11566/15750 (epoch 36), train_loss = 2.279, time/batch = 0.204\n",
            "11567/15750 (epoch 36), train_loss = 2.199, time/batch = 0.208\n",
            "11568/15750 (epoch 36), train_loss = 2.245, time/batch = 0.203\n",
            "11569/15750 (epoch 36), train_loss = 2.325, time/batch = 0.201\n",
            "11570/15750 (epoch 36), train_loss = 2.180, time/batch = 0.201\n",
            "11571/15750 (epoch 36), train_loss = 2.198, time/batch = 0.200\n",
            "11572/15750 (epoch 36), train_loss = 2.239, time/batch = 0.207\n",
            "11573/15750 (epoch 36), train_loss = 2.241, time/batch = 0.200\n",
            "11574/15750 (epoch 36), train_loss = 2.194, time/batch = 0.202\n",
            "11575/15750 (epoch 36), train_loss = 2.183, time/batch = 0.201\n",
            "11576/15750 (epoch 36), train_loss = 2.155, time/batch = 0.201\n",
            "11577/15750 (epoch 36), train_loss = 2.201, time/batch = 0.207\n",
            "11578/15750 (epoch 36), train_loss = 2.404, time/batch = 0.203\n",
            "11579/15750 (epoch 36), train_loss = 2.233, time/batch = 0.202\n",
            "11580/15750 (epoch 36), train_loss = 2.290, time/batch = 0.202\n",
            "11581/15750 (epoch 36), train_loss = 2.169, time/batch = 0.199\n",
            "11582/15750 (epoch 36), train_loss = 2.219, time/batch = 0.204\n",
            "11583/15750 (epoch 36), train_loss = 2.242, time/batch = 0.203\n",
            "11584/15750 (epoch 36), train_loss = 2.251, time/batch = 0.199\n",
            "11585/15750 (epoch 36), train_loss = 2.305, time/batch = 0.200\n",
            "11586/15750 (epoch 36), train_loss = 2.261, time/batch = 0.202\n",
            "11587/15750 (epoch 36), train_loss = 2.261, time/batch = 0.208\n",
            "11588/15750 (epoch 36), train_loss = 2.236, time/batch = 0.201\n",
            "11589/15750 (epoch 36), train_loss = 2.264, time/batch = 0.201\n",
            "11590/15750 (epoch 36), train_loss = 2.166, time/batch = 0.202\n",
            "11591/15750 (epoch 36), train_loss = 2.159, time/batch = 0.201\n",
            "11592/15750 (epoch 36), train_loss = 2.248, time/batch = 0.204\n",
            "11593/15750 (epoch 36), train_loss = 2.265, time/batch = 0.198\n",
            "11594/15750 (epoch 36), train_loss = 2.233, time/batch = 0.199\n",
            "11595/15750 (epoch 36), train_loss = 2.199, time/batch = 0.199\n",
            "11596/15750 (epoch 36), train_loss = 2.149, time/batch = 0.198\n",
            "11597/15750 (epoch 36), train_loss = 2.177, time/batch = 0.204\n",
            "11598/15750 (epoch 36), train_loss = 2.329, time/batch = 0.202\n",
            "11599/15750 (epoch 36), train_loss = 2.303, time/batch = 0.202\n",
            "11600/15750 (epoch 36), train_loss = 2.276, time/batch = 0.201\n",
            "11601/15750 (epoch 36), train_loss = 2.222, time/batch = 0.198\n",
            "11602/15750 (epoch 36), train_loss = 2.244, time/batch = 0.208\n",
            "11603/15750 (epoch 36), train_loss = 2.235, time/batch = 0.198\n",
            "11604/15750 (epoch 36), train_loss = 2.256, time/batch = 0.202\n",
            "11605/15750 (epoch 36), train_loss = 2.306, time/batch = 0.199\n",
            "11606/15750 (epoch 36), train_loss = 2.307, time/batch = 0.206\n",
            "11607/15750 (epoch 36), train_loss = 2.234, time/batch = 0.207\n",
            "11608/15750 (epoch 36), train_loss = 2.265, time/batch = 0.199\n",
            "11609/15750 (epoch 36), train_loss = 2.300, time/batch = 0.202\n",
            "11610/15750 (epoch 36), train_loss = 2.285, time/batch = 0.203\n",
            "11611/15750 (epoch 36), train_loss = 2.197, time/batch = 0.202\n",
            "11612/15750 (epoch 36), train_loss = 2.233, time/batch = 0.207\n",
            "11613/15750 (epoch 36), train_loss = 2.294, time/batch = 0.200\n",
            "11614/15750 (epoch 36), train_loss = 2.309, time/batch = 0.200\n",
            "11615/15750 (epoch 36), train_loss = 2.252, time/batch = 0.202\n",
            "11616/15750 (epoch 36), train_loss = 2.314, time/batch = 0.202\n",
            "11617/15750 (epoch 36), train_loss = 2.249, time/batch = 0.206\n",
            "11618/15750 (epoch 36), train_loss = 2.224, time/batch = 0.199\n",
            "11619/15750 (epoch 36), train_loss = 2.174, time/batch = 0.205\n",
            "11620/15750 (epoch 36), train_loss = 2.389, time/batch = 0.197\n",
            "11621/15750 (epoch 36), train_loss = 2.218, time/batch = 0.202\n",
            "11622/15750 (epoch 36), train_loss = 2.190, time/batch = 0.206\n",
            "11623/15750 (epoch 36), train_loss = 2.297, time/batch = 0.197\n",
            "11624/15750 (epoch 36), train_loss = 2.204, time/batch = 0.200\n",
            "11625/15750 (epoch 36), train_loss = 2.336, time/batch = 0.199\n",
            "11626/15750 (epoch 36), train_loss = 2.243, time/batch = 0.202\n",
            "11627/15750 (epoch 36), train_loss = 2.253, time/batch = 0.202\n",
            "11628/15750 (epoch 36), train_loss = 2.174, time/batch = 0.199\n",
            "11629/15750 (epoch 36), train_loss = 2.266, time/batch = 0.202\n",
            "11630/15750 (epoch 36), train_loss = 2.193, time/batch = 0.201\n",
            "11631/15750 (epoch 36), train_loss = 2.260, time/batch = 0.202\n",
            "11632/15750 (epoch 36), train_loss = 2.262, time/batch = 0.202\n",
            "11633/15750 (epoch 36), train_loss = 2.218, time/batch = 0.205\n",
            "11634/15750 (epoch 36), train_loss = 2.273, time/batch = 0.201\n",
            "11635/15750 (epoch 36), train_loss = 2.350, time/batch = 0.203\n",
            "11636/15750 (epoch 36), train_loss = 2.299, time/batch = 0.199\n",
            "11637/15750 (epoch 36), train_loss = 2.323, time/batch = 0.202\n",
            "11638/15750 (epoch 36), train_loss = 2.203, time/batch = 0.209\n",
            "11639/15750 (epoch 36), train_loss = 2.268, time/batch = 0.202\n",
            "11640/15750 (epoch 36), train_loss = 2.254, time/batch = 0.202\n",
            "11641/15750 (epoch 36), train_loss = 2.194, time/batch = 0.200\n",
            "11642/15750 (epoch 36), train_loss = 2.320, time/batch = 0.201\n",
            "11643/15750 (epoch 36), train_loss = 2.172, time/batch = 0.207\n",
            "11644/15750 (epoch 36), train_loss = 2.297, time/batch = 0.198\n",
            "11645/15750 (epoch 36), train_loss = 2.251, time/batch = 0.198\n",
            "11646/15750 (epoch 36), train_loss = 2.217, time/batch = 0.204\n",
            "11647/15750 (epoch 36), train_loss = 2.166, time/batch = 0.199\n",
            "11648/15750 (epoch 36), train_loss = 2.201, time/batch = 0.207\n",
            "11649/15750 (epoch 36), train_loss = 2.315, time/batch = 0.198\n",
            "11650/15750 (epoch 36), train_loss = 2.189, time/batch = 0.204\n",
            "11651/15750 (epoch 36), train_loss = 2.165, time/batch = 0.203\n",
            "11652/15750 (epoch 36), train_loss = 2.199, time/batch = 0.200\n",
            "11653/15750 (epoch 36), train_loss = 2.212, time/batch = 0.202\n",
            "11654/15750 (epoch 36), train_loss = 2.308, time/batch = 0.202\n",
            "11655/15750 (epoch 37), train_loss = 2.154, time/batch = 0.202\n",
            "11656/15750 (epoch 37), train_loss = 2.299, time/batch = 0.202\n",
            "11657/15750 (epoch 37), train_loss = 2.228, time/batch = 0.207\n",
            "11658/15750 (epoch 37), train_loss = 2.328, time/batch = 0.196\n",
            "11659/15750 (epoch 37), train_loss = 2.253, time/batch = 0.201\n",
            "11660/15750 (epoch 37), train_loss = 2.250, time/batch = 0.199\n",
            "11661/15750 (epoch 37), train_loss = 2.401, time/batch = 0.203\n",
            "11662/15750 (epoch 37), train_loss = 2.321, time/batch = 0.208\n",
            "11663/15750 (epoch 37), train_loss = 2.316, time/batch = 0.201\n",
            "11664/15750 (epoch 37), train_loss = 2.264, time/batch = 0.204\n",
            "11665/15750 (epoch 37), train_loss = 2.262, time/batch = 0.204\n",
            "11666/15750 (epoch 37), train_loss = 2.230, time/batch = 0.202\n",
            "11667/15750 (epoch 37), train_loss = 2.309, time/batch = 0.209\n",
            "11668/15750 (epoch 37), train_loss = 2.290, time/batch = 0.204\n",
            "11669/15750 (epoch 37), train_loss = 2.263, time/batch = 0.201\n",
            "11670/15750 (epoch 37), train_loss = 2.285, time/batch = 0.203\n",
            "11671/15750 (epoch 37), train_loss = 2.290, time/batch = 0.204\n",
            "11672/15750 (epoch 37), train_loss = 2.350, time/batch = 0.206\n",
            "11673/15750 (epoch 37), train_loss = 2.365, time/batch = 0.202\n",
            "11674/15750 (epoch 37), train_loss = 2.315, time/batch = 0.202\n",
            "11675/15750 (epoch 37), train_loss = 2.300, time/batch = 0.201\n",
            "11676/15750 (epoch 37), train_loss = 2.312, time/batch = 0.202\n",
            "11677/15750 (epoch 37), train_loss = 2.260, time/batch = 0.206\n",
            "11678/15750 (epoch 37), train_loss = 2.319, time/batch = 0.203\n",
            "11679/15750 (epoch 37), train_loss = 2.324, time/batch = 0.199\n",
            "11680/15750 (epoch 37), train_loss = 2.346, time/batch = 0.201\n",
            "11681/15750 (epoch 37), train_loss = 2.353, time/batch = 0.200\n",
            "11682/15750 (epoch 37), train_loss = 2.332, time/batch = 0.208\n",
            "11683/15750 (epoch 37), train_loss = 2.441, time/batch = 0.200\n",
            "11684/15750 (epoch 37), train_loss = 2.355, time/batch = 0.206\n",
            "11685/15750 (epoch 37), train_loss = 2.315, time/batch = 0.201\n",
            "11686/15750 (epoch 37), train_loss = 2.281, time/batch = 0.198\n",
            "11687/15750 (epoch 37), train_loss = 2.198, time/batch = 0.204\n",
            "11688/15750 (epoch 37), train_loss = 2.212, time/batch = 0.201\n",
            "11689/15750 (epoch 37), train_loss = 2.299, time/batch = 0.201\n",
            "11690/15750 (epoch 37), train_loss = 2.198, time/batch = 0.198\n",
            "11691/15750 (epoch 37), train_loss = 2.283, time/batch = 0.198\n",
            "11692/15750 (epoch 37), train_loss = 2.330, time/batch = 0.202\n",
            "11693/15750 (epoch 37), train_loss = 2.241, time/batch = 0.197\n",
            "11694/15750 (epoch 37), train_loss = 2.288, time/batch = 0.205\n",
            "11695/15750 (epoch 37), train_loss = 2.247, time/batch = 0.200\n",
            "11696/15750 (epoch 37), train_loss = 2.295, time/batch = 0.199\n",
            "11697/15750 (epoch 37), train_loss = 2.293, time/batch = 0.204\n",
            "11698/15750 (epoch 37), train_loss = 2.260, time/batch = 0.201\n",
            "11699/15750 (epoch 37), train_loss = 2.290, time/batch = 0.200\n",
            "11700/15750 (epoch 37), train_loss = 2.220, time/batch = 0.200\n",
            "11701/15750 (epoch 37), train_loss = 2.260, time/batch = 0.200\n",
            "11702/15750 (epoch 37), train_loss = 2.273, time/batch = 0.200\n",
            "11703/15750 (epoch 37), train_loss = 2.313, time/batch = 0.202\n",
            "11704/15750 (epoch 37), train_loss = 2.198, time/batch = 0.200\n",
            "11705/15750 (epoch 37), train_loss = 2.270, time/batch = 0.200\n",
            "11706/15750 (epoch 37), train_loss = 2.219, time/batch = 0.204\n",
            "11707/15750 (epoch 37), train_loss = 2.273, time/batch = 0.201\n",
            "11708/15750 (epoch 37), train_loss = 2.290, time/batch = 0.207\n",
            "11709/15750 (epoch 37), train_loss = 2.287, time/batch = 0.199\n",
            "11710/15750 (epoch 37), train_loss = 2.319, time/batch = 0.204\n",
            "11711/15750 (epoch 37), train_loss = 2.207, time/batch = 0.201\n",
            "11712/15750 (epoch 37), train_loss = 2.199, time/batch = 0.201\n",
            "11713/15750 (epoch 37), train_loss = 2.299, time/batch = 0.209\n",
            "11714/15750 (epoch 37), train_loss = 2.162, time/batch = 0.199\n",
            "11715/15750 (epoch 37), train_loss = 2.263, time/batch = 0.199\n",
            "11716/15750 (epoch 37), train_loss = 2.269, time/batch = 0.201\n",
            "11717/15750 (epoch 37), train_loss = 2.196, time/batch = 0.200\n",
            "11718/15750 (epoch 37), train_loss = 2.255, time/batch = 0.207\n",
            "11719/15750 (epoch 37), train_loss = 2.159, time/batch = 0.199\n",
            "11720/15750 (epoch 37), train_loss = 2.183, time/batch = 0.202\n",
            "11721/15750 (epoch 37), train_loss = 2.121, time/batch = 0.202\n",
            "11722/15750 (epoch 37), train_loss = 2.139, time/batch = 0.205\n",
            "11723/15750 (epoch 37), train_loss = 2.194, time/batch = 0.209\n",
            "11724/15750 (epoch 37), train_loss = 2.292, time/batch = 0.204\n",
            "11725/15750 (epoch 37), train_loss = 2.212, time/batch = 0.203\n",
            "11726/15750 (epoch 37), train_loss = 2.201, time/batch = 0.202\n",
            "11727/15750 (epoch 37), train_loss = 2.124, time/batch = 0.202\n",
            "11728/15750 (epoch 37), train_loss = 2.185, time/batch = 0.204\n",
            "11729/15750 (epoch 37), train_loss = 2.305, time/batch = 0.202\n",
            "11730/15750 (epoch 37), train_loss = 2.240, time/batch = 0.200\n",
            "11731/15750 (epoch 37), train_loss = 2.234, time/batch = 0.201\n",
            "11732/15750 (epoch 37), train_loss = 2.233, time/batch = 0.206\n",
            "11733/15750 (epoch 37), train_loss = 2.241, time/batch = 0.211\n",
            "11734/15750 (epoch 37), train_loss = 2.233, time/batch = 0.202\n",
            "11735/15750 (epoch 37), train_loss = 2.133, time/batch = 0.202\n",
            "11736/15750 (epoch 37), train_loss = 2.235, time/batch = 0.201\n",
            "11737/15750 (epoch 37), train_loss = 2.182, time/batch = 0.202\n",
            "11738/15750 (epoch 37), train_loss = 2.233, time/batch = 0.205\n",
            "11739/15750 (epoch 37), train_loss = 2.288, time/batch = 0.202\n",
            "11740/15750 (epoch 37), train_loss = 2.308, time/batch = 0.199\n",
            "11741/15750 (epoch 37), train_loss = 2.145, time/batch = 0.200\n",
            "11742/15750 (epoch 37), train_loss = 2.184, time/batch = 0.201\n",
            "11743/15750 (epoch 37), train_loss = 2.199, time/batch = 0.203\n",
            "11744/15750 (epoch 37), train_loss = 2.206, time/batch = 0.198\n",
            "11745/15750 (epoch 37), train_loss = 2.196, time/batch = 0.202\n",
            "11746/15750 (epoch 37), train_loss = 2.260, time/batch = 0.202\n",
            "11747/15750 (epoch 37), train_loss = 2.246, time/batch = 0.201\n",
            "11748/15750 (epoch 37), train_loss = 2.258, time/batch = 0.202\n",
            "11749/15750 (epoch 37), train_loss = 2.320, time/batch = 0.203\n",
            "11750/15750 (epoch 37), train_loss = 2.236, time/batch = 0.200\n",
            "11751/15750 (epoch 37), train_loss = 2.264, time/batch = 0.201\n",
            "11752/15750 (epoch 37), train_loss = 2.283, time/batch = 0.202\n",
            "11753/15750 (epoch 37), train_loss = 2.261, time/batch = 0.219\n",
            "11754/15750 (epoch 37), train_loss = 2.274, time/batch = 0.198\n",
            "11755/15750 (epoch 37), train_loss = 2.251, time/batch = 0.195\n",
            "11756/15750 (epoch 37), train_loss = 2.196, time/batch = 0.199\n",
            "11757/15750 (epoch 37), train_loss = 2.211, time/batch = 0.200\n",
            "11758/15750 (epoch 37), train_loss = 2.334, time/batch = 0.203\n",
            "11759/15750 (epoch 37), train_loss = 2.258, time/batch = 0.201\n",
            "11760/15750 (epoch 37), train_loss = 2.167, time/batch = 0.200\n",
            "11761/15750 (epoch 37), train_loss = 2.230, time/batch = 0.201\n",
            "11762/15750 (epoch 37), train_loss = 2.260, time/batch = 0.202\n",
            "11763/15750 (epoch 37), train_loss = 2.291, time/batch = 0.205\n",
            "11764/15750 (epoch 37), train_loss = 2.319, time/batch = 0.200\n",
            "11765/15750 (epoch 37), train_loss = 2.376, time/batch = 0.200\n",
            "11766/15750 (epoch 37), train_loss = 2.239, time/batch = 0.202\n",
            "11767/15750 (epoch 37), train_loss = 2.249, time/batch = 0.201\n",
            "11768/15750 (epoch 37), train_loss = 2.244, time/batch = 0.206\n",
            "11769/15750 (epoch 37), train_loss = 2.248, time/batch = 0.200\n",
            "11770/15750 (epoch 37), train_loss = 2.335, time/batch = 0.201\n",
            "11771/15750 (epoch 37), train_loss = 2.258, time/batch = 0.200\n",
            "11772/15750 (epoch 37), train_loss = 2.374, time/batch = 0.200\n",
            "11773/15750 (epoch 37), train_loss = 2.258, time/batch = 0.204\n",
            "11774/15750 (epoch 37), train_loss = 2.247, time/batch = 0.201\n",
            "11775/15750 (epoch 37), train_loss = 2.219, time/batch = 0.201\n",
            "11776/15750 (epoch 37), train_loss = 2.199, time/batch = 0.200\n",
            "11777/15750 (epoch 37), train_loss = 2.241, time/batch = 0.201\n",
            "11778/15750 (epoch 37), train_loss = 2.193, time/batch = 0.207\n",
            "11779/15750 (epoch 37), train_loss = 2.228, time/batch = 0.200\n",
            "11780/15750 (epoch 37), train_loss = 2.245, time/batch = 0.201\n",
            "11781/15750 (epoch 37), train_loss = 2.328, time/batch = 0.202\n",
            "11782/15750 (epoch 37), train_loss = 2.214, time/batch = 0.202\n",
            "11783/15750 (epoch 37), train_loss = 2.237, time/batch = 0.203\n",
            "11784/15750 (epoch 37), train_loss = 2.201, time/batch = 0.199\n",
            "11785/15750 (epoch 37), train_loss = 2.156, time/batch = 0.202\n",
            "11786/15750 (epoch 37), train_loss = 2.169, time/batch = 0.204\n",
            "11787/15750 (epoch 37), train_loss = 2.179, time/batch = 0.202\n",
            "11788/15750 (epoch 37), train_loss = 2.202, time/batch = 0.201\n",
            "11789/15750 (epoch 37), train_loss = 2.219, time/batch = 0.196\n",
            "11790/15750 (epoch 37), train_loss = 2.347, time/batch = 0.201\n",
            "11791/15750 (epoch 37), train_loss = 2.306, time/batch = 0.205\n",
            "11792/15750 (epoch 37), train_loss = 2.307, time/batch = 0.206\n",
            "11793/15750 (epoch 37), train_loss = 2.296, time/batch = 0.194\n",
            "11794/15750 (epoch 37), train_loss = 2.221, time/batch = 0.210\n",
            "11795/15750 (epoch 37), train_loss = 2.223, time/batch = 0.207\n",
            "11796/15750 (epoch 37), train_loss = 2.315, time/batch = 0.205\n",
            "11797/15750 (epoch 37), train_loss = 2.333, time/batch = 0.203\n",
            "11798/15750 (epoch 37), train_loss = 2.306, time/batch = 0.202\n",
            "11799/15750 (epoch 37), train_loss = 2.222, time/batch = 0.206\n",
            "11800/15750 (epoch 37), train_loss = 2.217, time/batch = 0.200\n",
            "11801/15750 (epoch 37), train_loss = 2.184, time/batch = 0.200\n",
            "11802/15750 (epoch 37), train_loss = 2.276, time/batch = 0.202\n",
            "11803/15750 (epoch 37), train_loss = 2.305, time/batch = 0.201\n",
            "11804/15750 (epoch 37), train_loss = 2.253, time/batch = 0.204\n",
            "11805/15750 (epoch 37), train_loss = 2.243, time/batch = 0.202\n",
            "11806/15750 (epoch 37), train_loss = 2.286, time/batch = 0.202\n",
            "11807/15750 (epoch 37), train_loss = 2.321, time/batch = 0.201\n",
            "11808/15750 (epoch 37), train_loss = 2.270, time/batch = 0.200\n",
            "11809/15750 (epoch 37), train_loss = 2.281, time/batch = 0.205\n",
            "11810/15750 (epoch 37), train_loss = 2.278, time/batch = 0.202\n",
            "11811/15750 (epoch 37), train_loss = 2.278, time/batch = 0.202\n",
            "11812/15750 (epoch 37), train_loss = 2.272, time/batch = 0.198\n",
            "11813/15750 (epoch 37), train_loss = 2.356, time/batch = 0.202\n",
            "11814/15750 (epoch 37), train_loss = 2.217, time/batch = 0.205\n",
            "11815/15750 (epoch 37), train_loss = 2.293, time/batch = 0.202\n",
            "11816/15750 (epoch 37), train_loss = 2.279, time/batch = 0.200\n",
            "11817/15750 (epoch 37), train_loss = 2.303, time/batch = 0.200\n",
            "11818/15750 (epoch 37), train_loss = 2.374, time/batch = 0.202\n",
            "11819/15750 (epoch 37), train_loss = 2.299, time/batch = 0.204\n",
            "11820/15750 (epoch 37), train_loss = 2.298, time/batch = 0.202\n",
            "11821/15750 (epoch 37), train_loss = 2.281, time/batch = 0.203\n",
            "11822/15750 (epoch 37), train_loss = 2.251, time/batch = 0.202\n",
            "11823/15750 (epoch 37), train_loss = 2.217, time/batch = 0.202\n",
            "11824/15750 (epoch 37), train_loss = 2.210, time/batch = 0.206\n",
            "11825/15750 (epoch 37), train_loss = 2.251, time/batch = 0.200\n",
            "11826/15750 (epoch 37), train_loss = 2.284, time/batch = 0.202\n",
            "11827/15750 (epoch 37), train_loss = 2.257, time/batch = 0.199\n",
            "11828/15750 (epoch 37), train_loss = 2.325, time/batch = 0.202\n",
            "11829/15750 (epoch 37), train_loss = 2.260, time/batch = 0.206\n",
            "11830/15750 (epoch 37), train_loss = 2.194, time/batch = 0.202\n",
            "11831/15750 (epoch 37), train_loss = 2.220, time/batch = 0.203\n",
            "11832/15750 (epoch 37), train_loss = 2.282, time/batch = 0.198\n",
            "11833/15750 (epoch 37), train_loss = 2.218, time/batch = 0.202\n",
            "11834/15750 (epoch 37), train_loss = 2.176, time/batch = 0.207\n",
            "11835/15750 (epoch 37), train_loss = 2.212, time/batch = 0.199\n",
            "11836/15750 (epoch 37), train_loss = 2.288, time/batch = 0.202\n",
            "11837/15750 (epoch 37), train_loss = 2.265, time/batch = 0.195\n",
            "11838/15750 (epoch 37), train_loss = 2.326, time/batch = 0.200\n",
            "11839/15750 (epoch 37), train_loss = 2.305, time/batch = 0.206\n",
            "11840/15750 (epoch 37), train_loss = 2.264, time/batch = 0.201\n",
            "11841/15750 (epoch 37), train_loss = 2.219, time/batch = 0.200\n",
            "11842/15750 (epoch 37), train_loss = 2.288, time/batch = 0.203\n",
            "11843/15750 (epoch 37), train_loss = 2.312, time/batch = 0.201\n",
            "11844/15750 (epoch 37), train_loss = 2.375, time/batch = 0.206\n",
            "11845/15750 (epoch 37), train_loss = 2.358, time/batch = 0.198\n",
            "11846/15750 (epoch 37), train_loss = 2.265, time/batch = 0.201\n",
            "11847/15750 (epoch 37), train_loss = 2.283, time/batch = 0.196\n",
            "11848/15750 (epoch 37), train_loss = 2.208, time/batch = 0.203\n",
            "11849/15750 (epoch 37), train_loss = 2.337, time/batch = 0.207\n",
            "11850/15750 (epoch 37), train_loss = 2.306, time/batch = 0.201\n",
            "11851/15750 (epoch 37), train_loss = 2.263, time/batch = 0.202\n",
            "11852/15750 (epoch 37), train_loss = 2.209, time/batch = 0.199\n",
            "11853/15750 (epoch 37), train_loss = 2.315, time/batch = 0.200\n",
            "11854/15750 (epoch 37), train_loss = 2.101, time/batch = 0.207\n",
            "11855/15750 (epoch 37), train_loss = 2.216, time/batch = 0.199\n",
            "11856/15750 (epoch 37), train_loss = 2.179, time/batch = 0.199\n",
            "11857/15750 (epoch 37), train_loss = 2.253, time/batch = 0.203\n",
            "11858/15750 (epoch 37), train_loss = 2.226, time/batch = 0.203\n",
            "11859/15750 (epoch 37), train_loss = 2.294, time/batch = 0.208\n",
            "11860/15750 (epoch 37), train_loss = 2.235, time/batch = 0.201\n",
            "11861/15750 (epoch 37), train_loss = 2.122, time/batch = 0.202\n",
            "11862/15750 (epoch 37), train_loss = 2.190, time/batch = 0.200\n",
            "11863/15750 (epoch 37), train_loss = 2.194, time/batch = 0.200\n",
            "11864/15750 (epoch 37), train_loss = 2.257, time/batch = 0.206\n",
            "11865/15750 (epoch 37), train_loss = 2.146, time/batch = 0.202\n",
            "11866/15750 (epoch 37), train_loss = 2.220, time/batch = 0.201\n",
            "11867/15750 (epoch 37), train_loss = 2.113, time/batch = 0.199\n",
            "11868/15750 (epoch 37), train_loss = 2.184, time/batch = 0.201\n",
            "11869/15750 (epoch 37), train_loss = 2.174, time/batch = 0.204\n",
            "11870/15750 (epoch 37), train_loss = 2.160, time/batch = 0.200\n",
            "11871/15750 (epoch 37), train_loss = 2.317, time/batch = 0.201\n",
            "11872/15750 (epoch 37), train_loss = 2.141, time/batch = 0.202\n",
            "11873/15750 (epoch 37), train_loss = 2.386, time/batch = 0.207\n",
            "11874/15750 (epoch 37), train_loss = 2.251, time/batch = 0.203\n",
            "11875/15750 (epoch 37), train_loss = 2.132, time/batch = 0.197\n",
            "11876/15750 (epoch 37), train_loss = 2.163, time/batch = 0.199\n",
            "11877/15750 (epoch 37), train_loss = 2.226, time/batch = 0.203\n",
            "11878/15750 (epoch 37), train_loss = 2.214, time/batch = 0.204\n",
            "11879/15750 (epoch 37), train_loss = 2.198, time/batch = 0.200\n",
            "11880/15750 (epoch 37), train_loss = 2.209, time/batch = 0.202\n",
            "11881/15750 (epoch 37), train_loss = 2.274, time/batch = 0.199\n",
            "11882/15750 (epoch 37), train_loss = 2.193, time/batch = 0.199\n",
            "11883/15750 (epoch 37), train_loss = 2.240, time/batch = 0.200\n",
            "11884/15750 (epoch 37), train_loss = 2.320, time/batch = 0.206\n",
            "11885/15750 (epoch 37), train_loss = 2.176, time/batch = 0.211\n",
            "11886/15750 (epoch 37), train_loss = 2.193, time/batch = 0.203\n",
            "11887/15750 (epoch 37), train_loss = 2.234, time/batch = 0.202\n",
            "11888/15750 (epoch 37), train_loss = 2.236, time/batch = 0.201\n",
            "11889/15750 (epoch 37), train_loss = 2.189, time/batch = 0.203\n",
            "11890/15750 (epoch 37), train_loss = 2.178, time/batch = 0.206\n",
            "11891/15750 (epoch 37), train_loss = 2.150, time/batch = 0.202\n",
            "11892/15750 (epoch 37), train_loss = 2.195, time/batch = 0.197\n",
            "11893/15750 (epoch 37), train_loss = 2.398, time/batch = 0.205\n",
            "11894/15750 (epoch 37), train_loss = 2.228, time/batch = 0.203\n",
            "11895/15750 (epoch 37), train_loss = 2.285, time/batch = 0.207\n",
            "11896/15750 (epoch 37), train_loss = 2.164, time/batch = 0.199\n",
            "11897/15750 (epoch 37), train_loss = 2.214, time/batch = 0.197\n",
            "11898/15750 (epoch 37), train_loss = 2.237, time/batch = 0.204\n",
            "11899/15750 (epoch 37), train_loss = 2.245, time/batch = 0.201\n",
            "11900/15750 (epoch 37), train_loss = 2.300, time/batch = 0.204\n",
            "11901/15750 (epoch 37), train_loss = 2.255, time/batch = 0.201\n",
            "11902/15750 (epoch 37), train_loss = 2.256, time/batch = 0.198\n",
            "11903/15750 (epoch 37), train_loss = 2.231, time/batch = 0.200\n",
            "11904/15750 (epoch 37), train_loss = 2.258, time/batch = 0.200\n",
            "11905/15750 (epoch 37), train_loss = 2.161, time/batch = 0.205\n",
            "11906/15750 (epoch 37), train_loss = 2.153, time/batch = 0.202\n",
            "11907/15750 (epoch 37), train_loss = 2.243, time/batch = 0.201\n",
            "11908/15750 (epoch 37), train_loss = 2.260, time/batch = 0.202\n",
            "11909/15750 (epoch 37), train_loss = 2.228, time/batch = 0.201\n",
            "11910/15750 (epoch 37), train_loss = 2.194, time/batch = 0.204\n",
            "11911/15750 (epoch 37), train_loss = 2.144, time/batch = 0.200\n",
            "11912/15750 (epoch 37), train_loss = 2.172, time/batch = 0.199\n",
            "11913/15750 (epoch 37), train_loss = 2.323, time/batch = 0.203\n",
            "11914/15750 (epoch 37), train_loss = 2.298, time/batch = 0.201\n",
            "11915/15750 (epoch 37), train_loss = 2.271, time/batch = 0.210\n",
            "11916/15750 (epoch 37), train_loss = 2.217, time/batch = 0.202\n",
            "11917/15750 (epoch 37), train_loss = 2.239, time/batch = 0.203\n",
            "11918/15750 (epoch 37), train_loss = 2.230, time/batch = 0.199\n",
            "11919/15750 (epoch 37), train_loss = 2.250, time/batch = 0.199\n",
            "11920/15750 (epoch 37), train_loss = 2.300, time/batch = 0.203\n",
            "11921/15750 (epoch 37), train_loss = 2.300, time/batch = 0.202\n",
            "11922/15750 (epoch 37), train_loss = 2.228, time/batch = 0.202\n",
            "11923/15750 (epoch 37), train_loss = 2.259, time/batch = 0.193\n",
            "11924/15750 (epoch 37), train_loss = 2.294, time/batch = 0.202\n",
            "11925/15750 (epoch 37), train_loss = 2.280, time/batch = 0.205\n",
            "11926/15750 (epoch 37), train_loss = 2.193, time/batch = 0.202\n",
            "11927/15750 (epoch 37), train_loss = 2.228, time/batch = 0.201\n",
            "11928/15750 (epoch 37), train_loss = 2.288, time/batch = 0.200\n",
            "11929/15750 (epoch 37), train_loss = 2.303, time/batch = 0.200\n",
            "11930/15750 (epoch 37), train_loss = 2.245, time/batch = 0.205\n",
            "11931/15750 (epoch 37), train_loss = 2.309, time/batch = 0.200\n",
            "11932/15750 (epoch 37), train_loss = 2.244, time/batch = 0.198\n",
            "11933/15750 (epoch 37), train_loss = 2.219, time/batch = 0.200\n",
            "11934/15750 (epoch 37), train_loss = 2.169, time/batch = 0.203\n",
            "11935/15750 (epoch 37), train_loss = 2.384, time/batch = 0.207\n",
            "11936/15750 (epoch 37), train_loss = 2.212, time/batch = 0.201\n",
            "11937/15750 (epoch 37), train_loss = 2.185, time/batch = 0.202\n",
            "11938/15750 (epoch 37), train_loss = 2.291, time/batch = 0.202\n",
            "11939/15750 (epoch 37), train_loss = 2.199, time/batch = 0.203\n",
            "11940/15750 (epoch 37), train_loss = 2.330, time/batch = 0.205\n",
            "11941/15750 (epoch 37), train_loss = 2.238, time/batch = 0.202\n",
            "11942/15750 (epoch 37), train_loss = 2.248, time/batch = 0.203\n",
            "11943/15750 (epoch 37), train_loss = 2.169, time/batch = 0.202\n",
            "11944/15750 (epoch 37), train_loss = 2.261, time/batch = 0.200\n",
            "11945/15750 (epoch 37), train_loss = 2.187, time/batch = 0.207\n",
            "11946/15750 (epoch 37), train_loss = 2.254, time/batch = 0.199\n",
            "11947/15750 (epoch 37), train_loss = 2.257, time/batch = 0.200\n",
            "11948/15750 (epoch 37), train_loss = 2.212, time/batch = 0.202\n",
            "11949/15750 (epoch 37), train_loss = 2.267, time/batch = 0.198\n",
            "11950/15750 (epoch 37), train_loss = 2.344, time/batch = 0.205\n",
            "11951/15750 (epoch 37), train_loss = 2.293, time/batch = 0.197\n",
            "11952/15750 (epoch 37), train_loss = 2.318, time/batch = 0.202\n",
            "11953/15750 (epoch 37), train_loss = 2.198, time/batch = 0.202\n",
            "11954/15750 (epoch 37), train_loss = 2.264, time/batch = 0.200\n",
            "11955/15750 (epoch 37), train_loss = 2.249, time/batch = 0.202\n",
            "11956/15750 (epoch 37), train_loss = 2.190, time/batch = 0.197\n",
            "11957/15750 (epoch 37), train_loss = 2.315, time/batch = 0.200\n",
            "11958/15750 (epoch 37), train_loss = 2.167, time/batch = 0.202\n",
            "11959/15750 (epoch 37), train_loss = 2.292, time/batch = 0.202\n",
            "11960/15750 (epoch 37), train_loss = 2.247, time/batch = 0.201\n",
            "11961/15750 (epoch 37), train_loss = 2.212, time/batch = 0.213\n",
            "11962/15750 (epoch 37), train_loss = 2.160, time/batch = 0.203\n",
            "11963/15750 (epoch 37), train_loss = 2.196, time/batch = 0.202\n",
            "11964/15750 (epoch 37), train_loss = 2.309, time/batch = 0.202\n",
            "11965/15750 (epoch 37), train_loss = 2.185, time/batch = 0.202\n",
            "11966/15750 (epoch 37), train_loss = 2.159, time/batch = 0.205\n",
            "11967/15750 (epoch 37), train_loss = 2.194, time/batch = 0.201\n",
            "11968/15750 (epoch 37), train_loss = 2.208, time/batch = 0.201\n",
            "11969/15750 (epoch 37), train_loss = 2.303, time/batch = 0.201\n",
            "11970/15750 (epoch 38), train_loss = 2.140, time/batch = 0.207\n",
            "11971/15750 (epoch 38), train_loss = 2.294, time/batch = 0.200\n",
            "11972/15750 (epoch 38), train_loss = 2.222, time/batch = 0.201\n",
            "11973/15750 (epoch 38), train_loss = 2.323, time/batch = 0.207\n",
            "11974/15750 (epoch 38), train_loss = 2.248, time/batch = 0.202\n",
            "11975/15750 (epoch 38), train_loss = 2.246, time/batch = 0.207\n",
            "11976/15750 (epoch 38), train_loss = 2.395, time/batch = 0.204\n",
            "11977/15750 (epoch 38), train_loss = 2.316, time/batch = 0.204\n",
            "11978/15750 (epoch 38), train_loss = 2.311, time/batch = 0.203\n",
            "11979/15750 (epoch 38), train_loss = 2.259, time/batch = 0.202\n",
            "11980/15750 (epoch 38), train_loss = 2.256, time/batch = 0.210\n",
            "11981/15750 (epoch 38), train_loss = 2.225, time/batch = 0.203\n",
            "11982/15750 (epoch 38), train_loss = 2.303, time/batch = 0.204\n",
            "11983/15750 (epoch 38), train_loss = 2.286, time/batch = 0.204\n",
            "11984/15750 (epoch 38), train_loss = 2.259, time/batch = 0.205\n",
            "11985/15750 (epoch 38), train_loss = 2.280, time/batch = 0.205\n",
            "11986/15750 (epoch 38), train_loss = 2.284, time/batch = 0.199\n",
            "11987/15750 (epoch 38), train_loss = 2.345, time/batch = 0.200\n",
            "11988/15750 (epoch 38), train_loss = 2.360, time/batch = 0.201\n",
            "11989/15750 (epoch 38), train_loss = 2.310, time/batch = 0.203\n",
            "11990/15750 (epoch 38), train_loss = 2.294, time/batch = 0.207\n",
            "11991/15750 (epoch 38), train_loss = 2.306, time/batch = 0.202\n",
            "11992/15750 (epoch 38), train_loss = 2.255, time/batch = 0.203\n",
            "11993/15750 (epoch 38), train_loss = 2.313, time/batch = 0.198\n",
            "11994/15750 (epoch 38), train_loss = 2.318, time/batch = 0.200\n",
            "11995/15750 (epoch 38), train_loss = 2.340, time/batch = 0.208\n",
            "11996/15750 (epoch 38), train_loss = 2.348, time/batch = 0.201\n",
            "11997/15750 (epoch 38), train_loss = 2.327, time/batch = 0.200\n",
            "11998/15750 (epoch 38), train_loss = 2.435, time/batch = 0.200\n",
            "11999/15750 (epoch 38), train_loss = 2.349, time/batch = 0.201\n",
            "12000/15750 (epoch 38), train_loss = 2.310, time/batch = 0.205\n",
            "model saved to ./save_star/model.ckpt\n",
            "12001/15750 (epoch 38), train_loss = 2.276, time/batch = 0.203\n",
            "12002/15750 (epoch 38), train_loss = 2.193, time/batch = 0.201\n",
            "12003/15750 (epoch 38), train_loss = 2.207, time/batch = 0.203\n",
            "12004/15750 (epoch 38), train_loss = 2.293, time/batch = 0.198\n",
            "12005/15750 (epoch 38), train_loss = 2.193, time/batch = 0.204\n",
            "12006/15750 (epoch 38), train_loss = 2.277, time/batch = 0.203\n",
            "12007/15750 (epoch 38), train_loss = 2.325, time/batch = 0.203\n",
            "12008/15750 (epoch 38), train_loss = 2.236, time/batch = 0.200\n",
            "12009/15750 (epoch 38), train_loss = 2.283, time/batch = 0.202\n",
            "12010/15750 (epoch 38), train_loss = 2.242, time/batch = 0.201\n",
            "12011/15750 (epoch 38), train_loss = 2.291, time/batch = 0.201\n",
            "12012/15750 (epoch 38), train_loss = 2.288, time/batch = 0.205\n",
            "12013/15750 (epoch 38), train_loss = 2.255, time/batch = 0.203\n",
            "12014/15750 (epoch 38), train_loss = 2.285, time/batch = 0.200\n",
            "12015/15750 (epoch 38), train_loss = 2.215, time/batch = 0.204\n",
            "12016/15750 (epoch 38), train_loss = 2.255, time/batch = 0.205\n",
            "12017/15750 (epoch 38), train_loss = 2.268, time/batch = 0.201\n",
            "12018/15750 (epoch 38), train_loss = 2.308, time/batch = 0.201\n",
            "12019/15750 (epoch 38), train_loss = 2.193, time/batch = 0.218\n",
            "12020/15750 (epoch 38), train_loss = 2.265, time/batch = 0.205\n",
            "12021/15750 (epoch 38), train_loss = 2.214, time/batch = 0.202\n",
            "12022/15750 (epoch 38), train_loss = 2.268, time/batch = 0.202\n",
            "12023/15750 (epoch 38), train_loss = 2.284, time/batch = 0.201\n",
            "12024/15750 (epoch 38), train_loss = 2.282, time/batch = 0.218\n",
            "12025/15750 (epoch 38), train_loss = 2.314, time/batch = 0.204\n",
            "12026/15750 (epoch 38), train_loss = 2.202, time/batch = 0.206\n",
            "12027/15750 (epoch 38), train_loss = 2.193, time/batch = 0.199\n",
            "12028/15750 (epoch 38), train_loss = 2.294, time/batch = 0.201\n",
            "12029/15750 (epoch 38), train_loss = 2.158, time/batch = 0.211\n",
            "12030/15750 (epoch 38), train_loss = 2.258, time/batch = 0.201\n",
            "12031/15750 (epoch 38), train_loss = 2.265, time/batch = 0.204\n",
            "12032/15750 (epoch 38), train_loss = 2.191, time/batch = 0.202\n",
            "12033/15750 (epoch 38), train_loss = 2.249, time/batch = 0.204\n",
            "12034/15750 (epoch 38), train_loss = 2.154, time/batch = 0.209\n",
            "12035/15750 (epoch 38), train_loss = 2.178, time/batch = 0.199\n",
            "12036/15750 (epoch 38), train_loss = 2.116, time/batch = 0.205\n",
            "12037/15750 (epoch 38), train_loss = 2.134, time/batch = 0.204\n",
            "12038/15750 (epoch 38), train_loss = 2.188, time/batch = 0.202\n",
            "12039/15750 (epoch 38), train_loss = 2.288, time/batch = 0.208\n",
            "12040/15750 (epoch 38), train_loss = 2.208, time/batch = 0.200\n",
            "12041/15750 (epoch 38), train_loss = 2.196, time/batch = 0.203\n",
            "12042/15750 (epoch 38), train_loss = 2.120, time/batch = 0.199\n",
            "12043/15750 (epoch 38), train_loss = 2.180, time/batch = 0.201\n",
            "12044/15750 (epoch 38), train_loss = 2.300, time/batch = 0.208\n",
            "12045/15750 (epoch 38), train_loss = 2.235, time/batch = 0.199\n",
            "12046/15750 (epoch 38), train_loss = 2.229, time/batch = 0.206\n",
            "12047/15750 (epoch 38), train_loss = 2.227, time/batch = 0.201\n",
            "12048/15750 (epoch 38), train_loss = 2.236, time/batch = 0.200\n",
            "12049/15750 (epoch 38), train_loss = 2.228, time/batch = 0.210\n",
            "12050/15750 (epoch 38), train_loss = 2.127, time/batch = 0.204\n",
            "12051/15750 (epoch 38), train_loss = 2.230, time/batch = 0.202\n",
            "12052/15750 (epoch 38), train_loss = 2.177, time/batch = 0.204\n",
            "12053/15750 (epoch 38), train_loss = 2.227, time/batch = 0.201\n",
            "12054/15750 (epoch 38), train_loss = 2.282, time/batch = 0.212\n",
            "12055/15750 (epoch 38), train_loss = 2.302, time/batch = 0.202\n",
            "12056/15750 (epoch 38), train_loss = 2.140, time/batch = 0.203\n",
            "12057/15750 (epoch 38), train_loss = 2.179, time/batch = 0.200\n",
            "12058/15750 (epoch 38), train_loss = 2.194, time/batch = 0.199\n",
            "12059/15750 (epoch 38), train_loss = 2.201, time/batch = 0.206\n",
            "12060/15750 (epoch 38), train_loss = 2.191, time/batch = 0.205\n",
            "12061/15750 (epoch 38), train_loss = 2.255, time/batch = 0.207\n",
            "12062/15750 (epoch 38), train_loss = 2.241, time/batch = 0.205\n",
            "12063/15750 (epoch 38), train_loss = 2.253, time/batch = 0.205\n",
            "12064/15750 (epoch 38), train_loss = 2.314, time/batch = 0.213\n",
            "12065/15750 (epoch 38), train_loss = 2.231, time/batch = 0.207\n",
            "12066/15750 (epoch 38), train_loss = 2.259, time/batch = 0.204\n",
            "12067/15750 (epoch 38), train_loss = 2.278, time/batch = 0.199\n",
            "12068/15750 (epoch 38), train_loss = 2.256, time/batch = 0.205\n",
            "12069/15750 (epoch 38), train_loss = 2.269, time/batch = 0.211\n",
            "12070/15750 (epoch 38), train_loss = 2.246, time/batch = 0.203\n",
            "12071/15750 (epoch 38), train_loss = 2.191, time/batch = 0.202\n",
            "12072/15750 (epoch 38), train_loss = 2.205, time/batch = 0.203\n",
            "12073/15750 (epoch 38), train_loss = 2.329, time/batch = 0.201\n",
            "12074/15750 (epoch 38), train_loss = 2.253, time/batch = 0.213\n",
            "12075/15750 (epoch 38), train_loss = 2.161, time/batch = 0.207\n",
            "12076/15750 (epoch 38), train_loss = 2.225, time/batch = 0.203\n",
            "12077/15750 (epoch 38), train_loss = 2.255, time/batch = 0.199\n",
            "12078/15750 (epoch 38), train_loss = 2.285, time/batch = 0.200\n",
            "12079/15750 (epoch 38), train_loss = 2.314, time/batch = 0.206\n",
            "12080/15750 (epoch 38), train_loss = 2.371, time/batch = 0.204\n",
            "12081/15750 (epoch 38), train_loss = 2.233, time/batch = 0.203\n",
            "12082/15750 (epoch 38), train_loss = 2.244, time/batch = 0.201\n",
            "12083/15750 (epoch 38), train_loss = 2.239, time/batch = 0.200\n",
            "12084/15750 (epoch 38), train_loss = 2.242, time/batch = 0.206\n",
            "12085/15750 (epoch 38), train_loss = 2.329, time/batch = 0.205\n",
            "12086/15750 (epoch 38), train_loss = 2.253, time/batch = 0.195\n",
            "12087/15750 (epoch 38), train_loss = 2.368, time/batch = 0.200\n",
            "12088/15750 (epoch 38), train_loss = 2.253, time/batch = 0.203\n",
            "12089/15750 (epoch 38), train_loss = 2.242, time/batch = 0.203\n",
            "12090/15750 (epoch 38), train_loss = 2.214, time/batch = 0.202\n",
            "12091/15750 (epoch 38), train_loss = 2.194, time/batch = 0.200\n",
            "12092/15750 (epoch 38), train_loss = 2.236, time/batch = 0.197\n",
            "12093/15750 (epoch 38), train_loss = 2.188, time/batch = 0.204\n",
            "12094/15750 (epoch 38), train_loss = 2.223, time/batch = 0.205\n",
            "12095/15750 (epoch 38), train_loss = 2.240, time/batch = 0.197\n",
            "12096/15750 (epoch 38), train_loss = 2.323, time/batch = 0.199\n",
            "12097/15750 (epoch 38), train_loss = 2.210, time/batch = 0.200\n",
            "12098/15750 (epoch 38), train_loss = 2.233, time/batch = 0.202\n",
            "12099/15750 (epoch 38), train_loss = 2.196, time/batch = 0.204\n",
            "12100/15750 (epoch 38), train_loss = 2.152, time/batch = 0.199\n",
            "12101/15750 (epoch 38), train_loss = 2.165, time/batch = 0.199\n",
            "12102/15750 (epoch 38), train_loss = 2.174, time/batch = 0.198\n",
            "12103/15750 (epoch 38), train_loss = 2.197, time/batch = 0.201\n",
            "12104/15750 (epoch 38), train_loss = 2.214, time/batch = 0.205\n",
            "12105/15750 (epoch 38), train_loss = 2.342, time/batch = 0.202\n",
            "12106/15750 (epoch 38), train_loss = 2.301, time/batch = 0.200\n",
            "12107/15750 (epoch 38), train_loss = 2.302, time/batch = 0.198\n",
            "12108/15750 (epoch 38), train_loss = 2.291, time/batch = 0.205\n",
            "12109/15750 (epoch 38), train_loss = 2.216, time/batch = 0.211\n",
            "12110/15750 (epoch 38), train_loss = 2.218, time/batch = 0.207\n",
            "12111/15750 (epoch 38), train_loss = 2.310, time/batch = 0.203\n",
            "12112/15750 (epoch 38), train_loss = 2.328, time/batch = 0.203\n",
            "12113/15750 (epoch 38), train_loss = 2.301, time/batch = 0.203\n",
            "12114/15750 (epoch 38), train_loss = 2.217, time/batch = 0.208\n",
            "12115/15750 (epoch 38), train_loss = 2.213, time/batch = 0.203\n",
            "12116/15750 (epoch 38), train_loss = 2.179, time/batch = 0.200\n",
            "12117/15750 (epoch 38), train_loss = 2.271, time/batch = 0.202\n",
            "12118/15750 (epoch 38), train_loss = 2.300, time/batch = 0.202\n",
            "12119/15750 (epoch 38), train_loss = 2.248, time/batch = 0.204\n",
            "12120/15750 (epoch 38), train_loss = 2.237, time/batch = 0.202\n",
            "12121/15750 (epoch 38), train_loss = 2.280, time/batch = 0.203\n",
            "12122/15750 (epoch 38), train_loss = 2.315, time/batch = 0.204\n",
            "12123/15750 (epoch 38), train_loss = 2.264, time/batch = 0.205\n",
            "12124/15750 (epoch 38), train_loss = 2.276, time/batch = 0.209\n",
            "12125/15750 (epoch 38), train_loss = 2.273, time/batch = 0.208\n",
            "12126/15750 (epoch 38), train_loss = 2.273, time/batch = 0.208\n",
            "12127/15750 (epoch 38), train_loss = 2.268, time/batch = 0.201\n",
            "12128/15750 (epoch 38), train_loss = 2.351, time/batch = 0.204\n",
            "12129/15750 (epoch 38), train_loss = 2.212, time/batch = 0.212\n",
            "12130/15750 (epoch 38), train_loss = 2.288, time/batch = 0.203\n",
            "12131/15750 (epoch 38), train_loss = 2.274, time/batch = 0.202\n",
            "12132/15750 (epoch 38), train_loss = 2.298, time/batch = 0.204\n",
            "12133/15750 (epoch 38), train_loss = 2.368, time/batch = 0.205\n",
            "12134/15750 (epoch 38), train_loss = 2.293, time/batch = 0.209\n",
            "12135/15750 (epoch 38), train_loss = 2.292, time/batch = 0.202\n",
            "12136/15750 (epoch 38), train_loss = 2.276, time/batch = 0.208\n",
            "12137/15750 (epoch 38), train_loss = 2.246, time/batch = 0.204\n",
            "12138/15750 (epoch 38), train_loss = 2.212, time/batch = 0.202\n",
            "12139/15750 (epoch 38), train_loss = 2.205, time/batch = 0.211\n",
            "12140/15750 (epoch 38), train_loss = 2.246, time/batch = 0.201\n",
            "12141/15750 (epoch 38), train_loss = 2.279, time/batch = 0.205\n",
            "12142/15750 (epoch 38), train_loss = 2.252, time/batch = 0.205\n",
            "12143/15750 (epoch 38), train_loss = 2.321, time/batch = 0.204\n",
            "12144/15750 (epoch 38), train_loss = 2.255, time/batch = 0.212\n",
            "12145/15750 (epoch 38), train_loss = 2.189, time/batch = 0.201\n",
            "12146/15750 (epoch 38), train_loss = 2.215, time/batch = 0.200\n",
            "12147/15750 (epoch 38), train_loss = 2.277, time/batch = 0.198\n",
            "12148/15750 (epoch 38), train_loss = 2.212, time/batch = 0.205\n",
            "12149/15750 (epoch 38), train_loss = 2.172, time/batch = 0.206\n",
            "12150/15750 (epoch 38), train_loss = 2.207, time/batch = 0.196\n",
            "12151/15750 (epoch 38), train_loss = 2.283, time/batch = 0.200\n",
            "12152/15750 (epoch 38), train_loss = 2.260, time/batch = 0.200\n",
            "12153/15750 (epoch 38), train_loss = 2.321, time/batch = 0.201\n",
            "12154/15750 (epoch 38), train_loss = 2.300, time/batch = 0.208\n",
            "12155/15750 (epoch 38), train_loss = 2.259, time/batch = 0.198\n",
            "12156/15750 (epoch 38), train_loss = 2.214, time/batch = 0.201\n",
            "12157/15750 (epoch 38), train_loss = 2.283, time/batch = 0.200\n",
            "12158/15750 (epoch 38), train_loss = 2.307, time/batch = 0.202\n",
            "12159/15750 (epoch 38), train_loss = 2.369, time/batch = 0.211\n",
            "12160/15750 (epoch 38), train_loss = 2.353, time/batch = 0.200\n",
            "12161/15750 (epoch 38), train_loss = 2.260, time/batch = 0.204\n",
            "12162/15750 (epoch 38), train_loss = 2.277, time/batch = 0.199\n",
            "12163/15750 (epoch 38), train_loss = 2.204, time/batch = 0.202\n",
            "12164/15750 (epoch 38), train_loss = 2.332, time/batch = 0.208\n",
            "12165/15750 (epoch 38), train_loss = 2.301, time/batch = 0.200\n",
            "12166/15750 (epoch 38), train_loss = 2.258, time/batch = 0.199\n",
            "12167/15750 (epoch 38), train_loss = 2.204, time/batch = 0.197\n",
            "12168/15750 (epoch 38), train_loss = 2.310, time/batch = 0.204\n",
            "12169/15750 (epoch 38), train_loss = 2.096, time/batch = 0.207\n",
            "12170/15750 (epoch 38), train_loss = 2.211, time/batch = 0.196\n",
            "12171/15750 (epoch 38), train_loss = 2.174, time/batch = 0.200\n",
            "12172/15750 (epoch 38), train_loss = 2.249, time/batch = 0.206\n",
            "12173/15750 (epoch 38), train_loss = 2.221, time/batch = 0.201\n",
            "12174/15750 (epoch 38), train_loss = 2.290, time/batch = 0.209\n",
            "12175/15750 (epoch 38), train_loss = 2.229, time/batch = 0.199\n",
            "12176/15750 (epoch 38), train_loss = 2.117, time/batch = 0.197\n",
            "12177/15750 (epoch 38), train_loss = 2.184, time/batch = 0.203\n",
            "12178/15750 (epoch 38), train_loss = 2.189, time/batch = 0.201\n",
            "12179/15750 (epoch 38), train_loss = 2.252, time/batch = 0.198\n",
            "12180/15750 (epoch 38), train_loss = 2.142, time/batch = 0.197\n",
            "12181/15750 (epoch 38), train_loss = 2.216, time/batch = 0.204\n",
            "12182/15750 (epoch 38), train_loss = 2.109, time/batch = 0.202\n",
            "12183/15750 (epoch 38), train_loss = 2.179, time/batch = 0.203\n",
            "12184/15750 (epoch 38), train_loss = 2.169, time/batch = 0.204\n",
            "12185/15750 (epoch 38), train_loss = 2.155, time/batch = 0.193\n",
            "12186/15750 (epoch 38), train_loss = 2.312, time/batch = 0.202\n",
            "12187/15750 (epoch 38), train_loss = 2.136, time/batch = 0.201\n",
            "12188/15750 (epoch 38), train_loss = 2.381, time/batch = 0.201\n",
            "12189/15750 (epoch 38), train_loss = 2.246, time/batch = 0.203\n",
            "12190/15750 (epoch 38), train_loss = 2.128, time/batch = 0.203\n",
            "12191/15750 (epoch 38), train_loss = 2.158, time/batch = 0.201\n",
            "12192/15750 (epoch 38), train_loss = 2.221, time/batch = 0.203\n",
            "12193/15750 (epoch 38), train_loss = 2.209, time/batch = 0.205\n",
            "12194/15750 (epoch 38), train_loss = 2.193, time/batch = 0.202\n",
            "12195/15750 (epoch 38), train_loss = 2.204, time/batch = 0.214\n",
            "12196/15750 (epoch 38), train_loss = 2.268, time/batch = 0.200\n",
            "12197/15750 (epoch 38), train_loss = 2.188, time/batch = 0.205\n",
            "12198/15750 (epoch 38), train_loss = 2.235, time/batch = 0.202\n",
            "12199/15750 (epoch 38), train_loss = 2.316, time/batch = 0.202\n",
            "12200/15750 (epoch 38), train_loss = 2.172, time/batch = 0.211\n",
            "12201/15750 (epoch 38), train_loss = 2.189, time/batch = 0.204\n",
            "12202/15750 (epoch 38), train_loss = 2.229, time/batch = 0.204\n",
            "12203/15750 (epoch 38), train_loss = 2.231, time/batch = 0.203\n",
            "12204/15750 (epoch 38), train_loss = 2.184, time/batch = 0.205\n",
            "12205/15750 (epoch 38), train_loss = 2.173, time/batch = 0.215\n",
            "12206/15750 (epoch 38), train_loss = 2.145, time/batch = 0.204\n",
            "12207/15750 (epoch 38), train_loss = 2.190, time/batch = 0.206\n",
            "12208/15750 (epoch 38), train_loss = 2.392, time/batch = 0.207\n",
            "12209/15750 (epoch 38), train_loss = 2.223, time/batch = 0.202\n",
            "12210/15750 (epoch 38), train_loss = 2.280, time/batch = 0.208\n",
            "12211/15750 (epoch 38), train_loss = 2.159, time/batch = 0.205\n",
            "12212/15750 (epoch 38), train_loss = 2.208, time/batch = 0.206\n",
            "12213/15750 (epoch 38), train_loss = 2.232, time/batch = 0.208\n",
            "12214/15750 (epoch 38), train_loss = 2.241, time/batch = 0.209\n",
            "12215/15750 (epoch 38), train_loss = 2.295, time/batch = 0.205\n",
            "12216/15750 (epoch 38), train_loss = 2.250, time/batch = 0.207\n",
            "12217/15750 (epoch 38), train_loss = 2.251, time/batch = 0.205\n",
            "12218/15750 (epoch 38), train_loss = 2.225, time/batch = 0.203\n",
            "12219/15750 (epoch 38), train_loss = 2.252, time/batch = 0.202\n",
            "12220/15750 (epoch 38), train_loss = 2.156, time/batch = 0.207\n",
            "12221/15750 (epoch 38), train_loss = 2.148, time/batch = 0.206\n",
            "12222/15750 (epoch 38), train_loss = 2.238, time/batch = 0.202\n",
            "12223/15750 (epoch 38), train_loss = 2.255, time/batch = 0.199\n",
            "12224/15750 (epoch 38), train_loss = 2.223, time/batch = 0.195\n",
            "12225/15750 (epoch 38), train_loss = 2.189, time/batch = 0.207\n",
            "12226/15750 (epoch 38), train_loss = 2.139, time/batch = 0.202\n",
            "12227/15750 (epoch 38), train_loss = 2.167, time/batch = 0.199\n",
            "12228/15750 (epoch 38), train_loss = 2.318, time/batch = 0.201\n",
            "12229/15750 (epoch 38), train_loss = 2.293, time/batch = 0.199\n",
            "12230/15750 (epoch 38), train_loss = 2.266, time/batch = 0.204\n",
            "12231/15750 (epoch 38), train_loss = 2.212, time/batch = 0.206\n",
            "12232/15750 (epoch 38), train_loss = 2.234, time/batch = 0.205\n",
            "12233/15750 (epoch 38), train_loss = 2.225, time/batch = 0.201\n",
            "12234/15750 (epoch 38), train_loss = 2.244, time/batch = 0.201\n",
            "12235/15750 (epoch 38), train_loss = 2.295, time/batch = 0.205\n",
            "12236/15750 (epoch 38), train_loss = 2.294, time/batch = 0.202\n",
            "12237/15750 (epoch 38), train_loss = 2.223, time/batch = 0.203\n",
            "12238/15750 (epoch 38), train_loss = 2.254, time/batch = 0.203\n",
            "12239/15750 (epoch 38), train_loss = 2.289, time/batch = 0.203\n",
            "12240/15750 (epoch 38), train_loss = 2.275, time/batch = 0.212\n",
            "12241/15750 (epoch 38), train_loss = 2.189, time/batch = 0.203\n",
            "12242/15750 (epoch 38), train_loss = 2.224, time/batch = 0.206\n",
            "12243/15750 (epoch 38), train_loss = 2.283, time/batch = 0.202\n",
            "12244/15750 (epoch 38), train_loss = 2.298, time/batch = 0.202\n",
            "12245/15750 (epoch 38), train_loss = 2.240, time/batch = 0.211\n",
            "12246/15750 (epoch 38), train_loss = 2.303, time/batch = 0.205\n",
            "12247/15750 (epoch 38), train_loss = 2.239, time/batch = 0.203\n",
            "12248/15750 (epoch 38), train_loss = 2.215, time/batch = 0.203\n",
            "12249/15750 (epoch 38), train_loss = 2.164, time/batch = 0.200\n",
            "12250/15750 (epoch 38), train_loss = 2.378, time/batch = 0.208\n",
            "12251/15750 (epoch 38), train_loss = 2.207, time/batch = 0.206\n",
            "12252/15750 (epoch 38), train_loss = 2.180, time/batch = 0.203\n",
            "12253/15750 (epoch 38), train_loss = 2.285, time/batch = 0.203\n",
            "12254/15750 (epoch 38), train_loss = 2.194, time/batch = 0.204\n",
            "12255/15750 (epoch 38), train_loss = 2.324, time/batch = 0.210\n",
            "12256/15750 (epoch 38), train_loss = 2.234, time/batch = 0.204\n",
            "12257/15750 (epoch 38), train_loss = 2.244, time/batch = 0.209\n",
            "12258/15750 (epoch 38), train_loss = 2.164, time/batch = 0.204\n",
            "12259/15750 (epoch 38), train_loss = 2.257, time/batch = 0.205\n",
            "12260/15750 (epoch 38), train_loss = 2.183, time/batch = 0.211\n",
            "12261/15750 (epoch 38), train_loss = 2.249, time/batch = 0.203\n",
            "12262/15750 (epoch 38), train_loss = 2.253, time/batch = 0.206\n",
            "12263/15750 (epoch 38), train_loss = 2.207, time/batch = 0.205\n",
            "12264/15750 (epoch 38), train_loss = 2.262, time/batch = 0.201\n",
            "12265/15750 (epoch 38), train_loss = 2.339, time/batch = 0.215\n",
            "12266/15750 (epoch 38), train_loss = 2.287, time/batch = 0.204\n",
            "12267/15750 (epoch 38), train_loss = 2.313, time/batch = 0.204\n",
            "12268/15750 (epoch 38), train_loss = 2.193, time/batch = 0.202\n",
            "12269/15750 (epoch 38), train_loss = 2.259, time/batch = 0.203\n",
            "12270/15750 (epoch 38), train_loss = 2.244, time/batch = 0.206\n",
            "12271/15750 (epoch 38), train_loss = 2.186, time/batch = 0.200\n",
            "12272/15750 (epoch 38), train_loss = 2.312, time/batch = 0.203\n",
            "12273/15750 (epoch 38), train_loss = 2.162, time/batch = 0.203\n",
            "12274/15750 (epoch 38), train_loss = 2.286, time/batch = 0.199\n",
            "12275/15750 (epoch 38), train_loss = 2.242, time/batch = 0.204\n",
            "12276/15750 (epoch 38), train_loss = 2.207, time/batch = 0.202\n",
            "12277/15750 (epoch 38), train_loss = 2.155, time/batch = 0.204\n",
            "12278/15750 (epoch 38), train_loss = 2.191, time/batch = 0.197\n",
            "12279/15750 (epoch 38), train_loss = 2.304, time/batch = 0.201\n",
            "12280/15750 (epoch 38), train_loss = 2.180, time/batch = 0.210\n",
            "12281/15750 (epoch 38), train_loss = 2.154, time/batch = 0.204\n",
            "12282/15750 (epoch 38), train_loss = 2.189, time/batch = 0.205\n",
            "12283/15750 (epoch 38), train_loss = 2.204, time/batch = 0.205\n",
            "12284/15750 (epoch 38), train_loss = 2.298, time/batch = 0.203\n",
            "12285/15750 (epoch 39), train_loss = 2.130, time/batch = 0.200\n",
            "12286/15750 (epoch 39), train_loss = 2.289, time/batch = 0.203\n",
            "12287/15750 (epoch 39), train_loss = 2.216, time/batch = 0.198\n",
            "12288/15750 (epoch 39), train_loss = 2.317, time/batch = 0.200\n",
            "12289/15750 (epoch 39), train_loss = 2.243, time/batch = 0.205\n",
            "12290/15750 (epoch 39), train_loss = 2.240, time/batch = 0.200\n",
            "12291/15750 (epoch 39), train_loss = 2.390, time/batch = 0.203\n",
            "12292/15750 (epoch 39), train_loss = 2.311, time/batch = 0.200\n",
            "12293/15750 (epoch 39), train_loss = 2.307, time/batch = 0.197\n",
            "12294/15750 (epoch 39), train_loss = 2.255, time/batch = 0.203\n",
            "12295/15750 (epoch 39), train_loss = 2.251, time/batch = 0.201\n",
            "12296/15750 (epoch 39), train_loss = 2.221, time/batch = 0.200\n",
            "12297/15750 (epoch 39), train_loss = 2.298, time/batch = 0.203\n",
            "12298/15750 (epoch 39), train_loss = 2.281, time/batch = 0.202\n",
            "12299/15750 (epoch 39), train_loss = 2.254, time/batch = 0.206\n",
            "12300/15750 (epoch 39), train_loss = 2.275, time/batch = 0.201\n",
            "12301/15750 (epoch 39), train_loss = 2.278, time/batch = 0.198\n",
            "12302/15750 (epoch 39), train_loss = 2.339, time/batch = 0.198\n",
            "12303/15750 (epoch 39), train_loss = 2.354, time/batch = 0.203\n",
            "12304/15750 (epoch 39), train_loss = 2.305, time/batch = 0.206\n",
            "12305/15750 (epoch 39), train_loss = 2.289, time/batch = 0.206\n",
            "12306/15750 (epoch 39), train_loss = 2.300, time/batch = 0.196\n",
            "12307/15750 (epoch 39), train_loss = 2.249, time/batch = 0.202\n",
            "12308/15750 (epoch 39), train_loss = 2.308, time/batch = 0.202\n",
            "12309/15750 (epoch 39), train_loss = 2.313, time/batch = 0.204\n",
            "12310/15750 (epoch 39), train_loss = 2.334, time/batch = 0.203\n",
            "12311/15750 (epoch 39), train_loss = 2.342, time/batch = 0.201\n",
            "12312/15750 (epoch 39), train_loss = 2.321, time/batch = 0.202\n",
            "12313/15750 (epoch 39), train_loss = 2.429, time/batch = 0.207\n",
            "12314/15750 (epoch 39), train_loss = 2.344, time/batch = 0.202\n",
            "12315/15750 (epoch 39), train_loss = 2.304, time/batch = 0.201\n",
            "12316/15750 (epoch 39), train_loss = 2.271, time/batch = 0.198\n",
            "12317/15750 (epoch 39), train_loss = 2.188, time/batch = 0.200\n",
            "12318/15750 (epoch 39), train_loss = 2.201, time/batch = 0.203\n",
            "12319/15750 (epoch 39), train_loss = 2.288, time/batch = 0.205\n",
            "12320/15750 (epoch 39), train_loss = 2.188, time/batch = 0.204\n",
            "12321/15750 (epoch 39), train_loss = 2.273, time/batch = 0.200\n",
            "12322/15750 (epoch 39), train_loss = 2.320, time/batch = 0.202\n",
            "12323/15750 (epoch 39), train_loss = 2.231, time/batch = 0.201\n",
            "12324/15750 (epoch 39), train_loss = 2.278, time/batch = 0.206\n",
            "12325/15750 (epoch 39), train_loss = 2.237, time/batch = 0.202\n",
            "12326/15750 (epoch 39), train_loss = 2.286, time/batch = 0.198\n",
            "12327/15750 (epoch 39), train_loss = 2.284, time/batch = 0.204\n",
            "12328/15750 (epoch 39), train_loss = 2.251, time/batch = 0.200\n",
            "12329/15750 (epoch 39), train_loss = 2.280, time/batch = 0.202\n",
            "12330/15750 (epoch 39), train_loss = 2.210, time/batch = 0.201\n",
            "12331/15750 (epoch 39), train_loss = 2.251, time/batch = 0.203\n",
            "12332/15750 (epoch 39), train_loss = 2.262, time/batch = 0.200\n",
            "12333/15750 (epoch 39), train_loss = 2.304, time/batch = 0.200\n",
            "12334/15750 (epoch 39), train_loss = 2.188, time/batch = 0.203\n",
            "12335/15750 (epoch 39), train_loss = 2.260, time/batch = 0.204\n",
            "12336/15750 (epoch 39), train_loss = 2.209, time/batch = 0.204\n",
            "12337/15750 (epoch 39), train_loss = 2.263, time/batch = 0.203\n",
            "12338/15750 (epoch 39), train_loss = 2.280, time/batch = 0.201\n",
            "12339/15750 (epoch 39), train_loss = 2.277, time/batch = 0.203\n",
            "12340/15750 (epoch 39), train_loss = 2.309, time/batch = 0.199\n",
            "12341/15750 (epoch 39), train_loss = 2.197, time/batch = 0.195\n",
            "12342/15750 (epoch 39), train_loss = 2.188, time/batch = 0.216\n",
            "12343/15750 (epoch 39), train_loss = 2.290, time/batch = 0.202\n",
            "12344/15750 (epoch 39), train_loss = 2.153, time/batch = 0.202\n",
            "12345/15750 (epoch 39), train_loss = 2.253, time/batch = 0.207\n",
            "12346/15750 (epoch 39), train_loss = 2.260, time/batch = 0.199\n",
            "12347/15750 (epoch 39), train_loss = 2.186, time/batch = 0.202\n",
            "12348/15750 (epoch 39), train_loss = 2.244, time/batch = 0.202\n",
            "12349/15750 (epoch 39), train_loss = 2.149, time/batch = 0.197\n",
            "12350/15750 (epoch 39), train_loss = 2.173, time/batch = 0.209\n",
            "12351/15750 (epoch 39), train_loss = 2.111, time/batch = 0.201\n",
            "12352/15750 (epoch 39), train_loss = 2.129, time/batch = 0.199\n",
            "12353/15750 (epoch 39), train_loss = 2.183, time/batch = 0.197\n",
            "12354/15750 (epoch 39), train_loss = 2.283, time/batch = 0.200\n",
            "12355/15750 (epoch 39), train_loss = 2.203, time/batch = 0.209\n",
            "12356/15750 (epoch 39), train_loss = 2.191, time/batch = 0.200\n",
            "12357/15750 (epoch 39), train_loss = 2.116, time/batch = 0.201\n",
            "12358/15750 (epoch 39), train_loss = 2.175, time/batch = 0.198\n",
            "12359/15750 (epoch 39), train_loss = 2.296, time/batch = 0.201\n",
            "12360/15750 (epoch 39), train_loss = 2.231, time/batch = 0.212\n",
            "12361/15750 (epoch 39), train_loss = 2.225, time/batch = 0.200\n",
            "12362/15750 (epoch 39), train_loss = 2.223, time/batch = 0.201\n",
            "12363/15750 (epoch 39), train_loss = 2.231, time/batch = 0.207\n",
            "12364/15750 (epoch 39), train_loss = 2.223, time/batch = 0.198\n",
            "12365/15750 (epoch 39), train_loss = 2.121, time/batch = 0.203\n",
            "12366/15750 (epoch 39), train_loss = 2.224, time/batch = 0.202\n",
            "12367/15750 (epoch 39), train_loss = 2.172, time/batch = 0.203\n",
            "12368/15750 (epoch 39), train_loss = 2.223, time/batch = 0.201\n",
            "12369/15750 (epoch 39), train_loss = 2.276, time/batch = 0.202\n",
            "12370/15750 (epoch 39), train_loss = 2.297, time/batch = 0.209\n",
            "12371/15750 (epoch 39), train_loss = 2.135, time/batch = 0.197\n",
            "12372/15750 (epoch 39), train_loss = 2.175, time/batch = 0.200\n",
            "12373/15750 (epoch 39), train_loss = 2.189, time/batch = 0.196\n",
            "12374/15750 (epoch 39), train_loss = 2.196, time/batch = 0.202\n",
            "12375/15750 (epoch 39), train_loss = 2.186, time/batch = 0.209\n",
            "12376/15750 (epoch 39), train_loss = 2.250, time/batch = 0.201\n",
            "12377/15750 (epoch 39), train_loss = 2.236, time/batch = 0.203\n",
            "12378/15750 (epoch 39), train_loss = 2.247, time/batch = 0.200\n",
            "12379/15750 (epoch 39), train_loss = 2.309, time/batch = 0.203\n",
            "12380/15750 (epoch 39), train_loss = 2.226, time/batch = 0.203\n",
            "12381/15750 (epoch 39), train_loss = 2.254, time/batch = 0.200\n",
            "12382/15750 (epoch 39), train_loss = 2.274, time/batch = 0.205\n",
            "12383/15750 (epoch 39), train_loss = 2.251, time/batch = 0.199\n",
            "12384/15750 (epoch 39), train_loss = 2.264, time/batch = 0.202\n",
            "12385/15750 (epoch 39), train_loss = 2.241, time/batch = 0.206\n",
            "12386/15750 (epoch 39), train_loss = 2.187, time/batch = 0.200\n",
            "12387/15750 (epoch 39), train_loss = 2.201, time/batch = 0.195\n",
            "12388/15750 (epoch 39), train_loss = 2.324, time/batch = 0.204\n",
            "12389/15750 (epoch 39), train_loss = 2.247, time/batch = 0.198\n",
            "12390/15750 (epoch 39), train_loss = 2.156, time/batch = 0.207\n",
            "12391/15750 (epoch 39), train_loss = 2.221, time/batch = 0.199\n",
            "12392/15750 (epoch 39), train_loss = 2.250, time/batch = 0.205\n",
            "12393/15750 (epoch 39), train_loss = 2.280, time/batch = 0.202\n",
            "12394/15750 (epoch 39), train_loss = 2.309, time/batch = 0.199\n",
            "12395/15750 (epoch 39), train_loss = 2.367, time/batch = 0.203\n",
            "12396/15750 (epoch 39), train_loss = 2.228, time/batch = 0.200\n",
            "12397/15750 (epoch 39), train_loss = 2.240, time/batch = 0.202\n",
            "12398/15750 (epoch 39), train_loss = 2.234, time/batch = 0.201\n",
            "12399/15750 (epoch 39), train_loss = 2.236, time/batch = 0.200\n",
            "12400/15750 (epoch 39), train_loss = 2.324, time/batch = 0.206\n",
            "12401/15750 (epoch 39), train_loss = 2.248, time/batch = 0.203\n",
            "12402/15750 (epoch 39), train_loss = 2.363, time/batch = 0.200\n",
            "12403/15750 (epoch 39), train_loss = 2.247, time/batch = 0.201\n",
            "12404/15750 (epoch 39), train_loss = 2.238, time/batch = 0.208\n",
            "12405/15750 (epoch 39), train_loss = 2.210, time/batch = 0.207\n",
            "12406/15750 (epoch 39), train_loss = 2.189, time/batch = 0.200\n",
            "12407/15750 (epoch 39), train_loss = 2.232, time/batch = 0.199\n",
            "12408/15750 (epoch 39), train_loss = 2.183, time/batch = 0.202\n",
            "12409/15750 (epoch 39), train_loss = 2.218, time/batch = 0.198\n",
            "12410/15750 (epoch 39), train_loss = 2.235, time/batch = 0.202\n",
            "12411/15750 (epoch 39), train_loss = 2.319, time/batch = 0.202\n",
            "12412/15750 (epoch 39), train_loss = 2.205, time/batch = 0.203\n",
            "12413/15750 (epoch 39), train_loss = 2.228, time/batch = 0.197\n",
            "12414/15750 (epoch 39), train_loss = 2.191, time/batch = 0.205\n",
            "12415/15750 (epoch 39), train_loss = 2.147, time/batch = 0.202\n",
            "12416/15750 (epoch 39), train_loss = 2.160, time/batch = 0.198\n",
            "12417/15750 (epoch 39), train_loss = 2.170, time/batch = 0.201\n",
            "12418/15750 (epoch 39), train_loss = 2.192, time/batch = 0.200\n",
            "12419/15750 (epoch 39), train_loss = 2.209, time/batch = 0.204\n",
            "12420/15750 (epoch 39), train_loss = 2.338, time/batch = 0.201\n",
            "12421/15750 (epoch 39), train_loss = 2.296, time/batch = 0.197\n",
            "12422/15750 (epoch 39), train_loss = 2.298, time/batch = 0.199\n",
            "12423/15750 (epoch 39), train_loss = 2.286, time/batch = 0.201\n",
            "12424/15750 (epoch 39), train_loss = 2.211, time/batch = 0.207\n",
            "12425/15750 (epoch 39), train_loss = 2.213, time/batch = 0.200\n",
            "12426/15750 (epoch 39), train_loss = 2.305, time/batch = 0.208\n",
            "12427/15750 (epoch 39), train_loss = 2.323, time/batch = 0.197\n",
            "12428/15750 (epoch 39), train_loss = 2.296, time/batch = 0.202\n",
            "12429/15750 (epoch 39), train_loss = 2.212, time/batch = 0.206\n",
            "12430/15750 (epoch 39), train_loss = 2.207, time/batch = 0.204\n",
            "12431/15750 (epoch 39), train_loss = 2.174, time/batch = 0.217\n",
            "12432/15750 (epoch 39), train_loss = 2.267, time/batch = 0.207\n",
            "12433/15750 (epoch 39), train_loss = 2.296, time/batch = 0.205\n",
            "12434/15750 (epoch 39), train_loss = 2.245, time/batch = 0.200\n",
            "12435/15750 (epoch 39), train_loss = 2.233, time/batch = 0.205\n",
            "12436/15750 (epoch 39), train_loss = 2.276, time/batch = 0.206\n",
            "12437/15750 (epoch 39), train_loss = 2.309, time/batch = 0.204\n",
            "12438/15750 (epoch 39), train_loss = 2.259, time/batch = 0.204\n",
            "12439/15750 (epoch 39), train_loss = 2.271, time/batch = 0.205\n",
            "12440/15750 (epoch 39), train_loss = 2.269, time/batch = 0.203\n",
            "12441/15750 (epoch 39), train_loss = 2.268, time/batch = 0.215\n",
            "12442/15750 (epoch 39), train_loss = 2.263, time/batch = 0.205\n",
            "12443/15750 (epoch 39), train_loss = 2.346, time/batch = 0.207\n",
            "12444/15750 (epoch 39), train_loss = 2.207, time/batch = 0.204\n",
            "12445/15750 (epoch 39), train_loss = 2.284, time/batch = 0.215\n",
            "12446/15750 (epoch 39), train_loss = 2.269, time/batch = 0.210\n",
            "12447/15750 (epoch 39), train_loss = 2.293, time/batch = 0.204\n",
            "12448/15750 (epoch 39), train_loss = 2.362, time/batch = 0.204\n",
            "12449/15750 (epoch 39), train_loss = 2.287, time/batch = 0.202\n",
            "12450/15750 (epoch 39), train_loss = 2.286, time/batch = 0.201\n",
            "12451/15750 (epoch 39), train_loss = 2.271, time/batch = 0.206\n",
            "12452/15750 (epoch 39), train_loss = 2.242, time/batch = 0.206\n",
            "12453/15750 (epoch 39), train_loss = 2.207, time/batch = 0.210\n",
            "12454/15750 (epoch 39), train_loss = 2.200, time/batch = 0.198\n",
            "12455/15750 (epoch 39), train_loss = 2.241, time/batch = 0.201\n",
            "12456/15750 (epoch 39), train_loss = 2.274, time/batch = 0.206\n",
            "12457/15750 (epoch 39), train_loss = 2.247, time/batch = 0.196\n",
            "12458/15750 (epoch 39), train_loss = 2.317, time/batch = 0.205\n",
            "12459/15750 (epoch 39), train_loss = 2.249, time/batch = 0.202\n",
            "12460/15750 (epoch 39), train_loss = 2.184, time/batch = 0.201\n",
            "12461/15750 (epoch 39), train_loss = 2.210, time/batch = 0.206\n",
            "12462/15750 (epoch 39), train_loss = 2.272, time/batch = 0.206\n",
            "12463/15750 (epoch 39), train_loss = 2.207, time/batch = 0.201\n",
            "12464/15750 (epoch 39), train_loss = 2.167, time/batch = 0.201\n",
            "12465/15750 (epoch 39), train_loss = 2.203, time/batch = 0.205\n",
            "12466/15750 (epoch 39), train_loss = 2.278, time/batch = 0.210\n",
            "12467/15750 (epoch 39), train_loss = 2.255, time/batch = 0.205\n",
            "12468/15750 (epoch 39), train_loss = 2.317, time/batch = 0.207\n",
            "12469/15750 (epoch 39), train_loss = 2.294, time/batch = 0.203\n",
            "12470/15750 (epoch 39), train_loss = 2.255, time/batch = 0.201\n",
            "12471/15750 (epoch 39), train_loss = 2.209, time/batch = 0.209\n",
            "12472/15750 (epoch 39), train_loss = 2.278, time/batch = 0.206\n",
            "12473/15750 (epoch 39), train_loss = 2.302, time/batch = 0.202\n",
            "12474/15750 (epoch 39), train_loss = 2.364, time/batch = 0.198\n",
            "12475/15750 (epoch 39), train_loss = 2.349, time/batch = 0.204\n",
            "12476/15750 (epoch 39), train_loss = 2.255, time/batch = 0.208\n",
            "12477/15750 (epoch 39), train_loss = 2.273, time/batch = 0.207\n",
            "12478/15750 (epoch 39), train_loss = 2.199, time/batch = 0.204\n",
            "12479/15750 (epoch 39), train_loss = 2.328, time/batch = 0.207\n",
            "12480/15750 (epoch 39), train_loss = 2.296, time/batch = 0.209\n",
            "12481/15750 (epoch 39), train_loss = 2.253, time/batch = 0.207\n",
            "12482/15750 (epoch 39), train_loss = 2.200, time/batch = 0.210\n",
            "12483/15750 (epoch 39), train_loss = 2.305, time/batch = 0.203\n",
            "12484/15750 (epoch 39), train_loss = 2.091, time/batch = 0.202\n",
            "12485/15750 (epoch 39), train_loss = 2.206, time/batch = 0.202\n",
            "12486/15750 (epoch 39), train_loss = 2.170, time/batch = 0.210\n",
            "12487/15750 (epoch 39), train_loss = 2.244, time/batch = 0.206\n",
            "12488/15750 (epoch 39), train_loss = 2.216, time/batch = 0.197\n",
            "12489/15750 (epoch 39), train_loss = 2.285, time/batch = 0.204\n",
            "12490/15750 (epoch 39), train_loss = 2.224, time/batch = 0.202\n",
            "12491/15750 (epoch 39), train_loss = 2.113, time/batch = 0.212\n",
            "12492/15750 (epoch 39), train_loss = 2.179, time/batch = 0.203\n",
            "12493/15750 (epoch 39), train_loss = 2.185, time/batch = 0.200\n",
            "12494/15750 (epoch 39), train_loss = 2.248, time/batch = 0.201\n",
            "12495/15750 (epoch 39), train_loss = 2.138, time/batch = 0.199\n",
            "12496/15750 (epoch 39), train_loss = 2.211, time/batch = 0.201\n",
            "12497/15750 (epoch 39), train_loss = 2.104, time/batch = 0.200\n",
            "12498/15750 (epoch 39), train_loss = 2.175, time/batch = 0.195\n",
            "12499/15750 (epoch 39), train_loss = 2.165, time/batch = 0.204\n",
            "12500/15750 (epoch 39), train_loss = 2.149, time/batch = 0.203\n",
            "12501/15750 (epoch 39), train_loss = 2.307, time/batch = 0.204\n",
            "12502/15750 (epoch 39), train_loss = 2.132, time/batch = 0.205\n",
            "12503/15750 (epoch 39), train_loss = 2.375, time/batch = 0.202\n",
            "12504/15750 (epoch 39), train_loss = 2.242, time/batch = 0.200\n",
            "12505/15750 (epoch 39), train_loss = 2.124, time/batch = 0.197\n",
            "12506/15750 (epoch 39), train_loss = 2.153, time/batch = 0.209\n",
            "12507/15750 (epoch 39), train_loss = 2.217, time/batch = 0.202\n",
            "12508/15750 (epoch 39), train_loss = 2.204, time/batch = 0.198\n",
            "12509/15750 (epoch 39), train_loss = 2.187, time/batch = 0.198\n",
            "12510/15750 (epoch 39), train_loss = 2.199, time/batch = 0.195\n",
            "12511/15750 (epoch 39), train_loss = 2.263, time/batch = 0.205\n",
            "12512/15750 (epoch 39), train_loss = 2.184, time/batch = 0.206\n",
            "12513/15750 (epoch 39), train_loss = 2.230, time/batch = 0.195\n",
            "12514/15750 (epoch 39), train_loss = 2.312, time/batch = 0.204\n",
            "12515/15750 (epoch 39), train_loss = 2.168, time/batch = 0.204\n",
            "12516/15750 (epoch 39), train_loss = 2.184, time/batch = 0.201\n",
            "12517/15750 (epoch 39), train_loss = 2.224, time/batch = 0.201\n",
            "12518/15750 (epoch 39), train_loss = 2.226, time/batch = 0.202\n",
            "12519/15750 (epoch 39), train_loss = 2.180, time/batch = 0.201\n",
            "12520/15750 (epoch 39), train_loss = 2.168, time/batch = 0.196\n",
            "12521/15750 (epoch 39), train_loss = 2.140, time/batch = 0.208\n",
            "12522/15750 (epoch 39), train_loss = 2.184, time/batch = 0.199\n",
            "12523/15750 (epoch 39), train_loss = 2.386, time/batch = 0.203\n",
            "12524/15750 (epoch 39), train_loss = 2.218, time/batch = 0.205\n",
            "12525/15750 (epoch 39), train_loss = 2.275, time/batch = 0.197\n",
            "12526/15750 (epoch 39), train_loss = 2.154, time/batch = 0.205\n",
            "12527/15750 (epoch 39), train_loss = 2.203, time/batch = 0.205\n",
            "12528/15750 (epoch 39), train_loss = 2.227, time/batch = 0.198\n",
            "12529/15750 (epoch 39), train_loss = 2.236, time/batch = 0.195\n",
            "12530/15750 (epoch 39), train_loss = 2.290, time/batch = 0.205\n",
            "12531/15750 (epoch 39), train_loss = 2.245, time/batch = 0.205\n",
            "12532/15750 (epoch 39), train_loss = 2.246, time/batch = 0.200\n",
            "12533/15750 (epoch 39), train_loss = 2.220, time/batch = 0.201\n",
            "12534/15750 (epoch 39), train_loss = 2.247, time/batch = 0.196\n",
            "12535/15750 (epoch 39), train_loss = 2.151, time/batch = 0.204\n",
            "12536/15750 (epoch 39), train_loss = 2.143, time/batch = 0.207\n",
            "12537/15750 (epoch 39), train_loss = 2.233, time/batch = 0.196\n",
            "12538/15750 (epoch 39), train_loss = 2.251, time/batch = 0.202\n",
            "12539/15750 (epoch 39), train_loss = 2.218, time/batch = 0.204\n",
            "12540/15750 (epoch 39), train_loss = 2.184, time/batch = 0.198\n",
            "12541/15750 (epoch 39), train_loss = 2.135, time/batch = 0.204\n",
            "12542/15750 (epoch 39), train_loss = 2.163, time/batch = 0.201\n",
            "12543/15750 (epoch 39), train_loss = 2.313, time/batch = 0.202\n",
            "12544/15750 (epoch 39), train_loss = 2.288, time/batch = 0.205\n",
            "12545/15750 (epoch 39), train_loss = 2.261, time/batch = 0.195\n",
            "12546/15750 (epoch 39), train_loss = 2.207, time/batch = 0.201\n",
            "12547/15750 (epoch 39), train_loss = 2.229, time/batch = 0.202\n",
            "12548/15750 (epoch 39), train_loss = 2.220, time/batch = 0.203\n",
            "12549/15750 (epoch 39), train_loss = 2.238, time/batch = 0.203\n",
            "12550/15750 (epoch 39), train_loss = 2.289, time/batch = 0.198\n",
            "12551/15750 (epoch 39), train_loss = 2.289, time/batch = 0.202\n",
            "12552/15750 (epoch 39), train_loss = 2.218, time/batch = 0.200\n",
            "12553/15750 (epoch 39), train_loss = 2.248, time/batch = 0.202\n",
            "12554/15750 (epoch 39), train_loss = 2.285, time/batch = 0.202\n",
            "12555/15750 (epoch 39), train_loss = 2.270, time/batch = 0.206\n",
            "12556/15750 (epoch 39), train_loss = 2.184, time/batch = 0.206\n",
            "12557/15750 (epoch 39), train_loss = 2.220, time/batch = 0.202\n",
            "12558/15750 (epoch 39), train_loss = 2.279, time/batch = 0.196\n",
            "12559/15750 (epoch 39), train_loss = 2.293, time/batch = 0.203\n",
            "12560/15750 (epoch 39), train_loss = 2.234, time/batch = 0.201\n",
            "12561/15750 (epoch 39), train_loss = 2.298, time/batch = 0.203\n",
            "12562/15750 (epoch 39), train_loss = 2.235, time/batch = 0.210\n",
            "12563/15750 (epoch 39), train_loss = 2.212, time/batch = 0.200\n",
            "12564/15750 (epoch 39), train_loss = 2.159, time/batch = 0.200\n",
            "12565/15750 (epoch 39), train_loss = 2.372, time/batch = 0.205\n",
            "12566/15750 (epoch 39), train_loss = 2.202, time/batch = 0.203\n",
            "12567/15750 (epoch 39), train_loss = 2.176, time/batch = 0.212\n",
            "12568/15750 (epoch 39), train_loss = 2.280, time/batch = 0.202\n",
            "12569/15750 (epoch 39), train_loss = 2.189, time/batch = 0.200\n",
            "12570/15750 (epoch 39), train_loss = 2.319, time/batch = 0.201\n",
            "12571/15750 (epoch 39), train_loss = 2.230, time/batch = 0.206\n",
            "12572/15750 (epoch 39), train_loss = 2.239, time/batch = 0.211\n",
            "12573/15750 (epoch 39), train_loss = 2.160, time/batch = 0.210\n",
            "12574/15750 (epoch 39), train_loss = 2.253, time/batch = 0.209\n",
            "12575/15750 (epoch 39), train_loss = 2.178, time/batch = 0.202\n",
            "12576/15750 (epoch 39), train_loss = 2.244, time/batch = 0.206\n",
            "12577/15750 (epoch 39), train_loss = 2.249, time/batch = 0.207\n",
            "12578/15750 (epoch 39), train_loss = 2.202, time/batch = 0.204\n",
            "12579/15750 (epoch 39), train_loss = 2.257, time/batch = 0.208\n",
            "12580/15750 (epoch 39), train_loss = 2.334, time/batch = 0.206\n",
            "12581/15750 (epoch 39), train_loss = 2.282, time/batch = 0.208\n",
            "12582/15750 (epoch 39), train_loss = 2.308, time/batch = 0.209\n",
            "12583/15750 (epoch 39), train_loss = 2.189, time/batch = 0.209\n",
            "12584/15750 (epoch 39), train_loss = 2.254, time/batch = 0.206\n",
            "12585/15750 (epoch 39), train_loss = 2.239, time/batch = 0.204\n",
            "12586/15750 (epoch 39), train_loss = 2.182, time/batch = 0.207\n",
            "12587/15750 (epoch 39), train_loss = 2.308, time/batch = 0.208\n",
            "12588/15750 (epoch 39), train_loss = 2.158, time/batch = 0.200\n",
            "12589/15750 (epoch 39), train_loss = 2.282, time/batch = 0.201\n",
            "12590/15750 (epoch 39), train_loss = 2.238, time/batch = 0.202\n",
            "12591/15750 (epoch 39), train_loss = 2.202, time/batch = 0.199\n",
            "12592/15750 (epoch 39), train_loss = 2.150, time/batch = 0.210\n",
            "12593/15750 (epoch 39), train_loss = 2.186, time/batch = 0.195\n",
            "12594/15750 (epoch 39), train_loss = 2.299, time/batch = 0.199\n",
            "12595/15750 (epoch 39), train_loss = 2.176, time/batch = 0.202\n",
            "12596/15750 (epoch 39), train_loss = 2.150, time/batch = 0.200\n",
            "12597/15750 (epoch 39), train_loss = 2.185, time/batch = 0.207\n",
            "12598/15750 (epoch 39), train_loss = 2.201, time/batch = 0.201\n",
            "12599/15750 (epoch 39), train_loss = 2.293, time/batch = 0.202\n",
            "12600/15750 (epoch 40), train_loss = 2.121, time/batch = 0.203\n",
            "12601/15750 (epoch 40), train_loss = 2.285, time/batch = 0.204\n",
            "12602/15750 (epoch 40), train_loss = 2.210, time/batch = 0.207\n",
            "12603/15750 (epoch 40), train_loss = 2.312, time/batch = 0.207\n",
            "12604/15750 (epoch 40), train_loss = 2.239, time/batch = 0.205\n",
            "12605/15750 (epoch 40), train_loss = 2.236, time/batch = 0.205\n",
            "12606/15750 (epoch 40), train_loss = 2.385, time/batch = 0.209\n",
            "12607/15750 (epoch 40), train_loss = 2.306, time/batch = 0.210\n",
            "12608/15750 (epoch 40), train_loss = 2.303, time/batch = 0.211\n",
            "12609/15750 (epoch 40), train_loss = 2.251, time/batch = 0.199\n",
            "12610/15750 (epoch 40), train_loss = 2.245, time/batch = 0.203\n",
            "12611/15750 (epoch 40), train_loss = 2.217, time/batch = 0.206\n",
            "12612/15750 (epoch 40), train_loss = 2.293, time/batch = 0.201\n",
            "12613/15750 (epoch 40), train_loss = 2.277, time/batch = 0.201\n",
            "12614/15750 (epoch 40), train_loss = 2.249, time/batch = 0.199\n",
            "12615/15750 (epoch 40), train_loss = 2.270, time/batch = 0.200\n",
            "12616/15750 (epoch 40), train_loss = 2.273, time/batch = 0.202\n",
            "12617/15750 (epoch 40), train_loss = 2.334, time/batch = 0.198\n",
            "12618/15750 (epoch 40), train_loss = 2.350, time/batch = 0.203\n",
            "12619/15750 (epoch 40), train_loss = 2.300, time/batch = 0.203\n",
            "12620/15750 (epoch 40), train_loss = 2.284, time/batch = 0.204\n",
            "12621/15750 (epoch 40), train_loss = 2.294, time/batch = 0.206\n",
            "12622/15750 (epoch 40), train_loss = 2.245, time/batch = 0.202\n",
            "12623/15750 (epoch 40), train_loss = 2.303, time/batch = 0.203\n",
            "12624/15750 (epoch 40), train_loss = 2.308, time/batch = 0.204\n",
            "12625/15750 (epoch 40), train_loss = 2.329, time/batch = 0.202\n",
            "12626/15750 (epoch 40), train_loss = 2.337, time/batch = 0.204\n",
            "12627/15750 (epoch 40), train_loss = 2.317, time/batch = 0.203\n",
            "12628/15750 (epoch 40), train_loss = 2.424, time/batch = 0.197\n",
            "12629/15750 (epoch 40), train_loss = 2.338, time/batch = 0.202\n",
            "12630/15750 (epoch 40), train_loss = 2.299, time/batch = 0.203\n",
            "12631/15750 (epoch 40), train_loss = 2.266, time/batch = 0.207\n",
            "12632/15750 (epoch 40), train_loss = 2.184, time/batch = 0.198\n",
            "12633/15750 (epoch 40), train_loss = 2.196, time/batch = 0.201\n",
            "12634/15750 (epoch 40), train_loss = 2.283, time/batch = 0.203\n",
            "12635/15750 (epoch 40), train_loss = 2.183, time/batch = 0.202\n",
            "12636/15750 (epoch 40), train_loss = 2.268, time/batch = 0.206\n",
            "12637/15750 (epoch 40), train_loss = 2.316, time/batch = 0.196\n",
            "12638/15750 (epoch 40), train_loss = 2.226, time/batch = 0.203\n",
            "12639/15750 (epoch 40), train_loss = 2.273, time/batch = 0.203\n",
            "12640/15750 (epoch 40), train_loss = 2.232, time/batch = 0.201\n",
            "12641/15750 (epoch 40), train_loss = 2.282, time/batch = 0.202\n",
            "12642/15750 (epoch 40), train_loss = 2.279, time/batch = 0.200\n",
            "12643/15750 (epoch 40), train_loss = 2.246, time/batch = 0.202\n",
            "12644/15750 (epoch 40), train_loss = 2.276, time/batch = 0.203\n",
            "12645/15750 (epoch 40), train_loss = 2.206, time/batch = 0.201\n",
            "12646/15750 (epoch 40), train_loss = 2.248, time/batch = 0.203\n",
            "12647/15750 (epoch 40), train_loss = 2.258, time/batch = 0.204\n",
            "12648/15750 (epoch 40), train_loss = 2.299, time/batch = 0.203\n",
            "12649/15750 (epoch 40), train_loss = 2.183, time/batch = 0.202\n",
            "12650/15750 (epoch 40), train_loss = 2.256, time/batch = 0.199\n",
            "12651/15750 (epoch 40), train_loss = 2.205, time/batch = 0.215\n",
            "12652/15750 (epoch 40), train_loss = 2.258, time/batch = 0.211\n",
            "12653/15750 (epoch 40), train_loss = 2.275, time/batch = 0.207\n",
            "12654/15750 (epoch 40), train_loss = 2.273, time/batch = 0.209\n",
            "12655/15750 (epoch 40), train_loss = 2.305, time/batch = 0.204\n",
            "12656/15750 (epoch 40), train_loss = 2.193, time/batch = 0.213\n",
            "12657/15750 (epoch 40), train_loss = 2.184, time/batch = 0.207\n",
            "12658/15750 (epoch 40), train_loss = 2.286, time/batch = 0.209\n",
            "12659/15750 (epoch 40), train_loss = 2.149, time/batch = 0.210\n",
            "12660/15750 (epoch 40), train_loss = 2.248, time/batch = 0.202\n",
            "12661/15750 (epoch 40), train_loss = 2.256, time/batch = 0.213\n",
            "12662/15750 (epoch 40), train_loss = 2.181, time/batch = 0.207\n",
            "12663/15750 (epoch 40), train_loss = 2.240, time/batch = 0.205\n",
            "12664/15750 (epoch 40), train_loss = 2.144, time/batch = 0.202\n",
            "12665/15750 (epoch 40), train_loss = 2.171, time/batch = 0.200\n",
            "12666/15750 (epoch 40), train_loss = 2.107, time/batch = 0.213\n",
            "12667/15750 (epoch 40), train_loss = 2.137, time/batch = 0.207\n",
            "12668/15750 (epoch 40), train_loss = 2.194, time/batch = 0.210\n",
            "12669/15750 (epoch 40), train_loss = 2.288, time/batch = 0.207\n",
            "12670/15750 (epoch 40), train_loss = 2.211, time/batch = 0.210\n",
            "12671/15750 (epoch 40), train_loss = 2.200, time/batch = 0.213\n",
            "12672/15750 (epoch 40), train_loss = 2.119, time/batch = 0.208\n",
            "12673/15750 (epoch 40), train_loss = 2.171, time/batch = 0.205\n",
            "12674/15750 (epoch 40), train_loss = 2.291, time/batch = 0.205\n",
            "12675/15750 (epoch 40), train_loss = 2.227, time/batch = 0.204\n",
            "12676/15750 (epoch 40), train_loss = 2.221, time/batch = 0.216\n",
            "12677/15750 (epoch 40), train_loss = 2.218, time/batch = 0.210\n",
            "12678/15750 (epoch 40), train_loss = 2.227, time/batch = 0.214\n",
            "12679/15750 (epoch 40), train_loss = 2.218, time/batch = 0.209\n",
            "12680/15750 (epoch 40), train_loss = 2.116, time/batch = 0.208\n",
            "12681/15750 (epoch 40), train_loss = 2.220, time/batch = 0.213\n",
            "12682/15750 (epoch 40), train_loss = 2.167, time/batch = 0.207\n",
            "12683/15750 (epoch 40), train_loss = 2.218, time/batch = 0.211\n",
            "12684/15750 (epoch 40), train_loss = 2.271, time/batch = 0.204\n",
            "12685/15750 (epoch 40), train_loss = 2.291, time/batch = 0.212\n",
            "12686/15750 (epoch 40), train_loss = 2.129, time/batch = 0.211\n",
            "12687/15750 (epoch 40), train_loss = 2.170, time/batch = 0.205\n",
            "12688/15750 (epoch 40), train_loss = 2.184, time/batch = 0.206\n",
            "12689/15750 (epoch 40), train_loss = 2.192, time/batch = 0.201\n",
            "12690/15750 (epoch 40), train_loss = 2.181, time/batch = 0.209\n",
            "12691/15750 (epoch 40), train_loss = 2.245, time/batch = 0.210\n",
            "12692/15750 (epoch 40), train_loss = 2.231, time/batch = 0.205\n",
            "12693/15750 (epoch 40), train_loss = 2.242, time/batch = 0.206\n",
            "12694/15750 (epoch 40), train_loss = 2.304, time/batch = 0.206\n",
            "12695/15750 (epoch 40), train_loss = 2.221, time/batch = 0.213\n",
            "12696/15750 (epoch 40), train_loss = 2.250, time/batch = 0.201\n",
            "12697/15750 (epoch 40), train_loss = 2.269, time/batch = 0.207\n",
            "12698/15750 (epoch 40), train_loss = 2.247, time/batch = 0.203\n",
            "12699/15750 (epoch 40), train_loss = 2.260, time/batch = 0.205\n",
            "12700/15750 (epoch 40), train_loss = 2.237, time/batch = 0.204\n",
            "12701/15750 (epoch 40), train_loss = 2.183, time/batch = 0.202\n",
            "12702/15750 (epoch 40), train_loss = 2.196, time/batch = 0.209\n",
            "12703/15750 (epoch 40), train_loss = 2.319, time/batch = 0.204\n",
            "12704/15750 (epoch 40), train_loss = 2.242, time/batch = 0.210\n",
            "12705/15750 (epoch 40), train_loss = 2.150, time/batch = 0.211\n",
            "12706/15750 (epoch 40), train_loss = 2.216, time/batch = 0.209\n",
            "12707/15750 (epoch 40), train_loss = 2.245, time/batch = 0.212\n",
            "12708/15750 (epoch 40), train_loss = 2.275, time/batch = 0.211\n",
            "12709/15750 (epoch 40), train_loss = 2.304, time/batch = 0.207\n",
            "12710/15750 (epoch 40), train_loss = 2.362, time/batch = 0.217\n",
            "12711/15750 (epoch 40), train_loss = 2.222, time/batch = 0.210\n",
            "12712/15750 (epoch 40), train_loss = 2.235, time/batch = 0.211\n",
            "12713/15750 (epoch 40), train_loss = 2.229, time/batch = 0.206\n",
            "12714/15750 (epoch 40), train_loss = 2.230, time/batch = 0.207\n",
            "12715/15750 (epoch 40), train_loss = 2.319, time/batch = 0.208\n",
            "12716/15750 (epoch 40), train_loss = 2.243, time/batch = 0.203\n",
            "12717/15750 (epoch 40), train_loss = 2.358, time/batch = 0.202\n",
            "12718/15750 (epoch 40), train_loss = 2.242, time/batch = 0.208\n",
            "12719/15750 (epoch 40), train_loss = 2.234, time/batch = 0.206\n",
            "12720/15750 (epoch 40), train_loss = 2.206, time/batch = 0.215\n",
            "12721/15750 (epoch 40), train_loss = 2.185, time/batch = 0.210\n",
            "12722/15750 (epoch 40), train_loss = 2.228, time/batch = 0.212\n",
            "12723/15750 (epoch 40), train_loss = 2.178, time/batch = 0.210\n",
            "12724/15750 (epoch 40), train_loss = 2.214, time/batch = 0.206\n",
            "12725/15750 (epoch 40), train_loss = 2.230, time/batch = 0.215\n",
            "12726/15750 (epoch 40), train_loss = 2.314, time/batch = 0.207\n",
            "12727/15750 (epoch 40), train_loss = 2.201, time/batch = 0.208\n",
            "12728/15750 (epoch 40), train_loss = 2.224, time/batch = 0.208\n",
            "12729/15750 (epoch 40), train_loss = 2.186, time/batch = 0.207\n",
            "12730/15750 (epoch 40), train_loss = 2.143, time/batch = 0.215\n",
            "12731/15750 (epoch 40), train_loss = 2.156, time/batch = 0.209\n",
            "12732/15750 (epoch 40), train_loss = 2.165, time/batch = 0.210\n",
            "12733/15750 (epoch 40), train_loss = 2.188, time/batch = 0.209\n",
            "12734/15750 (epoch 40), train_loss = 2.204, time/batch = 0.210\n",
            "12735/15750 (epoch 40), train_loss = 2.334, time/batch = 0.215\n",
            "12736/15750 (epoch 40), train_loss = 2.292, time/batch = 0.201\n",
            "12737/15750 (epoch 40), train_loss = 2.294, time/batch = 0.208\n",
            "12738/15750 (epoch 40), train_loss = 2.282, time/batch = 0.212\n",
            "12739/15750 (epoch 40), train_loss = 2.206, time/batch = 0.211\n",
            "12740/15750 (epoch 40), train_loss = 2.209, time/batch = 0.218\n",
            "12741/15750 (epoch 40), train_loss = 2.301, time/batch = 0.204\n",
            "12742/15750 (epoch 40), train_loss = 2.319, time/batch = 0.206\n",
            "12743/15750 (epoch 40), train_loss = 2.291, time/batch = 0.209\n",
            "12744/15750 (epoch 40), train_loss = 2.207, time/batch = 0.202\n",
            "12745/15750 (epoch 40), train_loss = 2.203, time/batch = 0.213\n",
            "12746/15750 (epoch 40), train_loss = 2.170, time/batch = 0.205\n",
            "12747/15750 (epoch 40), train_loss = 2.262, time/batch = 0.213\n",
            "12748/15750 (epoch 40), train_loss = 2.291, time/batch = 0.208\n",
            "12749/15750 (epoch 40), train_loss = 2.240, time/batch = 0.204\n",
            "12750/15750 (epoch 40), train_loss = 2.228, time/batch = 0.218\n",
            "12751/15750 (epoch 40), train_loss = 2.270, time/batch = 0.214\n",
            "12752/15750 (epoch 40), train_loss = 2.304, time/batch = 0.211\n",
            "12753/15750 (epoch 40), train_loss = 2.254, time/batch = 0.204\n",
            "12754/15750 (epoch 40), train_loss = 2.266, time/batch = 0.218\n",
            "12755/15750 (epoch 40), train_loss = 2.264, time/batch = 0.203\n",
            "12756/15750 (epoch 40), train_loss = 2.263, time/batch = 0.209\n",
            "12757/15750 (epoch 40), train_loss = 2.259, time/batch = 0.206\n",
            "12758/15750 (epoch 40), train_loss = 2.340, time/batch = 0.205\n",
            "12759/15750 (epoch 40), train_loss = 2.202, time/batch = 0.214\n",
            "12760/15750 (epoch 40), train_loss = 2.280, time/batch = 0.206\n",
            "12761/15750 (epoch 40), train_loss = 2.264, time/batch = 0.208\n",
            "12762/15750 (epoch 40), train_loss = 2.288, time/batch = 0.208\n",
            "12763/15750 (epoch 40), train_loss = 2.357, time/batch = 0.209\n",
            "12764/15750 (epoch 40), train_loss = 2.282, time/batch = 0.216\n",
            "12765/15750 (epoch 40), train_loss = 2.281, time/batch = 0.208\n",
            "12766/15750 (epoch 40), train_loss = 2.266, time/batch = 0.213\n",
            "12767/15750 (epoch 40), train_loss = 2.237, time/batch = 0.207\n",
            "12768/15750 (epoch 40), train_loss = 2.203, time/batch = 0.208\n",
            "12769/15750 (epoch 40), train_loss = 2.195, time/batch = 0.216\n",
            "12770/15750 (epoch 40), train_loss = 2.236, time/batch = 0.208\n",
            "12771/15750 (epoch 40), train_loss = 2.269, time/batch = 0.200\n",
            "12772/15750 (epoch 40), train_loss = 2.242, time/batch = 0.205\n",
            "12773/15750 (epoch 40), train_loss = 2.313, time/batch = 0.202\n",
            "12774/15750 (epoch 40), train_loss = 2.245, time/batch = 0.206\n",
            "12775/15750 (epoch 40), train_loss = 2.180, time/batch = 0.202\n",
            "12776/15750 (epoch 40), train_loss = 2.206, time/batch = 0.210\n",
            "12777/15750 (epoch 40), train_loss = 2.268, time/batch = 0.204\n",
            "12778/15750 (epoch 40), train_loss = 2.203, time/batch = 0.210\n",
            "12779/15750 (epoch 40), train_loss = 2.162, time/batch = 0.214\n",
            "12780/15750 (epoch 40), train_loss = 2.198, time/batch = 0.210\n",
            "12781/15750 (epoch 40), train_loss = 2.273, time/batch = 0.210\n",
            "12782/15750 (epoch 40), train_loss = 2.251, time/batch = 0.208\n",
            "12783/15750 (epoch 40), train_loss = 2.312, time/batch = 0.209\n",
            "12784/15750 (epoch 40), train_loss = 2.289, time/batch = 0.208\n",
            "12785/15750 (epoch 40), train_loss = 2.251, time/batch = 0.201\n",
            "12786/15750 (epoch 40), train_loss = 2.205, time/batch = 0.207\n",
            "12787/15750 (epoch 40), train_loss = 2.273, time/batch = 0.203\n",
            "12788/15750 (epoch 40), train_loss = 2.297, time/batch = 0.202\n",
            "12789/15750 (epoch 40), train_loss = 2.358, time/batch = 0.208\n",
            "12790/15750 (epoch 40), train_loss = 2.345, time/batch = 0.204\n",
            "12791/15750 (epoch 40), train_loss = 2.250, time/batch = 0.204\n",
            "12792/15750 (epoch 40), train_loss = 2.268, time/batch = 0.209\n",
            "12793/15750 (epoch 40), train_loss = 2.195, time/batch = 0.206\n",
            "12794/15750 (epoch 40), train_loss = 2.324, time/batch = 0.216\n",
            "12795/15750 (epoch 40), train_loss = 2.291, time/batch = 0.211\n",
            "12796/15750 (epoch 40), train_loss = 2.248, time/batch = 0.209\n",
            "12797/15750 (epoch 40), train_loss = 2.195, time/batch = 0.208\n",
            "12798/15750 (epoch 40), train_loss = 2.301, time/batch = 0.209\n",
            "12799/15750 (epoch 40), train_loss = 2.087, time/batch = 0.219\n",
            "12800/15750 (epoch 40), train_loss = 2.201, time/batch = 0.213\n",
            "12801/15750 (epoch 40), train_loss = 2.165, time/batch = 0.208\n",
            "12802/15750 (epoch 40), train_loss = 2.240, time/batch = 0.210\n",
            "12803/15750 (epoch 40), train_loss = 2.211, time/batch = 0.209\n",
            "12804/15750 (epoch 40), train_loss = 2.280, time/batch = 0.204\n",
            "12805/15750 (epoch 40), train_loss = 2.219, time/batch = 0.202\n",
            "12806/15750 (epoch 40), train_loss = 2.109, time/batch = 0.208\n",
            "12807/15750 (epoch 40), train_loss = 2.174, time/batch = 0.213\n",
            "12808/15750 (epoch 40), train_loss = 2.180, time/batch = 0.207\n",
            "12809/15750 (epoch 40), train_loss = 2.243, time/batch = 0.208\n",
            "12810/15750 (epoch 40), train_loss = 2.133, time/batch = 0.209\n",
            "12811/15750 (epoch 40), train_loss = 2.207, time/batch = 0.209\n",
            "12812/15750 (epoch 40), train_loss = 2.100, time/batch = 0.210\n",
            "12813/15750 (epoch 40), train_loss = 2.170, time/batch = 0.210\n",
            "12814/15750 (epoch 40), train_loss = 2.160, time/batch = 0.204\n",
            "12815/15750 (epoch 40), train_loss = 2.144, time/batch = 0.213\n",
            "12816/15750 (epoch 40), train_loss = 2.303, time/batch = 0.208\n",
            "12817/15750 (epoch 40), train_loss = 2.128, time/batch = 0.210\n",
            "12818/15750 (epoch 40), train_loss = 2.371, time/batch = 0.214\n",
            "12819/15750 (epoch 40), train_loss = 2.237, time/batch = 0.201\n",
            "12820/15750 (epoch 40), train_loss = 2.120, time/batch = 0.206\n",
            "12821/15750 (epoch 40), train_loss = 2.149, time/batch = 0.209\n",
            "12822/15750 (epoch 40), train_loss = 2.212, time/batch = 0.208\n",
            "12823/15750 (epoch 40), train_loss = 2.199, time/batch = 0.213\n",
            "12824/15750 (epoch 40), train_loss = 2.182, time/batch = 0.206\n",
            "12825/15750 (epoch 40), train_loss = 2.195, time/batch = 0.209\n",
            "12826/15750 (epoch 40), train_loss = 2.258, time/batch = 0.209\n",
            "12827/15750 (epoch 40), train_loss = 2.179, time/batch = 0.207\n",
            "12828/15750 (epoch 40), train_loss = 2.226, time/batch = 0.215\n",
            "12829/15750 (epoch 40), train_loss = 2.309, time/batch = 0.210\n",
            "12830/15750 (epoch 40), train_loss = 2.164, time/batch = 0.210\n",
            "12831/15750 (epoch 40), train_loss = 2.180, time/batch = 0.198\n",
            "12832/15750 (epoch 40), train_loss = 2.219, time/batch = 0.202\n",
            "12833/15750 (epoch 40), train_loss = 2.222, time/batch = 0.210\n",
            "12834/15750 (epoch 40), train_loss = 2.175, time/batch = 0.208\n",
            "12835/15750 (epoch 40), train_loss = 2.164, time/batch = 0.202\n",
            "12836/15750 (epoch 40), train_loss = 2.135, time/batch = 0.204\n",
            "12837/15750 (epoch 40), train_loss = 2.179, time/batch = 0.197\n",
            "12838/15750 (epoch 40), train_loss = 2.381, time/batch = 0.208\n",
            "12839/15750 (epoch 40), train_loss = 2.214, time/batch = 0.200\n",
            "12840/15750 (epoch 40), train_loss = 2.270, time/batch = 0.208\n",
            "12841/15750 (epoch 40), train_loss = 2.150, time/batch = 0.207\n",
            "12842/15750 (epoch 40), train_loss = 2.198, time/batch = 0.210\n",
            "12843/15750 (epoch 40), train_loss = 2.222, time/batch = 0.218\n",
            "12844/15750 (epoch 40), train_loss = 2.232, time/batch = 0.210\n",
            "12845/15750 (epoch 40), train_loss = 2.286, time/batch = 0.208\n",
            "12846/15750 (epoch 40), train_loss = 2.240, time/batch = 0.212\n",
            "12847/15750 (epoch 40), train_loss = 2.242, time/batch = 0.207\n",
            "12848/15750 (epoch 40), train_loss = 2.216, time/batch = 0.216\n",
            "12849/15750 (epoch 40), train_loss = 2.241, time/batch = 0.210\n",
            "12850/15750 (epoch 40), train_loss = 2.147, time/batch = 0.208\n",
            "12851/15750 (epoch 40), train_loss = 2.138, time/batch = 0.211\n",
            "12852/15750 (epoch 40), train_loss = 2.229, time/batch = 0.205\n",
            "12853/15750 (epoch 40), train_loss = 2.246, time/batch = 0.209\n",
            "12854/15750 (epoch 40), train_loss = 2.214, time/batch = 0.207\n",
            "12855/15750 (epoch 40), train_loss = 2.180, time/batch = 0.207\n",
            "12856/15750 (epoch 40), train_loss = 2.131, time/batch = 0.208\n",
            "12857/15750 (epoch 40), train_loss = 2.159, time/batch = 0.208\n",
            "12858/15750 (epoch 40), train_loss = 2.308, time/batch = 0.223\n",
            "12859/15750 (epoch 40), train_loss = 2.284, time/batch = 0.212\n",
            "12860/15750 (epoch 40), train_loss = 2.257, time/batch = 0.208\n",
            "12861/15750 (epoch 40), train_loss = 2.203, time/batch = 0.208\n",
            "12862/15750 (epoch 40), train_loss = 2.225, time/batch = 0.209\n",
            "12863/15750 (epoch 40), train_loss = 2.216, time/batch = 0.205\n",
            "12864/15750 (epoch 40), train_loss = 2.233, time/batch = 0.209\n",
            "12865/15750 (epoch 40), train_loss = 2.284, time/batch = 0.208\n",
            "12866/15750 (epoch 40), train_loss = 2.283, time/batch = 0.205\n",
            "12867/15750 (epoch 40), train_loss = 2.214, time/batch = 0.214\n",
            "12868/15750 (epoch 40), train_loss = 2.243, time/batch = 0.207\n",
            "12869/15750 (epoch 40), train_loss = 2.280, time/batch = 0.209\n",
            "12870/15750 (epoch 40), train_loss = 2.265, time/batch = 0.209\n",
            "12871/15750 (epoch 40), train_loss = 2.180, time/batch = 0.207\n",
            "12872/15750 (epoch 40), train_loss = 2.216, time/batch = 0.214\n",
            "12873/15750 (epoch 40), train_loss = 2.274, time/batch = 0.209\n",
            "12874/15750 (epoch 40), train_loss = 2.289, time/batch = 0.210\n",
            "12875/15750 (epoch 40), train_loss = 2.229, time/batch = 0.201\n",
            "12876/15750 (epoch 40), train_loss = 2.294, time/batch = 0.212\n",
            "12877/15750 (epoch 40), train_loss = 2.230, time/batch = 0.215\n",
            "12878/15750 (epoch 40), train_loss = 2.206, time/batch = 0.205\n",
            "12879/15750 (epoch 40), train_loss = 2.155, time/batch = 0.198\n",
            "12880/15750 (epoch 40), train_loss = 2.367, time/batch = 0.203\n",
            "12881/15750 (epoch 40), train_loss = 2.197, time/batch = 0.203\n",
            "12882/15750 (epoch 40), train_loss = 2.172, time/batch = 0.208\n",
            "12883/15750 (epoch 40), train_loss = 2.275, time/batch = 0.200\n",
            "12884/15750 (epoch 40), train_loss = 2.185, time/batch = 0.200\n",
            "12885/15750 (epoch 40), train_loss = 2.314, time/batch = 0.201\n",
            "12886/15750 (epoch 40), train_loss = 2.226, time/batch = 0.202\n",
            "12887/15750 (epoch 40), train_loss = 2.235, time/batch = 0.211\n",
            "12888/15750 (epoch 40), train_loss = 2.155, time/batch = 0.203\n",
            "12889/15750 (epoch 40), train_loss = 2.249, time/batch = 0.205\n",
            "12890/15750 (epoch 40), train_loss = 2.174, time/batch = 0.203\n",
            "12891/15750 (epoch 40), train_loss = 2.239, time/batch = 0.214\n",
            "12892/15750 (epoch 40), train_loss = 2.245, time/batch = 0.213\n",
            "12893/15750 (epoch 40), train_loss = 2.198, time/batch = 0.206\n",
            "12894/15750 (epoch 40), train_loss = 2.252, time/batch = 0.212\n",
            "12895/15750 (epoch 40), train_loss = 2.329, time/batch = 0.210\n",
            "12896/15750 (epoch 40), train_loss = 2.277, time/batch = 0.209\n",
            "12897/15750 (epoch 40), train_loss = 2.304, time/batch = 0.216\n",
            "12898/15750 (epoch 40), train_loss = 2.184, time/batch = 0.216\n",
            "12899/15750 (epoch 40), train_loss = 2.250, time/batch = 0.209\n",
            "12900/15750 (epoch 40), train_loss = 2.234, time/batch = 0.209\n",
            "12901/15750 (epoch 40), train_loss = 2.178, time/batch = 0.203\n",
            "12902/15750 (epoch 40), train_loss = 2.304, time/batch = 0.217\n",
            "12903/15750 (epoch 40), train_loss = 2.154, time/batch = 0.209\n",
            "12904/15750 (epoch 40), train_loss = 2.277, time/batch = 0.205\n",
            "12905/15750 (epoch 40), train_loss = 2.234, time/batch = 0.211\n",
            "12906/15750 (epoch 40), train_loss = 2.198, time/batch = 0.208\n",
            "12907/15750 (epoch 40), train_loss = 2.145, time/batch = 0.212\n",
            "12908/15750 (epoch 40), train_loss = 2.182, time/batch = 0.210\n",
            "12909/15750 (epoch 40), train_loss = 2.294, time/batch = 0.208\n",
            "12910/15750 (epoch 40), train_loss = 2.172, time/batch = 0.213\n",
            "12911/15750 (epoch 40), train_loss = 2.145, time/batch = 0.210\n",
            "12912/15750 (epoch 40), train_loss = 2.181, time/batch = 0.209\n",
            "12913/15750 (epoch 40), train_loss = 2.197, time/batch = 0.207\n",
            "12914/15750 (epoch 40), train_loss = 2.289, time/batch = 0.205\n",
            "12915/15750 (epoch 41), train_loss = 2.115, time/batch = 0.214\n",
            "12916/15750 (epoch 41), train_loss = 2.281, time/batch = 0.214\n",
            "12917/15750 (epoch 41), train_loss = 2.205, time/batch = 0.210\n",
            "12918/15750 (epoch 41), train_loss = 2.307, time/batch = 0.200\n",
            "12919/15750 (epoch 41), train_loss = 2.234, time/batch = 0.201\n",
            "12920/15750 (epoch 41), train_loss = 2.231, time/batch = 0.203\n",
            "12921/15750 (epoch 41), train_loss = 2.379, time/batch = 0.221\n",
            "12922/15750 (epoch 41), train_loss = 2.301, time/batch = 0.211\n",
            "12923/15750 (epoch 41), train_loss = 2.298, time/batch = 0.209\n",
            "12924/15750 (epoch 41), train_loss = 2.247, time/batch = 0.213\n",
            "12925/15750 (epoch 41), train_loss = 2.241, time/batch = 0.209\n",
            "12926/15750 (epoch 41), train_loss = 2.213, time/batch = 0.203\n",
            "12927/15750 (epoch 41), train_loss = 2.288, time/batch = 0.204\n",
            "12928/15750 (epoch 41), train_loss = 2.272, time/batch = 0.205\n",
            "12929/15750 (epoch 41), train_loss = 2.245, time/batch = 0.206\n",
            "12930/15750 (epoch 41), train_loss = 2.264, time/batch = 0.210\n",
            "12931/15750 (epoch 41), train_loss = 2.268, time/batch = 0.205\n",
            "12932/15750 (epoch 41), train_loss = 2.329, time/batch = 0.203\n",
            "12933/15750 (epoch 41), train_loss = 2.344, time/batch = 0.207\n",
            "12934/15750 (epoch 41), train_loss = 2.295, time/batch = 0.208\n",
            "12935/15750 (epoch 41), train_loss = 2.279, time/batch = 0.205\n",
            "12936/15750 (epoch 41), train_loss = 2.289, time/batch = 0.213\n",
            "12937/15750 (epoch 41), train_loss = 2.240, time/batch = 0.205\n",
            "12938/15750 (epoch 41), train_loss = 2.299, time/batch = 0.208\n",
            "12939/15750 (epoch 41), train_loss = 2.304, time/batch = 0.210\n",
            "12940/15750 (epoch 41), train_loss = 2.324, time/batch = 0.210\n",
            "12941/15750 (epoch 41), train_loss = 2.332, time/batch = 0.207\n",
            "12942/15750 (epoch 41), train_loss = 2.312, time/batch = 0.207\n",
            "12943/15750 (epoch 41), train_loss = 2.418, time/batch = 0.211\n",
            "12944/15750 (epoch 41), train_loss = 2.333, time/batch = 0.208\n",
            "12945/15750 (epoch 41), train_loss = 2.295, time/batch = 0.213\n",
            "12946/15750 (epoch 41), train_loss = 2.262, time/batch = 0.208\n",
            "12947/15750 (epoch 41), train_loss = 2.179, time/batch = 0.208\n",
            "12948/15750 (epoch 41), train_loss = 2.192, time/batch = 0.208\n",
            "12949/15750 (epoch 41), train_loss = 2.279, time/batch = 0.208\n",
            "12950/15750 (epoch 41), train_loss = 2.178, time/batch = 0.207\n",
            "12951/15750 (epoch 41), train_loss = 2.264, time/batch = 0.203\n",
            "12952/15750 (epoch 41), train_loss = 2.312, time/batch = 0.203\n",
            "12953/15750 (epoch 41), train_loss = 2.221, time/batch = 0.203\n",
            "12954/15750 (epoch 41), train_loss = 2.268, time/batch = 0.206\n",
            "12955/15750 (epoch 41), train_loss = 2.227, time/batch = 0.208\n",
            "12956/15750 (epoch 41), train_loss = 2.277, time/batch = 0.206\n",
            "12957/15750 (epoch 41), train_loss = 2.275, time/batch = 0.210\n",
            "12958/15750 (epoch 41), train_loss = 2.242, time/batch = 0.213\n",
            "12959/15750 (epoch 41), train_loss = 2.272, time/batch = 0.210\n",
            "12960/15750 (epoch 41), train_loss = 2.201, time/batch = 0.215\n",
            "12961/15750 (epoch 41), train_loss = 2.244, time/batch = 0.208\n",
            "12962/15750 (epoch 41), train_loss = 2.253, time/batch = 0.211\n",
            "12963/15750 (epoch 41), train_loss = 2.296, time/batch = 0.207\n",
            "12964/15750 (epoch 41), train_loss = 2.179, time/batch = 0.205\n",
            "12965/15750 (epoch 41), train_loss = 2.252, time/batch = 0.212\n",
            "12966/15750 (epoch 41), train_loss = 2.201, time/batch = 0.200\n",
            "12967/15750 (epoch 41), train_loss = 2.254, time/batch = 0.208\n",
            "12968/15750 (epoch 41), train_loss = 2.271, time/batch = 0.207\n",
            "12969/15750 (epoch 41), train_loss = 2.268, time/batch = 0.204\n",
            "12970/15750 (epoch 41), train_loss = 2.301, time/batch = 0.208\n",
            "12971/15750 (epoch 41), train_loss = 2.189, time/batch = 0.203\n",
            "12972/15750 (epoch 41), train_loss = 2.180, time/batch = 0.209\n",
            "12973/15750 (epoch 41), train_loss = 2.281, time/batch = 0.212\n",
            "12974/15750 (epoch 41), train_loss = 2.145, time/batch = 0.209\n",
            "12975/15750 (epoch 41), train_loss = 2.243, time/batch = 0.212\n",
            "12976/15750 (epoch 41), train_loss = 2.251, time/batch = 0.206\n",
            "12977/15750 (epoch 41), train_loss = 2.177, time/batch = 0.208\n",
            "12978/15750 (epoch 41), train_loss = 2.235, time/batch = 0.207\n",
            "12979/15750 (epoch 41), train_loss = 2.140, time/batch = 0.203\n",
            "12980/15750 (epoch 41), train_loss = 2.165, time/batch = 0.209\n",
            "12981/15750 (epoch 41), train_loss = 2.103, time/batch = 0.206\n",
            "12982/15750 (epoch 41), train_loss = 2.119, time/batch = 0.207\n",
            "12983/15750 (epoch 41), train_loss = 2.173, time/batch = 0.206\n",
            "12984/15750 (epoch 41), train_loss = 2.275, time/batch = 0.210\n",
            "12985/15750 (epoch 41), train_loss = 2.194, time/batch = 0.214\n",
            "12986/15750 (epoch 41), train_loss = 2.182, time/batch = 0.206\n",
            "12987/15750 (epoch 41), train_loss = 2.109, time/batch = 0.206\n",
            "12988/15750 (epoch 41), train_loss = 2.166, time/batch = 0.206\n",
            "12989/15750 (epoch 41), train_loss = 2.286, time/batch = 0.212\n",
            "12990/15750 (epoch 41), train_loss = 2.223, time/batch = 0.219\n",
            "12991/15750 (epoch 41), train_loss = 2.217, time/batch = 0.208\n",
            "12992/15750 (epoch 41), train_loss = 2.213, time/batch = 0.207\n",
            "12993/15750 (epoch 41), train_loss = 2.222, time/batch = 0.210\n",
            "12994/15750 (epoch 41), train_loss = 2.213, time/batch = 0.208\n",
            "12995/15750 (epoch 41), train_loss = 2.112, time/batch = 0.206\n",
            "12996/15750 (epoch 41), train_loss = 2.215, time/batch = 0.205\n",
            "12997/15750 (epoch 41), train_loss = 2.163, time/batch = 0.208\n",
            "12998/15750 (epoch 41), train_loss = 2.213, time/batch = 0.206\n",
            "12999/15750 (epoch 41), train_loss = 2.266, time/batch = 0.213\n",
            "13000/15750 (epoch 41), train_loss = 2.287, time/batch = 0.206\n",
            "model saved to ./save_star/model.ckpt\n",
            "13001/15750 (epoch 41), train_loss = 2.124, time/batch = 0.207\n",
            "13002/15750 (epoch 41), train_loss = 2.166, time/batch = 0.212\n",
            "13003/15750 (epoch 41), train_loss = 2.179, time/batch = 0.214\n",
            "13004/15750 (epoch 41), train_loss = 2.188, time/batch = 0.210\n",
            "13005/15750 (epoch 41), train_loss = 2.177, time/batch = 0.211\n",
            "13006/15750 (epoch 41), train_loss = 2.240, time/batch = 0.208\n",
            "13007/15750 (epoch 41), train_loss = 2.226, time/batch = 0.208\n",
            "13008/15750 (epoch 41), train_loss = 2.237, time/batch = 0.207\n",
            "13009/15750 (epoch 41), train_loss = 2.298, time/batch = 0.212\n",
            "13010/15750 (epoch 41), train_loss = 2.217, time/batch = 0.206\n",
            "13011/15750 (epoch 41), train_loss = 2.246, time/batch = 0.211\n",
            "13012/15750 (epoch 41), train_loss = 2.265, time/batch = 0.207\n",
            "13013/15750 (epoch 41), train_loss = 2.242, time/batch = 0.209\n",
            "13014/15750 (epoch 41), train_loss = 2.256, time/batch = 0.213\n",
            "13015/15750 (epoch 41), train_loss = 2.232, time/batch = 0.212\n",
            "13016/15750 (epoch 41), train_loss = 2.179, time/batch = 0.209\n",
            "13017/15750 (epoch 41), train_loss = 2.192, time/batch = 0.215\n",
            "13018/15750 (epoch 41), train_loss = 2.315, time/batch = 0.206\n",
            "13019/15750 (epoch 41), train_loss = 2.237, time/batch = 0.208\n",
            "13020/15750 (epoch 41), train_loss = 2.145, time/batch = 0.206\n",
            "13021/15750 (epoch 41), train_loss = 2.212, time/batch = 0.204\n",
            "13022/15750 (epoch 41), train_loss = 2.241, time/batch = 0.206\n",
            "13023/15750 (epoch 41), train_loss = 2.270, time/batch = 0.196\n",
            "13024/15750 (epoch 41), train_loss = 2.299, time/batch = 0.201\n",
            "13025/15750 (epoch 41), train_loss = 2.358, time/batch = 0.202\n",
            "13026/15750 (epoch 41), train_loss = 2.218, time/batch = 0.199\n",
            "13027/15750 (epoch 41), train_loss = 2.231, time/batch = 0.202\n",
            "13028/15750 (epoch 41), train_loss = 2.224, time/batch = 0.197\n",
            "13029/15750 (epoch 41), train_loss = 2.225, time/batch = 0.206\n",
            "13030/15750 (epoch 41), train_loss = 2.315, time/batch = 0.210\n",
            "13031/15750 (epoch 41), train_loss = 2.239, time/batch = 0.205\n",
            "13032/15750 (epoch 41), train_loss = 2.353, time/batch = 0.210\n",
            "13033/15750 (epoch 41), train_loss = 2.237, time/batch = 0.205\n",
            "13034/15750 (epoch 41), train_loss = 2.230, time/batch = 0.210\n",
            "13035/15750 (epoch 41), train_loss = 2.202, time/batch = 0.208\n",
            "13036/15750 (epoch 41), train_loss = 2.181, time/batch = 0.210\n",
            "13037/15750 (epoch 41), train_loss = 2.224, time/batch = 0.215\n",
            "13038/15750 (epoch 41), train_loss = 2.173, time/batch = 0.210\n",
            "13039/15750 (epoch 41), train_loss = 2.209, time/batch = 0.207\n",
            "13040/15750 (epoch 41), train_loss = 2.225, time/batch = 0.212\n",
            "13041/15750 (epoch 41), train_loss = 2.310, time/batch = 0.209\n",
            "13042/15750 (epoch 41), train_loss = 2.197, time/batch = 0.213\n",
            "13043/15750 (epoch 41), train_loss = 2.220, time/batch = 0.207\n",
            "13044/15750 (epoch 41), train_loss = 2.182, time/batch = 0.203\n",
            "13045/15750 (epoch 41), train_loss = 2.139, time/batch = 0.201\n",
            "13046/15750 (epoch 41), train_loss = 2.152, time/batch = 0.201\n",
            "13047/15750 (epoch 41), train_loss = 2.161, time/batch = 0.211\n",
            "13048/15750 (epoch 41), train_loss = 2.184, time/batch = 0.211\n",
            "13049/15750 (epoch 41), train_loss = 2.199, time/batch = 0.208\n",
            "13050/15750 (epoch 41), train_loss = 2.330, time/batch = 0.213\n",
            "13051/15750 (epoch 41), train_loss = 2.288, time/batch = 0.205\n",
            "13052/15750 (epoch 41), train_loss = 2.290, time/batch = 0.213\n",
            "13053/15750 (epoch 41), train_loss = 2.278, time/batch = 0.210\n",
            "13054/15750 (epoch 41), train_loss = 2.201, time/batch = 0.211\n",
            "13055/15750 (epoch 41), train_loss = 2.204, time/batch = 0.209\n",
            "13056/15750 (epoch 41), train_loss = 2.297, time/batch = 0.203\n",
            "13057/15750 (epoch 41), train_loss = 2.314, time/batch = 0.215\n",
            "13058/15750 (epoch 41), train_loss = 2.287, time/batch = 0.207\n",
            "13059/15750 (epoch 41), train_loss = 2.203, time/batch = 0.207\n",
            "13060/15750 (epoch 41), train_loss = 2.199, time/batch = 0.205\n",
            "13061/15750 (epoch 41), train_loss = 2.166, time/batch = 0.211\n",
            "13062/15750 (epoch 41), train_loss = 2.258, time/batch = 0.212\n",
            "13063/15750 (epoch 41), train_loss = 2.287, time/batch = 0.210\n",
            "13064/15750 (epoch 41), train_loss = 2.236, time/batch = 0.206\n",
            "13065/15750 (epoch 41), train_loss = 2.224, time/batch = 0.205\n",
            "13066/15750 (epoch 41), train_loss = 2.266, time/batch = 0.216\n",
            "13067/15750 (epoch 41), train_loss = 2.298, time/batch = 0.209\n",
            "13068/15750 (epoch 41), train_loss = 2.249, time/batch = 0.208\n",
            "13069/15750 (epoch 41), train_loss = 2.262, time/batch = 0.212\n",
            "13070/15750 (epoch 41), train_loss = 2.260, time/batch = 0.201\n",
            "13071/15750 (epoch 41), train_loss = 2.259, time/batch = 0.205\n",
            "13072/15750 (epoch 41), train_loss = 2.254, time/batch = 0.207\n",
            "13073/15750 (epoch 41), train_loss = 2.336, time/batch = 0.211\n",
            "13074/15750 (epoch 41), train_loss = 2.198, time/batch = 0.202\n",
            "13075/15750 (epoch 41), train_loss = 2.276, time/batch = 0.199\n",
            "13076/15750 (epoch 41), train_loss = 2.260, time/batch = 0.205\n",
            "13077/15750 (epoch 41), train_loss = 2.284, time/batch = 0.218\n",
            "13078/15750 (epoch 41), train_loss = 2.352, time/batch = 0.210\n",
            "13079/15750 (epoch 41), train_loss = 2.277, time/batch = 0.212\n",
            "13080/15750 (epoch 41), train_loss = 2.277, time/batch = 0.209\n",
            "13081/15750 (epoch 41), train_loss = 2.261, time/batch = 0.207\n",
            "13082/15750 (epoch 41), train_loss = 2.233, time/batch = 0.209\n",
            "13083/15750 (epoch 41), train_loss = 2.198, time/batch = 0.213\n",
            "13084/15750 (epoch 41), train_loss = 2.190, time/batch = 0.205\n",
            "13085/15750 (epoch 41), train_loss = 2.231, time/batch = 0.223\n",
            "13086/15750 (epoch 41), train_loss = 2.264, time/batch = 0.217\n",
            "13087/15750 (epoch 41), train_loss = 2.238, time/batch = 0.207\n",
            "13088/15750 (epoch 41), train_loss = 2.309, time/batch = 0.209\n",
            "13089/15750 (epoch 41), train_loss = 2.240, time/batch = 0.207\n",
            "13090/15750 (epoch 41), train_loss = 2.175, time/batch = 0.207\n",
            "13091/15750 (epoch 41), train_loss = 2.202, time/batch = 0.219\n",
            "13092/15750 (epoch 41), train_loss = 2.263, time/batch = 0.209\n",
            "13093/15750 (epoch 41), train_loss = 2.198, time/batch = 0.208\n",
            "13094/15750 (epoch 41), train_loss = 2.157, time/batch = 0.212\n",
            "13095/15750 (epoch 41), train_loss = 2.194, time/batch = 0.208\n",
            "13096/15750 (epoch 41), train_loss = 2.269, time/batch = 0.216\n",
            "13097/15750 (epoch 41), train_loss = 2.247, time/batch = 0.209\n",
            "13098/15750 (epoch 41), train_loss = 2.308, time/batch = 0.207\n",
            "13099/15750 (epoch 41), train_loss = 2.284, time/batch = 0.205\n",
            "13100/15750 (epoch 41), train_loss = 2.247, time/batch = 0.211\n",
            "13101/15750 (epoch 41), train_loss = 2.201, time/batch = 0.218\n",
            "13102/15750 (epoch 41), train_loss = 2.269, time/batch = 0.212\n",
            "13103/15750 (epoch 41), train_loss = 2.293, time/batch = 0.205\n",
            "13104/15750 (epoch 41), train_loss = 2.353, time/batch = 0.211\n",
            "13105/15750 (epoch 41), train_loss = 2.341, time/batch = 0.211\n",
            "13106/15750 (epoch 41), train_loss = 2.245, time/batch = 0.218\n",
            "13107/15750 (epoch 41), train_loss = 2.263, time/batch = 0.206\n",
            "13108/15750 (epoch 41), train_loss = 2.191, time/batch = 0.206\n",
            "13109/15750 (epoch 41), train_loss = 2.320, time/batch = 0.209\n",
            "13110/15750 (epoch 41), train_loss = 2.286, time/batch = 0.208\n",
            "13111/15750 (epoch 41), train_loss = 2.243, time/batch = 0.208\n",
            "13112/15750 (epoch 41), train_loss = 2.191, time/batch = 0.207\n",
            "13113/15750 (epoch 41), train_loss = 2.297, time/batch = 0.208\n",
            "13114/15750 (epoch 41), train_loss = 2.082, time/batch = 0.207\n",
            "13115/15750 (epoch 41), train_loss = 2.196, time/batch = 0.208\n",
            "13116/15750 (epoch 41), train_loss = 2.161, time/batch = 0.218\n",
            "13117/15750 (epoch 41), train_loss = 2.236, time/batch = 0.208\n",
            "13118/15750 (epoch 41), train_loss = 2.206, time/batch = 0.205\n",
            "13119/15750 (epoch 41), train_loss = 2.276, time/batch = 0.209\n",
            "13120/15750 (epoch 41), train_loss = 2.215, time/batch = 0.205\n",
            "13121/15750 (epoch 41), train_loss = 2.106, time/batch = 0.206\n",
            "13122/15750 (epoch 41), train_loss = 2.170, time/batch = 0.209\n",
            "13123/15750 (epoch 41), train_loss = 2.176, time/batch = 0.207\n",
            "13124/15750 (epoch 41), train_loss = 2.239, time/batch = 0.205\n",
            "13125/15750 (epoch 41), train_loss = 2.129, time/batch = 0.206\n",
            "13126/15750 (epoch 41), train_loss = 2.203, time/batch = 0.207\n",
            "13127/15750 (epoch 41), train_loss = 2.096, time/batch = 0.203\n",
            "13128/15750 (epoch 41), train_loss = 2.166, time/batch = 0.201\n",
            "13129/15750 (epoch 41), train_loss = 2.156, time/batch = 0.202\n",
            "13130/15750 (epoch 41), train_loss = 2.139, time/batch = 0.202\n",
            "13131/15750 (epoch 41), train_loss = 2.299, time/batch = 0.210\n",
            "13132/15750 (epoch 41), train_loss = 2.123, time/batch = 0.201\n",
            "13133/15750 (epoch 41), train_loss = 2.366, time/batch = 0.211\n",
            "13134/15750 (epoch 41), train_loss = 2.233, time/batch = 0.210\n",
            "13135/15750 (epoch 41), train_loss = 2.117, time/batch = 0.213\n",
            "13136/15750 (epoch 41), train_loss = 2.144, time/batch = 0.213\n",
            "13137/15750 (epoch 41), train_loss = 2.208, time/batch = 0.208\n",
            "13138/15750 (epoch 41), train_loss = 2.194, time/batch = 0.208\n",
            "13139/15750 (epoch 41), train_loss = 2.178, time/batch = 0.209\n",
            "13140/15750 (epoch 41), train_loss = 2.190, time/batch = 0.206\n",
            "13141/15750 (epoch 41), train_loss = 2.253, time/batch = 0.204\n",
            "13142/15750 (epoch 41), train_loss = 2.175, time/batch = 0.211\n",
            "13143/15750 (epoch 41), train_loss = 2.221, time/batch = 0.208\n",
            "13144/15750 (epoch 41), train_loss = 2.305, time/batch = 0.204\n",
            "13145/15750 (epoch 41), train_loss = 2.160, time/batch = 0.206\n",
            "13146/15750 (epoch 41), train_loss = 2.175, time/batch = 0.205\n",
            "13147/15750 (epoch 41), train_loss = 2.215, time/batch = 0.203\n",
            "13148/15750 (epoch 41), train_loss = 2.218, time/batch = 0.209\n",
            "13149/15750 (epoch 41), train_loss = 2.171, time/batch = 0.213\n",
            "13150/15750 (epoch 41), train_loss = 2.159, time/batch = 0.217\n",
            "13151/15750 (epoch 41), train_loss = 2.130, time/batch = 0.212\n",
            "13152/15750 (epoch 41), train_loss = 2.175, time/batch = 0.207\n",
            "13153/15750 (epoch 41), train_loss = 2.375, time/batch = 0.214\n",
            "13154/15750 (epoch 41), train_loss = 2.210, time/batch = 0.205\n",
            "13155/15750 (epoch 41), train_loss = 2.265, time/batch = 0.216\n",
            "13156/15750 (epoch 41), train_loss = 2.146, time/batch = 0.203\n",
            "13157/15750 (epoch 41), train_loss = 2.194, time/batch = 0.205\n",
            "13158/15750 (epoch 41), train_loss = 2.218, time/batch = 0.212\n",
            "13159/15750 (epoch 41), train_loss = 2.228, time/batch = 0.202\n",
            "13160/15750 (epoch 41), train_loss = 2.282, time/batch = 0.210\n",
            "13161/15750 (epoch 41), train_loss = 2.236, time/batch = 0.209\n",
            "13162/15750 (epoch 41), train_loss = 2.238, time/batch = 0.208\n",
            "13163/15750 (epoch 41), train_loss = 2.211, time/batch = 0.210\n",
            "13164/15750 (epoch 41), train_loss = 2.236, time/batch = 0.206\n",
            "13165/15750 (epoch 41), train_loss = 2.143, time/batch = 0.218\n",
            "13166/15750 (epoch 41), train_loss = 2.134, time/batch = 0.207\n",
            "13167/15750 (epoch 41), train_loss = 2.225, time/batch = 0.211\n",
            "13168/15750 (epoch 41), train_loss = 2.242, time/batch = 0.200\n",
            "13169/15750 (epoch 41), train_loss = 2.210, time/batch = 0.207\n",
            "13170/15750 (epoch 41), train_loss = 2.176, time/batch = 0.211\n",
            "13171/15750 (epoch 41), train_loss = 2.126, time/batch = 0.206\n",
            "13172/15750 (epoch 41), train_loss = 2.155, time/batch = 0.204\n",
            "13173/15750 (epoch 41), train_loss = 2.304, time/batch = 0.205\n",
            "13174/15750 (epoch 41), train_loss = 2.279, time/batch = 0.207\n",
            "13175/15750 (epoch 41), train_loss = 2.253, time/batch = 0.210\n",
            "13176/15750 (epoch 41), train_loss = 2.199, time/batch = 0.203\n",
            "13177/15750 (epoch 41), train_loss = 2.221, time/batch = 0.202\n",
            "13178/15750 (epoch 41), train_loss = 2.212, time/batch = 0.200\n",
            "13179/15750 (epoch 41), train_loss = 2.228, time/batch = 0.202\n",
            "13180/15750 (epoch 41), train_loss = 2.279, time/batch = 0.215\n",
            "13181/15750 (epoch 41), train_loss = 2.278, time/batch = 0.208\n",
            "13182/15750 (epoch 41), train_loss = 2.209, time/batch = 0.212\n",
            "13183/15750 (epoch 41), train_loss = 2.238, time/batch = 0.209\n",
            "13184/15750 (epoch 41), train_loss = 2.276, time/batch = 0.215\n",
            "13185/15750 (epoch 41), train_loss = 2.261, time/batch = 0.219\n",
            "13186/15750 (epoch 41), train_loss = 2.176, time/batch = 0.208\n",
            "13187/15750 (epoch 41), train_loss = 2.212, time/batch = 0.209\n",
            "13188/15750 (epoch 41), train_loss = 2.270, time/batch = 0.202\n",
            "13189/15750 (epoch 41), train_loss = 2.284, time/batch = 0.208\n",
            "13190/15750 (epoch 41), train_loss = 2.225, time/batch = 0.206\n",
            "13191/15750 (epoch 41), train_loss = 2.289, time/batch = 0.207\n",
            "13192/15750 (epoch 41), train_loss = 2.226, time/batch = 0.207\n",
            "13193/15750 (epoch 41), train_loss = 2.202, time/batch = 0.207\n",
            "13194/15750 (epoch 41), train_loss = 2.151, time/batch = 0.210\n",
            "13195/15750 (epoch 41), train_loss = 2.362, time/batch = 0.202\n",
            "13196/15750 (epoch 41), train_loss = 2.192, time/batch = 0.208\n",
            "13197/15750 (epoch 41), train_loss = 2.167, time/batch = 0.211\n",
            "13198/15750 (epoch 41), train_loss = 2.271, time/batch = 0.206\n",
            "13199/15750 (epoch 41), train_loss = 2.181, time/batch = 0.208\n",
            "13200/15750 (epoch 41), train_loss = 2.309, time/batch = 0.209\n",
            "13201/15750 (epoch 41), train_loss = 2.222, time/batch = 0.209\n",
            "13202/15750 (epoch 41), train_loss = 2.230, time/batch = 0.203\n",
            "13203/15750 (epoch 41), train_loss = 2.151, time/batch = 0.207\n",
            "13204/15750 (epoch 41), train_loss = 2.245, time/batch = 0.211\n",
            "13205/15750 (epoch 41), train_loss = 2.169, time/batch = 0.208\n",
            "13206/15750 (epoch 41), train_loss = 2.234, time/batch = 0.210\n",
            "13207/15750 (epoch 41), train_loss = 2.241, time/batch = 0.208\n",
            "13208/15750 (epoch 41), train_loss = 2.193, time/batch = 0.206\n",
            "13209/15750 (epoch 41), train_loss = 2.248, time/batch = 0.206\n",
            "13210/15750 (epoch 41), train_loss = 2.324, time/batch = 0.209\n",
            "13211/15750 (epoch 41), train_loss = 2.272, time/batch = 0.211\n",
            "13212/15750 (epoch 41), train_loss = 2.299, time/batch = 0.205\n",
            "13213/15750 (epoch 41), train_loss = 2.180, time/batch = 0.205\n",
            "13214/15750 (epoch 41), train_loss = 2.246, time/batch = 0.206\n",
            "13215/15750 (epoch 41), train_loss = 2.230, time/batch = 0.201\n",
            "13216/15750 (epoch 41), train_loss = 2.174, time/batch = 0.206\n",
            "13217/15750 (epoch 41), train_loss = 2.300, time/batch = 0.204\n",
            "13218/15750 (epoch 41), train_loss = 2.150, time/batch = 0.209\n",
            "13219/15750 (epoch 41), train_loss = 2.273, time/batch = 0.210\n",
            "13220/15750 (epoch 41), train_loss = 2.230, time/batch = 0.206\n",
            "13221/15750 (epoch 41), train_loss = 2.193, time/batch = 0.207\n",
            "13222/15750 (epoch 41), train_loss = 2.141, time/batch = 0.210\n",
            "13223/15750 (epoch 41), train_loss = 2.178, time/batch = 0.209\n",
            "13224/15750 (epoch 41), train_loss = 2.289, time/batch = 0.211\n",
            "13225/15750 (epoch 41), train_loss = 2.168, time/batch = 0.205\n",
            "13226/15750 (epoch 41), train_loss = 2.141, time/batch = 0.206\n",
            "13227/15750 (epoch 41), train_loss = 2.177, time/batch = 0.201\n",
            "13228/15750 (epoch 41), train_loss = 2.194, time/batch = 0.204\n",
            "13229/15750 (epoch 41), train_loss = 2.284, time/batch = 0.212\n",
            "13230/15750 (epoch 42), train_loss = 2.102, time/batch = 0.208\n",
            "13231/15750 (epoch 42), train_loss = 2.276, time/batch = 0.210\n",
            "13232/15750 (epoch 42), train_loss = 2.201, time/batch = 0.205\n",
            "13233/15750 (epoch 42), train_loss = 2.303, time/batch = 0.213\n",
            "13234/15750 (epoch 42), train_loss = 2.230, time/batch = 0.210\n",
            "13235/15750 (epoch 42), train_loss = 2.227, time/batch = 0.203\n",
            "13236/15750 (epoch 42), train_loss = 2.375, time/batch = 0.204\n",
            "13237/15750 (epoch 42), train_loss = 2.297, time/batch = 0.208\n",
            "13238/15750 (epoch 42), train_loss = 2.293, time/batch = 0.218\n",
            "13239/15750 (epoch 42), train_loss = 2.242, time/batch = 0.207\n",
            "13240/15750 (epoch 42), train_loss = 2.236, time/batch = 0.213\n",
            "13241/15750 (epoch 42), train_loss = 2.209, time/batch = 0.210\n",
            "13242/15750 (epoch 42), train_loss = 2.284, time/batch = 0.205\n",
            "13243/15750 (epoch 42), train_loss = 2.268, time/batch = 0.213\n",
            "13244/15750 (epoch 42), train_loss = 2.241, time/batch = 0.204\n",
            "13245/15750 (epoch 42), train_loss = 2.260, time/batch = 0.205\n",
            "13246/15750 (epoch 42), train_loss = 2.263, time/batch = 0.210\n",
            "13247/15750 (epoch 42), train_loss = 2.324, time/batch = 0.205\n",
            "13248/15750 (epoch 42), train_loss = 2.340, time/batch = 0.215\n",
            "13249/15750 (epoch 42), train_loss = 2.291, time/batch = 0.202\n",
            "13250/15750 (epoch 42), train_loss = 2.274, time/batch = 0.204\n",
            "13251/15750 (epoch 42), train_loss = 2.285, time/batch = 0.208\n",
            "13252/15750 (epoch 42), train_loss = 2.236, time/batch = 0.217\n",
            "13253/15750 (epoch 42), train_loss = 2.294, time/batch = 0.207\n",
            "13254/15750 (epoch 42), train_loss = 2.304, time/batch = 0.206\n",
            "13255/15750 (epoch 42), train_loss = 2.321, time/batch = 0.207\n",
            "13256/15750 (epoch 42), train_loss = 2.329, time/batch = 0.206\n",
            "13257/15750 (epoch 42), train_loss = 2.307, time/batch = 0.207\n",
            "13258/15750 (epoch 42), train_loss = 2.413, time/batch = 0.214\n",
            "13259/15750 (epoch 42), train_loss = 2.328, time/batch = 0.205\n",
            "13260/15750 (epoch 42), train_loss = 2.290, time/batch = 0.207\n",
            "13261/15750 (epoch 42), train_loss = 2.258, time/batch = 0.207\n",
            "13262/15750 (epoch 42), train_loss = 2.174, time/batch = 0.206\n",
            "13263/15750 (epoch 42), train_loss = 2.188, time/batch = 0.214\n",
            "13264/15750 (epoch 42), train_loss = 2.275, time/batch = 0.202\n",
            "13265/15750 (epoch 42), train_loss = 2.174, time/batch = 0.207\n",
            "13266/15750 (epoch 42), train_loss = 2.260, time/batch = 0.202\n",
            "13267/15750 (epoch 42), train_loss = 2.308, time/batch = 0.204\n",
            "13268/15750 (epoch 42), train_loss = 2.217, time/batch = 0.217\n",
            "13269/15750 (epoch 42), train_loss = 2.264, time/batch = 0.210\n",
            "13270/15750 (epoch 42), train_loss = 2.223, time/batch = 0.212\n",
            "13271/15750 (epoch 42), train_loss = 2.273, time/batch = 0.204\n",
            "13272/15750 (epoch 42), train_loss = 2.271, time/batch = 0.210\n",
            "13273/15750 (epoch 42), train_loss = 2.238, time/batch = 0.207\n",
            "13274/15750 (epoch 42), train_loss = 2.268, time/batch = 0.209\n",
            "13275/15750 (epoch 42), train_loss = 2.198, time/batch = 0.210\n",
            "13276/15750 (epoch 42), train_loss = 2.240, time/batch = 0.210\n",
            "13277/15750 (epoch 42), train_loss = 2.249, time/batch = 0.212\n",
            "13278/15750 (epoch 42), train_loss = 2.291, time/batch = 0.209\n",
            "13279/15750 (epoch 42), train_loss = 2.175, time/batch = 0.208\n",
            "13280/15750 (epoch 42), train_loss = 2.248, time/batch = 0.207\n",
            "13281/15750 (epoch 42), train_loss = 2.197, time/batch = 0.204\n",
            "13282/15750 (epoch 42), train_loss = 2.250, time/batch = 0.204\n",
            "13283/15750 (epoch 42), train_loss = 2.268, time/batch = 0.202\n",
            "13284/15750 (epoch 42), train_loss = 2.264, time/batch = 0.207\n",
            "13285/15750 (epoch 42), train_loss = 2.297, time/batch = 0.203\n",
            "13286/15750 (epoch 42), train_loss = 2.185, time/batch = 0.208\n",
            "13287/15750 (epoch 42), train_loss = 2.176, time/batch = 0.213\n",
            "13288/15750 (epoch 42), train_loss = 2.277, time/batch = 0.211\n",
            "13289/15750 (epoch 42), train_loss = 2.141, time/batch = 0.209\n",
            "13290/15750 (epoch 42), train_loss = 2.239, time/batch = 0.205\n",
            "13291/15750 (epoch 42), train_loss = 2.247, time/batch = 0.210\n",
            "13292/15750 (epoch 42), train_loss = 2.173, time/batch = 0.217\n",
            "13293/15750 (epoch 42), train_loss = 2.231, time/batch = 0.209\n",
            "13294/15750 (epoch 42), train_loss = 2.136, time/batch = 0.211\n",
            "13295/15750 (epoch 42), train_loss = 2.161, time/batch = 0.208\n",
            "13296/15750 (epoch 42), train_loss = 2.099, time/batch = 0.208\n",
            "13297/15750 (epoch 42), train_loss = 2.115, time/batch = 0.213\n",
            "13298/15750 (epoch 42), train_loss = 2.168, time/batch = 0.203\n",
            "13299/15750 (epoch 42), train_loss = 2.271, time/batch = 0.204\n",
            "13300/15750 (epoch 42), train_loss = 2.190, time/batch = 0.205\n",
            "13301/15750 (epoch 42), train_loss = 2.178, time/batch = 0.206\n",
            "13302/15750 (epoch 42), train_loss = 2.105, time/batch = 0.210\n",
            "13303/15750 (epoch 42), train_loss = 2.162, time/batch = 0.211\n",
            "13304/15750 (epoch 42), train_loss = 2.282, time/batch = 0.210\n",
            "13305/15750 (epoch 42), train_loss = 2.220, time/batch = 0.213\n",
            "13306/15750 (epoch 42), train_loss = 2.213, time/batch = 0.210\n",
            "13307/15750 (epoch 42), train_loss = 2.209, time/batch = 0.213\n",
            "13308/15750 (epoch 42), train_loss = 2.218, time/batch = 0.209\n",
            "13309/15750 (epoch 42), train_loss = 2.208, time/batch = 0.203\n",
            "13310/15750 (epoch 42), train_loss = 2.108, time/batch = 0.203\n",
            "13311/15750 (epoch 42), train_loss = 2.211, time/batch = 0.205\n",
            "13312/15750 (epoch 42), train_loss = 2.160, time/batch = 0.206\n",
            "13313/15750 (epoch 42), train_loss = 2.209, time/batch = 0.205\n",
            "13314/15750 (epoch 42), train_loss = 2.261, time/batch = 0.200\n",
            "13315/15750 (epoch 42), train_loss = 2.282, time/batch = 0.201\n",
            "13316/15750 (epoch 42), train_loss = 2.120, time/batch = 0.204\n",
            "13317/15750 (epoch 42), train_loss = 2.162, time/batch = 0.212\n",
            "13318/15750 (epoch 42), train_loss = 2.175, time/batch = 0.205\n",
            "13319/15750 (epoch 42), train_loss = 2.184, time/batch = 0.202\n",
            "13320/15750 (epoch 42), train_loss = 2.172, time/batch = 0.205\n",
            "13321/15750 (epoch 42), train_loss = 2.235, time/batch = 0.207\n",
            "13322/15750 (epoch 42), train_loss = 2.222, time/batch = 0.209\n",
            "13323/15750 (epoch 42), train_loss = 2.232, time/batch = 0.210\n",
            "13324/15750 (epoch 42), train_loss = 2.294, time/batch = 0.212\n",
            "13325/15750 (epoch 42), train_loss = 2.213, time/batch = 0.207\n",
            "13326/15750 (epoch 42), train_loss = 2.242, time/batch = 0.213\n",
            "13327/15750 (epoch 42), train_loss = 2.261, time/batch = 0.217\n",
            "13328/15750 (epoch 42), train_loss = 2.238, time/batch = 0.205\n",
            "13329/15750 (epoch 42), train_loss = 2.251, time/batch = 0.212\n",
            "13330/15750 (epoch 42), train_loss = 2.228, time/batch = 0.209\n",
            "13331/15750 (epoch 42), train_loss = 2.175, time/batch = 0.211\n",
            "13332/15750 (epoch 42), train_loss = 2.188, time/batch = 0.202\n",
            "13333/15750 (epoch 42), train_loss = 2.311, time/batch = 0.201\n",
            "13334/15750 (epoch 42), train_loss = 2.233, time/batch = 0.201\n",
            "13335/15750 (epoch 42), train_loss = 2.141, time/batch = 0.200\n",
            "13336/15750 (epoch 42), train_loss = 2.208, time/batch = 0.201\n",
            "13337/15750 (epoch 42), train_loss = 2.237, time/batch = 0.219\n",
            "13338/15750 (epoch 42), train_loss = 2.265, time/batch = 0.210\n",
            "13339/15750 (epoch 42), train_loss = 2.295, time/batch = 0.212\n",
            "13340/15750 (epoch 42), train_loss = 2.354, time/batch = 0.208\n",
            "13341/15750 (epoch 42), train_loss = 2.213, time/batch = 0.210\n",
            "13342/15750 (epoch 42), train_loss = 2.228, time/batch = 0.209\n",
            "13343/15750 (epoch 42), train_loss = 2.220, time/batch = 0.206\n",
            "13344/15750 (epoch 42), train_loss = 2.221, time/batch = 0.211\n",
            "13345/15750 (epoch 42), train_loss = 2.310, time/batch = 0.209\n",
            "13346/15750 (epoch 42), train_loss = 2.234, time/batch = 0.206\n",
            "13347/15750 (epoch 42), train_loss = 2.348, time/batch = 0.205\n",
            "13348/15750 (epoch 42), train_loss = 2.233, time/batch = 0.205\n",
            "13349/15750 (epoch 42), train_loss = 2.226, time/batch = 0.206\n",
            "13350/15750 (epoch 42), train_loss = 2.198, time/batch = 0.207\n",
            "13351/15750 (epoch 42), train_loss = 2.177, time/batch = 0.213\n",
            "13352/15750 (epoch 42), train_loss = 2.220, time/batch = 0.205\n",
            "13353/15750 (epoch 42), train_loss = 2.169, time/batch = 0.243\n",
            "13354/15750 (epoch 42), train_loss = 2.204, time/batch = 0.201\n",
            "13355/15750 (epoch 42), train_loss = 2.221, time/batch = 0.203\n",
            "13356/15750 (epoch 42), train_loss = 2.305, time/batch = 0.212\n",
            "13357/15750 (epoch 42), train_loss = 2.193, time/batch = 0.203\n",
            "13358/15750 (epoch 42), train_loss = 2.216, time/batch = 0.210\n",
            "13359/15750 (epoch 42), train_loss = 2.178, time/batch = 0.207\n",
            "13360/15750 (epoch 42), train_loss = 2.136, time/batch = 0.206\n",
            "13361/15750 (epoch 42), train_loss = 2.148, time/batch = 0.216\n",
            "13362/15750 (epoch 42), train_loss = 2.157, time/batch = 0.204\n",
            "13363/15750 (epoch 42), train_loss = 2.180, time/batch = 0.206\n",
            "13364/15750 (epoch 42), train_loss = 2.194, time/batch = 0.207\n",
            "13365/15750 (epoch 42), train_loss = 2.326, time/batch = 0.211\n",
            "13366/15750 (epoch 42), train_loss = 2.283, time/batch = 0.215\n",
            "13367/15750 (epoch 42), train_loss = 2.286, time/batch = 0.205\n",
            "13368/15750 (epoch 42), train_loss = 2.273, time/batch = 0.204\n",
            "13369/15750 (epoch 42), train_loss = 2.197, time/batch = 0.205\n",
            "13370/15750 (epoch 42), train_loss = 2.200, time/batch = 0.207\n",
            "13371/15750 (epoch 42), train_loss = 2.293, time/batch = 0.212\n",
            "13372/15750 (epoch 42), train_loss = 2.310, time/batch = 0.205\n",
            "13373/15750 (epoch 42), train_loss = 2.283, time/batch = 0.212\n",
            "13374/15750 (epoch 42), train_loss = 2.199, time/batch = 0.207\n",
            "13375/15750 (epoch 42), train_loss = 2.195, time/batch = 0.210\n",
            "13376/15750 (epoch 42), train_loss = 2.162, time/batch = 0.213\n",
            "13377/15750 (epoch 42), train_loss = 2.254, time/batch = 0.209\n",
            "13378/15750 (epoch 42), train_loss = 2.283, time/batch = 0.205\n",
            "13379/15750 (epoch 42), train_loss = 2.232, time/batch = 0.207\n",
            "13380/15750 (epoch 42), train_loss = 2.219, time/batch = 0.211\n",
            "13381/15750 (epoch 42), train_loss = 2.262, time/batch = 0.221\n",
            "13382/15750 (epoch 42), train_loss = 2.293, time/batch = 0.205\n",
            "13383/15750 (epoch 42), train_loss = 2.245, time/batch = 0.206\n",
            "13384/15750 (epoch 42), train_loss = 2.257, time/batch = 0.206\n",
            "13385/15750 (epoch 42), train_loss = 2.255, time/batch = 0.209\n",
            "13386/15750 (epoch 42), train_loss = 2.255, time/batch = 0.221\n",
            "13387/15750 (epoch 42), train_loss = 2.250, time/batch = 0.208\n",
            "13388/15750 (epoch 42), train_loss = 2.331, time/batch = 0.209\n",
            "13389/15750 (epoch 42), train_loss = 2.194, time/batch = 0.208\n",
            "13390/15750 (epoch 42), train_loss = 2.272, time/batch = 0.206\n",
            "13391/15750 (epoch 42), train_loss = 2.255, time/batch = 0.207\n",
            "13392/15750 (epoch 42), train_loss = 2.280, time/batch = 0.211\n",
            "13393/15750 (epoch 42), train_loss = 2.348, time/batch = 0.209\n",
            "13394/15750 (epoch 42), train_loss = 2.272, time/batch = 0.208\n",
            "13395/15750 (epoch 42), train_loss = 2.272, time/batch = 0.208\n",
            "13396/15750 (epoch 42), train_loss = 2.257, time/batch = 0.203\n",
            "13397/15750 (epoch 42), train_loss = 2.228, time/batch = 0.206\n",
            "13398/15750 (epoch 42), train_loss = 2.193, time/batch = 0.205\n",
            "13399/15750 (epoch 42), train_loss = 2.186, time/batch = 0.207\n",
            "13400/15750 (epoch 42), train_loss = 2.226, time/batch = 0.203\n",
            "13401/15750 (epoch 42), train_loss = 2.259, time/batch = 0.199\n",
            "13402/15750 (epoch 42), train_loss = 2.234, time/batch = 0.198\n",
            "13403/15750 (epoch 42), train_loss = 2.306, time/batch = 0.205\n",
            "13404/15750 (epoch 42), train_loss = 2.236, time/batch = 0.202\n",
            "13405/15750 (epoch 42), train_loss = 2.171, time/batch = 0.202\n",
            "13406/15750 (epoch 42), train_loss = 2.198, time/batch = 0.200\n",
            "13407/15750 (epoch 42), train_loss = 2.259, time/batch = 0.199\n",
            "13408/15750 (epoch 42), train_loss = 2.194, time/batch = 0.206\n",
            "13409/15750 (epoch 42), train_loss = 2.153, time/batch = 0.206\n",
            "13410/15750 (epoch 42), train_loss = 2.190, time/batch = 0.202\n",
            "13411/15750 (epoch 42), train_loss = 2.264, time/batch = 0.212\n",
            "13412/15750 (epoch 42), train_loss = 2.242, time/batch = 0.206\n",
            "13413/15750 (epoch 42), train_loss = 2.304, time/batch = 0.210\n",
            "13414/15750 (epoch 42), train_loss = 2.280, time/batch = 0.211\n",
            "13415/15750 (epoch 42), train_loss = 2.244, time/batch = 0.205\n",
            "13416/15750 (epoch 42), train_loss = 2.197, time/batch = 0.215\n",
            "13417/15750 (epoch 42), train_loss = 2.265, time/batch = 0.207\n",
            "13418/15750 (epoch 42), train_loss = 2.288, time/batch = 0.206\n",
            "13419/15750 (epoch 42), train_loss = 2.348, time/batch = 0.210\n",
            "13420/15750 (epoch 42), train_loss = 2.337, time/batch = 0.207\n",
            "13421/15750 (epoch 42), train_loss = 2.241, time/batch = 0.207\n",
            "13422/15750 (epoch 42), train_loss = 2.259, time/batch = 0.208\n",
            "13423/15750 (epoch 42), train_loss = 2.187, time/batch = 0.211\n",
            "13424/15750 (epoch 42), train_loss = 2.316, time/batch = 0.204\n",
            "13425/15750 (epoch 42), train_loss = 2.281, time/batch = 0.204\n",
            "13426/15750 (epoch 42), train_loss = 2.239, time/batch = 0.205\n",
            "13427/15750 (epoch 42), train_loss = 2.187, time/batch = 0.203\n",
            "13428/15750 (epoch 42), train_loss = 2.293, time/batch = 0.210\n",
            "13429/15750 (epoch 42), train_loss = 2.078, time/batch = 0.209\n",
            "13430/15750 (epoch 42), train_loss = 2.192, time/batch = 0.217\n",
            "13431/15750 (epoch 42), train_loss = 2.157, time/batch = 0.207\n",
            "13432/15750 (epoch 42), train_loss = 2.232, time/batch = 0.209\n",
            "13433/15750 (epoch 42), train_loss = 2.202, time/batch = 0.210\n",
            "13434/15750 (epoch 42), train_loss = 2.272, time/batch = 0.210\n",
            "13435/15750 (epoch 42), train_loss = 2.211, time/batch = 0.212\n",
            "13436/15750 (epoch 42), train_loss = 2.102, time/batch = 0.210\n",
            "13437/15750 (epoch 42), train_loss = 2.166, time/batch = 0.206\n",
            "13438/15750 (epoch 42), train_loss = 2.172, time/batch = 0.210\n",
            "13439/15750 (epoch 42), train_loss = 2.235, time/batch = 0.202\n",
            "13440/15750 (epoch 42), train_loss = 2.126, time/batch = 0.210\n",
            "13441/15750 (epoch 42), train_loss = 2.199, time/batch = 0.207\n",
            "13442/15750 (epoch 42), train_loss = 2.093, time/batch = 0.206\n",
            "13443/15750 (epoch 42), train_loss = 2.162, time/batch = 0.209\n",
            "13444/15750 (epoch 42), train_loss = 2.152, time/batch = 0.209\n",
            "13445/15750 (epoch 42), train_loss = 2.135, time/batch = 0.213\n",
            "13446/15750 (epoch 42), train_loss = 2.295, time/batch = 0.208\n",
            "13447/15750 (epoch 42), train_loss = 2.120, time/batch = 0.208\n",
            "13448/15750 (epoch 42), train_loss = 2.361, time/batch = 0.209\n",
            "13449/15750 (epoch 42), train_loss = 2.229, time/batch = 0.211\n",
            "13450/15750 (epoch 42), train_loss = 2.113, time/batch = 0.212\n",
            "13451/15750 (epoch 42), train_loss = 2.140, time/batch = 0.203\n",
            "13452/15750 (epoch 42), train_loss = 2.205, time/batch = 0.206\n",
            "13453/15750 (epoch 42), train_loss = 2.190, time/batch = 0.200\n",
            "13454/15750 (epoch 42), train_loss = 2.173, time/batch = 0.204\n",
            "13455/15750 (epoch 42), train_loss = 2.186, time/batch = 0.210\n",
            "13456/15750 (epoch 42), train_loss = 2.249, time/batch = 0.196\n",
            "13457/15750 (epoch 42), train_loss = 2.171, time/batch = 0.199\n",
            "13458/15750 (epoch 42), train_loss = 2.217, time/batch = 0.201\n",
            "13459/15750 (epoch 42), train_loss = 2.301, time/batch = 0.200\n",
            "13460/15750 (epoch 42), train_loss = 2.156, time/batch = 0.208\n",
            "13461/15750 (epoch 42), train_loss = 2.171, time/batch = 0.203\n",
            "13462/15750 (epoch 42), train_loss = 2.211, time/batch = 0.203\n",
            "13463/15750 (epoch 42), train_loss = 2.213, time/batch = 0.202\n",
            "13464/15750 (epoch 42), train_loss = 2.167, time/batch = 0.205\n",
            "13465/15750 (epoch 42), train_loss = 2.155, time/batch = 0.208\n",
            "13466/15750 (epoch 42), train_loss = 2.126, time/batch = 0.206\n",
            "13467/15750 (epoch 42), train_loss = 2.170, time/batch = 0.206\n",
            "13468/15750 (epoch 42), train_loss = 2.370, time/batch = 0.209\n",
            "13469/15750 (epoch 42), train_loss = 2.206, time/batch = 0.214\n",
            "13470/15750 (epoch 42), train_loss = 2.261, time/batch = 0.216\n",
            "13471/15750 (epoch 42), train_loss = 2.142, time/batch = 0.207\n",
            "13472/15750 (epoch 42), train_loss = 2.189, time/batch = 0.217\n",
            "13473/15750 (epoch 42), train_loss = 2.214, time/batch = 0.208\n",
            "13474/15750 (epoch 42), train_loss = 2.224, time/batch = 0.207\n",
            "13475/15750 (epoch 42), train_loss = 2.278, time/batch = 0.215\n",
            "13476/15750 (epoch 42), train_loss = 2.232, time/batch = 0.205\n",
            "13477/15750 (epoch 42), train_loss = 2.234, time/batch = 0.205\n",
            "13478/15750 (epoch 42), train_loss = 2.207, time/batch = 0.199\n",
            "13479/15750 (epoch 42), train_loss = 2.232, time/batch = 0.206\n",
            "13480/15750 (epoch 42), train_loss = 2.139, time/batch = 0.207\n",
            "13481/15750 (epoch 42), train_loss = 2.130, time/batch = 0.208\n",
            "13482/15750 (epoch 42), train_loss = 2.221, time/batch = 0.208\n",
            "13483/15750 (epoch 42), train_loss = 2.238, time/batch = 0.205\n",
            "13484/15750 (epoch 42), train_loss = 2.206, time/batch = 0.214\n",
            "13485/15750 (epoch 42), train_loss = 2.172, time/batch = 0.217\n",
            "13486/15750 (epoch 42), train_loss = 2.122, time/batch = 0.205\n",
            "13487/15750 (epoch 42), train_loss = 2.151, time/batch = 0.207\n",
            "13488/15750 (epoch 42), train_loss = 2.299, time/batch = 0.209\n",
            "13489/15750 (epoch 42), train_loss = 2.275, time/batch = 0.213\n",
            "13490/15750 (epoch 42), train_loss = 2.249, time/batch = 0.216\n",
            "13491/15750 (epoch 42), train_loss = 2.195, time/batch = 0.207\n",
            "13492/15750 (epoch 42), train_loss = 2.216, time/batch = 0.204\n",
            "13493/15750 (epoch 42), train_loss = 2.208, time/batch = 0.202\n",
            "13494/15750 (epoch 42), train_loss = 2.224, time/batch = 0.202\n",
            "13495/15750 (epoch 42), train_loss = 2.275, time/batch = 0.209\n",
            "13496/15750 (epoch 42), train_loss = 2.273, time/batch = 0.213\n",
            "13497/15750 (epoch 42), train_loss = 2.205, time/batch = 0.211\n",
            "13498/15750 (epoch 42), train_loss = 2.234, time/batch = 0.212\n",
            "13499/15750 (epoch 42), train_loss = 2.272, time/batch = 0.215\n",
            "13500/15750 (epoch 42), train_loss = 2.257, time/batch = 0.205\n",
            "13501/15750 (epoch 42), train_loss = 2.173, time/batch = 0.201\n",
            "13502/15750 (epoch 42), train_loss = 2.209, time/batch = 0.203\n",
            "13503/15750 (epoch 42), train_loss = 2.266, time/batch = 0.205\n",
            "13504/15750 (epoch 42), train_loss = 2.280, time/batch = 0.211\n",
            "13505/15750 (epoch 42), train_loss = 2.220, time/batch = 0.206\n",
            "13506/15750 (epoch 42), train_loss = 2.284, time/batch = 0.205\n",
            "13507/15750 (epoch 42), train_loss = 2.222, time/batch = 0.203\n",
            "13508/15750 (epoch 42), train_loss = 2.199, time/batch = 0.207\n",
            "13509/15750 (epoch 42), train_loss = 2.147, time/batch = 0.211\n",
            "13510/15750 (epoch 42), train_loss = 2.357, time/batch = 0.201\n",
            "13511/15750 (epoch 42), train_loss = 2.188, time/batch = 0.205\n",
            "13512/15750 (epoch 42), train_loss = 2.163, time/batch = 0.208\n",
            "13513/15750 (epoch 42), train_loss = 2.267, time/batch = 0.206\n",
            "13514/15750 (epoch 42), train_loss = 2.177, time/batch = 0.209\n",
            "13515/15750 (epoch 42), train_loss = 2.304, time/batch = 0.206\n",
            "13516/15750 (epoch 42), train_loss = 2.218, time/batch = 0.203\n",
            "13517/15750 (epoch 42), train_loss = 2.226, time/batch = 0.214\n",
            "13518/15750 (epoch 42), train_loss = 2.147, time/batch = 0.208\n",
            "13519/15750 (epoch 42), train_loss = 2.242, time/batch = 0.214\n",
            "13520/15750 (epoch 42), train_loss = 2.166, time/batch = 0.212\n",
            "13521/15750 (epoch 42), train_loss = 2.230, time/batch = 0.207\n",
            "13522/15750 (epoch 42), train_loss = 2.237, time/batch = 0.210\n",
            "13523/15750 (epoch 42), train_loss = 2.189, time/batch = 0.207\n",
            "13524/15750 (epoch 42), train_loss = 2.244, time/batch = 0.212\n",
            "13525/15750 (epoch 42), train_loss = 2.320, time/batch = 0.207\n",
            "13526/15750 (epoch 42), train_loss = 2.267, time/batch = 0.200\n",
            "13527/15750 (epoch 42), train_loss = 2.295, time/batch = 0.201\n",
            "13528/15750 (epoch 42), train_loss = 2.176, time/batch = 0.205\n",
            "13529/15750 (epoch 42), train_loss = 2.242, time/batch = 0.208\n",
            "13530/15750 (epoch 42), train_loss = 2.226, time/batch = 0.210\n",
            "13531/15750 (epoch 42), train_loss = 2.170, time/batch = 0.205\n",
            "13532/15750 (epoch 42), train_loss = 2.297, time/batch = 0.209\n",
            "13533/15750 (epoch 42), train_loss = 2.146, time/batch = 0.208\n",
            "13534/15750 (epoch 42), train_loss = 2.268, time/batch = 0.214\n",
            "13535/15750 (epoch 42), train_loss = 2.226, time/batch = 0.205\n",
            "13536/15750 (epoch 42), train_loss = 2.189, time/batch = 0.213\n",
            "13537/15750 (epoch 42), train_loss = 2.137, time/batch = 0.207\n",
            "13538/15750 (epoch 42), train_loss = 2.174, time/batch = 0.206\n",
            "13539/15750 (epoch 42), train_loss = 2.285, time/batch = 0.216\n",
            "13540/15750 (epoch 42), train_loss = 2.164, time/batch = 0.203\n",
            "13541/15750 (epoch 42), train_loss = 2.137, time/batch = 0.206\n",
            "13542/15750 (epoch 42), train_loss = 2.173, time/batch = 0.208\n",
            "13543/15750 (epoch 42), train_loss = 2.191, time/batch = 0.201\n",
            "13544/15750 (epoch 42), train_loss = 2.280, time/batch = 0.214\n",
            "13545/15750 (epoch 43), train_loss = 2.094, time/batch = 0.202\n",
            "13546/15750 (epoch 43), train_loss = 2.273, time/batch = 0.205\n",
            "13547/15750 (epoch 43), train_loss = 2.196, time/batch = 0.205\n",
            "13548/15750 (epoch 43), train_loss = 2.299, time/batch = 0.215\n",
            "13549/15750 (epoch 43), train_loss = 2.227, time/batch = 0.205\n",
            "13550/15750 (epoch 43), train_loss = 2.223, time/batch = 0.208\n",
            "13551/15750 (epoch 43), train_loss = 2.370, time/batch = 0.208\n",
            "13552/15750 (epoch 43), train_loss = 2.293, time/batch = 0.203\n",
            "13553/15750 (epoch 43), train_loss = 2.290, time/batch = 0.216\n",
            "13554/15750 (epoch 43), train_loss = 2.239, time/batch = 0.208\n",
            "13555/15750 (epoch 43), train_loss = 2.232, time/batch = 0.205\n",
            "13556/15750 (epoch 43), train_loss = 2.205, time/batch = 0.208\n",
            "13557/15750 (epoch 43), train_loss = 2.280, time/batch = 0.208\n",
            "13558/15750 (epoch 43), train_loss = 2.264, time/batch = 0.204\n",
            "13559/15750 (epoch 43), train_loss = 2.237, time/batch = 0.205\n",
            "13560/15750 (epoch 43), train_loss = 2.256, time/batch = 0.205\n",
            "13561/15750 (epoch 43), train_loss = 2.259, time/batch = 0.199\n",
            "13562/15750 (epoch 43), train_loss = 2.320, time/batch = 0.206\n",
            "13563/15750 (epoch 43), train_loss = 2.335, time/batch = 0.213\n",
            "13564/15750 (epoch 43), train_loss = 2.287, time/batch = 0.212\n",
            "13565/15750 (epoch 43), train_loss = 2.269, time/batch = 0.211\n",
            "13566/15750 (epoch 43), train_loss = 2.279, time/batch = 0.209\n",
            "13567/15750 (epoch 43), train_loss = 2.231, time/batch = 0.215\n",
            "13568/15750 (epoch 43), train_loss = 2.290, time/batch = 0.197\n",
            "13569/15750 (epoch 43), train_loss = 2.295, time/batch = 0.210\n",
            "13570/15750 (epoch 43), train_loss = 2.315, time/batch = 0.212\n",
            "13571/15750 (epoch 43), train_loss = 2.324, time/batch = 0.209\n",
            "13572/15750 (epoch 43), train_loss = 2.303, time/batch = 0.216\n",
            "13573/15750 (epoch 43), train_loss = 2.409, time/batch = 0.208\n",
            "13574/15750 (epoch 43), train_loss = 2.324, time/batch = 0.204\n",
            "13575/15750 (epoch 43), train_loss = 2.285, time/batch = 0.208\n",
            "13576/15750 (epoch 43), train_loss = 2.253, time/batch = 0.204\n",
            "13577/15750 (epoch 43), train_loss = 2.171, time/batch = 0.212\n",
            "13578/15750 (epoch 43), train_loss = 2.183, time/batch = 0.210\n",
            "13579/15750 (epoch 43), train_loss = 2.270, time/batch = 0.212\n",
            "13580/15750 (epoch 43), train_loss = 2.170, time/batch = 0.207\n",
            "13581/15750 (epoch 43), train_loss = 2.256, time/batch = 0.208\n",
            "13582/15750 (epoch 43), train_loss = 2.303, time/batch = 0.213\n",
            "13583/15750 (epoch 43), train_loss = 2.213, time/batch = 0.210\n",
            "13584/15750 (epoch 43), train_loss = 2.260, time/batch = 0.209\n",
            "13585/15750 (epoch 43), train_loss = 2.219, time/batch = 0.207\n",
            "13586/15750 (epoch 43), train_loss = 2.268, time/batch = 0.210\n",
            "13587/15750 (epoch 43), train_loss = 2.267, time/batch = 0.214\n",
            "13588/15750 (epoch 43), train_loss = 2.235, time/batch = 0.207\n",
            "13589/15750 (epoch 43), train_loss = 2.266, time/batch = 0.204\n",
            "13590/15750 (epoch 43), train_loss = 2.194, time/batch = 0.204\n",
            "13591/15750 (epoch 43), train_loss = 2.237, time/batch = 0.205\n",
            "13592/15750 (epoch 43), train_loss = 2.245, time/batch = 0.212\n",
            "13593/15750 (epoch 43), train_loss = 2.288, time/batch = 0.212\n",
            "13594/15750 (epoch 43), train_loss = 2.171, time/batch = 0.211\n",
            "13595/15750 (epoch 43), train_loss = 2.244, time/batch = 0.207\n",
            "13596/15750 (epoch 43), train_loss = 2.193, time/batch = 0.209\n",
            "13597/15750 (epoch 43), train_loss = 2.245, time/batch = 0.213\n",
            "13598/15750 (epoch 43), train_loss = 2.264, time/batch = 0.207\n",
            "13599/15750 (epoch 43), train_loss = 2.260, time/batch = 0.209\n",
            "13600/15750 (epoch 43), train_loss = 2.293, time/batch = 0.209\n",
            "13601/15750 (epoch 43), train_loss = 2.181, time/batch = 0.205\n",
            "13602/15750 (epoch 43), train_loss = 2.172, time/batch = 0.209\n",
            "13603/15750 (epoch 43), train_loss = 2.273, time/batch = 0.214\n",
            "13604/15750 (epoch 43), train_loss = 2.137, time/batch = 0.207\n",
            "13605/15750 (epoch 43), train_loss = 2.235, time/batch = 0.207\n",
            "13606/15750 (epoch 43), train_loss = 2.243, time/batch = 0.205\n",
            "13607/15750 (epoch 43), train_loss = 2.169, time/batch = 0.214\n",
            "13608/15750 (epoch 43), train_loss = 2.227, time/batch = 0.206\n",
            "13609/15750 (epoch 43), train_loss = 2.132, time/batch = 0.206\n",
            "13610/15750 (epoch 43), train_loss = 2.157, time/batch = 0.211\n",
            "13611/15750 (epoch 43), train_loss = 2.094, time/batch = 0.210\n",
            "13612/15750 (epoch 43), train_loss = 2.111, time/batch = 0.212\n",
            "13613/15750 (epoch 43), train_loss = 2.163, time/batch = 0.209\n",
            "13614/15750 (epoch 43), train_loss = 2.267, time/batch = 0.209\n",
            "13615/15750 (epoch 43), train_loss = 2.186, time/batch = 0.218\n",
            "13616/15750 (epoch 43), train_loss = 2.174, time/batch = 0.210\n",
            "13617/15750 (epoch 43), train_loss = 2.102, time/batch = 0.205\n",
            "13618/15750 (epoch 43), train_loss = 2.157, time/batch = 0.209\n",
            "13619/15750 (epoch 43), train_loss = 2.278, time/batch = 0.205\n",
            "13620/15750 (epoch 43), train_loss = 2.216, time/batch = 0.203\n",
            "13621/15750 (epoch 43), train_loss = 2.209, time/batch = 0.210\n",
            "13622/15750 (epoch 43), train_loss = 2.205, time/batch = 0.205\n",
            "13623/15750 (epoch 43), train_loss = 2.214, time/batch = 0.211\n",
            "13624/15750 (epoch 43), train_loss = 2.204, time/batch = 0.212\n",
            "13625/15750 (epoch 43), train_loss = 2.104, time/batch = 0.210\n",
            "13626/15750 (epoch 43), train_loss = 2.206, time/batch = 0.214\n",
            "13627/15750 (epoch 43), train_loss = 2.156, time/batch = 0.210\n",
            "13628/15750 (epoch 43), train_loss = 2.205, time/batch = 0.206\n",
            "13629/15750 (epoch 43), train_loss = 2.257, time/batch = 0.207\n",
            "13630/15750 (epoch 43), train_loss = 2.278, time/batch = 0.208\n",
            "13631/15750 (epoch 43), train_loss = 2.115, time/batch = 0.214\n",
            "13632/15750 (epoch 43), train_loss = 2.158, time/batch = 0.208\n",
            "13633/15750 (epoch 43), train_loss = 2.170, time/batch = 0.211\n",
            "13634/15750 (epoch 43), train_loss = 2.180, time/batch = 0.205\n",
            "13635/15750 (epoch 43), train_loss = 2.168, time/batch = 0.204\n",
            "13636/15750 (epoch 43), train_loss = 2.231, time/batch = 0.209\n",
            "13637/15750 (epoch 43), train_loss = 2.218, time/batch = 0.207\n",
            "13638/15750 (epoch 43), train_loss = 2.228, time/batch = 0.207\n",
            "13639/15750 (epoch 43), train_loss = 2.289, time/batch = 0.209\n",
            "13640/15750 (epoch 43), train_loss = 2.209, time/batch = 0.206\n",
            "13641/15750 (epoch 43), train_loss = 2.238, time/batch = 0.213\n",
            "13642/15750 (epoch 43), train_loss = 2.257, time/batch = 0.209\n",
            "13643/15750 (epoch 43), train_loss = 2.233, time/batch = 0.207\n",
            "13644/15750 (epoch 43), train_loss = 2.247, time/batch = 0.203\n",
            "13645/15750 (epoch 43), train_loss = 2.224, time/batch = 0.207\n",
            "13646/15750 (epoch 43), train_loss = 2.172, time/batch = 0.215\n",
            "13647/15750 (epoch 43), train_loss = 2.184, time/batch = 0.211\n",
            "13648/15750 (epoch 43), train_loss = 2.307, time/batch = 0.207\n",
            "13649/15750 (epoch 43), train_loss = 2.229, time/batch = 0.203\n",
            "13650/15750 (epoch 43), train_loss = 2.136, time/batch = 0.203\n",
            "13651/15750 (epoch 43), train_loss = 2.205, time/batch = 0.214\n",
            "13652/15750 (epoch 43), train_loss = 2.233, time/batch = 0.206\n",
            "13653/15750 (epoch 43), train_loss = 2.261, time/batch = 0.212\n",
            "13654/15750 (epoch 43), train_loss = 2.291, time/batch = 0.200\n",
            "13655/15750 (epoch 43), train_loss = 2.350, time/batch = 0.206\n",
            "13656/15750 (epoch 43), train_loss = 2.209, time/batch = 0.219\n",
            "13657/15750 (epoch 43), train_loss = 2.224, time/batch = 0.210\n",
            "13658/15750 (epoch 43), train_loss = 2.215, time/batch = 0.215\n",
            "13659/15750 (epoch 43), train_loss = 2.216, time/batch = 0.208\n",
            "13660/15750 (epoch 43), train_loss = 2.306, time/batch = 0.216\n",
            "13661/15750 (epoch 43), train_loss = 2.230, time/batch = 0.206\n",
            "13662/15750 (epoch 43), train_loss = 2.343, time/batch = 0.209\n",
            "13663/15750 (epoch 43), train_loss = 2.228, time/batch = 0.208\n",
            "13664/15750 (epoch 43), train_loss = 2.222, time/batch = 0.202\n",
            "13665/15750 (epoch 43), train_loss = 2.194, time/batch = 0.217\n",
            "13666/15750 (epoch 43), train_loss = 2.173, time/batch = 0.210\n",
            "13667/15750 (epoch 43), train_loss = 2.216, time/batch = 0.209\n",
            "13668/15750 (epoch 43), train_loss = 2.165, time/batch = 0.210\n",
            "13669/15750 (epoch 43), train_loss = 2.200, time/batch = 0.210\n",
            "13670/15750 (epoch 43), train_loss = 2.217, time/batch = 0.215\n",
            "13671/15750 (epoch 43), train_loss = 2.302, time/batch = 0.208\n",
            "13672/15750 (epoch 43), train_loss = 2.190, time/batch = 0.213\n",
            "13673/15750 (epoch 43), train_loss = 2.213, time/batch = 0.205\n",
            "13674/15750 (epoch 43), train_loss = 2.174, time/batch = 0.208\n",
            "13675/15750 (epoch 43), train_loss = 2.132, time/batch = 0.213\n",
            "13676/15750 (epoch 43), train_loss = 2.145, time/batch = 0.205\n",
            "13677/15750 (epoch 43), train_loss = 2.153, time/batch = 0.201\n",
            "13678/15750 (epoch 43), train_loss = 2.176, time/batch = 0.203\n",
            "13679/15750 (epoch 43), train_loss = 2.189, time/batch = 0.207\n",
            "13680/15750 (epoch 43), train_loss = 2.322, time/batch = 0.212\n",
            "13681/15750 (epoch 43), train_loss = 2.280, time/batch = 0.207\n",
            "13682/15750 (epoch 43), train_loss = 2.283, time/batch = 0.206\n",
            "13683/15750 (epoch 43), train_loss = 2.270, time/batch = 0.212\n",
            "13684/15750 (epoch 43), train_loss = 2.192, time/batch = 0.211\n",
            "13685/15750 (epoch 43), train_loss = 2.196, time/batch = 0.214\n",
            "13686/15750 (epoch 43), train_loss = 2.289, time/batch = 0.209\n",
            "13687/15750 (epoch 43), train_loss = 2.306, time/batch = 0.207\n",
            "13688/15750 (epoch 43), train_loss = 2.279, time/batch = 0.211\n",
            "13689/15750 (epoch 43), train_loss = 2.195, time/batch = 0.208\n",
            "13690/15750 (epoch 43), train_loss = 2.192, time/batch = 0.212\n",
            "13691/15750 (epoch 43), train_loss = 2.158, time/batch = 0.203\n",
            "13692/15750 (epoch 43), train_loss = 2.250, time/batch = 0.201\n",
            "13693/15750 (epoch 43), train_loss = 2.278, time/batch = 0.199\n",
            "13694/15750 (epoch 43), train_loss = 2.228, time/batch = 0.203\n",
            "13695/15750 (epoch 43), train_loss = 2.215, time/batch = 0.209\n",
            "13696/15750 (epoch 43), train_loss = 2.257, time/batch = 0.198\n",
            "13697/15750 (epoch 43), train_loss = 2.289, time/batch = 0.197\n",
            "13698/15750 (epoch 43), train_loss = 2.241, time/batch = 0.203\n",
            "13699/15750 (epoch 43), train_loss = 2.253, time/batch = 0.205\n",
            "13700/15750 (epoch 43), train_loss = 2.251, time/batch = 0.205\n",
            "13701/15750 (epoch 43), train_loss = 2.251, time/batch = 0.210\n",
            "13702/15750 (epoch 43), train_loss = 2.246, time/batch = 0.207\n",
            "13703/15750 (epoch 43), train_loss = 2.327, time/batch = 0.214\n",
            "13704/15750 (epoch 43), train_loss = 2.190, time/batch = 0.211\n",
            "13705/15750 (epoch 43), train_loss = 2.269, time/batch = 0.214\n",
            "13706/15750 (epoch 43), train_loss = 2.252, time/batch = 0.211\n",
            "13707/15750 (epoch 43), train_loss = 2.276, time/batch = 0.209\n",
            "13708/15750 (epoch 43), train_loss = 2.343, time/batch = 0.208\n",
            "13709/15750 (epoch 43), train_loss = 2.267, time/batch = 0.207\n",
            "13710/15750 (epoch 43), train_loss = 2.267, time/batch = 0.210\n",
            "13711/15750 (epoch 43), train_loss = 2.253, time/batch = 0.206\n",
            "13712/15750 (epoch 43), train_loss = 2.224, time/batch = 0.206\n",
            "13713/15750 (epoch 43), train_loss = 2.189, time/batch = 0.211\n",
            "13714/15750 (epoch 43), train_loss = 2.182, time/batch = 0.203\n",
            "13715/15750 (epoch 43), train_loss = 2.222, time/batch = 0.207\n",
            "13716/15750 (epoch 43), train_loss = 2.255, time/batch = 0.201\n",
            "13717/15750 (epoch 43), train_loss = 2.230, time/batch = 0.211\n",
            "13718/15750 (epoch 43), train_loss = 2.302, time/batch = 0.210\n",
            "13719/15750 (epoch 43), train_loss = 2.231, time/batch = 0.214\n",
            "13720/15750 (epoch 43), train_loss = 2.167, time/batch = 0.206\n",
            "13721/15750 (epoch 43), train_loss = 2.194, time/batch = 0.206\n",
            "13722/15750 (epoch 43), train_loss = 2.255, time/batch = 0.200\n",
            "13723/15750 (epoch 43), train_loss = 2.190, time/batch = 0.202\n",
            "13724/15750 (epoch 43), train_loss = 2.149, time/batch = 0.202\n",
            "13725/15750 (epoch 43), train_loss = 2.186, time/batch = 0.201\n",
            "13726/15750 (epoch 43), train_loss = 2.260, time/batch = 0.207\n",
            "13727/15750 (epoch 43), train_loss = 2.238, time/batch = 0.211\n",
            "13728/15750 (epoch 43), train_loss = 2.300, time/batch = 0.215\n",
            "13729/15750 (epoch 43), train_loss = 2.275, time/batch = 0.212\n",
            "13730/15750 (epoch 43), train_loss = 2.240, time/batch = 0.209\n",
            "13731/15750 (epoch 43), train_loss = 2.193, time/batch = 0.208\n",
            "13732/15750 (epoch 43), train_loss = 2.261, time/batch = 0.212\n",
            "13733/15750 (epoch 43), train_loss = 2.284, time/batch = 0.210\n",
            "13734/15750 (epoch 43), train_loss = 2.344, time/batch = 0.217\n",
            "13735/15750 (epoch 43), train_loss = 2.333, time/batch = 0.212\n",
            "13736/15750 (epoch 43), train_loss = 2.237, time/batch = 0.210\n",
            "13737/15750 (epoch 43), train_loss = 2.254, time/batch = 0.208\n",
            "13738/15750 (epoch 43), train_loss = 2.183, time/batch = 0.206\n",
            "13739/15750 (epoch 43), train_loss = 2.312, time/batch = 0.210\n",
            "13740/15750 (epoch 43), train_loss = 2.277, time/batch = 0.203\n",
            "13741/15750 (epoch 43), train_loss = 2.235, time/batch = 0.205\n",
            "13742/15750 (epoch 43), train_loss = 2.183, time/batch = 0.208\n",
            "13743/15750 (epoch 43), train_loss = 2.289, time/batch = 0.203\n",
            "13744/15750 (epoch 43), train_loss = 2.074, time/batch = 0.208\n",
            "13745/15750 (epoch 43), train_loss = 2.188, time/batch = 0.204\n",
            "13746/15750 (epoch 43), train_loss = 2.153, time/batch = 0.203\n",
            "13747/15750 (epoch 43), train_loss = 2.228, time/batch = 0.203\n",
            "13748/15750 (epoch 43), train_loss = 2.198, time/batch = 0.206\n",
            "13749/15750 (epoch 43), train_loss = 2.268, time/batch = 0.208\n",
            "13750/15750 (epoch 43), train_loss = 2.207, time/batch = 0.209\n",
            "13751/15750 (epoch 43), train_loss = 2.098, time/batch = 0.208\n",
            "13752/15750 (epoch 43), train_loss = 2.162, time/batch = 0.209\n",
            "13753/15750 (epoch 43), train_loss = 2.168, time/batch = 0.205\n",
            "13754/15750 (epoch 43), train_loss = 2.232, time/batch = 0.215\n",
            "13755/15750 (epoch 43), train_loss = 2.122, time/batch = 0.207\n",
            "13756/15750 (epoch 43), train_loss = 2.195, time/batch = 0.215\n",
            "13757/15750 (epoch 43), train_loss = 2.089, time/batch = 0.208\n",
            "13758/15750 (epoch 43), train_loss = 2.159, time/batch = 0.210\n",
            "13759/15750 (epoch 43), train_loss = 2.148, time/batch = 0.215\n",
            "13760/15750 (epoch 43), train_loss = 2.130, time/batch = 0.213\n",
            "13761/15750 (epoch 43), train_loss = 2.291, time/batch = 0.204\n",
            "13762/15750 (epoch 43), train_loss = 2.116, time/batch = 0.205\n",
            "13763/15750 (epoch 43), train_loss = 2.357, time/batch = 0.215\n",
            "13764/15750 (epoch 43), train_loss = 2.226, time/batch = 0.210\n",
            "13765/15750 (epoch 43), train_loss = 2.110, time/batch = 0.207\n",
            "13766/15750 (epoch 43), train_loss = 2.136, time/batch = 0.210\n",
            "13767/15750 (epoch 43), train_loss = 2.201, time/batch = 0.205\n",
            "13768/15750 (epoch 43), train_loss = 2.186, time/batch = 0.210\n",
            "13769/15750 (epoch 43), train_loss = 2.168, time/batch = 0.209\n",
            "13770/15750 (epoch 43), train_loss = 2.182, time/batch = 0.209\n",
            "13771/15750 (epoch 43), train_loss = 2.245, time/batch = 0.213\n",
            "13772/15750 (epoch 43), train_loss = 2.167, time/batch = 0.211\n",
            "13773/15750 (epoch 43), train_loss = 2.213, time/batch = 0.207\n",
            "13774/15750 (epoch 43), train_loss = 2.298, time/batch = 0.200\n",
            "13775/15750 (epoch 43), train_loss = 2.153, time/batch = 0.206\n",
            "13776/15750 (epoch 43), train_loss = 2.168, time/batch = 0.209\n",
            "13777/15750 (epoch 43), train_loss = 2.207, time/batch = 0.202\n",
            "13778/15750 (epoch 43), train_loss = 2.209, time/batch = 0.204\n",
            "13779/15750 (epoch 43), train_loss = 2.163, time/batch = 0.205\n",
            "13780/15750 (epoch 43), train_loss = 2.151, time/batch = 0.211\n",
            "13781/15750 (epoch 43), train_loss = 2.122, time/batch = 0.211\n",
            "13782/15750 (epoch 43), train_loss = 2.166, time/batch = 0.207\n",
            "13783/15750 (epoch 43), train_loss = 2.365, time/batch = 0.211\n",
            "13784/15750 (epoch 43), train_loss = 2.202, time/batch = 0.199\n",
            "13785/15750 (epoch 43), train_loss = 2.257, time/batch = 0.208\n",
            "13786/15750 (epoch 43), train_loss = 2.138, time/batch = 0.208\n",
            "13787/15750 (epoch 43), train_loss = 2.185, time/batch = 0.207\n",
            "13788/15750 (epoch 43), train_loss = 2.210, time/batch = 0.211\n",
            "13789/15750 (epoch 43), train_loss = 2.220, time/batch = 0.207\n",
            "13790/15750 (epoch 43), train_loss = 2.273, time/batch = 0.205\n",
            "13791/15750 (epoch 43), train_loss = 2.228, time/batch = 0.209\n",
            "13792/15750 (epoch 43), train_loss = 2.230, time/batch = 0.210\n",
            "13793/15750 (epoch 43), train_loss = 2.204, time/batch = 0.210\n",
            "13794/15750 (epoch 43), train_loss = 2.227, time/batch = 0.200\n",
            "13795/15750 (epoch 43), train_loss = 2.135, time/batch = 0.206\n",
            "13796/15750 (epoch 43), train_loss = 2.126, time/batch = 0.205\n",
            "13797/15750 (epoch 43), train_loss = 2.217, time/batch = 0.202\n",
            "13798/15750 (epoch 43), train_loss = 2.234, time/batch = 0.212\n",
            "13799/15750 (epoch 43), train_loss = 2.202, time/batch = 0.210\n",
            "13800/15750 (epoch 43), train_loss = 2.168, time/batch = 0.207\n",
            "13801/15750 (epoch 43), train_loss = 2.119, time/batch = 0.205\n",
            "13802/15750 (epoch 43), train_loss = 2.148, time/batch = 0.211\n",
            "13803/15750 (epoch 43), train_loss = 2.295, time/batch = 0.212\n",
            "13804/15750 (epoch 43), train_loss = 2.271, time/batch = 0.212\n",
            "13805/15750 (epoch 43), train_loss = 2.246, time/batch = 0.213\n",
            "13806/15750 (epoch 43), train_loss = 2.191, time/batch = 0.204\n",
            "13807/15750 (epoch 43), train_loss = 2.213, time/batch = 0.206\n",
            "13808/15750 (epoch 43), train_loss = 2.204, time/batch = 0.212\n",
            "13809/15750 (epoch 43), train_loss = 2.219, time/batch = 0.209\n",
            "13810/15750 (epoch 43), train_loss = 2.270, time/batch = 0.205\n",
            "13811/15750 (epoch 43), train_loss = 2.268, time/batch = 0.211\n",
            "13812/15750 (epoch 43), train_loss = 2.201, time/batch = 0.204\n",
            "13813/15750 (epoch 43), train_loss = 2.229, time/batch = 0.212\n",
            "13814/15750 (epoch 43), train_loss = 2.267, time/batch = 0.203\n",
            "13815/15750 (epoch 43), train_loss = 2.253, time/batch = 0.202\n",
            "13816/15750 (epoch 43), train_loss = 2.169, time/batch = 0.205\n",
            "13817/15750 (epoch 43), train_loss = 2.205, time/batch = 0.206\n",
            "13818/15750 (epoch 43), train_loss = 2.262, time/batch = 0.214\n",
            "13819/15750 (epoch 43), train_loss = 2.276, time/batch = 0.210\n",
            "13820/15750 (epoch 43), train_loss = 2.216, time/batch = 0.206\n",
            "13821/15750 (epoch 43), train_loss = 2.280, time/batch = 0.209\n",
            "13822/15750 (epoch 43), train_loss = 2.218, time/batch = 0.205\n",
            "13823/15750 (epoch 43), train_loss = 2.196, time/batch = 0.218\n",
            "13824/15750 (epoch 43), train_loss = 2.143, time/batch = 0.211\n",
            "13825/15750 (epoch 43), train_loss = 2.352, time/batch = 0.206\n",
            "13826/15750 (epoch 43), train_loss = 2.183, time/batch = 0.201\n",
            "13827/15750 (epoch 43), train_loss = 2.159, time/batch = 0.208\n",
            "13828/15750 (epoch 43), train_loss = 2.262, time/batch = 0.215\n",
            "13829/15750 (epoch 43), train_loss = 2.173, time/batch = 0.205\n",
            "13830/15750 (epoch 43), train_loss = 2.300, time/batch = 0.202\n",
            "13831/15750 (epoch 43), train_loss = 2.215, time/batch = 0.201\n",
            "13832/15750 (epoch 43), train_loss = 2.222, time/batch = 0.202\n",
            "13833/15750 (epoch 43), train_loss = 2.143, time/batch = 0.209\n",
            "13834/15750 (epoch 43), train_loss = 2.238, time/batch = 0.198\n",
            "13835/15750 (epoch 43), train_loss = 2.162, time/batch = 0.200\n",
            "13836/15750 (epoch 43), train_loss = 2.226, time/batch = 0.203\n",
            "13837/15750 (epoch 43), train_loss = 2.234, time/batch = 0.197\n",
            "13838/15750 (epoch 43), train_loss = 2.185, time/batch = 0.209\n",
            "13839/15750 (epoch 43), train_loss = 2.240, time/batch = 0.200\n",
            "13840/15750 (epoch 43), train_loss = 2.315, time/batch = 0.203\n",
            "13841/15750 (epoch 43), train_loss = 2.263, time/batch = 0.201\n",
            "13842/15750 (epoch 43), train_loss = 2.291, time/batch = 0.200\n",
            "13843/15750 (epoch 43), train_loss = 2.172, time/batch = 0.209\n",
            "13844/15750 (epoch 43), train_loss = 2.238, time/batch = 0.204\n",
            "13845/15750 (epoch 43), train_loss = 2.221, time/batch = 0.207\n",
            "13846/15750 (epoch 43), train_loss = 2.166, time/batch = 0.203\n",
            "13847/15750 (epoch 43), train_loss = 2.293, time/batch = 0.202\n",
            "13848/15750 (epoch 43), train_loss = 2.142, time/batch = 0.209\n",
            "13849/15750 (epoch 43), train_loss = 2.264, time/batch = 0.202\n",
            "13850/15750 (epoch 43), train_loss = 2.223, time/batch = 0.205\n",
            "13851/15750 (epoch 43), train_loss = 2.185, time/batch = 0.203\n",
            "13852/15750 (epoch 43), train_loss = 2.132, time/batch = 0.214\n",
            "13853/15750 (epoch 43), train_loss = 2.170, time/batch = 0.219\n",
            "13854/15750 (epoch 43), train_loss = 2.280, time/batch = 0.209\n",
            "13855/15750 (epoch 43), train_loss = 2.160, time/batch = 0.212\n",
            "13856/15750 (epoch 43), train_loss = 2.133, time/batch = 0.210\n",
            "13857/15750 (epoch 43), train_loss = 2.170, time/batch = 0.211\n",
            "13858/15750 (epoch 43), train_loss = 2.187, time/batch = 0.217\n",
            "13859/15750 (epoch 43), train_loss = 2.276, time/batch = 0.204\n",
            "13860/15750 (epoch 44), train_loss = 2.084, time/batch = 0.204\n",
            "13861/15750 (epoch 44), train_loss = 2.269, time/batch = 0.210\n",
            "13862/15750 (epoch 44), train_loss = 2.191, time/batch = 0.213\n",
            "13863/15750 (epoch 44), train_loss = 2.294, time/batch = 0.208\n",
            "13864/15750 (epoch 44), train_loss = 2.223, time/batch = 0.202\n",
            "13865/15750 (epoch 44), train_loss = 2.220, time/batch = 0.201\n",
            "13866/15750 (epoch 44), train_loss = 2.366, time/batch = 0.210\n",
            "13867/15750 (epoch 44), train_loss = 2.288, time/batch = 0.211\n",
            "13868/15750 (epoch 44), train_loss = 2.285, time/batch = 0.205\n",
            "13869/15750 (epoch 44), train_loss = 2.234, time/batch = 0.207\n",
            "13870/15750 (epoch 44), train_loss = 2.227, time/batch = 0.204\n",
            "13871/15750 (epoch 44), train_loss = 2.202, time/batch = 0.212\n",
            "13872/15750 (epoch 44), train_loss = 2.276, time/batch = 0.204\n",
            "13873/15750 (epoch 44), train_loss = 2.260, time/batch = 0.203\n",
            "13874/15750 (epoch 44), train_loss = 2.234, time/batch = 0.203\n",
            "13875/15750 (epoch 44), train_loss = 2.251, time/batch = 0.203\n",
            "13876/15750 (epoch 44), train_loss = 2.254, time/batch = 0.210\n",
            "13877/15750 (epoch 44), train_loss = 2.315, time/batch = 0.214\n",
            "13878/15750 (epoch 44), train_loss = 2.331, time/batch = 0.211\n",
            "13879/15750 (epoch 44), train_loss = 2.282, time/batch = 0.208\n",
            "13880/15750 (epoch 44), train_loss = 2.265, time/batch = 0.209\n",
            "13881/15750 (epoch 44), train_loss = 2.275, time/batch = 0.208\n",
            "13882/15750 (epoch 44), train_loss = 2.227, time/batch = 0.216\n",
            "13883/15750 (epoch 44), train_loss = 2.286, time/batch = 0.206\n",
            "13884/15750 (epoch 44), train_loss = 2.291, time/batch = 0.204\n",
            "13885/15750 (epoch 44), train_loss = 2.312, time/batch = 0.206\n",
            "13886/15750 (epoch 44), train_loss = 2.319, time/batch = 0.205\n",
            "13887/15750 (epoch 44), train_loss = 2.299, time/batch = 0.203\n",
            "13888/15750 (epoch 44), train_loss = 2.405, time/batch = 0.204\n",
            "13889/15750 (epoch 44), train_loss = 2.319, time/batch = 0.204\n",
            "13890/15750 (epoch 44), train_loss = 2.281, time/batch = 0.205\n",
            "13891/15750 (epoch 44), train_loss = 2.249, time/batch = 0.207\n",
            "13892/15750 (epoch 44), train_loss = 2.167, time/batch = 0.204\n",
            "13893/15750 (epoch 44), train_loss = 2.180, time/batch = 0.205\n",
            "13894/15750 (epoch 44), train_loss = 2.266, time/batch = 0.205\n",
            "13895/15750 (epoch 44), train_loss = 2.167, time/batch = 0.204\n",
            "13896/15750 (epoch 44), train_loss = 2.252, time/batch = 0.206\n",
            "13897/15750 (epoch 44), train_loss = 2.300, time/batch = 0.209\n",
            "13898/15750 (epoch 44), train_loss = 2.209, time/batch = 0.211\n",
            "13899/15750 (epoch 44), train_loss = 2.255, time/batch = 0.208\n",
            "13900/15750 (epoch 44), train_loss = 2.215, time/batch = 0.206\n",
            "13901/15750 (epoch 44), train_loss = 2.264, time/batch = 0.209\n",
            "13902/15750 (epoch 44), train_loss = 2.263, time/batch = 0.205\n",
            "13903/15750 (epoch 44), train_loss = 2.230, time/batch = 0.207\n",
            "13904/15750 (epoch 44), train_loss = 2.261, time/batch = 0.214\n",
            "13905/15750 (epoch 44), train_loss = 2.191, time/batch = 0.212\n",
            "13906/15750 (epoch 44), train_loss = 2.233, time/batch = 0.211\n",
            "13907/15750 (epoch 44), train_loss = 2.241, time/batch = 0.206\n",
            "13908/15750 (epoch 44), train_loss = 2.284, time/batch = 0.206\n",
            "13909/15750 (epoch 44), train_loss = 2.166, time/batch = 0.205\n",
            "13910/15750 (epoch 44), train_loss = 2.241, time/batch = 0.204\n",
            "13911/15750 (epoch 44), train_loss = 2.189, time/batch = 0.207\n",
            "13912/15750 (epoch 44), train_loss = 2.241, time/batch = 0.211\n",
            "13913/15750 (epoch 44), train_loss = 2.259, time/batch = 0.209\n",
            "13914/15750 (epoch 44), train_loss = 2.256, time/batch = 0.207\n",
            "13915/15750 (epoch 44), train_loss = 2.289, time/batch = 0.208\n",
            "13916/15750 (epoch 44), train_loss = 2.177, time/batch = 0.213\n",
            "13917/15750 (epoch 44), train_loss = 2.168, time/batch = 0.211\n",
            "13918/15750 (epoch 44), train_loss = 2.270, time/batch = 0.207\n",
            "13919/15750 (epoch 44), train_loss = 2.134, time/batch = 0.207\n",
            "13920/15750 (epoch 44), train_loss = 2.231, time/batch = 0.210\n",
            "13921/15750 (epoch 44), train_loss = 2.240, time/batch = 0.210\n",
            "13922/15750 (epoch 44), train_loss = 2.165, time/batch = 0.210\n",
            "13923/15750 (epoch 44), train_loss = 2.223, time/batch = 0.203\n",
            "13924/15750 (epoch 44), train_loss = 2.129, time/batch = 0.204\n",
            "13925/15750 (epoch 44), train_loss = 2.154, time/batch = 0.202\n",
            "13926/15750 (epoch 44), train_loss = 2.091, time/batch = 0.211\n",
            "13927/15750 (epoch 44), train_loss = 2.107, time/batch = 0.208\n",
            "13928/15750 (epoch 44), train_loss = 2.159, time/batch = 0.209\n",
            "13929/15750 (epoch 44), train_loss = 2.264, time/batch = 0.210\n",
            "13930/15750 (epoch 44), train_loss = 2.182, time/batch = 0.207\n",
            "13931/15750 (epoch 44), train_loss = 2.170, time/batch = 0.215\n",
            "13932/15750 (epoch 44), train_loss = 2.098, time/batch = 0.206\n",
            "13933/15750 (epoch 44), train_loss = 2.153, time/batch = 0.206\n",
            "13934/15750 (epoch 44), train_loss = 2.274, time/batch = 0.210\n",
            "13935/15750 (epoch 44), train_loss = 2.213, time/batch = 0.206\n",
            "13936/15750 (epoch 44), train_loss = 2.206, time/batch = 0.210\n",
            "13937/15750 (epoch 44), train_loss = 2.201, time/batch = 0.205\n",
            "13938/15750 (epoch 44), train_loss = 2.210, time/batch = 0.210\n",
            "13939/15750 (epoch 44), train_loss = 2.200, time/batch = 0.204\n",
            "13940/15750 (epoch 44), train_loss = 2.100, time/batch = 0.207\n",
            "13941/15750 (epoch 44), train_loss = 2.202, time/batch = 0.218\n",
            "13942/15750 (epoch 44), train_loss = 2.152, time/batch = 0.205\n",
            "13943/15750 (epoch 44), train_loss = 2.201, time/batch = 0.210\n",
            "13944/15750 (epoch 44), train_loss = 2.252, time/batch = 0.210\n",
            "13945/15750 (epoch 44), train_loss = 2.274, time/batch = 0.208\n",
            "13946/15750 (epoch 44), train_loss = 2.111, time/batch = 0.213\n",
            "13947/15750 (epoch 44), train_loss = 2.154, time/batch = 0.208\n",
            "13948/15750 (epoch 44), train_loss = 2.166, time/batch = 0.211\n",
            "13949/15750 (epoch 44), train_loss = 2.176, time/batch = 0.204\n",
            "13950/15750 (epoch 44), train_loss = 2.164, time/batch = 0.210\n",
            "13951/15750 (epoch 44), train_loss = 2.227, time/batch = 0.215\n",
            "13952/15750 (epoch 44), train_loss = 2.214, time/batch = 0.209\n",
            "13953/15750 (epoch 44), train_loss = 2.224, time/batch = 0.206\n",
            "13954/15750 (epoch 44), train_loss = 2.285, time/batch = 0.207\n",
            "13955/15750 (epoch 44), train_loss = 2.205, time/batch = 0.208\n",
            "13956/15750 (epoch 44), train_loss = 2.234, time/batch = 0.203\n",
            "13957/15750 (epoch 44), train_loss = 2.253, time/batch = 0.208\n",
            "13958/15750 (epoch 44), train_loss = 2.229, time/batch = 0.207\n",
            "13959/15750 (epoch 44), train_loss = 2.243, time/batch = 0.210\n",
            "13960/15750 (epoch 44), train_loss = 2.220, time/batch = 0.211\n",
            "13961/15750 (epoch 44), train_loss = 2.169, time/batch = 0.208\n",
            "13962/15750 (epoch 44), train_loss = 2.180, time/batch = 0.204\n",
            "13963/15750 (epoch 44), train_loss = 2.303, time/batch = 0.206\n",
            "13964/15750 (epoch 44), train_loss = 2.225, time/batch = 0.209\n",
            "13965/15750 (epoch 44), train_loss = 2.132, time/batch = 0.208\n",
            "13966/15750 (epoch 44), train_loss = 2.201, time/batch = 0.199\n",
            "13967/15750 (epoch 44), train_loss = 2.229, time/batch = 0.210\n",
            "13968/15750 (epoch 44), train_loss = 2.256, time/batch = 0.209\n",
            "13969/15750 (epoch 44), train_loss = 2.287, time/batch = 0.209\n",
            "13970/15750 (epoch 44), train_loss = 2.346, time/batch = 0.205\n",
            "13971/15750 (epoch 44), train_loss = 2.205, time/batch = 0.203\n",
            "13972/15750 (epoch 44), train_loss = 2.221, time/batch = 0.206\n",
            "13973/15750 (epoch 44), train_loss = 2.211, time/batch = 0.206\n",
            "13974/15750 (epoch 44), train_loss = 2.212, time/batch = 0.207\n",
            "13975/15750 (epoch 44), train_loss = 2.302, time/batch = 0.210\n",
            "13976/15750 (epoch 44), train_loss = 2.226, time/batch = 0.198\n",
            "13977/15750 (epoch 44), train_loss = 2.339, time/batch = 0.205\n",
            "13978/15750 (epoch 44), train_loss = 2.224, time/batch = 0.206\n",
            "13979/15750 (epoch 44), train_loss = 2.219, time/batch = 0.209\n",
            "13980/15750 (epoch 44), train_loss = 2.191, time/batch = 0.207\n",
            "13981/15750 (epoch 44), train_loss = 2.170, time/batch = 0.202\n",
            "13982/15750 (epoch 44), train_loss = 2.213, time/batch = 0.202\n",
            "13983/15750 (epoch 44), train_loss = 2.161, time/batch = 0.201\n",
            "13984/15750 (epoch 44), train_loss = 2.196, time/batch = 0.200\n",
            "13985/15750 (epoch 44), train_loss = 2.212, time/batch = 0.205\n",
            "13986/15750 (epoch 44), train_loss = 2.298, time/batch = 0.207\n",
            "13987/15750 (epoch 44), train_loss = 2.187, time/batch = 0.209\n",
            "13988/15750 (epoch 44), train_loss = 2.210, time/batch = 0.206\n",
            "13989/15750 (epoch 44), train_loss = 2.170, time/batch = 0.207\n",
            "13990/15750 (epoch 44), train_loss = 2.129, time/batch = 0.216\n",
            "13991/15750 (epoch 44), train_loss = 2.141, time/batch = 0.200\n",
            "13992/15750 (epoch 44), train_loss = 2.149, time/batch = 0.207\n",
            "13993/15750 (epoch 44), train_loss = 2.173, time/batch = 0.205\n",
            "13994/15750 (epoch 44), train_loss = 2.185, time/batch = 0.215\n",
            "13995/15750 (epoch 44), train_loss = 2.319, time/batch = 0.209\n",
            "13996/15750 (epoch 44), train_loss = 2.276, time/batch = 0.206\n",
            "13997/15750 (epoch 44), train_loss = 2.279, time/batch = 0.205\n",
            "13998/15750 (epoch 44), train_loss = 2.266, time/batch = 0.207\n",
            "13999/15750 (epoch 44), train_loss = 2.188, time/batch = 0.208\n",
            "14000/15750 (epoch 44), train_loss = 2.192, time/batch = 0.211\n",
            "model saved to ./save_star/model.ckpt\n",
            "14001/15750 (epoch 44), train_loss = 2.285, time/batch = 0.203\n",
            "14002/15750 (epoch 44), train_loss = 2.302, time/batch = 0.207\n",
            "14003/15750 (epoch 44), train_loss = 2.275, time/batch = 0.210\n",
            "14004/15750 (epoch 44), train_loss = 2.191, time/batch = 0.212\n",
            "14005/15750 (epoch 44), train_loss = 2.188, time/batch = 0.210\n",
            "14006/15750 (epoch 44), train_loss = 2.154, time/batch = 0.210\n",
            "14007/15750 (epoch 44), train_loss = 2.246, time/batch = 0.213\n",
            "14008/15750 (epoch 44), train_loss = 2.275, time/batch = 0.205\n",
            "14009/15750 (epoch 44), train_loss = 2.225, time/batch = 0.203\n",
            "14010/15750 (epoch 44), train_loss = 2.211, time/batch = 0.211\n",
            "14011/15750 (epoch 44), train_loss = 2.253, time/batch = 0.209\n",
            "14012/15750 (epoch 44), train_loss = 2.284, time/batch = 0.210\n",
            "14013/15750 (epoch 44), train_loss = 2.236, time/batch = 0.207\n",
            "14014/15750 (epoch 44), train_loss = 2.249, time/batch = 0.204\n",
            "14015/15750 (epoch 44), train_loss = 2.247, time/batch = 0.202\n",
            "14016/15750 (epoch 44), train_loss = 2.247, time/batch = 0.205\n",
            "14017/15750 (epoch 44), train_loss = 2.243, time/batch = 0.200\n",
            "14018/15750 (epoch 44), train_loss = 2.322, time/batch = 0.203\n",
            "14019/15750 (epoch 44), train_loss = 2.186, time/batch = 0.201\n",
            "14020/15750 (epoch 44), train_loss = 2.265, time/batch = 0.203\n",
            "14021/15750 (epoch 44), train_loss = 2.248, time/batch = 0.200\n",
            "14022/15750 (epoch 44), train_loss = 2.272, time/batch = 0.200\n",
            "14023/15750 (epoch 44), train_loss = 2.339, time/batch = 0.206\n",
            "14024/15750 (epoch 44), train_loss = 2.263, time/batch = 0.209\n",
            "14025/15750 (epoch 44), train_loss = 2.263, time/batch = 0.206\n",
            "14026/15750 (epoch 44), train_loss = 2.249, time/batch = 0.211\n",
            "14027/15750 (epoch 44), train_loss = 2.220, time/batch = 0.208\n",
            "14028/15750 (epoch 44), train_loss = 2.185, time/batch = 0.203\n",
            "14029/15750 (epoch 44), train_loss = 2.179, time/batch = 0.208\n",
            "14030/15750 (epoch 44), train_loss = 2.218, time/batch = 0.204\n",
            "14031/15750 (epoch 44), train_loss = 2.250, time/batch = 0.207\n",
            "14032/15750 (epoch 44), train_loss = 2.226, time/batch = 0.204\n",
            "14033/15750 (epoch 44), train_loss = 2.299, time/batch = 0.209\n",
            "14034/15750 (epoch 44), train_loss = 2.227, time/batch = 0.207\n",
            "14035/15750 (epoch 44), train_loss = 2.163, time/batch = 0.210\n",
            "14036/15750 (epoch 44), train_loss = 2.191, time/batch = 0.206\n",
            "14037/15750 (epoch 44), train_loss = 2.252, time/batch = 0.207\n",
            "14038/15750 (epoch 44), train_loss = 2.186, time/batch = 0.216\n",
            "14039/15750 (epoch 44), train_loss = 2.145, time/batch = 0.207\n",
            "14040/15750 (epoch 44), train_loss = 2.182, time/batch = 0.199\n",
            "14041/15750 (epoch 44), train_loss = 2.256, time/batch = 0.204\n",
            "14042/15750 (epoch 44), train_loss = 2.234, time/batch = 0.198\n",
            "14043/15750 (epoch 44), train_loss = 2.297, time/batch = 0.210\n",
            "14044/15750 (epoch 44), train_loss = 2.271, time/batch = 0.205\n",
            "14045/15750 (epoch 44), train_loss = 2.236, time/batch = 0.210\n",
            "14046/15750 (epoch 44), train_loss = 2.190, time/batch = 0.206\n",
            "14047/15750 (epoch 44), train_loss = 2.256, time/batch = 0.209\n",
            "14048/15750 (epoch 44), train_loss = 2.279, time/batch = 0.211\n",
            "14049/15750 (epoch 44), train_loss = 2.339, time/batch = 0.204\n",
            "14050/15750 (epoch 44), train_loss = 2.329, time/batch = 0.213\n",
            "14051/15750 (epoch 44), train_loss = 2.233, time/batch = 0.207\n",
            "14052/15750 (epoch 44), train_loss = 2.250, time/batch = 0.208\n",
            "14053/15750 (epoch 44), train_loss = 2.180, time/batch = 0.211\n",
            "14054/15750 (epoch 44), train_loss = 2.308, time/batch = 0.210\n",
            "14055/15750 (epoch 44), train_loss = 2.273, time/batch = 0.204\n",
            "14056/15750 (epoch 44), train_loss = 2.231, time/batch = 0.207\n",
            "14057/15750 (epoch 44), train_loss = 2.179, time/batch = 0.207\n",
            "14058/15750 (epoch 44), train_loss = 2.285, time/batch = 0.216\n",
            "14059/15750 (epoch 44), train_loss = 2.071, time/batch = 0.209\n",
            "14060/15750 (epoch 44), train_loss = 2.185, time/batch = 0.204\n",
            "14061/15750 (epoch 44), train_loss = 2.149, time/batch = 0.205\n",
            "14062/15750 (epoch 44), train_loss = 2.225, time/batch = 0.208\n",
            "14063/15750 (epoch 44), train_loss = 2.194, time/batch = 0.213\n",
            "14064/15750 (epoch 44), train_loss = 2.264, time/batch = 0.208\n",
            "14065/15750 (epoch 44), train_loss = 2.202, time/batch = 0.208\n",
            "14066/15750 (epoch 44), train_loss = 2.095, time/batch = 0.204\n",
            "14067/15750 (epoch 44), train_loss = 2.158, time/batch = 0.209\n",
            "14068/15750 (epoch 44), train_loss = 2.164, time/batch = 0.216\n",
            "14069/15750 (epoch 44), train_loss = 2.228, time/batch = 0.202\n",
            "14070/15750 (epoch 44), train_loss = 2.119, time/batch = 0.207\n",
            "14071/15750 (epoch 44), train_loss = 2.192, time/batch = 0.207\n",
            "14072/15750 (epoch 44), train_loss = 2.085, time/batch = 0.205\n",
            "14073/15750 (epoch 44), train_loss = 2.155, time/batch = 0.214\n",
            "14074/15750 (epoch 44), train_loss = 2.145, time/batch = 0.201\n",
            "14075/15750 (epoch 44), train_loss = 2.126, time/batch = 0.208\n",
            "14076/15750 (epoch 44), train_loss = 2.287, time/batch = 0.198\n",
            "14077/15750 (epoch 44), train_loss = 2.112, time/batch = 0.198\n",
            "14078/15750 (epoch 44), train_loss = 2.352, time/batch = 0.210\n",
            "14079/15750 (epoch 44), train_loss = 2.223, time/batch = 0.198\n",
            "14080/15750 (epoch 44), train_loss = 2.107, time/batch = 0.203\n",
            "14081/15750 (epoch 44), train_loss = 2.132, time/batch = 0.196\n",
            "14082/15750 (epoch 44), train_loss = 2.197, time/batch = 0.201\n",
            "14083/15750 (epoch 44), train_loss = 2.182, time/batch = 0.206\n",
            "14084/15750 (epoch 44), train_loss = 2.164, time/batch = 0.205\n",
            "14085/15750 (epoch 44), train_loss = 2.178, time/batch = 0.198\n",
            "14086/15750 (epoch 44), train_loss = 2.241, time/batch = 0.203\n",
            "14087/15750 (epoch 44), train_loss = 2.163, time/batch = 0.204\n",
            "14088/15750 (epoch 44), train_loss = 2.209, time/batch = 0.202\n",
            "14089/15750 (epoch 44), train_loss = 2.295, time/batch = 0.195\n",
            "14090/15750 (epoch 44), train_loss = 2.150, time/batch = 0.205\n",
            "14091/15750 (epoch 44), train_loss = 2.164, time/batch = 0.202\n",
            "14092/15750 (epoch 44), train_loss = 2.203, time/batch = 0.204\n",
            "14093/15750 (epoch 44), train_loss = 2.206, time/batch = 0.206\n",
            "14094/15750 (epoch 44), train_loss = 2.159, time/batch = 0.207\n",
            "14095/15750 (epoch 44), train_loss = 2.147, time/batch = 0.203\n",
            "14096/15750 (epoch 44), train_loss = 2.118, time/batch = 0.207\n",
            "14097/15750 (epoch 44), train_loss = 2.162, time/batch = 0.204\n",
            "14098/15750 (epoch 44), train_loss = 2.360, time/batch = 0.213\n",
            "14099/15750 (epoch 44), train_loss = 2.198, time/batch = 0.209\n",
            "14100/15750 (epoch 44), train_loss = 2.253, time/batch = 0.204\n",
            "14101/15750 (epoch 44), train_loss = 2.134, time/batch = 0.206\n",
            "14102/15750 (epoch 44), train_loss = 2.181, time/batch = 0.212\n",
            "14103/15750 (epoch 44), train_loss = 2.206, time/batch = 0.210\n",
            "14104/15750 (epoch 44), train_loss = 2.216, time/batch = 0.205\n",
            "14105/15750 (epoch 44), train_loss = 2.270, time/batch = 0.207\n",
            "14106/15750 (epoch 44), train_loss = 2.224, time/batch = 0.209\n",
            "14107/15750 (epoch 44), train_loss = 2.226, time/batch = 0.212\n",
            "14108/15750 (epoch 44), train_loss = 2.200, time/batch = 0.215\n",
            "14109/15750 (epoch 44), train_loss = 2.222, time/batch = 0.204\n",
            "14110/15750 (epoch 44), train_loss = 2.131, time/batch = 0.203\n",
            "14111/15750 (epoch 44), train_loss = 2.121, time/batch = 0.207\n",
            "14112/15750 (epoch 44), train_loss = 2.213, time/batch = 0.206\n",
            "14113/15750 (epoch 44), train_loss = 2.231, time/batch = 0.214\n",
            "14114/15750 (epoch 44), train_loss = 2.198, time/batch = 0.209\n",
            "14115/15750 (epoch 44), train_loss = 2.163, time/batch = 0.206\n",
            "14116/15750 (epoch 44), train_loss = 2.115, time/batch = 0.209\n",
            "14117/15750 (epoch 44), train_loss = 2.145, time/batch = 0.210\n",
            "14118/15750 (epoch 44), train_loss = 2.291, time/batch = 0.208\n",
            "14119/15750 (epoch 44), train_loss = 2.268, time/batch = 0.206\n",
            "14120/15750 (epoch 44), train_loss = 2.242, time/batch = 0.212\n",
            "14121/15750 (epoch 44), train_loss = 2.187, time/batch = 0.211\n",
            "14122/15750 (epoch 44), train_loss = 2.209, time/batch = 0.212\n",
            "14123/15750 (epoch 44), train_loss = 2.201, time/batch = 0.203\n",
            "14124/15750 (epoch 44), train_loss = 2.214, time/batch = 0.205\n",
            "14125/15750 (epoch 44), train_loss = 2.265, time/batch = 0.205\n",
            "14126/15750 (epoch 44), train_loss = 2.264, time/batch = 0.205\n",
            "14127/15750 (epoch 44), train_loss = 2.198, time/batch = 0.204\n",
            "14128/15750 (epoch 44), train_loss = 2.225, time/batch = 0.195\n",
            "14129/15750 (epoch 44), train_loss = 2.263, time/batch = 0.202\n",
            "14130/15750 (epoch 44), train_loss = 2.249, time/batch = 0.201\n",
            "14131/15750 (epoch 44), train_loss = 2.165, time/batch = 0.206\n",
            "14132/15750 (epoch 44), train_loss = 2.202, time/batch = 0.205\n",
            "14133/15750 (epoch 44), train_loss = 2.258, time/batch = 0.204\n",
            "14134/15750 (epoch 44), train_loss = 2.272, time/batch = 0.205\n",
            "14135/15750 (epoch 44), train_loss = 2.212, time/batch = 0.207\n",
            "14136/15750 (epoch 44), train_loss = 2.276, time/batch = 0.199\n",
            "14137/15750 (epoch 44), train_loss = 2.215, time/batch = 0.200\n",
            "14138/15750 (epoch 44), train_loss = 2.192, time/batch = 0.205\n",
            "14139/15750 (epoch 44), train_loss = 2.140, time/batch = 0.203\n",
            "14140/15750 (epoch 44), train_loss = 2.347, time/batch = 0.206\n",
            "14141/15750 (epoch 44), train_loss = 2.179, time/batch = 0.208\n",
            "14142/15750 (epoch 44), train_loss = 2.156, time/batch = 0.212\n",
            "14143/15750 (epoch 44), train_loss = 2.258, time/batch = 0.205\n",
            "14144/15750 (epoch 44), train_loss = 2.170, time/batch = 0.205\n",
            "14145/15750 (epoch 44), train_loss = 2.296, time/batch = 0.208\n",
            "14146/15750 (epoch 44), train_loss = 2.212, time/batch = 0.208\n",
            "14147/15750 (epoch 44), train_loss = 2.218, time/batch = 0.217\n",
            "14148/15750 (epoch 44), train_loss = 2.139, time/batch = 0.205\n",
            "14149/15750 (epoch 44), train_loss = 2.235, time/batch = 0.214\n",
            "14150/15750 (epoch 44), train_loss = 2.159, time/batch = 0.209\n",
            "14151/15750 (epoch 44), train_loss = 2.222, time/batch = 0.210\n",
            "14152/15750 (epoch 44), train_loss = 2.231, time/batch = 0.211\n",
            "14153/15750 (epoch 44), train_loss = 2.181, time/batch = 0.208\n",
            "14154/15750 (epoch 44), train_loss = 2.236, time/batch = 0.204\n",
            "14155/15750 (epoch 44), train_loss = 2.311, time/batch = 0.203\n",
            "14156/15750 (epoch 44), train_loss = 2.258, time/batch = 0.201\n",
            "14157/15750 (epoch 44), train_loss = 2.287, time/batch = 0.209\n",
            "14158/15750 (epoch 44), train_loss = 2.168, time/batch = 0.208\n",
            "14159/15750 (epoch 44), train_loss = 2.235, time/batch = 0.211\n",
            "14160/15750 (epoch 44), train_loss = 2.218, time/batch = 0.209\n",
            "14161/15750 (epoch 44), train_loss = 2.163, time/batch = 0.207\n",
            "14162/15750 (epoch 44), train_loss = 2.290, time/batch = 0.212\n",
            "14163/15750 (epoch 44), train_loss = 2.138, time/batch = 0.213\n",
            "14164/15750 (epoch 44), train_loss = 2.261, time/batch = 0.204\n",
            "14165/15750 (epoch 44), train_loss = 2.219, time/batch = 0.209\n",
            "14166/15750 (epoch 44), train_loss = 2.182, time/batch = 0.207\n",
            "14167/15750 (epoch 44), train_loss = 2.129, time/batch = 0.211\n",
            "14168/15750 (epoch 44), train_loss = 2.167, time/batch = 0.202\n",
            "14169/15750 (epoch 44), train_loss = 2.276, time/batch = 0.205\n",
            "14170/15750 (epoch 44), train_loss = 2.157, time/batch = 0.206\n",
            "14171/15750 (epoch 44), train_loss = 2.130, time/batch = 0.202\n",
            "14172/15750 (epoch 44), train_loss = 2.166, time/batch = 0.205\n",
            "14173/15750 (epoch 44), train_loss = 2.184, time/batch = 0.199\n",
            "14174/15750 (epoch 44), train_loss = 2.272, time/batch = 0.204\n",
            "14175/15750 (epoch 45), train_loss = 2.080, time/batch = 0.216\n",
            "14176/15750 (epoch 45), train_loss = 2.266, time/batch = 0.209\n",
            "14177/15750 (epoch 45), train_loss = 2.187, time/batch = 0.206\n",
            "14178/15750 (epoch 45), train_loss = 2.290, time/batch = 0.202\n",
            "14179/15750 (epoch 45), train_loss = 2.219, time/batch = 0.204\n",
            "14180/15750 (epoch 45), train_loss = 2.215, time/batch = 0.206\n",
            "14181/15750 (epoch 45), train_loss = 2.362, time/batch = 0.214\n",
            "14182/15750 (epoch 45), train_loss = 2.284, time/batch = 0.203\n",
            "14183/15750 (epoch 45), train_loss = 2.281, time/batch = 0.201\n",
            "14184/15750 (epoch 45), train_loss = 2.230, time/batch = 0.203\n",
            "14185/15750 (epoch 45), train_loss = 2.223, time/batch = 0.199\n",
            "14186/15750 (epoch 45), train_loss = 2.198, time/batch = 0.207\n",
            "14187/15750 (epoch 45), train_loss = 2.272, time/batch = 0.207\n",
            "14188/15750 (epoch 45), train_loss = 2.256, time/batch = 0.204\n",
            "14189/15750 (epoch 45), train_loss = 2.230, time/batch = 0.212\n",
            "14190/15750 (epoch 45), train_loss = 2.247, time/batch = 0.208\n",
            "14191/15750 (epoch 45), train_loss = 2.250, time/batch = 0.212\n",
            "14192/15750 (epoch 45), train_loss = 2.311, time/batch = 0.210\n",
            "14193/15750 (epoch 45), train_loss = 2.326, time/batch = 0.213\n",
            "14194/15750 (epoch 45), train_loss = 2.279, time/batch = 0.208\n",
            "14195/15750 (epoch 45), train_loss = 2.260, time/batch = 0.204\n",
            "14196/15750 (epoch 45), train_loss = 2.270, time/batch = 0.208\n",
            "14197/15750 (epoch 45), train_loss = 2.223, time/batch = 0.209\n",
            "14198/15750 (epoch 45), train_loss = 2.283, time/batch = 0.213\n",
            "14199/15750 (epoch 45), train_loss = 2.287, time/batch = 0.203\n",
            "14200/15750 (epoch 45), train_loss = 2.308, time/batch = 0.204\n",
            "14201/15750 (epoch 45), train_loss = 2.315, time/batch = 0.209\n",
            "14202/15750 (epoch 45), train_loss = 2.295, time/batch = 0.205\n",
            "14203/15750 (epoch 45), train_loss = 2.401, time/batch = 0.200\n",
            "14204/15750 (epoch 45), train_loss = 2.316, time/batch = 0.197\n",
            "14205/15750 (epoch 45), train_loss = 2.276, time/batch = 0.211\n",
            "14206/15750 (epoch 45), train_loss = 2.245, time/batch = 0.208\n",
            "14207/15750 (epoch 45), train_loss = 2.163, time/batch = 0.206\n",
            "14208/15750 (epoch 45), train_loss = 2.176, time/batch = 0.211\n",
            "14209/15750 (epoch 45), train_loss = 2.262, time/batch = 0.206\n",
            "14210/15750 (epoch 45), train_loss = 2.163, time/batch = 0.211\n",
            "14211/15750 (epoch 45), train_loss = 2.249, time/batch = 0.215\n",
            "14212/15750 (epoch 45), train_loss = 2.296, time/batch = 0.208\n",
            "14213/15750 (epoch 45), train_loss = 2.205, time/batch = 0.205\n",
            "14214/15750 (epoch 45), train_loss = 2.252, time/batch = 0.216\n",
            "14215/15750 (epoch 45), train_loss = 2.211, time/batch = 0.203\n",
            "14216/15750 (epoch 45), train_loss = 2.261, time/batch = 0.215\n",
            "14217/15750 (epoch 45), train_loss = 2.259, time/batch = 0.207\n",
            "14218/15750 (epoch 45), train_loss = 2.227, time/batch = 0.203\n",
            "14219/15750 (epoch 45), train_loss = 2.257, time/batch = 0.208\n",
            "14220/15750 (epoch 45), train_loss = 2.187, time/batch = 0.201\n",
            "14221/15750 (epoch 45), train_loss = 2.230, time/batch = 0.210\n",
            "14222/15750 (epoch 45), train_loss = 2.238, time/batch = 0.203\n",
            "14223/15750 (epoch 45), train_loss = 2.280, time/batch = 0.201\n",
            "14224/15750 (epoch 45), train_loss = 2.163, time/batch = 0.201\n",
            "14225/15750 (epoch 45), train_loss = 2.237, time/batch = 0.201\n",
            "14226/15750 (epoch 45), train_loss = 2.186, time/batch = 0.212\n",
            "14227/15750 (epoch 45), train_loss = 2.238, time/batch = 0.202\n",
            "14228/15750 (epoch 45), train_loss = 2.256, time/batch = 0.203\n",
            "14229/15750 (epoch 45), train_loss = 2.252, time/batch = 0.211\n",
            "14230/15750 (epoch 45), train_loss = 2.286, time/batch = 0.207\n",
            "14231/15750 (epoch 45), train_loss = 2.174, time/batch = 0.213\n",
            "14232/15750 (epoch 45), train_loss = 2.164, time/batch = 0.207\n",
            "14233/15750 (epoch 45), train_loss = 2.266, time/batch = 0.210\n",
            "14234/15750 (epoch 45), train_loss = 2.131, time/batch = 0.212\n",
            "14235/15750 (epoch 45), train_loss = 2.227, time/batch = 0.207\n",
            "14236/15750 (epoch 45), train_loss = 2.236, time/batch = 0.202\n",
            "14237/15750 (epoch 45), train_loss = 2.161, time/batch = 0.208\n",
            "14238/15750 (epoch 45), train_loss = 2.220, time/batch = 0.206\n",
            "14239/15750 (epoch 45), train_loss = 2.125, time/batch = 0.203\n",
            "14240/15750 (epoch 45), train_loss = 2.151, time/batch = 0.206\n",
            "14241/15750 (epoch 45), train_loss = 2.087, time/batch = 0.203\n",
            "14242/15750 (epoch 45), train_loss = 2.103, time/batch = 0.205\n",
            "14243/15750 (epoch 45), train_loss = 2.156, time/batch = 0.210\n",
            "14244/15750 (epoch 45), train_loss = 2.260, time/batch = 0.201\n",
            "14245/15750 (epoch 45), train_loss = 2.179, time/batch = 0.206\n",
            "14246/15750 (epoch 45), train_loss = 2.166, time/batch = 0.205\n",
            "14247/15750 (epoch 45), train_loss = 2.095, time/batch = 0.205\n",
            "14248/15750 (epoch 45), train_loss = 2.149, time/batch = 0.210\n",
            "14249/15750 (epoch 45), train_loss = 2.270, time/batch = 0.209\n",
            "14250/15750 (epoch 45), train_loss = 2.209, time/batch = 0.211\n",
            "14251/15750 (epoch 45), train_loss = 2.202, time/batch = 0.202\n",
            "14252/15750 (epoch 45), train_loss = 2.198, time/batch = 0.205\n",
            "14253/15750 (epoch 45), train_loss = 2.207, time/batch = 0.206\n",
            "14254/15750 (epoch 45), train_loss = 2.196, time/batch = 0.205\n",
            "14255/15750 (epoch 45), train_loss = 2.096, time/batch = 0.206\n",
            "14256/15750 (epoch 45), train_loss = 2.199, time/batch = 0.201\n",
            "14257/15750 (epoch 45), train_loss = 2.150, time/batch = 0.203\n",
            "14258/15750 (epoch 45), train_loss = 2.197, time/batch = 0.205\n",
            "14259/15750 (epoch 45), train_loss = 2.248, time/batch = 0.203\n",
            "14260/15750 (epoch 45), train_loss = 2.270, time/batch = 0.215\n",
            "14261/15750 (epoch 45), train_loss = 2.107, time/batch = 0.207\n",
            "14262/15750 (epoch 45), train_loss = 2.151, time/batch = 0.205\n",
            "14263/15750 (epoch 45), train_loss = 2.162, time/batch = 0.204\n",
            "14264/15750 (epoch 45), train_loss = 2.172, time/batch = 0.202\n",
            "14265/15750 (epoch 45), train_loss = 2.160, time/batch = 0.208\n",
            "14266/15750 (epoch 45), train_loss = 2.223, time/batch = 0.204\n",
            "14267/15750 (epoch 45), train_loss = 2.210, time/batch = 0.200\n",
            "14268/15750 (epoch 45), train_loss = 2.220, time/batch = 0.201\n",
            "14269/15750 (epoch 45), train_loss = 2.281, time/batch = 0.199\n",
            "14270/15750 (epoch 45), train_loss = 2.201, time/batch = 0.202\n",
            "14271/15750 (epoch 45), train_loss = 2.231, time/batch = 0.195\n",
            "14272/15750 (epoch 45), train_loss = 2.249, time/batch = 0.199\n",
            "14273/15750 (epoch 45), train_loss = 2.226, time/batch = 0.201\n",
            "14274/15750 (epoch 45), train_loss = 2.239, time/batch = 0.202\n",
            "14275/15750 (epoch 45), train_loss = 2.217, time/batch = 0.204\n",
            "14276/15750 (epoch 45), train_loss = 2.165, time/batch = 0.203\n",
            "14277/15750 (epoch 45), train_loss = 2.177, time/batch = 0.200\n",
            "14278/15750 (epoch 45), train_loss = 2.299, time/batch = 0.205\n",
            "14279/15750 (epoch 45), train_loss = 2.221, time/batch = 0.199\n",
            "14280/15750 (epoch 45), train_loss = 2.128, time/batch = 0.200\n",
            "14281/15750 (epoch 45), train_loss = 2.198, time/batch = 0.210\n",
            "14282/15750 (epoch 45), train_loss = 2.226, time/batch = 0.200\n",
            "14283/15750 (epoch 45), train_loss = 2.252, time/batch = 0.205\n",
            "14284/15750 (epoch 45), train_loss = 2.283, time/batch = 0.202\n",
            "14285/15750 (epoch 45), train_loss = 2.342, time/batch = 0.202\n",
            "14286/15750 (epoch 45), train_loss = 2.201, time/batch = 0.209\n",
            "14287/15750 (epoch 45), train_loss = 2.218, time/batch = 0.198\n",
            "14288/15750 (epoch 45), train_loss = 2.208, time/batch = 0.202\n",
            "14289/15750 (epoch 45), train_loss = 2.208, time/batch = 0.199\n",
            "14290/15750 (epoch 45), train_loss = 2.298, time/batch = 0.202\n",
            "14291/15750 (epoch 45), train_loss = 2.222, time/batch = 0.207\n",
            "14292/15750 (epoch 45), train_loss = 2.335, time/batch = 0.201\n",
            "14293/15750 (epoch 45), train_loss = 2.220, time/batch = 0.200\n",
            "14294/15750 (epoch 45), train_loss = 2.216, time/batch = 0.198\n",
            "14295/15750 (epoch 45), train_loss = 2.187, time/batch = 0.203\n",
            "14296/15750 (epoch 45), train_loss = 2.166, time/batch = 0.206\n",
            "14297/15750 (epoch 45), train_loss = 2.210, time/batch = 0.201\n",
            "14298/15750 (epoch 45), train_loss = 2.157, time/batch = 0.196\n",
            "14299/15750 (epoch 45), train_loss = 2.192, time/batch = 0.200\n",
            "14300/15750 (epoch 45), train_loss = 2.208, time/batch = 0.202\n",
            "14301/15750 (epoch 45), train_loss = 2.294, time/batch = 0.208\n",
            "14302/15750 (epoch 45), train_loss = 2.183, time/batch = 0.203\n",
            "14303/15750 (epoch 45), train_loss = 2.207, time/batch = 0.199\n",
            "14304/15750 (epoch 45), train_loss = 2.167, time/batch = 0.200\n",
            "14305/15750 (epoch 45), train_loss = 2.126, time/batch = 0.206\n",
            "14306/15750 (epoch 45), train_loss = 2.138, time/batch = 0.206\n",
            "14307/15750 (epoch 45), train_loss = 2.145, time/batch = 0.202\n",
            "14308/15750 (epoch 45), train_loss = 2.169, time/batch = 0.196\n",
            "14309/15750 (epoch 45), train_loss = 2.180, time/batch = 0.200\n",
            "14310/15750 (epoch 45), train_loss = 2.316, time/batch = 0.204\n",
            "14311/15750 (epoch 45), train_loss = 2.272, time/batch = 0.204\n",
            "14312/15750 (epoch 45), train_loss = 2.276, time/batch = 0.197\n",
            "14313/15750 (epoch 45), train_loss = 2.262, time/batch = 0.200\n",
            "14314/15750 (epoch 45), train_loss = 2.184, time/batch = 0.202\n",
            "14315/15750 (epoch 45), train_loss = 2.188, time/batch = 0.204\n",
            "14316/15750 (epoch 45), train_loss = 2.281, time/batch = 0.207\n",
            "14317/15750 (epoch 45), train_loss = 2.299, time/batch = 0.202\n",
            "14318/15750 (epoch 45), train_loss = 2.272, time/batch = 0.203\n",
            "14319/15750 (epoch 45), train_loss = 2.187, time/batch = 0.196\n",
            "14320/15750 (epoch 45), train_loss = 2.185, time/batch = 0.201\n",
            "14321/15750 (epoch 45), train_loss = 2.151, time/batch = 0.207\n",
            "14322/15750 (epoch 45), train_loss = 2.242, time/batch = 0.200\n",
            "14323/15750 (epoch 45), train_loss = 2.271, time/batch = 0.201\n",
            "14324/15750 (epoch 45), train_loss = 2.222, time/batch = 0.200\n",
            "14325/15750 (epoch 45), train_loss = 2.207, time/batch = 0.195\n",
            "14326/15750 (epoch 45), train_loss = 2.250, time/batch = 0.208\n",
            "14327/15750 (epoch 45), train_loss = 2.279, time/batch = 0.202\n",
            "14328/15750 (epoch 45), train_loss = 2.232, time/batch = 0.197\n",
            "14329/15750 (epoch 45), train_loss = 2.245, time/batch = 0.201\n",
            "14330/15750 (epoch 45), train_loss = 2.243, time/batch = 0.203\n",
            "14331/15750 (epoch 45), train_loss = 2.243, time/batch = 0.200\n",
            "14332/15750 (epoch 45), train_loss = 2.239, time/batch = 0.204\n",
            "14333/15750 (epoch 45), train_loss = 2.318, time/batch = 0.201\n",
            "14334/15750 (epoch 45), train_loss = 2.183, time/batch = 0.202\n",
            "14335/15750 (epoch 45), train_loss = 2.262, time/batch = 0.199\n",
            "14336/15750 (epoch 45), train_loss = 2.244, time/batch = 0.207\n",
            "14337/15750 (epoch 45), train_loss = 2.269, time/batch = 0.204\n",
            "14338/15750 (epoch 45), train_loss = 2.335, time/batch = 0.200\n",
            "14339/15750 (epoch 45), train_loss = 2.259, time/batch = 0.203\n",
            "14340/15750 (epoch 45), train_loss = 2.259, time/batch = 0.204\n",
            "14341/15750 (epoch 45), train_loss = 2.245, time/batch = 0.208\n",
            "14342/15750 (epoch 45), train_loss = 2.216, time/batch = 0.201\n",
            "14343/15750 (epoch 45), train_loss = 2.181, time/batch = 0.195\n",
            "14344/15750 (epoch 45), train_loss = 2.175, time/batch = 0.200\n",
            "14345/15750 (epoch 45), train_loss = 2.214, time/batch = 0.201\n",
            "14346/15750 (epoch 45), train_loss = 2.246, time/batch = 0.204\n",
            "14347/15750 (epoch 45), train_loss = 2.223, time/batch = 0.199\n",
            "14348/15750 (epoch 45), train_loss = 2.296, time/batch = 0.199\n",
            "14349/15750 (epoch 45), train_loss = 2.224, time/batch = 0.204\n",
            "14350/15750 (epoch 45), train_loss = 2.159, time/batch = 0.199\n",
            "14351/15750 (epoch 45), train_loss = 2.187, time/batch = 0.199\n",
            "14352/15750 (epoch 45), train_loss = 2.248, time/batch = 0.199\n",
            "14353/15750 (epoch 45), train_loss = 2.182, time/batch = 0.202\n",
            "14354/15750 (epoch 45), train_loss = 2.141, time/batch = 0.202\n",
            "14355/15750 (epoch 45), train_loss = 2.179, time/batch = 0.203\n",
            "14356/15750 (epoch 45), train_loss = 2.252, time/batch = 0.201\n",
            "14357/15750 (epoch 45), train_loss = 2.230, time/batch = 0.207\n",
            "14358/15750 (epoch 45), train_loss = 2.293, time/batch = 0.202\n",
            "14359/15750 (epoch 45), train_loss = 2.266, time/batch = 0.200\n",
            "14360/15750 (epoch 45), train_loss = 2.233, time/batch = 0.198\n",
            "14361/15750 (epoch 45), train_loss = 2.186, time/batch = 0.202\n",
            "14362/15750 (epoch 45), train_loss = 2.253, time/batch = 0.204\n",
            "14363/15750 (epoch 45), train_loss = 2.276, time/batch = 0.200\n",
            "14364/15750 (epoch 45), train_loss = 2.334, time/batch = 0.201\n",
            "14365/15750 (epoch 45), train_loss = 2.325, time/batch = 0.202\n",
            "14366/15750 (epoch 45), train_loss = 2.229, time/batch = 0.202\n",
            "14367/15750 (epoch 45), train_loss = 2.246, time/batch = 0.207\n",
            "14368/15750 (epoch 45), train_loss = 2.177, time/batch = 0.200\n",
            "14369/15750 (epoch 45), train_loss = 2.304, time/batch = 0.200\n",
            "14370/15750 (epoch 45), train_loss = 2.268, time/batch = 0.200\n",
            "14371/15750 (epoch 45), train_loss = 2.227, time/batch = 0.199\n",
            "14372/15750 (epoch 45), train_loss = 2.175, time/batch = 0.207\n",
            "14373/15750 (epoch 45), train_loss = 2.282, time/batch = 0.200\n",
            "14374/15750 (epoch 45), train_loss = 2.067, time/batch = 0.200\n",
            "14375/15750 (epoch 45), train_loss = 2.180, time/batch = 0.201\n",
            "14376/15750 (epoch 45), train_loss = 2.146, time/batch = 0.201\n",
            "14377/15750 (epoch 45), train_loss = 2.221, time/batch = 0.207\n",
            "14378/15750 (epoch 45), train_loss = 2.190, time/batch = 0.203\n",
            "14379/15750 (epoch 45), train_loss = 2.260, time/batch = 0.203\n",
            "14380/15750 (epoch 45), train_loss = 2.199, time/batch = 0.202\n",
            "14381/15750 (epoch 45), train_loss = 2.091, time/batch = 0.203\n",
            "14382/15750 (epoch 45), train_loss = 2.154, time/batch = 0.205\n",
            "14383/15750 (epoch 45), train_loss = 2.160, time/batch = 0.201\n",
            "14384/15750 (epoch 45), train_loss = 2.225, time/batch = 0.201\n",
            "14385/15750 (epoch 45), train_loss = 2.116, time/batch = 0.196\n",
            "14386/15750 (epoch 45), train_loss = 2.189, time/batch = 0.202\n",
            "14387/15750 (epoch 45), train_loss = 2.081, time/batch = 0.205\n",
            "14388/15750 (epoch 45), train_loss = 2.152, time/batch = 0.200\n",
            "14389/15750 (epoch 45), train_loss = 2.142, time/batch = 0.203\n",
            "14390/15750 (epoch 45), train_loss = 2.122, time/batch = 0.195\n",
            "14391/15750 (epoch 45), train_loss = 2.284, time/batch = 0.200\n",
            "14392/15750 (epoch 45), train_loss = 2.109, time/batch = 0.208\n",
            "14393/15750 (epoch 45), train_loss = 2.348, time/batch = 0.201\n",
            "14394/15750 (epoch 45), train_loss = 2.219, time/batch = 0.204\n",
            "14395/15750 (epoch 45), train_loss = 2.104, time/batch = 0.203\n",
            "14396/15750 (epoch 45), train_loss = 2.129, time/batch = 0.200\n",
            "14397/15750 (epoch 45), train_loss = 2.194, time/batch = 0.207\n",
            "14398/15750 (epoch 45), train_loss = 2.178, time/batch = 0.201\n",
            "14399/15750 (epoch 45), train_loss = 2.160, time/batch = 0.198\n",
            "14400/15750 (epoch 45), train_loss = 2.174, time/batch = 0.201\n",
            "14401/15750 (epoch 45), train_loss = 2.238, time/batch = 0.203\n",
            "14402/15750 (epoch 45), train_loss = 2.159, time/batch = 0.208\n",
            "14403/15750 (epoch 45), train_loss = 2.206, time/batch = 0.201\n",
            "14404/15750 (epoch 45), train_loss = 2.291, time/batch = 0.200\n",
            "14405/15750 (epoch 45), train_loss = 2.147, time/batch = 0.201\n",
            "14406/15750 (epoch 45), train_loss = 2.161, time/batch = 0.202\n",
            "14407/15750 (epoch 45), train_loss = 2.199, time/batch = 0.203\n",
            "14408/15750 (epoch 45), train_loss = 2.202, time/batch = 0.200\n",
            "14409/15750 (epoch 45), train_loss = 2.155, time/batch = 0.202\n",
            "14410/15750 (epoch 45), train_loss = 2.143, time/batch = 0.199\n",
            "14411/15750 (epoch 45), train_loss = 2.114, time/batch = 0.201\n",
            "14412/15750 (epoch 45), train_loss = 2.158, time/batch = 0.203\n",
            "14413/15750 (epoch 45), train_loss = 2.356, time/batch = 0.197\n",
            "14414/15750 (epoch 45), train_loss = 2.195, time/batch = 0.200\n",
            "14415/15750 (epoch 45), train_loss = 2.249, time/batch = 0.199\n",
            "14416/15750 (epoch 45), train_loss = 2.131, time/batch = 0.202\n",
            "14417/15750 (epoch 45), train_loss = 2.178, time/batch = 0.206\n",
            "14418/15750 (epoch 45), train_loss = 2.202, time/batch = 0.202\n",
            "14419/15750 (epoch 45), train_loss = 2.212, time/batch = 0.199\n",
            "14420/15750 (epoch 45), train_loss = 2.266, time/batch = 0.201\n",
            "14421/15750 (epoch 45), train_loss = 2.221, time/batch = 0.202\n",
            "14422/15750 (epoch 45), train_loss = 2.223, time/batch = 0.201\n",
            "14423/15750 (epoch 45), train_loss = 2.196, time/batch = 0.193\n",
            "14424/15750 (epoch 45), train_loss = 2.218, time/batch = 0.202\n",
            "14425/15750 (epoch 45), train_loss = 2.128, time/batch = 0.202\n",
            "14426/15750 (epoch 45), train_loss = 2.118, time/batch = 0.204\n",
            "14427/15750 (epoch 45), train_loss = 2.210, time/batch = 0.202\n",
            "14428/15750 (epoch 45), train_loss = 2.227, time/batch = 0.203\n",
            "14429/15750 (epoch 45), train_loss = 2.195, time/batch = 0.201\n",
            "14430/15750 (epoch 45), train_loss = 2.160, time/batch = 0.201\n",
            "14431/15750 (epoch 45), train_loss = 2.111, time/batch = 0.202\n",
            "14432/15750 (epoch 45), train_loss = 2.142, time/batch = 0.206\n",
            "14433/15750 (epoch 45), train_loss = 2.287, time/batch = 0.210\n",
            "14434/15750 (epoch 45), train_loss = 2.264, time/batch = 0.205\n",
            "14435/15750 (epoch 45), train_loss = 2.238, time/batch = 0.210\n",
            "14436/15750 (epoch 45), train_loss = 2.183, time/batch = 0.200\n",
            "14437/15750 (epoch 45), train_loss = 2.205, time/batch = 0.198\n",
            "14438/15750 (epoch 45), train_loss = 2.197, time/batch = 0.207\n",
            "14439/15750 (epoch 45), train_loss = 2.210, time/batch = 0.206\n",
            "14440/15750 (epoch 45), train_loss = 2.261, time/batch = 0.205\n",
            "14441/15750 (epoch 45), train_loss = 2.259, time/batch = 0.213\n",
            "14442/15750 (epoch 45), train_loss = 2.194, time/batch = 0.205\n",
            "14443/15750 (epoch 45), train_loss = 2.220, time/batch = 0.223\n",
            "14444/15750 (epoch 45), train_loss = 2.259, time/batch = 0.209\n",
            "14445/15750 (epoch 45), train_loss = 2.245, time/batch = 0.206\n",
            "14446/15750 (epoch 45), train_loss = 2.162, time/batch = 0.210\n",
            "14447/15750 (epoch 45), train_loss = 2.198, time/batch = 0.204\n",
            "14448/15750 (epoch 45), train_loss = 2.255, time/batch = 0.212\n",
            "14449/15750 (epoch 45), train_loss = 2.268, time/batch = 0.206\n",
            "14450/15750 (epoch 45), train_loss = 2.208, time/batch = 0.210\n",
            "14451/15750 (epoch 45), train_loss = 2.272, time/batch = 0.207\n",
            "14452/15750 (epoch 45), train_loss = 2.211, time/batch = 0.206\n",
            "14453/15750 (epoch 45), train_loss = 2.189, time/batch = 0.204\n",
            "14454/15750 (epoch 45), train_loss = 2.136, time/batch = 0.203\n",
            "14455/15750 (epoch 45), train_loss = 2.343, time/batch = 0.210\n",
            "14456/15750 (epoch 45), train_loss = 2.176, time/batch = 0.209\n",
            "14457/15750 (epoch 45), train_loss = 2.152, time/batch = 0.213\n",
            "14458/15750 (epoch 45), train_loss = 2.255, time/batch = 0.211\n",
            "14459/15750 (epoch 45), train_loss = 2.166, time/batch = 0.206\n",
            "14460/15750 (epoch 45), train_loss = 2.292, time/batch = 0.210\n",
            "14461/15750 (epoch 45), train_loss = 2.209, time/batch = 0.207\n",
            "14462/15750 (epoch 45), train_loss = 2.215, time/batch = 0.215\n",
            "14463/15750 (epoch 45), train_loss = 2.135, time/batch = 0.208\n",
            "14464/15750 (epoch 45), train_loss = 2.232, time/batch = 0.205\n",
            "14465/15750 (epoch 45), train_loss = 2.155, time/batch = 0.204\n",
            "14466/15750 (epoch 45), train_loss = 2.218, time/batch = 0.205\n",
            "14467/15750 (epoch 45), train_loss = 2.227, time/batch = 0.213\n",
            "14468/15750 (epoch 45), train_loss = 2.177, time/batch = 0.205\n",
            "14469/15750 (epoch 45), train_loss = 2.232, time/batch = 0.205\n",
            "14470/15750 (epoch 45), train_loss = 2.306, time/batch = 0.205\n",
            "14471/15750 (epoch 45), train_loss = 2.254, time/batch = 0.200\n",
            "14472/15750 (epoch 45), train_loss = 2.284, time/batch = 0.209\n",
            "14473/15750 (epoch 45), train_loss = 2.164, time/batch = 0.207\n",
            "14474/15750 (epoch 45), train_loss = 2.231, time/batch = 0.210\n",
            "14475/15750 (epoch 45), train_loss = 2.214, time/batch = 0.209\n",
            "14476/15750 (epoch 45), train_loss = 2.159, time/batch = 0.207\n",
            "14477/15750 (epoch 45), train_loss = 2.286, time/batch = 0.215\n",
            "14478/15750 (epoch 45), train_loss = 2.135, time/batch = 0.206\n",
            "14479/15750 (epoch 45), train_loss = 2.257, time/batch = 0.210\n",
            "14480/15750 (epoch 45), train_loss = 2.216, time/batch = 0.204\n",
            "14481/15750 (epoch 45), train_loss = 2.178, time/batch = 0.208\n",
            "14482/15750 (epoch 45), train_loss = 2.125, time/batch = 0.218\n",
            "14483/15750 (epoch 45), train_loss = 2.163, time/batch = 0.208\n",
            "14484/15750 (epoch 45), train_loss = 2.272, time/batch = 0.206\n",
            "14485/15750 (epoch 45), train_loss = 2.154, time/batch = 0.208\n",
            "14486/15750 (epoch 45), train_loss = 2.126, time/batch = 0.208\n",
            "14487/15750 (epoch 45), train_loss = 2.163, time/batch = 0.213\n",
            "14488/15750 (epoch 45), train_loss = 2.181, time/batch = 0.204\n",
            "14489/15750 (epoch 45), train_loss = 2.269, time/batch = 0.213\n",
            "14490/15750 (epoch 46), train_loss = 2.068, time/batch = 0.209\n",
            "14491/15750 (epoch 46), train_loss = 2.261, time/batch = 0.212\n",
            "14492/15750 (epoch 46), train_loss = 2.183, time/batch = 0.211\n",
            "14493/15750 (epoch 46), train_loss = 2.286, time/batch = 0.214\n",
            "14494/15750 (epoch 46), train_loss = 2.216, time/batch = 0.208\n",
            "14495/15750 (epoch 46), train_loss = 2.213, time/batch = 0.210\n",
            "14496/15750 (epoch 46), train_loss = 2.358, time/batch = 0.212\n",
            "14497/15750 (epoch 46), train_loss = 2.280, time/batch = 0.204\n",
            "14498/15750 (epoch 46), train_loss = 2.278, time/batch = 0.205\n",
            "14499/15750 (epoch 46), train_loss = 2.227, time/batch = 0.205\n",
            "14500/15750 (epoch 46), train_loss = 2.219, time/batch = 0.210\n",
            "14501/15750 (epoch 46), train_loss = 2.195, time/batch = 0.215\n",
            "14502/15750 (epoch 46), train_loss = 2.267, time/batch = 0.205\n",
            "14503/15750 (epoch 46), train_loss = 2.252, time/batch = 0.201\n",
            "14504/15750 (epoch 46), train_loss = 2.227, time/batch = 0.200\n",
            "14505/15750 (epoch 46), train_loss = 2.242, time/batch = 0.207\n",
            "14506/15750 (epoch 46), train_loss = 2.246, time/batch = 0.217\n",
            "14507/15750 (epoch 46), train_loss = 2.307, time/batch = 0.214\n",
            "14508/15750 (epoch 46), train_loss = 2.322, time/batch = 0.209\n",
            "14509/15750 (epoch 46), train_loss = 2.275, time/batch = 0.207\n",
            "14510/15750 (epoch 46), train_loss = 2.256, time/batch = 0.209\n",
            "14511/15750 (epoch 46), train_loss = 2.266, time/batch = 0.210\n",
            "14512/15750 (epoch 46), train_loss = 2.219, time/batch = 0.205\n",
            "14513/15750 (epoch 46), train_loss = 2.279, time/batch = 0.202\n",
            "14514/15750 (epoch 46), train_loss = 2.283, time/batch = 0.209\n",
            "14515/15750 (epoch 46), train_loss = 2.304, time/batch = 0.206\n",
            "14516/15750 (epoch 46), train_loss = 2.312, time/batch = 0.196\n",
            "14517/15750 (epoch 46), train_loss = 2.292, time/batch = 0.205\n",
            "14518/15750 (epoch 46), train_loss = 2.397, time/batch = 0.201\n",
            "14519/15750 (epoch 46), train_loss = 2.312, time/batch = 0.207\n",
            "14520/15750 (epoch 46), train_loss = 2.273, time/batch = 0.208\n",
            "14521/15750 (epoch 46), train_loss = 2.241, time/batch = 0.209\n",
            "14522/15750 (epoch 46), train_loss = 2.159, time/batch = 0.207\n",
            "14523/15750 (epoch 46), train_loss = 2.173, time/batch = 0.201\n",
            "14524/15750 (epoch 46), train_loss = 2.258, time/batch = 0.204\n",
            "14525/15750 (epoch 46), train_loss = 2.159, time/batch = 0.206\n",
            "14526/15750 (epoch 46), train_loss = 2.245, time/batch = 0.202\n",
            "14527/15750 (epoch 46), train_loss = 2.293, time/batch = 0.208\n",
            "14528/15750 (epoch 46), train_loss = 2.202, time/batch = 0.206\n",
            "14529/15750 (epoch 46), train_loss = 2.248, time/batch = 0.208\n",
            "14530/15750 (epoch 46), train_loss = 2.208, time/batch = 0.211\n",
            "14531/15750 (epoch 46), train_loss = 2.258, time/batch = 0.206\n",
            "14532/15750 (epoch 46), train_loss = 2.256, time/batch = 0.210\n",
            "14533/15750 (epoch 46), train_loss = 2.223, time/batch = 0.210\n",
            "14534/15750 (epoch 46), train_loss = 2.254, time/batch = 0.207\n",
            "14535/15750 (epoch 46), train_loss = 2.184, time/batch = 0.214\n",
            "14536/15750 (epoch 46), train_loss = 2.227, time/batch = 0.212\n",
            "14537/15750 (epoch 46), train_loss = 2.234, time/batch = 0.208\n",
            "14538/15750 (epoch 46), train_loss = 2.276, time/batch = 0.203\n",
            "14539/15750 (epoch 46), train_loss = 2.160, time/batch = 0.204\n",
            "14540/15750 (epoch 46), train_loss = 2.234, time/batch = 0.215\n",
            "14541/15750 (epoch 46), train_loss = 2.182, time/batch = 0.212\n",
            "14542/15750 (epoch 46), train_loss = 2.234, time/batch = 0.203\n",
            "14543/15750 (epoch 46), train_loss = 2.252, time/batch = 0.206\n",
            "14544/15750 (epoch 46), train_loss = 2.249, time/batch = 0.209\n",
            "14545/15750 (epoch 46), train_loss = 2.282, time/batch = 0.210\n",
            "14546/15750 (epoch 46), train_loss = 2.170, time/batch = 0.206\n",
            "14547/15750 (epoch 46), train_loss = 2.161, time/batch = 0.205\n",
            "14548/15750 (epoch 46), train_loss = 2.263, time/batch = 0.206\n",
            "14549/15750 (epoch 46), train_loss = 2.128, time/batch = 0.203\n",
            "14550/15750 (epoch 46), train_loss = 2.224, time/batch = 0.206\n",
            "14551/15750 (epoch 46), train_loss = 2.233, time/batch = 0.200\n",
            "14552/15750 (epoch 46), train_loss = 2.158, time/batch = 0.203\n",
            "14553/15750 (epoch 46), train_loss = 2.216, time/batch = 0.205\n",
            "14554/15750 (epoch 46), train_loss = 2.122, time/batch = 0.203\n",
            "14555/15750 (epoch 46), train_loss = 2.147, time/batch = 0.207\n",
            "14556/15750 (epoch 46), train_loss = 2.084, time/batch = 0.204\n",
            "14557/15750 (epoch 46), train_loss = 2.099, time/batch = 0.209\n",
            "14558/15750 (epoch 46), train_loss = 2.152, time/batch = 0.207\n",
            "14559/15750 (epoch 46), train_loss = 2.256, time/batch = 0.203\n",
            "14560/15750 (epoch 46), train_loss = 2.175, time/batch = 0.205\n",
            "14561/15750 (epoch 46), train_loss = 2.162, time/batch = 0.200\n",
            "14562/15750 (epoch 46), train_loss = 2.093, time/batch = 0.202\n",
            "14563/15750 (epoch 46), train_loss = 2.145, time/batch = 0.202\n",
            "14564/15750 (epoch 46), train_loss = 2.267, time/batch = 0.200\n",
            "14565/15750 (epoch 46), train_loss = 2.206, time/batch = 0.209\n",
            "14566/15750 (epoch 46), train_loss = 2.199, time/batch = 0.202\n",
            "14567/15750 (epoch 46), train_loss = 2.194, time/batch = 0.201\n",
            "14568/15750 (epoch 46), train_loss = 2.204, time/batch = 0.203\n",
            "14569/15750 (epoch 46), train_loss = 2.192, time/batch = 0.203\n",
            "14570/15750 (epoch 46), train_loss = 2.093, time/batch = 0.208\n",
            "14571/15750 (epoch 46), train_loss = 2.195, time/batch = 0.199\n",
            "14572/15750 (epoch 46), train_loss = 2.147, time/batch = 0.200\n",
            "14573/15750 (epoch 46), train_loss = 2.194, time/batch = 0.202\n",
            "14574/15750 (epoch 46), train_loss = 2.244, time/batch = 0.203\n",
            "14575/15750 (epoch 46), train_loss = 2.266, time/batch = 0.208\n",
            "14576/15750 (epoch 46), train_loss = 2.103, time/batch = 0.203\n",
            "14577/15750 (epoch 46), train_loss = 2.147, time/batch = 0.203\n",
            "14578/15750 (epoch 46), train_loss = 2.159, time/batch = 0.202\n",
            "14579/15750 (epoch 46), train_loss = 2.169, time/batch = 0.204\n",
            "14580/15750 (epoch 46), train_loss = 2.157, time/batch = 0.206\n",
            "14581/15750 (epoch 46), train_loss = 2.219, time/batch = 0.197\n",
            "14582/15750 (epoch 46), train_loss = 2.206, time/batch = 0.198\n",
            "14583/15750 (epoch 46), train_loss = 2.216, time/batch = 0.201\n",
            "14584/15750 (epoch 46), train_loss = 2.277, time/batch = 0.203\n",
            "14585/15750 (epoch 46), train_loss = 2.197, time/batch = 0.209\n",
            "14586/15750 (epoch 46), train_loss = 2.227, time/batch = 0.202\n",
            "14587/15750 (epoch 46), train_loss = 2.246, time/batch = 0.203\n",
            "14588/15750 (epoch 46), train_loss = 2.222, time/batch = 0.202\n",
            "14589/15750 (epoch 46), train_loss = 2.236, time/batch = 0.203\n",
            "14590/15750 (epoch 46), train_loss = 2.214, time/batch = 0.211\n",
            "14591/15750 (epoch 46), train_loss = 2.162, time/batch = 0.200\n",
            "14592/15750 (epoch 46), train_loss = 2.173, time/batch = 0.202\n",
            "14593/15750 (epoch 46), train_loss = 2.295, time/batch = 0.201\n",
            "14594/15750 (epoch 46), train_loss = 2.217, time/batch = 0.203\n",
            "14595/15750 (epoch 46), train_loss = 2.124, time/batch = 0.205\n",
            "14596/15750 (epoch 46), train_loss = 2.195, time/batch = 0.199\n",
            "14597/15750 (epoch 46), train_loss = 2.222, time/batch = 0.200\n",
            "14598/15750 (epoch 46), train_loss = 2.248, time/batch = 0.199\n",
            "14599/15750 (epoch 46), train_loss = 2.279, time/batch = 0.199\n",
            "14600/15750 (epoch 46), train_loss = 2.339, time/batch = 0.208\n",
            "14601/15750 (epoch 46), train_loss = 2.197, time/batch = 0.204\n",
            "14602/15750 (epoch 46), train_loss = 2.214, time/batch = 0.200\n",
            "14603/15750 (epoch 46), train_loss = 2.204, time/batch = 0.200\n",
            "14604/15750 (epoch 46), train_loss = 2.204, time/batch = 0.206\n",
            "14605/15750 (epoch 46), train_loss = 2.294, time/batch = 0.208\n",
            "14606/15750 (epoch 46), train_loss = 2.219, time/batch = 0.203\n",
            "14607/15750 (epoch 46), train_loss = 2.331, time/batch = 0.202\n",
            "14608/15750 (epoch 46), train_loss = 2.216, time/batch = 0.205\n",
            "14609/15750 (epoch 46), train_loss = 2.212, time/batch = 0.203\n",
            "14610/15750 (epoch 46), train_loss = 2.185, time/batch = 0.206\n",
            "14611/15750 (epoch 46), train_loss = 2.163, time/batch = 0.202\n",
            "14612/15750 (epoch 46), train_loss = 2.206, time/batch = 0.205\n",
            "14613/15750 (epoch 46), train_loss = 2.153, time/batch = 0.201\n",
            "14614/15750 (epoch 46), train_loss = 2.188, time/batch = 0.202\n",
            "14615/15750 (epoch 46), train_loss = 2.205, time/batch = 0.203\n",
            "14616/15750 (epoch 46), train_loss = 2.290, time/batch = 0.203\n",
            "14617/15750 (epoch 46), train_loss = 2.180, time/batch = 0.203\n",
            "14618/15750 (epoch 46), train_loss = 2.204, time/batch = 0.201\n",
            "14619/15750 (epoch 46), train_loss = 2.163, time/batch = 0.203\n",
            "14620/15750 (epoch 46), train_loss = 2.124, time/batch = 0.206\n",
            "14621/15750 (epoch 46), train_loss = 2.135, time/batch = 0.196\n",
            "14622/15750 (epoch 46), train_loss = 2.141, time/batch = 0.201\n",
            "14623/15750 (epoch 46), train_loss = 2.166, time/batch = 0.203\n",
            "14624/15750 (epoch 46), train_loss = 2.176, time/batch = 0.202\n",
            "14625/15750 (epoch 46), train_loss = 2.313, time/batch = 0.203\n",
            "14626/15750 (epoch 46), train_loss = 2.269, time/batch = 0.197\n",
            "14627/15750 (epoch 46), train_loss = 2.273, time/batch = 0.205\n",
            "14628/15750 (epoch 46), train_loss = 2.259, time/batch = 0.204\n",
            "14629/15750 (epoch 46), train_loss = 2.180, time/batch = 0.204\n",
            "14630/15750 (epoch 46), train_loss = 2.184, time/batch = 0.203\n",
            "14631/15750 (epoch 46), train_loss = 2.278, time/batch = 0.205\n",
            "14632/15750 (epoch 46), train_loss = 2.295, time/batch = 0.209\n",
            "14633/15750 (epoch 46), train_loss = 2.268, time/batch = 0.203\n",
            "14634/15750 (epoch 46), train_loss = 2.184, time/batch = 0.200\n",
            "14635/15750 (epoch 46), train_loss = 2.181, time/batch = 0.200\n",
            "14636/15750 (epoch 46), train_loss = 2.147, time/batch = 0.210\n",
            "14637/15750 (epoch 46), train_loss = 2.239, time/batch = 0.203\n",
            "14638/15750 (epoch 46), train_loss = 2.267, time/batch = 0.204\n",
            "14639/15750 (epoch 46), train_loss = 2.218, time/batch = 0.205\n",
            "14640/15750 (epoch 46), train_loss = 2.204, time/batch = 0.201\n",
            "14641/15750 (epoch 46), train_loss = 2.247, time/batch = 0.209\n",
            "14642/15750 (epoch 46), train_loss = 2.275, time/batch = 0.201\n",
            "14643/15750 (epoch 46), train_loss = 2.229, time/batch = 0.200\n",
            "14644/15750 (epoch 46), train_loss = 2.241, time/batch = 0.204\n",
            "14645/15750 (epoch 46), train_loss = 2.240, time/batch = 0.202\n",
            "14646/15750 (epoch 46), train_loss = 2.239, time/batch = 0.211\n",
            "14647/15750 (epoch 46), train_loss = 2.235, time/batch = 0.202\n",
            "14648/15750 (epoch 46), train_loss = 2.314, time/batch = 0.203\n",
            "14649/15750 (epoch 46), train_loss = 2.179, time/batch = 0.203\n",
            "14650/15750 (epoch 46), train_loss = 2.259, time/batch = 0.202\n",
            "14651/15750 (epoch 46), train_loss = 2.240, time/batch = 0.208\n",
            "14652/15750 (epoch 46), train_loss = 2.265, time/batch = 0.199\n",
            "14653/15750 (epoch 46), train_loss = 2.331, time/batch = 0.202\n",
            "14654/15750 (epoch 46), train_loss = 2.255, time/batch = 0.202\n",
            "14655/15750 (epoch 46), train_loss = 2.255, time/batch = 0.197\n",
            "14656/15750 (epoch 46), train_loss = 2.241, time/batch = 0.208\n",
            "14657/15750 (epoch 46), train_loss = 2.213, time/batch = 0.202\n",
            "14658/15750 (epoch 46), train_loss = 2.177, time/batch = 0.196\n",
            "14659/15750 (epoch 46), train_loss = 2.171, time/batch = 0.205\n",
            "14660/15750 (epoch 46), train_loss = 2.210, time/batch = 0.199\n",
            "14661/15750 (epoch 46), train_loss = 2.242, time/batch = 0.206\n",
            "14662/15750 (epoch 46), train_loss = 2.219, time/batch = 0.196\n",
            "14663/15750 (epoch 46), train_loss = 2.293, time/batch = 0.200\n",
            "14664/15750 (epoch 46), train_loss = 2.220, time/batch = 0.202\n",
            "14665/15750 (epoch 46), train_loss = 2.155, time/batch = 0.201\n",
            "14666/15750 (epoch 46), train_loss = 2.184, time/batch = 0.206\n",
            "14667/15750 (epoch 46), train_loss = 2.244, time/batch = 0.199\n",
            "14668/15750 (epoch 46), train_loss = 2.178, time/batch = 0.203\n",
            "14669/15750 (epoch 46), train_loss = 2.137, time/batch = 0.203\n",
            "14670/15750 (epoch 46), train_loss = 2.175, time/batch = 0.201\n",
            "14671/15750 (epoch 46), train_loss = 2.248, time/batch = 0.207\n",
            "14672/15750 (epoch 46), train_loss = 2.227, time/batch = 0.199\n",
            "14673/15750 (epoch 46), train_loss = 2.289, time/batch = 0.203\n",
            "14674/15750 (epoch 46), train_loss = 2.262, time/batch = 0.202\n",
            "14675/15750 (epoch 46), train_loss = 2.229, time/batch = 0.198\n",
            "14676/15750 (epoch 46), train_loss = 2.183, time/batch = 0.206\n",
            "14677/15750 (epoch 46), train_loss = 2.248, time/batch = 0.201\n",
            "14678/15750 (epoch 46), train_loss = 2.272, time/batch = 0.204\n",
            "14679/15750 (epoch 46), train_loss = 2.330, time/batch = 0.194\n",
            "14680/15750 (epoch 46), train_loss = 2.322, time/batch = 0.203\n",
            "14681/15750 (epoch 46), train_loss = 2.225, time/batch = 0.207\n",
            "14682/15750 (epoch 46), train_loss = 2.243, time/batch = 0.199\n",
            "14683/15750 (epoch 46), train_loss = 2.174, time/batch = 0.198\n",
            "14684/15750 (epoch 46), train_loss = 2.301, time/batch = 0.200\n",
            "14685/15750 (epoch 46), train_loss = 2.264, time/batch = 0.202\n",
            "14686/15750 (epoch 46), train_loss = 2.223, time/batch = 0.208\n",
            "14687/15750 (epoch 46), train_loss = 2.172, time/batch = 0.201\n",
            "14688/15750 (epoch 46), train_loss = 2.279, time/batch = 0.201\n",
            "14689/15750 (epoch 46), train_loss = 2.063, time/batch = 0.200\n",
            "14690/15750 (epoch 46), train_loss = 2.176, time/batch = 0.199\n",
            "14691/15750 (epoch 46), train_loss = 2.142, time/batch = 0.206\n",
            "14692/15750 (epoch 46), train_loss = 2.218, time/batch = 0.203\n",
            "14693/15750 (epoch 46), train_loss = 2.186, time/batch = 0.206\n",
            "14694/15750 (epoch 46), train_loss = 2.256, time/batch = 0.204\n",
            "14695/15750 (epoch 46), train_loss = 2.195, time/batch = 0.202\n",
            "14696/15750 (epoch 46), train_loss = 2.088, time/batch = 0.206\n",
            "14697/15750 (epoch 46), train_loss = 2.150, time/batch = 0.203\n",
            "14698/15750 (epoch 46), train_loss = 2.157, time/batch = 0.201\n",
            "14699/15750 (epoch 46), train_loss = 2.221, time/batch = 0.199\n",
            "14700/15750 (epoch 46), train_loss = 2.113, time/batch = 0.202\n",
            "14701/15750 (epoch 46), train_loss = 2.186, time/batch = 0.207\n",
            "14702/15750 (epoch 46), train_loss = 2.078, time/batch = 0.201\n",
            "14703/15750 (epoch 46), train_loss = 2.148, time/batch = 0.200\n",
            "14704/15750 (epoch 46), train_loss = 2.138, time/batch = 0.201\n",
            "14705/15750 (epoch 46), train_loss = 2.118, time/batch = 0.196\n",
            "14706/15750 (epoch 46), train_loss = 2.280, time/batch = 0.209\n",
            "14707/15750 (epoch 46), train_loss = 2.106, time/batch = 0.202\n",
            "14708/15750 (epoch 46), train_loss = 2.344, time/batch = 0.203\n",
            "14709/15750 (epoch 46), train_loss = 2.216, time/batch = 0.202\n",
            "14710/15750 (epoch 46), train_loss = 2.101, time/batch = 0.202\n",
            "14711/15750 (epoch 46), train_loss = 2.125, time/batch = 0.205\n",
            "14712/15750 (epoch 46), train_loss = 2.190, time/batch = 0.195\n",
            "14713/15750 (epoch 46), train_loss = 2.175, time/batch = 0.203\n",
            "14714/15750 (epoch 46), train_loss = 2.156, time/batch = 0.202\n",
            "14715/15750 (epoch 46), train_loss = 2.170, time/batch = 0.199\n",
            "14716/15750 (epoch 46), train_loss = 2.234, time/batch = 0.212\n",
            "14717/15750 (epoch 46), train_loss = 2.156, time/batch = 0.204\n",
            "14718/15750 (epoch 46), train_loss = 2.203, time/batch = 0.203\n",
            "14719/15750 (epoch 46), train_loss = 2.288, time/batch = 0.198\n",
            "14720/15750 (epoch 46), train_loss = 2.144, time/batch = 0.199\n",
            "14721/15750 (epoch 46), train_loss = 2.157, time/batch = 0.209\n",
            "14722/15750 (epoch 46), train_loss = 2.195, time/batch = 0.202\n",
            "14723/15750 (epoch 46), train_loss = 2.198, time/batch = 0.201\n",
            "14724/15750 (epoch 46), train_loss = 2.152, time/batch = 0.202\n",
            "14725/15750 (epoch 46), train_loss = 2.139, time/batch = 0.200\n",
            "14726/15750 (epoch 46), train_loss = 2.110, time/batch = 0.205\n",
            "14727/15750 (epoch 46), train_loss = 2.154, time/batch = 0.198\n",
            "14728/15750 (epoch 46), train_loss = 2.352, time/batch = 0.205\n",
            "14729/15750 (epoch 46), train_loss = 2.192, time/batch = 0.203\n",
            "14730/15750 (epoch 46), train_loss = 2.245, time/batch = 0.199\n",
            "14731/15750 (epoch 46), train_loss = 2.127, time/batch = 0.199\n",
            "14732/15750 (epoch 46), train_loss = 2.174, time/batch = 0.195\n",
            "14733/15750 (epoch 46), train_loss = 2.199, time/batch = 0.201\n",
            "14734/15750 (epoch 46), train_loss = 2.209, time/batch = 0.201\n",
            "14735/15750 (epoch 46), train_loss = 2.263, time/batch = 0.200\n",
            "14736/15750 (epoch 46), train_loss = 2.217, time/batch = 0.202\n",
            "14737/15750 (epoch 46), train_loss = 2.219, time/batch = 0.208\n",
            "14738/15750 (epoch 46), train_loss = 2.193, time/batch = 0.200\n",
            "14739/15750 (epoch 46), train_loss = 2.213, time/batch = 0.201\n",
            "14740/15750 (epoch 46), train_loss = 2.124, time/batch = 0.201\n",
            "14741/15750 (epoch 46), train_loss = 2.114, time/batch = 0.202\n",
            "14742/15750 (epoch 46), train_loss = 2.206, time/batch = 0.207\n",
            "14743/15750 (epoch 46), train_loss = 2.224, time/batch = 0.202\n",
            "14744/15750 (epoch 46), train_loss = 2.191, time/batch = 0.200\n",
            "14745/15750 (epoch 46), train_loss = 2.156, time/batch = 0.201\n",
            "14746/15750 (epoch 46), train_loss = 2.108, time/batch = 0.199\n",
            "14747/15750 (epoch 46), train_loss = 2.139, time/batch = 0.207\n",
            "14748/15750 (epoch 46), train_loss = 2.283, time/batch = 0.203\n",
            "14749/15750 (epoch 46), train_loss = 2.260, time/batch = 0.203\n",
            "14750/15750 (epoch 46), train_loss = 2.235, time/batch = 0.202\n",
            "14751/15750 (epoch 46), train_loss = 2.180, time/batch = 0.199\n",
            "14752/15750 (epoch 46), train_loss = 2.202, time/batch = 0.207\n",
            "14753/15750 (epoch 46), train_loss = 2.194, time/batch = 0.200\n",
            "14754/15750 (epoch 46), train_loss = 2.206, time/batch = 0.200\n",
            "14755/15750 (epoch 46), train_loss = 2.257, time/batch = 0.199\n",
            "14756/15750 (epoch 46), train_loss = 2.255, time/batch = 0.201\n",
            "14757/15750 (epoch 46), train_loss = 2.190, time/batch = 0.208\n",
            "14758/15750 (epoch 46), train_loss = 2.216, time/batch = 0.198\n",
            "14759/15750 (epoch 46), train_loss = 2.255, time/batch = 0.201\n",
            "14760/15750 (epoch 46), train_loss = 2.241, time/batch = 0.200\n",
            "14761/15750 (epoch 46), train_loss = 2.158, time/batch = 0.201\n",
            "14762/15750 (epoch 46), train_loss = 2.195, time/batch = 0.210\n",
            "14763/15750 (epoch 46), train_loss = 2.252, time/batch = 0.195\n",
            "14764/15750 (epoch 46), train_loss = 2.264, time/batch = 0.199\n",
            "14765/15750 (epoch 46), train_loss = 2.204, time/batch = 0.202\n",
            "14766/15750 (epoch 46), train_loss = 2.269, time/batch = 0.201\n",
            "14767/15750 (epoch 46), train_loss = 2.208, time/batch = 0.208\n",
            "14768/15750 (epoch 46), train_loss = 2.186, time/batch = 0.203\n",
            "14769/15750 (epoch 46), train_loss = 2.133, time/batch = 0.201\n",
            "14770/15750 (epoch 46), train_loss = 2.338, time/batch = 0.202\n",
            "14771/15750 (epoch 46), train_loss = 2.172, time/batch = 0.200\n",
            "14772/15750 (epoch 46), train_loss = 2.148, time/batch = 0.206\n",
            "14773/15750 (epoch 46), train_loss = 2.251, time/batch = 0.201\n",
            "14774/15750 (epoch 46), train_loss = 2.163, time/batch = 0.202\n",
            "14775/15750 (epoch 46), train_loss = 2.288, time/batch = 0.202\n",
            "14776/15750 (epoch 46), train_loss = 2.207, time/batch = 0.201\n",
            "14777/15750 (epoch 46), train_loss = 2.211, time/batch = 0.208\n",
            "14778/15750 (epoch 46), train_loss = 2.132, time/batch = 0.202\n",
            "14779/15750 (epoch 46), train_loss = 2.228, time/batch = 0.201\n",
            "14780/15750 (epoch 46), train_loss = 2.152, time/batch = 0.207\n",
            "14781/15750 (epoch 46), train_loss = 2.214, time/batch = 0.201\n",
            "14782/15750 (epoch 46), train_loss = 2.224, time/batch = 0.199\n",
            "14783/15750 (epoch 46), train_loss = 2.174, time/batch = 0.200\n",
            "14784/15750 (epoch 46), train_loss = 2.228, time/batch = 0.201\n",
            "14785/15750 (epoch 46), train_loss = 2.302, time/batch = 0.200\n",
            "14786/15750 (epoch 46), train_loss = 2.250, time/batch = 0.206\n",
            "14787/15750 (epoch 46), train_loss = 2.280, time/batch = 0.206\n",
            "14788/15750 (epoch 46), train_loss = 2.161, time/batch = 0.200\n",
            "14789/15750 (epoch 46), train_loss = 2.228, time/batch = 0.197\n",
            "14790/15750 (epoch 46), train_loss = 2.210, time/batch = 0.201\n",
            "14791/15750 (epoch 46), train_loss = 2.156, time/batch = 0.197\n",
            "14792/15750 (epoch 46), train_loss = 2.283, time/batch = 0.208\n",
            "14793/15750 (epoch 46), train_loss = 2.132, time/batch = 0.203\n",
            "14794/15750 (epoch 46), train_loss = 2.254, time/batch = 0.202\n",
            "14795/15750 (epoch 46), train_loss = 2.213, time/batch = 0.199\n",
            "14796/15750 (epoch 46), train_loss = 2.174, time/batch = 0.200\n",
            "14797/15750 (epoch 46), train_loss = 2.121, time/batch = 0.204\n",
            "14798/15750 (epoch 46), train_loss = 2.160, time/batch = 0.202\n",
            "14799/15750 (epoch 46), train_loss = 2.268, time/batch = 0.201\n",
            "14800/15750 (epoch 46), train_loss = 2.150, time/batch = 0.204\n",
            "14801/15750 (epoch 46), train_loss = 2.123, time/batch = 0.203\n",
            "14802/15750 (epoch 46), train_loss = 2.160, time/batch = 0.208\n",
            "14803/15750 (epoch 46), train_loss = 2.178, time/batch = 0.201\n",
            "14804/15750 (epoch 46), train_loss = 2.265, time/batch = 0.204\n",
            "14805/15750 (epoch 47), train_loss = 2.062, time/batch = 0.202\n",
            "14806/15750 (epoch 47), train_loss = 2.258, time/batch = 0.199\n",
            "14807/15750 (epoch 47), train_loss = 2.179, time/batch = 0.200\n",
            "14808/15750 (epoch 47), train_loss = 2.282, time/batch = 0.205\n",
            "14809/15750 (epoch 47), train_loss = 2.213, time/batch = 0.202\n",
            "14810/15750 (epoch 47), train_loss = 2.209, time/batch = 0.205\n",
            "14811/15750 (epoch 47), train_loss = 2.354, time/batch = 0.200\n",
            "14812/15750 (epoch 47), train_loss = 2.277, time/batch = 0.212\n",
            "14813/15750 (epoch 47), train_loss = 2.274, time/batch = 0.205\n",
            "14814/15750 (epoch 47), train_loss = 2.223, time/batch = 0.205\n",
            "14815/15750 (epoch 47), train_loss = 2.215, time/batch = 0.203\n",
            "14816/15750 (epoch 47), train_loss = 2.191, time/batch = 0.204\n",
            "14817/15750 (epoch 47), train_loss = 2.264, time/batch = 0.206\n",
            "14818/15750 (epoch 47), train_loss = 2.249, time/batch = 0.199\n",
            "14819/15750 (epoch 47), train_loss = 2.224, time/batch = 0.204\n",
            "14820/15750 (epoch 47), train_loss = 2.238, time/batch = 0.203\n",
            "14821/15750 (epoch 47), train_loss = 2.242, time/batch = 0.203\n",
            "14822/15750 (epoch 47), train_loss = 2.303, time/batch = 0.211\n",
            "14823/15750 (epoch 47), train_loss = 2.318, time/batch = 0.201\n",
            "14824/15750 (epoch 47), train_loss = 2.271, time/batch = 0.201\n",
            "14825/15750 (epoch 47), train_loss = 2.252, time/batch = 0.203\n",
            "14826/15750 (epoch 47), train_loss = 2.262, time/batch = 0.200\n",
            "14827/15750 (epoch 47), train_loss = 2.216, time/batch = 0.201\n",
            "14828/15750 (epoch 47), train_loss = 2.275, time/batch = 0.201\n",
            "14829/15750 (epoch 47), train_loss = 2.279, time/batch = 0.200\n",
            "14830/15750 (epoch 47), train_loss = 2.300, time/batch = 0.197\n",
            "14831/15750 (epoch 47), train_loss = 2.308, time/batch = 0.202\n",
            "14832/15750 (epoch 47), train_loss = 2.289, time/batch = 0.203\n",
            "14833/15750 (epoch 47), train_loss = 2.394, time/batch = 0.198\n",
            "14834/15750 (epoch 47), train_loss = 2.307, time/batch = 0.200\n",
            "14835/15750 (epoch 47), train_loss = 2.268, time/batch = 0.203\n",
            "14836/15750 (epoch 47), train_loss = 2.237, time/batch = 0.204\n",
            "14837/15750 (epoch 47), train_loss = 2.155, time/batch = 0.204\n",
            "14838/15750 (epoch 47), train_loss = 2.170, time/batch = 0.199\n",
            "14839/15750 (epoch 47), train_loss = 2.255, time/batch = 0.197\n",
            "14840/15750 (epoch 47), train_loss = 2.155, time/batch = 0.200\n",
            "14841/15750 (epoch 47), train_loss = 2.241, time/batch = 0.207\n",
            "14842/15750 (epoch 47), train_loss = 2.289, time/batch = 0.203\n",
            "14843/15750 (epoch 47), train_loss = 2.199, time/batch = 0.200\n",
            "14844/15750 (epoch 47), train_loss = 2.245, time/batch = 0.201\n",
            "14845/15750 (epoch 47), train_loss = 2.204, time/batch = 0.199\n",
            "14846/15750 (epoch 47), train_loss = 2.255, time/batch = 0.200\n",
            "14847/15750 (epoch 47), train_loss = 2.253, time/batch = 0.205\n",
            "14848/15750 (epoch 47), train_loss = 2.220, time/batch = 0.199\n",
            "14849/15750 (epoch 47), train_loss = 2.251, time/batch = 0.200\n",
            "14850/15750 (epoch 47), train_loss = 2.181, time/batch = 0.201\n",
            "14851/15750 (epoch 47), train_loss = 2.225, time/batch = 0.199\n",
            "14852/15750 (epoch 47), train_loss = 2.231, time/batch = 0.208\n",
            "14853/15750 (epoch 47), train_loss = 2.273, time/batch = 0.202\n",
            "14854/15750 (epoch 47), train_loss = 2.157, time/batch = 0.200\n",
            "14855/15750 (epoch 47), train_loss = 2.231, time/batch = 0.199\n",
            "14856/15750 (epoch 47), train_loss = 2.179, time/batch = 0.202\n",
            "14857/15750 (epoch 47), train_loss = 2.231, time/batch = 0.206\n",
            "14858/15750 (epoch 47), train_loss = 2.249, time/batch = 0.201\n",
            "14859/15750 (epoch 47), train_loss = 2.246, time/batch = 0.202\n",
            "14860/15750 (epoch 47), train_loss = 2.279, time/batch = 0.202\n",
            "14861/15750 (epoch 47), train_loss = 2.167, time/batch = 0.202\n",
            "14862/15750 (epoch 47), train_loss = 2.158, time/batch = 0.202\n",
            "14863/15750 (epoch 47), train_loss = 2.259, time/batch = 0.200\n",
            "14864/15750 (epoch 47), train_loss = 2.125, time/batch = 0.201\n",
            "14865/15750 (epoch 47), train_loss = 2.220, time/batch = 0.200\n",
            "14866/15750 (epoch 47), train_loss = 2.229, time/batch = 0.199\n",
            "14867/15750 (epoch 47), train_loss = 2.154, time/batch = 0.207\n",
            "14868/15750 (epoch 47), train_loss = 2.214, time/batch = 0.203\n",
            "14869/15750 (epoch 47), train_loss = 2.120, time/batch = 0.202\n",
            "14870/15750 (epoch 47), train_loss = 2.144, time/batch = 0.198\n",
            "14871/15750 (epoch 47), train_loss = 2.081, time/batch = 0.199\n",
            "14872/15750 (epoch 47), train_loss = 2.097, time/batch = 0.207\n",
            "14873/15750 (epoch 47), train_loss = 2.148, time/batch = 0.203\n",
            "14874/15750 (epoch 47), train_loss = 2.253, time/batch = 0.198\n",
            "14875/15750 (epoch 47), train_loss = 2.172, time/batch = 0.204\n",
            "14876/15750 (epoch 47), train_loss = 2.159, time/batch = 0.202\n",
            "14877/15750 (epoch 47), train_loss = 2.090, time/batch = 0.204\n",
            "14878/15750 (epoch 47), train_loss = 2.143, time/batch = 0.195\n",
            "14879/15750 (epoch 47), train_loss = 2.264, time/batch = 0.202\n",
            "14880/15750 (epoch 47), train_loss = 2.204, time/batch = 0.204\n",
            "14881/15750 (epoch 47), train_loss = 2.196, time/batch = 0.200\n",
            "14882/15750 (epoch 47), train_loss = 2.191, time/batch = 0.200\n",
            "14883/15750 (epoch 47), train_loss = 2.200, time/batch = 0.201\n",
            "14884/15750 (epoch 47), train_loss = 2.189, time/batch = 0.202\n",
            "14885/15750 (epoch 47), train_loss = 2.090, time/batch = 0.201\n",
            "14886/15750 (epoch 47), train_loss = 2.191, time/batch = 0.198\n",
            "14887/15750 (epoch 47), train_loss = 2.144, time/batch = 0.204\n",
            "14888/15750 (epoch 47), train_loss = 2.190, time/batch = 0.207\n",
            "14889/15750 (epoch 47), train_loss = 2.240, time/batch = 0.202\n",
            "14890/15750 (epoch 47), train_loss = 2.262, time/batch = 0.199\n",
            "14891/15750 (epoch 47), train_loss = 2.099, time/batch = 0.199\n",
            "14892/15750 (epoch 47), train_loss = 2.144, time/batch = 0.200\n",
            "14893/15750 (epoch 47), train_loss = 2.155, time/batch = 0.206\n",
            "14894/15750 (epoch 47), train_loss = 2.166, time/batch = 0.202\n",
            "14895/15750 (epoch 47), train_loss = 2.153, time/batch = 0.202\n",
            "14896/15750 (epoch 47), train_loss = 2.215, time/batch = 0.203\n",
            "14897/15750 (epoch 47), train_loss = 2.202, time/batch = 0.199\n",
            "14898/15750 (epoch 47), train_loss = 2.212, time/batch = 0.208\n",
            "14899/15750 (epoch 47), train_loss = 2.273, time/batch = 0.204\n",
            "14900/15750 (epoch 47), train_loss = 2.194, time/batch = 0.204\n",
            "14901/15750 (epoch 47), train_loss = 2.224, time/batch = 0.199\n",
            "14902/15750 (epoch 47), train_loss = 2.243, time/batch = 0.200\n",
            "14903/15750 (epoch 47), train_loss = 2.218, time/batch = 0.209\n",
            "14904/15750 (epoch 47), train_loss = 2.233, time/batch = 0.203\n",
            "14905/15750 (epoch 47), train_loss = 2.210, time/batch = 0.199\n",
            "14906/15750 (epoch 47), train_loss = 2.159, time/batch = 0.199\n",
            "14907/15750 (epoch 47), train_loss = 2.170, time/batch = 0.199\n",
            "14908/15750 (epoch 47), train_loss = 2.292, time/batch = 0.207\n",
            "14909/15750 (epoch 47), train_loss = 2.214, time/batch = 0.199\n",
            "14910/15750 (epoch 47), train_loss = 2.121, time/batch = 0.202\n",
            "14911/15750 (epoch 47), train_loss = 2.192, time/batch = 0.199\n",
            "14912/15750 (epoch 47), train_loss = 2.219, time/batch = 0.203\n",
            "14913/15750 (epoch 47), train_loss = 2.245, time/batch = 0.204\n",
            "14914/15750 (epoch 47), train_loss = 2.276, time/batch = 0.202\n",
            "14915/15750 (epoch 47), train_loss = 2.335, time/batch = 0.203\n",
            "14916/15750 (epoch 47), train_loss = 2.193, time/batch = 0.201\n",
            "14917/15750 (epoch 47), train_loss = 2.212, time/batch = 0.201\n",
            "14918/15750 (epoch 47), train_loss = 2.201, time/batch = 0.207\n",
            "14919/15750 (epoch 47), train_loss = 2.200, time/batch = 0.200\n",
            "14920/15750 (epoch 47), train_loss = 2.290, time/batch = 0.203\n",
            "14921/15750 (epoch 47), train_loss = 2.215, time/batch = 0.202\n",
            "14922/15750 (epoch 47), train_loss = 2.327, time/batch = 0.202\n",
            "14923/15750 (epoch 47), train_loss = 2.212, time/batch = 0.208\n",
            "14924/15750 (epoch 47), train_loss = 2.209, time/batch = 0.201\n",
            "14925/15750 (epoch 47), train_loss = 2.181, time/batch = 0.200\n",
            "14926/15750 (epoch 47), train_loss = 2.160, time/batch = 0.200\n",
            "14927/15750 (epoch 47), train_loss = 2.204, time/batch = 0.202\n",
            "14928/15750 (epoch 47), train_loss = 2.150, time/batch = 0.212\n",
            "14929/15750 (epoch 47), train_loss = 2.185, time/batch = 0.201\n",
            "14930/15750 (epoch 47), train_loss = 2.201, time/batch = 0.200\n",
            "14931/15750 (epoch 47), train_loss = 2.286, time/batch = 0.200\n",
            "14932/15750 (epoch 47), train_loss = 2.178, time/batch = 0.203\n",
            "14933/15750 (epoch 47), train_loss = 2.200, time/batch = 0.204\n",
            "14934/15750 (epoch 47), train_loss = 2.160, time/batch = 0.199\n",
            "14935/15750 (epoch 47), train_loss = 2.121, time/batch = 0.202\n",
            "14936/15750 (epoch 47), train_loss = 2.132, time/batch = 0.200\n",
            "14937/15750 (epoch 47), train_loss = 2.138, time/batch = 0.199\n",
            "14938/15750 (epoch 47), train_loss = 2.163, time/batch = 0.205\n",
            "14939/15750 (epoch 47), train_loss = 2.172, time/batch = 0.200\n",
            "14940/15750 (epoch 47), train_loss = 2.309, time/batch = 0.200\n",
            "14941/15750 (epoch 47), train_loss = 2.265, time/batch = 0.201\n",
            "14942/15750 (epoch 47), train_loss = 2.270, time/batch = 0.199\n",
            "14943/15750 (epoch 47), train_loss = 2.255, time/batch = 0.205\n",
            "14944/15750 (epoch 47), train_loss = 2.176, time/batch = 0.203\n",
            "14945/15750 (epoch 47), train_loss = 2.181, time/batch = 0.199\n",
            "14946/15750 (epoch 47), train_loss = 2.274, time/batch = 0.199\n",
            "14947/15750 (epoch 47), train_loss = 2.292, time/batch = 0.203\n",
            "14948/15750 (epoch 47), train_loss = 2.265, time/batch = 0.200\n",
            "14949/15750 (epoch 47), train_loss = 2.180, time/batch = 0.199\n",
            "14950/15750 (epoch 47), train_loss = 2.178, time/batch = 0.202\n",
            "14951/15750 (epoch 47), train_loss = 2.144, time/batch = 0.201\n",
            "14952/15750 (epoch 47), train_loss = 2.235, time/batch = 0.202\n",
            "14953/15750 (epoch 47), train_loss = 2.264, time/batch = 0.206\n",
            "14954/15750 (epoch 47), train_loss = 2.215, time/batch = 0.196\n",
            "14955/15750 (epoch 47), train_loss = 2.200, time/batch = 0.198\n",
            "14956/15750 (epoch 47), train_loss = 2.243, time/batch = 0.199\n",
            "14957/15750 (epoch 47), train_loss = 2.271, time/batch = 0.202\n",
            "14958/15750 (epoch 47), train_loss = 2.225, time/batch = 0.202\n",
            "14959/15750 (epoch 47), train_loss = 2.238, time/batch = 0.193\n",
            "14960/15750 (epoch 47), train_loss = 2.236, time/batch = 0.203\n",
            "14961/15750 (epoch 47), train_loss = 2.236, time/batch = 0.199\n",
            "14962/15750 (epoch 47), train_loss = 2.232, time/batch = 0.201\n",
            "14963/15750 (epoch 47), train_loss = 2.310, time/batch = 0.203\n",
            "14964/15750 (epoch 47), train_loss = 2.176, time/batch = 0.206\n",
            "14965/15750 (epoch 47), train_loss = 2.256, time/batch = 0.203\n",
            "14966/15750 (epoch 47), train_loss = 2.237, time/batch = 0.201\n",
            "14967/15750 (epoch 47), train_loss = 2.262, time/batch = 0.200\n",
            "14968/15750 (epoch 47), train_loss = 2.328, time/batch = 0.200\n",
            "14969/15750 (epoch 47), train_loss = 2.251, time/batch = 0.206\n",
            "14970/15750 (epoch 47), train_loss = 2.251, time/batch = 0.203\n",
            "14971/15750 (epoch 47), train_loss = 2.237, time/batch = 0.203\n",
            "14972/15750 (epoch 47), train_loss = 2.209, time/batch = 0.203\n",
            "14973/15750 (epoch 47), train_loss = 2.173, time/batch = 0.203\n",
            "14974/15750 (epoch 47), train_loss = 2.168, time/batch = 0.207\n",
            "14975/15750 (epoch 47), train_loss = 2.206, time/batch = 0.202\n",
            "14976/15750 (epoch 47), train_loss = 2.238, time/batch = 0.202\n",
            "14977/15750 (epoch 47), train_loss = 2.216, time/batch = 0.201\n",
            "14978/15750 (epoch 47), train_loss = 2.290, time/batch = 0.199\n",
            "14979/15750 (epoch 47), train_loss = 2.216, time/batch = 0.208\n",
            "14980/15750 (epoch 47), train_loss = 2.151, time/batch = 0.202\n",
            "14981/15750 (epoch 47), train_loss = 2.180, time/batch = 0.200\n",
            "14982/15750 (epoch 47), train_loss = 2.241, time/batch = 0.201\n",
            "14983/15750 (epoch 47), train_loss = 2.175, time/batch = 0.202\n",
            "14984/15750 (epoch 47), train_loss = 2.134, time/batch = 0.208\n",
            "14985/15750 (epoch 47), train_loss = 2.172, time/batch = 0.198\n",
            "14986/15750 (epoch 47), train_loss = 2.244, time/batch = 0.200\n",
            "14987/15750 (epoch 47), train_loss = 2.223, time/batch = 0.199\n",
            "14988/15750 (epoch 47), train_loss = 2.286, time/batch = 0.201\n",
            "14989/15750 (epoch 47), train_loss = 2.258, time/batch = 0.206\n",
            "14990/15750 (epoch 47), train_loss = 2.226, time/batch = 0.200\n",
            "14991/15750 (epoch 47), train_loss = 2.180, time/batch = 0.203\n",
            "14992/15750 (epoch 47), train_loss = 2.245, time/batch = 0.202\n",
            "14993/15750 (epoch 47), train_loss = 2.269, time/batch = 0.200\n",
            "14994/15750 (epoch 47), train_loss = 2.326, time/batch = 0.209\n",
            "14995/15750 (epoch 47), train_loss = 2.318, time/batch = 0.196\n",
            "14996/15750 (epoch 47), train_loss = 2.222, time/batch = 0.201\n",
            "14997/15750 (epoch 47), train_loss = 2.239, time/batch = 0.203\n",
            "14998/15750 (epoch 47), train_loss = 2.171, time/batch = 0.204\n",
            "14999/15750 (epoch 47), train_loss = 2.297, time/batch = 0.206\n",
            "15000/15750 (epoch 47), train_loss = 2.260, time/batch = 0.196\n",
            "model saved to ./save_star/model.ckpt\n",
            "15001/15750 (epoch 47), train_loss = 2.220, time/batch = 0.200\n",
            "15002/15750 (epoch 47), train_loss = 2.169, time/batch = 0.206\n",
            "15003/15750 (epoch 47), train_loss = 2.276, time/batch = 0.205\n",
            "15004/15750 (epoch 47), train_loss = 2.060, time/batch = 0.204\n",
            "15005/15750 (epoch 47), train_loss = 2.173, time/batch = 0.201\n",
            "15006/15750 (epoch 47), train_loss = 2.139, time/batch = 0.202\n",
            "15007/15750 (epoch 47), train_loss = 2.215, time/batch = 0.207\n",
            "15008/15750 (epoch 47), train_loss = 2.182, time/batch = 0.204\n",
            "15009/15750 (epoch 47), train_loss = 2.253, time/batch = 0.204\n",
            "15010/15750 (epoch 47), train_loss = 2.192, time/batch = 0.204\n",
            "15011/15750 (epoch 47), train_loss = 2.085, time/batch = 0.205\n",
            "15012/15750 (epoch 47), train_loss = 2.146, time/batch = 0.208\n",
            "15013/15750 (epoch 47), train_loss = 2.153, time/batch = 0.202\n",
            "15014/15750 (epoch 47), train_loss = 2.218, time/batch = 0.200\n",
            "15015/15750 (epoch 47), train_loss = 2.111, time/batch = 0.207\n",
            "15016/15750 (epoch 47), train_loss = 2.182, time/batch = 0.201\n",
            "15017/15750 (epoch 47), train_loss = 2.075, time/batch = 0.208\n",
            "15018/15750 (epoch 47), train_loss = 2.145, time/batch = 0.204\n",
            "15019/15750 (epoch 47), train_loss = 2.135, time/batch = 0.203\n",
            "15020/15750 (epoch 47), train_loss = 2.115, time/batch = 0.199\n",
            "15021/15750 (epoch 47), train_loss = 2.277, time/batch = 0.203\n",
            "15022/15750 (epoch 47), train_loss = 2.103, time/batch = 0.209\n",
            "15023/15750 (epoch 47), train_loss = 2.340, time/batch = 0.201\n",
            "15024/15750 (epoch 47), train_loss = 2.213, time/batch = 0.201\n",
            "15025/15750 (epoch 47), train_loss = 2.098, time/batch = 0.201\n",
            "15026/15750 (epoch 47), train_loss = 2.122, time/batch = 0.201\n",
            "15027/15750 (epoch 47), train_loss = 2.186, time/batch = 0.203\n",
            "15028/15750 (epoch 47), train_loss = 2.171, time/batch = 0.199\n",
            "15029/15750 (epoch 47), train_loss = 2.152, time/batch = 0.199\n",
            "15030/15750 (epoch 47), train_loss = 2.167, time/batch = 0.202\n",
            "15031/15750 (epoch 47), train_loss = 2.231, time/batch = 0.203\n",
            "15032/15750 (epoch 47), train_loss = 2.152, time/batch = 0.200\n",
            "15033/15750 (epoch 47), train_loss = 2.199, time/batch = 0.200\n",
            "15034/15750 (epoch 47), train_loss = 2.286, time/batch = 0.199\n",
            "15035/15750 (epoch 47), train_loss = 2.141, time/batch = 0.204\n",
            "15036/15750 (epoch 47), train_loss = 2.154, time/batch = 0.202\n",
            "15037/15750 (epoch 47), train_loss = 2.192, time/batch = 0.202\n",
            "15038/15750 (epoch 47), train_loss = 2.195, time/batch = 0.210\n",
            "15039/15750 (epoch 47), train_loss = 2.149, time/batch = 0.203\n",
            "15040/15750 (epoch 47), train_loss = 2.136, time/batch = 0.201\n",
            "15041/15750 (epoch 47), train_loss = 2.107, time/batch = 0.203\n",
            "15042/15750 (epoch 47), train_loss = 2.151, time/batch = 0.203\n",
            "15043/15750 (epoch 47), train_loss = 2.348, time/batch = 0.213\n",
            "15044/15750 (epoch 47), train_loss = 2.188, time/batch = 0.203\n",
            "15045/15750 (epoch 47), train_loss = 2.242, time/batch = 0.202\n",
            "15046/15750 (epoch 47), train_loss = 2.124, time/batch = 0.201\n",
            "15047/15750 (epoch 47), train_loss = 2.171, time/batch = 0.201\n",
            "15048/15750 (epoch 47), train_loss = 2.196, time/batch = 0.206\n",
            "15049/15750 (epoch 47), train_loss = 2.205, time/batch = 0.203\n",
            "15050/15750 (epoch 47), train_loss = 2.259, time/batch = 0.199\n",
            "15051/15750 (epoch 47), train_loss = 2.214, time/batch = 0.200\n",
            "15052/15750 (epoch 47), train_loss = 2.216, time/batch = 0.199\n",
            "15053/15750 (epoch 47), train_loss = 2.190, time/batch = 0.206\n",
            "15054/15750 (epoch 47), train_loss = 2.209, time/batch = 0.200\n",
            "15055/15750 (epoch 47), train_loss = 2.121, time/batch = 0.200\n",
            "15056/15750 (epoch 47), train_loss = 2.111, time/batch = 0.199\n",
            "15057/15750 (epoch 47), train_loss = 2.203, time/batch = 0.201\n",
            "15058/15750 (epoch 47), train_loss = 2.221, time/batch = 0.205\n",
            "15059/15750 (epoch 47), train_loss = 2.188, time/batch = 0.203\n",
            "15060/15750 (epoch 47), train_loss = 2.153, time/batch = 0.202\n",
            "15061/15750 (epoch 47), train_loss = 2.104, time/batch = 0.203\n",
            "15062/15750 (epoch 47), train_loss = 2.136, time/batch = 0.200\n",
            "15063/15750 (epoch 47), train_loss = 2.279, time/batch = 0.208\n",
            "15064/15750 (epoch 47), train_loss = 2.257, time/batch = 0.199\n",
            "15065/15750 (epoch 47), train_loss = 2.232, time/batch = 0.202\n",
            "15066/15750 (epoch 47), train_loss = 2.176, time/batch = 0.203\n",
            "15067/15750 (epoch 47), train_loss = 2.198, time/batch = 0.200\n",
            "15068/15750 (epoch 47), train_loss = 2.191, time/batch = 0.205\n",
            "15069/15750 (epoch 47), train_loss = 2.202, time/batch = 0.196\n",
            "15070/15750 (epoch 47), train_loss = 2.253, time/batch = 0.203\n",
            "15071/15750 (epoch 47), train_loss = 2.251, time/batch = 0.202\n",
            "15072/15750 (epoch 47), train_loss = 2.187, time/batch = 0.203\n",
            "15073/15750 (epoch 47), train_loss = 2.212, time/batch = 0.207\n",
            "15074/15750 (epoch 47), train_loss = 2.251, time/batch = 0.196\n",
            "15075/15750 (epoch 47), train_loss = 2.237, time/batch = 0.210\n",
            "15076/15750 (epoch 47), train_loss = 2.155, time/batch = 0.199\n",
            "15077/15750 (epoch 47), train_loss = 2.193, time/batch = 0.197\n",
            "15078/15750 (epoch 47), train_loss = 2.249, time/batch = 0.205\n",
            "15079/15750 (epoch 47), train_loss = 2.260, time/batch = 0.203\n",
            "15080/15750 (epoch 47), train_loss = 2.200, time/batch = 0.202\n",
            "15081/15750 (epoch 47), train_loss = 2.266, time/batch = 0.202\n",
            "15082/15750 (epoch 47), train_loss = 2.205, time/batch = 0.200\n",
            "15083/15750 (epoch 47), train_loss = 2.183, time/batch = 0.200\n",
            "15084/15750 (epoch 47), train_loss = 2.130, time/batch = 0.198\n",
            "15085/15750 (epoch 47), train_loss = 2.334, time/batch = 0.202\n",
            "15086/15750 (epoch 47), train_loss = 2.168, time/batch = 0.203\n",
            "15087/15750 (epoch 47), train_loss = 2.145, time/batch = 0.200\n",
            "15088/15750 (epoch 47), train_loss = 2.247, time/batch = 0.204\n",
            "15089/15750 (epoch 47), train_loss = 2.160, time/batch = 0.201\n",
            "15090/15750 (epoch 47), train_loss = 2.284, time/batch = 0.200\n",
            "15091/15750 (epoch 47), train_loss = 2.204, time/batch = 0.200\n",
            "15092/15750 (epoch 47), train_loss = 2.208, time/batch = 0.201\n",
            "15093/15750 (epoch 47), train_loss = 2.128, time/batch = 0.205\n",
            "15094/15750 (epoch 47), train_loss = 2.225, time/batch = 0.201\n",
            "15095/15750 (epoch 47), train_loss = 2.149, time/batch = 0.202\n",
            "15096/15750 (epoch 47), train_loss = 2.211, time/batch = 0.202\n",
            "15097/15750 (epoch 47), train_loss = 2.221, time/batch = 0.200\n",
            "15098/15750 (epoch 47), train_loss = 2.170, time/batch = 0.205\n",
            "15099/15750 (epoch 47), train_loss = 2.225, time/batch = 0.202\n",
            "15100/15750 (epoch 47), train_loss = 2.299, time/batch = 0.202\n",
            "15101/15750 (epoch 47), train_loss = 2.246, time/batch = 0.200\n",
            "15102/15750 (epoch 47), train_loss = 2.276, time/batch = 0.199\n",
            "15103/15750 (epoch 47), train_loss = 2.158, time/batch = 0.205\n",
            "15104/15750 (epoch 47), train_loss = 2.225, time/batch = 0.203\n",
            "15105/15750 (epoch 47), train_loss = 2.207, time/batch = 0.201\n",
            "15106/15750 (epoch 47), train_loss = 2.153, time/batch = 0.201\n",
            "15107/15750 (epoch 47), train_loss = 2.280, time/batch = 0.201\n",
            "15108/15750 (epoch 47), train_loss = 2.128, time/batch = 0.200\n",
            "15109/15750 (epoch 47), train_loss = 2.250, time/batch = 0.199\n",
            "15110/15750 (epoch 47), train_loss = 2.210, time/batch = 0.200\n",
            "15111/15750 (epoch 47), train_loss = 2.171, time/batch = 0.203\n",
            "15112/15750 (epoch 47), train_loss = 2.118, time/batch = 0.202\n",
            "15113/15750 (epoch 47), train_loss = 2.157, time/batch = 0.204\n",
            "15114/15750 (epoch 47), train_loss = 2.264, time/batch = 0.200\n",
            "15115/15750 (epoch 47), train_loss = 2.147, time/batch = 0.202\n",
            "15116/15750 (epoch 47), train_loss = 2.119, time/batch = 0.203\n",
            "15117/15750 (epoch 47), train_loss = 2.157, time/batch = 0.201\n",
            "15118/15750 (epoch 47), train_loss = 2.175, time/batch = 0.199\n",
            "15119/15750 (epoch 47), train_loss = 2.262, time/batch = 0.201\n",
            "15120/15750 (epoch 48), train_loss = 2.053, time/batch = 0.201\n",
            "15121/15750 (epoch 48), train_loss = 2.253, time/batch = 0.198\n",
            "15122/15750 (epoch 48), train_loss = 2.175, time/batch = 0.201\n",
            "15123/15750 (epoch 48), train_loss = 2.279, time/batch = 0.210\n",
            "15124/15750 (epoch 48), train_loss = 2.210, time/batch = 0.202\n",
            "15125/15750 (epoch 48), train_loss = 2.207, time/batch = 0.204\n",
            "15126/15750 (epoch 48), train_loss = 2.351, time/batch = 0.203\n",
            "15127/15750 (epoch 48), train_loss = 2.273, time/batch = 0.203\n",
            "15128/15750 (epoch 48), train_loss = 2.270, time/batch = 0.208\n",
            "15129/15750 (epoch 48), train_loss = 2.219, time/batch = 0.199\n",
            "15130/15750 (epoch 48), train_loss = 2.212, time/batch = 0.202\n",
            "15131/15750 (epoch 48), train_loss = 2.188, time/batch = 0.200\n",
            "15132/15750 (epoch 48), train_loss = 2.261, time/batch = 0.203\n",
            "15133/15750 (epoch 48), train_loss = 2.246, time/batch = 0.206\n",
            "15134/15750 (epoch 48), train_loss = 2.221, time/batch = 0.203\n",
            "15135/15750 (epoch 48), train_loss = 2.234, time/batch = 0.197\n",
            "15136/15750 (epoch 48), train_loss = 2.239, time/batch = 0.201\n",
            "15137/15750 (epoch 48), train_loss = 2.300, time/batch = 0.202\n",
            "15138/15750 (epoch 48), train_loss = 2.315, time/batch = 0.206\n",
            "15139/15750 (epoch 48), train_loss = 2.269, time/batch = 0.203\n",
            "15140/15750 (epoch 48), train_loss = 2.249, time/batch = 0.203\n",
            "15141/15750 (epoch 48), train_loss = 2.259, time/batch = 0.201\n",
            "15142/15750 (epoch 48), train_loss = 2.212, time/batch = 0.203\n",
            "15143/15750 (epoch 48), train_loss = 2.272, time/batch = 0.208\n",
            "15144/15750 (epoch 48), train_loss = 2.280, time/batch = 0.202\n",
            "15145/15750 (epoch 48), train_loss = 2.297, time/batch = 0.201\n",
            "15146/15750 (epoch 48), train_loss = 2.304, time/batch = 0.202\n",
            "15147/15750 (epoch 48), train_loss = 2.286, time/batch = 0.196\n",
            "15148/15750 (epoch 48), train_loss = 2.390, time/batch = 0.205\n",
            "15149/15750 (epoch 48), train_loss = 2.304, time/batch = 0.201\n",
            "15150/15750 (epoch 48), train_loss = 2.265, time/batch = 0.202\n",
            "15151/15750 (epoch 48), train_loss = 2.234, time/batch = 0.201\n",
            "15152/15750 (epoch 48), train_loss = 2.152, time/batch = 0.201\n",
            "15153/15750 (epoch 48), train_loss = 2.167, time/batch = 0.203\n",
            "15154/15750 (epoch 48), train_loss = 2.251, time/batch = 0.202\n",
            "15155/15750 (epoch 48), train_loss = 2.151, time/batch = 0.203\n",
            "15156/15750 (epoch 48), train_loss = 2.238, time/batch = 0.201\n",
            "15157/15750 (epoch 48), train_loss = 2.286, time/batch = 0.198\n",
            "15158/15750 (epoch 48), train_loss = 2.195, time/batch = 0.206\n",
            "15159/15750 (epoch 48), train_loss = 2.241, time/batch = 0.204\n",
            "15160/15750 (epoch 48), train_loss = 2.201, time/batch = 0.202\n",
            "15161/15750 (epoch 48), train_loss = 2.251, time/batch = 0.201\n",
            "15162/15750 (epoch 48), train_loss = 2.249, time/batch = 0.199\n",
            "15163/15750 (epoch 48), train_loss = 2.217, time/batch = 0.207\n",
            "15164/15750 (epoch 48), train_loss = 2.248, time/batch = 0.201\n",
            "15165/15750 (epoch 48), train_loss = 2.177, time/batch = 0.196\n",
            "15166/15750 (epoch 48), train_loss = 2.222, time/batch = 0.200\n",
            "15167/15750 (epoch 48), train_loss = 2.228, time/batch = 0.202\n",
            "15168/15750 (epoch 48), train_loss = 2.270, time/batch = 0.207\n",
            "15169/15750 (epoch 48), train_loss = 2.154, time/batch = 0.202\n",
            "15170/15750 (epoch 48), train_loss = 2.227, time/batch = 0.199\n",
            "15171/15750 (epoch 48), train_loss = 2.176, time/batch = 0.200\n",
            "15172/15750 (epoch 48), train_loss = 2.228, time/batch = 0.201\n",
            "15173/15750 (epoch 48), train_loss = 2.246, time/batch = 0.205\n",
            "15174/15750 (epoch 48), train_loss = 2.243, time/batch = 0.201\n",
            "15175/15750 (epoch 48), train_loss = 2.275, time/batch = 0.199\n",
            "15176/15750 (epoch 48), train_loss = 2.164, time/batch = 0.202\n",
            "15177/15750 (epoch 48), train_loss = 2.155, time/batch = 0.202\n",
            "15178/15750 (epoch 48), train_loss = 2.256, time/batch = 0.208\n",
            "15179/15750 (epoch 48), train_loss = 2.122, time/batch = 0.201\n",
            "15180/15750 (epoch 48), train_loss = 2.217, time/batch = 0.201\n",
            "15181/15750 (epoch 48), train_loss = 2.226, time/batch = 0.200\n",
            "15182/15750 (epoch 48), train_loss = 2.151, time/batch = 0.201\n",
            "15183/15750 (epoch 48), train_loss = 2.211, time/batch = 0.197\n",
            "15184/15750 (epoch 48), train_loss = 2.116, time/batch = 0.202\n",
            "15185/15750 (epoch 48), train_loss = 2.141, time/batch = 0.202\n",
            "15186/15750 (epoch 48), train_loss = 2.078, time/batch = 0.203\n",
            "15187/15750 (epoch 48), train_loss = 2.093, time/batch = 0.200\n",
            "15188/15750 (epoch 48), train_loss = 2.144, time/batch = 0.205\n",
            "15189/15750 (epoch 48), train_loss = 2.250, time/batch = 0.201\n",
            "15190/15750 (epoch 48), train_loss = 2.168, time/batch = 0.201\n",
            "15191/15750 (epoch 48), train_loss = 2.156, time/batch = 0.202\n",
            "15192/15750 (epoch 48), train_loss = 2.087, time/batch = 0.199\n",
            "15193/15750 (epoch 48), train_loss = 2.139, time/batch = 0.203\n",
            "15194/15750 (epoch 48), train_loss = 2.261, time/batch = 0.200\n",
            "15195/15750 (epoch 48), train_loss = 2.201, time/batch = 0.199\n",
            "15196/15750 (epoch 48), train_loss = 2.193, time/batch = 0.198\n",
            "15197/15750 (epoch 48), train_loss = 2.188, time/batch = 0.201\n",
            "15198/15750 (epoch 48), train_loss = 2.197, time/batch = 0.201\n",
            "15199/15750 (epoch 48), train_loss = 2.185, time/batch = 0.202\n",
            "15200/15750 (epoch 48), train_loss = 2.087, time/batch = 0.198\n",
            "15201/15750 (epoch 48), train_loss = 2.188, time/batch = 0.200\n",
            "15202/15750 (epoch 48), train_loss = 2.141, time/batch = 0.202\n",
            "15203/15750 (epoch 48), train_loss = 2.187, time/batch = 0.199\n",
            "15204/15750 (epoch 48), train_loss = 2.236, time/batch = 0.210\n",
            "15205/15750 (epoch 48), train_loss = 2.258, time/batch = 0.200\n",
            "15206/15750 (epoch 48), train_loss = 2.095, time/batch = 0.201\n",
            "15207/15750 (epoch 48), train_loss = 2.141, time/batch = 0.200\n",
            "15208/15750 (epoch 48), train_loss = 2.151, time/batch = 0.202\n",
            "15209/15750 (epoch 48), train_loss = 2.163, time/batch = 0.209\n",
            "15210/15750 (epoch 48), train_loss = 2.150, time/batch = 0.201\n",
            "15211/15750 (epoch 48), train_loss = 2.212, time/batch = 0.203\n",
            "15212/15750 (epoch 48), train_loss = 2.199, time/batch = 0.195\n",
            "15213/15750 (epoch 48), train_loss = 2.208, time/batch = 0.198\n",
            "15214/15750 (epoch 48), train_loss = 2.270, time/batch = 0.210\n",
            "15215/15750 (epoch 48), train_loss = 2.190, time/batch = 0.201\n",
            "15216/15750 (epoch 48), train_loss = 2.221, time/batch = 0.199\n",
            "15217/15750 (epoch 48), train_loss = 2.240, time/batch = 0.200\n",
            "15218/15750 (epoch 48), train_loss = 2.215, time/batch = 0.204\n",
            "15219/15750 (epoch 48), train_loss = 2.229, time/batch = 0.210\n",
            "15220/15750 (epoch 48), train_loss = 2.207, time/batch = 0.201\n",
            "15221/15750 (epoch 48), train_loss = 2.156, time/batch = 0.200\n",
            "15222/15750 (epoch 48), train_loss = 2.166, time/batch = 0.201\n",
            "15223/15750 (epoch 48), train_loss = 2.288, time/batch = 0.215\n",
            "15224/15750 (epoch 48), train_loss = 2.210, time/batch = 0.205\n",
            "15225/15750 (epoch 48), train_loss = 2.117, time/batch = 0.196\n",
            "15226/15750 (epoch 48), train_loss = 2.188, time/batch = 0.201\n",
            "15227/15750 (epoch 48), train_loss = 2.215, time/batch = 0.200\n",
            "15228/15750 (epoch 48), train_loss = 2.241, time/batch = 0.203\n",
            "15229/15750 (epoch 48), train_loss = 2.273, time/batch = 0.204\n",
            "15230/15750 (epoch 48), train_loss = 2.332, time/batch = 0.200\n",
            "15231/15750 (epoch 48), train_loss = 2.190, time/batch = 0.203\n",
            "15232/15750 (epoch 48), train_loss = 2.209, time/batch = 0.202\n",
            "15233/15750 (epoch 48), train_loss = 2.198, time/batch = 0.199\n",
            "15234/15750 (epoch 48), train_loss = 2.196, time/batch = 0.207\n",
            "15235/15750 (epoch 48), train_loss = 2.286, time/batch = 0.202\n",
            "15236/15750 (epoch 48), train_loss = 2.212, time/batch = 0.200\n",
            "15237/15750 (epoch 48), train_loss = 2.323, time/batch = 0.202\n",
            "15238/15750 (epoch 48), train_loss = 2.209, time/batch = 0.201\n",
            "15239/15750 (epoch 48), train_loss = 2.206, time/batch = 0.208\n",
            "15240/15750 (epoch 48), train_loss = 2.179, time/batch = 0.201\n",
            "15241/15750 (epoch 48), train_loss = 2.157, time/batch = 0.203\n",
            "15242/15750 (epoch 48), train_loss = 2.201, time/batch = 0.203\n",
            "15243/15750 (epoch 48), train_loss = 2.147, time/batch = 0.203\n",
            "15244/15750 (epoch 48), train_loss = 2.181, time/batch = 0.208\n",
            "15245/15750 (epoch 48), train_loss = 2.197, time/batch = 0.198\n",
            "15246/15750 (epoch 48), train_loss = 2.283, time/batch = 0.202\n",
            "15247/15750 (epoch 48), train_loss = 2.175, time/batch = 0.201\n",
            "15248/15750 (epoch 48), train_loss = 2.198, time/batch = 0.196\n",
            "15249/15750 (epoch 48), train_loss = 2.157, time/batch = 0.202\n",
            "15250/15750 (epoch 48), train_loss = 2.119, time/batch = 0.202\n",
            "15251/15750 (epoch 48), train_loss = 2.129, time/batch = 0.203\n",
            "15252/15750 (epoch 48), train_loss = 2.134, time/batch = 0.198\n",
            "15253/15750 (epoch 48), train_loss = 2.160, time/batch = 0.200\n",
            "15254/15750 (epoch 48), train_loss = 2.168, time/batch = 0.207\n",
            "15255/15750 (epoch 48), train_loss = 2.306, time/batch = 0.200\n",
            "15256/15750 (epoch 48), train_loss = 2.262, time/batch = 0.202\n",
            "15257/15750 (epoch 48), train_loss = 2.267, time/batch = 0.202\n",
            "15258/15750 (epoch 48), train_loss = 2.252, time/batch = 0.203\n",
            "15259/15750 (epoch 48), train_loss = 2.173, time/batch = 0.207\n",
            "15260/15750 (epoch 48), train_loss = 2.177, time/batch = 0.200\n",
            "15261/15750 (epoch 48), train_loss = 2.270, time/batch = 0.196\n",
            "15262/15750 (epoch 48), train_loss = 2.288, time/batch = 0.203\n",
            "15263/15750 (epoch 48), train_loss = 2.261, time/batch = 0.201\n",
            "15264/15750 (epoch 48), train_loss = 2.177, time/batch = 0.201\n",
            "15265/15750 (epoch 48), train_loss = 2.175, time/batch = 0.202\n",
            "15266/15750 (epoch 48), train_loss = 2.141, time/batch = 0.198\n",
            "15267/15750 (epoch 48), train_loss = 2.232, time/batch = 0.198\n",
            "15268/15750 (epoch 48), train_loss = 2.261, time/batch = 0.202\n",
            "15269/15750 (epoch 48), train_loss = 2.212, time/batch = 0.204\n",
            "15270/15750 (epoch 48), train_loss = 2.196, time/batch = 0.201\n",
            "15271/15750 (epoch 48), train_loss = 2.240, time/batch = 0.202\n",
            "15272/15750 (epoch 48), train_loss = 2.267, time/batch = 0.206\n",
            "15273/15750 (epoch 48), train_loss = 2.222, time/batch = 0.198\n",
            "15274/15750 (epoch 48), train_loss = 2.235, time/batch = 0.205\n",
            "15275/15750 (epoch 48), train_loss = 2.233, time/batch = 0.202\n",
            "15276/15750 (epoch 48), train_loss = 2.232, time/batch = 0.202\n",
            "15277/15750 (epoch 48), train_loss = 2.229, time/batch = 0.199\n",
            "15278/15750 (epoch 48), train_loss = 2.307, time/batch = 0.200\n",
            "15279/15750 (epoch 48), train_loss = 2.173, time/batch = 0.203\n",
            "15280/15750 (epoch 48), train_loss = 2.252, time/batch = 0.195\n",
            "15281/15750 (epoch 48), train_loss = 2.234, time/batch = 0.201\n",
            "15282/15750 (epoch 48), train_loss = 2.259, time/batch = 0.199\n",
            "15283/15750 (epoch 48), train_loss = 2.324, time/batch = 0.202\n",
            "15284/15750 (epoch 48), train_loss = 2.247, time/batch = 0.203\n",
            "15285/15750 (epoch 48), train_loss = 2.248, time/batch = 0.204\n",
            "15286/15750 (epoch 48), train_loss = 2.234, time/batch = 0.204\n",
            "15287/15750 (epoch 48), train_loss = 2.205, time/batch = 0.202\n",
            "15288/15750 (epoch 48), train_loss = 2.169, time/batch = 0.200\n",
            "15289/15750 (epoch 48), train_loss = 2.165, time/batch = 0.202\n",
            "15290/15750 (epoch 48), train_loss = 2.203, time/batch = 0.209\n",
            "15291/15750 (epoch 48), train_loss = 2.234, time/batch = 0.205\n",
            "15292/15750 (epoch 48), train_loss = 2.212, time/batch = 0.200\n",
            "15293/15750 (epoch 48), train_loss = 2.287, time/batch = 0.199\n",
            "15294/15750 (epoch 48), train_loss = 2.213, time/batch = 0.201\n",
            "15295/15750 (epoch 48), train_loss = 2.148, time/batch = 0.206\n",
            "15296/15750 (epoch 48), train_loss = 2.178, time/batch = 0.203\n",
            "15297/15750 (epoch 48), train_loss = 2.237, time/batch = 0.202\n",
            "15298/15750 (epoch 48), train_loss = 2.171, time/batch = 0.201\n",
            "15299/15750 (epoch 48), train_loss = 2.130, time/batch = 0.202\n",
            "15300/15750 (epoch 48), train_loss = 2.168, time/batch = 0.204\n",
            "15301/15750 (epoch 48), train_loss = 2.240, time/batch = 0.201\n",
            "15302/15750 (epoch 48), train_loss = 2.220, time/batch = 0.203\n",
            "15303/15750 (epoch 48), train_loss = 2.283, time/batch = 0.193\n",
            "15304/15750 (epoch 48), train_loss = 2.254, time/batch = 0.199\n",
            "15305/15750 (epoch 48), train_loss = 2.222, time/batch = 0.203\n",
            "15306/15750 (epoch 48), train_loss = 2.177, time/batch = 0.200\n",
            "15307/15750 (epoch 48), train_loss = 2.241, time/batch = 0.204\n",
            "15308/15750 (epoch 48), train_loss = 2.265, time/batch = 0.208\n",
            "15309/15750 (epoch 48), train_loss = 2.322, time/batch = 0.203\n",
            "15310/15750 (epoch 48), train_loss = 2.315, time/batch = 0.207\n",
            "15311/15750 (epoch 48), train_loss = 2.219, time/batch = 0.200\n",
            "15312/15750 (epoch 48), train_loss = 2.235, time/batch = 0.202\n",
            "15313/15750 (epoch 48), train_loss = 2.168, time/batch = 0.203\n",
            "15314/15750 (epoch 48), train_loss = 2.294, time/batch = 0.201\n",
            "15315/15750 (epoch 48), train_loss = 2.257, time/batch = 0.207\n",
            "15316/15750 (epoch 48), train_loss = 2.217, time/batch = 0.197\n",
            "15317/15750 (epoch 48), train_loss = 2.165, time/batch = 0.199\n",
            "15318/15750 (epoch 48), train_loss = 2.273, time/batch = 0.202\n",
            "15319/15750 (epoch 48), train_loss = 2.056, time/batch = 0.200\n",
            "15320/15750 (epoch 48), train_loss = 2.170, time/batch = 0.204\n",
            "15321/15750 (epoch 48), train_loss = 2.136, time/batch = 0.201\n",
            "15322/15750 (epoch 48), train_loss = 2.212, time/batch = 0.202\n",
            "15323/15750 (epoch 48), train_loss = 2.179, time/batch = 0.203\n",
            "15324/15750 (epoch 48), train_loss = 2.249, time/batch = 0.199\n",
            "15325/15750 (epoch 48), train_loss = 2.188, time/batch = 0.205\n",
            "15326/15750 (epoch 48), train_loss = 2.081, time/batch = 0.203\n",
            "15327/15750 (epoch 48), train_loss = 2.143, time/batch = 0.203\n",
            "15328/15750 (epoch 48), train_loss = 2.149, time/batch = 0.203\n",
            "15329/15750 (epoch 48), train_loss = 2.214, time/batch = 0.196\n",
            "15330/15750 (epoch 48), train_loss = 2.108, time/batch = 0.204\n",
            "15331/15750 (epoch 48), train_loss = 2.179, time/batch = 0.205\n",
            "15332/15750 (epoch 48), train_loss = 2.072, time/batch = 0.198\n",
            "15333/15750 (epoch 48), train_loss = 2.142, time/batch = 0.199\n",
            "15334/15750 (epoch 48), train_loss = 2.132, time/batch = 0.201\n",
            "15335/15750 (epoch 48), train_loss = 2.111, time/batch = 0.206\n",
            "15336/15750 (epoch 48), train_loss = 2.274, time/batch = 0.201\n",
            "15337/15750 (epoch 48), train_loss = 2.100, time/batch = 0.199\n",
            "15338/15750 (epoch 48), train_loss = 2.336, time/batch = 0.203\n",
            "15339/15750 (epoch 48), train_loss = 2.210, time/batch = 0.199\n",
            "15340/15750 (epoch 48), train_loss = 2.095, time/batch = 0.206\n",
            "15341/15750 (epoch 48), train_loss = 2.119, time/batch = 0.202\n",
            "15342/15750 (epoch 48), train_loss = 2.183, time/batch = 0.200\n",
            "15343/15750 (epoch 48), train_loss = 2.168, time/batch = 0.203\n",
            "15344/15750 (epoch 48), train_loss = 2.148, time/batch = 0.201\n",
            "15345/15750 (epoch 48), train_loss = 2.163, time/batch = 0.205\n",
            "15346/15750 (epoch 48), train_loss = 2.228, time/batch = 0.200\n",
            "15347/15750 (epoch 48), train_loss = 2.149, time/batch = 0.202\n",
            "15348/15750 (epoch 48), train_loss = 2.196, time/batch = 0.201\n",
            "15349/15750 (epoch 48), train_loss = 2.283, time/batch = 0.200\n",
            "15350/15750 (epoch 48), train_loss = 2.138, time/batch = 0.204\n",
            "15351/15750 (epoch 48), train_loss = 2.151, time/batch = 0.199\n",
            "15352/15750 (epoch 48), train_loss = 2.188, time/batch = 0.199\n",
            "15353/15750 (epoch 48), train_loss = 2.192, time/batch = 0.200\n",
            "15354/15750 (epoch 48), train_loss = 2.145, time/batch = 0.201\n",
            "15355/15750 (epoch 48), train_loss = 2.132, time/batch = 0.203\n",
            "15356/15750 (epoch 48), train_loss = 2.104, time/batch = 0.201\n",
            "15357/15750 (epoch 48), train_loss = 2.147, time/batch = 0.199\n",
            "15358/15750 (epoch 48), train_loss = 2.345, time/batch = 0.205\n",
            "15359/15750 (epoch 48), train_loss = 2.186, time/batch = 0.202\n",
            "15360/15750 (epoch 48), train_loss = 2.239, time/batch = 0.201\n",
            "15361/15750 (epoch 48), train_loss = 2.120, time/batch = 0.198\n",
            "15362/15750 (epoch 48), train_loss = 2.167, time/batch = 0.203\n",
            "15363/15750 (epoch 48), train_loss = 2.192, time/batch = 0.203\n",
            "15364/15750 (epoch 48), train_loss = 2.202, time/batch = 0.199\n",
            "15365/15750 (epoch 48), train_loss = 2.256, time/batch = 0.201\n",
            "15366/15750 (epoch 48), train_loss = 2.211, time/batch = 0.213\n",
            "15367/15750 (epoch 48), train_loss = 2.213, time/batch = 0.202\n",
            "15368/15750 (epoch 48), train_loss = 2.187, time/batch = 0.201\n",
            "15369/15750 (epoch 48), train_loss = 2.205, time/batch = 0.201\n",
            "15370/15750 (epoch 48), train_loss = 2.118, time/batch = 0.202\n",
            "15371/15750 (epoch 48), train_loss = 2.107, time/batch = 0.209\n",
            "15372/15750 (epoch 48), train_loss = 2.200, time/batch = 0.202\n",
            "15373/15750 (epoch 48), train_loss = 2.217, time/batch = 0.199\n",
            "15374/15750 (epoch 48), train_loss = 2.185, time/batch = 0.201\n",
            "15375/15750 (epoch 48), train_loss = 2.149, time/batch = 0.204\n",
            "15376/15750 (epoch 48), train_loss = 2.101, time/batch = 0.208\n",
            "15377/15750 (epoch 48), train_loss = 2.133, time/batch = 0.203\n",
            "15378/15750 (epoch 48), train_loss = 2.275, time/batch = 0.201\n",
            "15379/15750 (epoch 48), train_loss = 2.253, time/batch = 0.203\n",
            "15380/15750 (epoch 48), train_loss = 2.229, time/batch = 0.200\n",
            "15381/15750 (epoch 48), train_loss = 2.173, time/batch = 0.206\n",
            "15382/15750 (epoch 48), train_loss = 2.195, time/batch = 0.199\n",
            "15383/15750 (epoch 48), train_loss = 2.188, time/batch = 0.202\n",
            "15384/15750 (epoch 48), train_loss = 2.198, time/batch = 0.200\n",
            "15385/15750 (epoch 48), train_loss = 2.249, time/batch = 0.201\n",
            "15386/15750 (epoch 48), train_loss = 2.247, time/batch = 0.208\n",
            "15387/15750 (epoch 48), train_loss = 2.184, time/batch = 0.199\n",
            "15388/15750 (epoch 48), train_loss = 2.209, time/batch = 0.194\n",
            "15389/15750 (epoch 48), train_loss = 2.248, time/batch = 0.203\n",
            "15390/15750 (epoch 48), train_loss = 2.234, time/batch = 0.201\n",
            "15391/15750 (epoch 48), train_loss = 2.151, time/batch = 0.205\n",
            "15392/15750 (epoch 48), train_loss = 2.190, time/batch = 0.203\n",
            "15393/15750 (epoch 48), train_loss = 2.246, time/batch = 0.199\n",
            "15394/15750 (epoch 48), train_loss = 2.256, time/batch = 0.201\n",
            "15395/15750 (epoch 48), train_loss = 2.197, time/batch = 0.202\n",
            "15396/15750 (epoch 48), train_loss = 2.262, time/batch = 0.206\n",
            "15397/15750 (epoch 48), train_loss = 2.202, time/batch = 0.199\n",
            "15398/15750 (epoch 48), train_loss = 2.180, time/batch = 0.202\n",
            "15399/15750 (epoch 48), train_loss = 2.127, time/batch = 0.203\n",
            "15400/15750 (epoch 48), train_loss = 2.331, time/batch = 0.201\n",
            "15401/15750 (epoch 48), train_loss = 2.165, time/batch = 0.207\n",
            "15402/15750 (epoch 48), train_loss = 2.142, time/batch = 0.198\n",
            "15403/15750 (epoch 48), train_loss = 2.244, time/batch = 0.209\n",
            "15404/15750 (epoch 48), train_loss = 2.157, time/batch = 0.200\n",
            "15405/15750 (epoch 48), train_loss = 2.281, time/batch = 0.198\n",
            "15406/15750 (epoch 48), train_loss = 2.201, time/batch = 0.202\n",
            "15407/15750 (epoch 48), train_loss = 2.204, time/batch = 0.203\n",
            "15408/15750 (epoch 48), train_loss = 2.125, time/batch = 0.199\n",
            "15409/15750 (epoch 48), train_loss = 2.222, time/batch = 0.197\n",
            "15410/15750 (epoch 48), train_loss = 2.146, time/batch = 0.202\n",
            "15411/15750 (epoch 48), train_loss = 2.207, time/batch = 0.200\n",
            "15412/15750 (epoch 48), train_loss = 2.218, time/batch = 0.204\n",
            "15413/15750 (epoch 48), train_loss = 2.167, time/batch = 0.198\n",
            "15414/15750 (epoch 48), train_loss = 2.222, time/batch = 0.201\n",
            "15415/15750 (epoch 48), train_loss = 2.295, time/batch = 0.201\n",
            "15416/15750 (epoch 48), train_loss = 2.243, time/batch = 0.209\n",
            "15417/15750 (epoch 48), train_loss = 2.273, time/batch = 0.196\n",
            "15418/15750 (epoch 48), train_loss = 2.155, time/batch = 0.203\n",
            "15419/15750 (epoch 48), train_loss = 2.221, time/batch = 0.200\n",
            "15420/15750 (epoch 48), train_loss = 2.204, time/batch = 0.196\n",
            "15421/15750 (epoch 48), train_loss = 2.151, time/batch = 0.204\n",
            "15422/15750 (epoch 48), train_loss = 2.277, time/batch = 0.201\n",
            "15423/15750 (epoch 48), train_loss = 2.125, time/batch = 0.203\n",
            "15424/15750 (epoch 48), train_loss = 2.247, time/batch = 0.202\n",
            "15425/15750 (epoch 48), train_loss = 2.207, time/batch = 0.201\n",
            "15426/15750 (epoch 48), train_loss = 2.168, time/batch = 0.209\n",
            "15427/15750 (epoch 48), train_loss = 2.114, time/batch = 0.200\n",
            "15428/15750 (epoch 48), train_loss = 2.154, time/batch = 0.199\n",
            "15429/15750 (epoch 48), train_loss = 2.260, time/batch = 0.195\n",
            "15430/15750 (epoch 48), train_loss = 2.144, time/batch = 0.200\n",
            "15431/15750 (epoch 48), train_loss = 2.116, time/batch = 0.206\n",
            "15432/15750 (epoch 48), train_loss = 2.154, time/batch = 0.191\n",
            "15433/15750 (epoch 48), train_loss = 2.172, time/batch = 0.200\n",
            "15434/15750 (epoch 48), train_loss = 2.258, time/batch = 0.202\n",
            "15435/15750 (epoch 49), train_loss = 2.045, time/batch = 0.203\n",
            "15436/15750 (epoch 49), train_loss = 2.252, time/batch = 0.206\n",
            "15437/15750 (epoch 49), train_loss = 2.171, time/batch = 0.204\n",
            "15438/15750 (epoch 49), train_loss = 2.275, time/batch = 0.203\n",
            "15439/15750 (epoch 49), train_loss = 2.207, time/batch = 0.203\n",
            "15440/15750 (epoch 49), train_loss = 2.203, time/batch = 0.200\n",
            "15441/15750 (epoch 49), train_loss = 2.347, time/batch = 0.208\n",
            "15442/15750 (epoch 49), train_loss = 2.270, time/batch = 0.200\n",
            "15443/15750 (epoch 49), train_loss = 2.266, time/batch = 0.202\n",
            "15444/15750 (epoch 49), train_loss = 2.215, time/batch = 0.202\n",
            "15445/15750 (epoch 49), train_loss = 2.208, time/batch = 0.202\n",
            "15446/15750 (epoch 49), train_loss = 2.185, time/batch = 0.206\n",
            "15447/15750 (epoch 49), train_loss = 2.257, time/batch = 0.201\n",
            "15448/15750 (epoch 49), train_loss = 2.243, time/batch = 0.200\n",
            "15449/15750 (epoch 49), train_loss = 2.217, time/batch = 0.199\n",
            "15450/15750 (epoch 49), train_loss = 2.230, time/batch = 0.204\n",
            "15451/15750 (epoch 49), train_loss = 2.235, time/batch = 0.205\n",
            "15452/15750 (epoch 49), train_loss = 2.295, time/batch = 0.200\n",
            "15453/15750 (epoch 49), train_loss = 2.311, time/batch = 0.201\n",
            "15454/15750 (epoch 49), train_loss = 2.265, time/batch = 0.200\n",
            "15455/15750 (epoch 49), train_loss = 2.244, time/batch = 0.200\n",
            "15456/15750 (epoch 49), train_loss = 2.254, time/batch = 0.206\n",
            "15457/15750 (epoch 49), train_loss = 2.209, time/batch = 0.204\n",
            "15458/15750 (epoch 49), train_loss = 2.269, time/batch = 0.203\n",
            "15459/15750 (epoch 49), train_loss = 2.272, time/batch = 0.203\n",
            "15460/15750 (epoch 49), train_loss = 2.293, time/batch = 0.202\n",
            "15461/15750 (epoch 49), train_loss = 2.301, time/batch = 0.206\n",
            "15462/15750 (epoch 49), train_loss = 2.283, time/batch = 0.202\n",
            "15463/15750 (epoch 49), train_loss = 2.387, time/batch = 0.204\n",
            "15464/15750 (epoch 49), train_loss = 2.300, time/batch = 0.203\n",
            "15465/15750 (epoch 49), train_loss = 2.261, time/batch = 0.205\n",
            "15466/15750 (epoch 49), train_loss = 2.231, time/batch = 0.202\n",
            "15467/15750 (epoch 49), train_loss = 2.149, time/batch = 0.196\n",
            "15468/15750 (epoch 49), train_loss = 2.163, time/batch = 0.200\n",
            "15469/15750 (epoch 49), train_loss = 2.247, time/batch = 0.202\n",
            "15470/15750 (epoch 49), train_loss = 2.148, time/batch = 0.202\n",
            "15471/15750 (epoch 49), train_loss = 2.235, time/batch = 0.208\n",
            "15472/15750 (epoch 49), train_loss = 2.282, time/batch = 0.200\n",
            "15473/15750 (epoch 49), train_loss = 2.192, time/batch = 0.202\n",
            "15474/15750 (epoch 49), train_loss = 2.238, time/batch = 0.201\n",
            "15475/15750 (epoch 49), train_loss = 2.198, time/batch = 0.200\n",
            "15476/15750 (epoch 49), train_loss = 2.248, time/batch = 0.203\n",
            "15477/15750 (epoch 49), train_loss = 2.247, time/batch = 0.202\n",
            "15478/15750 (epoch 49), train_loss = 2.214, time/batch = 0.203\n",
            "15479/15750 (epoch 49), train_loss = 2.245, time/batch = 0.202\n",
            "15480/15750 (epoch 49), train_loss = 2.174, time/batch = 0.200\n",
            "15481/15750 (epoch 49), train_loss = 2.219, time/batch = 0.207\n",
            "15482/15750 (epoch 49), train_loss = 2.225, time/batch = 0.199\n",
            "15483/15750 (epoch 49), train_loss = 2.267, time/batch = 0.203\n",
            "15484/15750 (epoch 49), train_loss = 2.151, time/batch = 0.203\n",
            "15485/15750 (epoch 49), train_loss = 2.224, time/batch = 0.203\n",
            "15486/15750 (epoch 49), train_loss = 2.173, time/batch = 0.204\n",
            "15487/15750 (epoch 49), train_loss = 2.225, time/batch = 0.199\n",
            "15488/15750 (epoch 49), train_loss = 2.244, time/batch = 0.203\n",
            "15489/15750 (epoch 49), train_loss = 2.240, time/batch = 0.201\n",
            "15490/15750 (epoch 49), train_loss = 2.272, time/batch = 0.197\n",
            "15491/15750 (epoch 49), train_loss = 2.161, time/batch = 0.205\n",
            "15492/15750 (epoch 49), train_loss = 2.151, time/batch = 0.200\n",
            "15493/15750 (epoch 49), train_loss = 2.253, time/batch = 0.201\n",
            "15494/15750 (epoch 49), train_loss = 2.120, time/batch = 0.202\n",
            "15495/15750 (epoch 49), train_loss = 2.215, time/batch = 0.198\n",
            "15496/15750 (epoch 49), train_loss = 2.223, time/batch = 0.204\n",
            "15497/15750 (epoch 49), train_loss = 2.147, time/batch = 0.202\n",
            "15498/15750 (epoch 49), train_loss = 2.208, time/batch = 0.203\n",
            "15499/15750 (epoch 49), train_loss = 2.114, time/batch = 0.200\n",
            "15500/15750 (epoch 49), train_loss = 2.139, time/batch = 0.201\n",
            "15501/15750 (epoch 49), train_loss = 2.075, time/batch = 0.207\n",
            "15502/15750 (epoch 49), train_loss = 2.090, time/batch = 0.195\n",
            "15503/15750 (epoch 49), train_loss = 2.141, time/batch = 0.202\n",
            "15504/15750 (epoch 49), train_loss = 2.247, time/batch = 0.200\n",
            "15505/15750 (epoch 49), train_loss = 2.165, time/batch = 0.204\n",
            "15506/15750 (epoch 49), train_loss = 2.153, time/batch = 0.207\n",
            "15507/15750 (epoch 49), train_loss = 2.085, time/batch = 0.203\n",
            "15508/15750 (epoch 49), train_loss = 2.136, time/batch = 0.198\n",
            "15509/15750 (epoch 49), train_loss = 2.257, time/batch = 0.200\n",
            "15510/15750 (epoch 49), train_loss = 2.199, time/batch = 0.200\n",
            "15511/15750 (epoch 49), train_loss = 2.190, time/batch = 0.201\n",
            "15512/15750 (epoch 49), train_loss = 2.184, time/batch = 0.198\n",
            "15513/15750 (epoch 49), train_loss = 2.194, time/batch = 0.204\n",
            "15514/15750 (epoch 49), train_loss = 2.182, time/batch = 0.201\n",
            "15515/15750 (epoch 49), train_loss = 2.084, time/batch = 0.201\n",
            "15516/15750 (epoch 49), train_loss = 2.185, time/batch = 0.198\n",
            "15517/15750 (epoch 49), train_loss = 2.138, time/batch = 0.202\n",
            "15518/15750 (epoch 49), train_loss = 2.184, time/batch = 0.204\n",
            "15519/15750 (epoch 49), train_loss = 2.232, time/batch = 0.210\n",
            "15520/15750 (epoch 49), train_loss = 2.255, time/batch = 0.199\n",
            "15521/15750 (epoch 49), train_loss = 2.092, time/batch = 0.199\n",
            "15522/15750 (epoch 49), train_loss = 2.138, time/batch = 0.206\n",
            "15523/15750 (epoch 49), train_loss = 2.148, time/batch = 0.198\n",
            "15524/15750 (epoch 49), train_loss = 2.160, time/batch = 0.202\n",
            "15525/15750 (epoch 49), train_loss = 2.147, time/batch = 0.201\n",
            "15526/15750 (epoch 49), train_loss = 2.208, time/batch = 0.200\n",
            "15527/15750 (epoch 49), train_loss = 2.195, time/batch = 0.207\n",
            "15528/15750 (epoch 49), train_loss = 2.205, time/batch = 0.200\n",
            "15529/15750 (epoch 49), train_loss = 2.267, time/batch = 0.202\n",
            "15530/15750 (epoch 49), train_loss = 2.186, time/batch = 0.204\n",
            "15531/15750 (epoch 49), train_loss = 2.218, time/batch = 0.201\n",
            "15532/15750 (epoch 49), train_loss = 2.238, time/batch = 0.210\n",
            "15533/15750 (epoch 49), train_loss = 2.211, time/batch = 0.196\n",
            "15534/15750 (epoch 49), train_loss = 2.226, time/batch = 0.203\n",
            "15535/15750 (epoch 49), train_loss = 2.205, time/batch = 0.203\n",
            "15536/15750 (epoch 49), train_loss = 2.153, time/batch = 0.201\n",
            "15537/15750 (epoch 49), train_loss = 2.163, time/batch = 0.205\n",
            "15538/15750 (epoch 49), train_loss = 2.285, time/batch = 0.203\n",
            "15539/15750 (epoch 49), train_loss = 2.207, time/batch = 0.200\n",
            "15540/15750 (epoch 49), train_loss = 2.113, time/batch = 0.201\n",
            "15541/15750 (epoch 49), train_loss = 2.185, time/batch = 0.200\n",
            "15542/15750 (epoch 49), train_loss = 2.212, time/batch = 0.208\n",
            "15543/15750 (epoch 49), train_loss = 2.237, time/batch = 0.198\n",
            "15544/15750 (epoch 49), train_loss = 2.269, time/batch = 0.201\n",
            "15545/15750 (epoch 49), train_loss = 2.329, time/batch = 0.197\n",
            "15546/15750 (epoch 49), train_loss = 2.186, time/batch = 0.199\n",
            "15547/15750 (epoch 49), train_loss = 2.206, time/batch = 0.204\n",
            "15548/15750 (epoch 49), train_loss = 2.194, time/batch = 0.200\n",
            "15549/15750 (epoch 49), train_loss = 2.193, time/batch = 0.201\n",
            "15550/15750 (epoch 49), train_loss = 2.283, time/batch = 0.202\n",
            "15551/15750 (epoch 49), train_loss = 2.208, time/batch = 0.201\n",
            "15552/15750 (epoch 49), train_loss = 2.319, time/batch = 0.206\n",
            "15553/15750 (epoch 49), train_loss = 2.205, time/batch = 0.202\n",
            "15554/15750 (epoch 49), train_loss = 2.203, time/batch = 0.203\n",
            "15555/15750 (epoch 49), train_loss = 2.176, time/batch = 0.201\n",
            "15556/15750 (epoch 49), train_loss = 2.155, time/batch = 0.200\n",
            "15557/15750 (epoch 49), train_loss = 2.198, time/batch = 0.207\n",
            "15558/15750 (epoch 49), train_loss = 2.143, time/batch = 0.202\n",
            "15559/15750 (epoch 49), train_loss = 2.178, time/batch = 0.198\n",
            "15560/15750 (epoch 49), train_loss = 2.194, time/batch = 0.200\n",
            "15561/15750 (epoch 49), train_loss = 2.279, time/batch = 0.203\n",
            "15562/15750 (epoch 49), train_loss = 2.172, time/batch = 0.205\n",
            "15563/15750 (epoch 49), train_loss = 2.194, time/batch = 0.198\n",
            "15564/15750 (epoch 49), train_loss = 2.154, time/batch = 0.201\n",
            "15565/15750 (epoch 49), train_loss = 2.117, time/batch = 0.201\n",
            "15566/15750 (epoch 49), train_loss = 2.127, time/batch = 0.200\n",
            "15567/15750 (epoch 49), train_loss = 2.131, time/batch = 0.205\n",
            "15568/15750 (epoch 49), train_loss = 2.157, time/batch = 0.199\n",
            "15569/15750 (epoch 49), train_loss = 2.164, time/batch = 0.201\n",
            "15570/15750 (epoch 49), train_loss = 2.303, time/batch = 0.202\n",
            "15571/15750 (epoch 49), train_loss = 2.259, time/batch = 0.201\n",
            "15572/15750 (epoch 49), train_loss = 2.265, time/batch = 0.206\n",
            "15573/15750 (epoch 49), train_loss = 2.249, time/batch = 0.200\n",
            "15574/15750 (epoch 49), train_loss = 2.169, time/batch = 0.201\n",
            "15575/15750 (epoch 49), train_loss = 2.174, time/batch = 0.203\n",
            "15576/15750 (epoch 49), train_loss = 2.267, time/batch = 0.199\n",
            "15577/15750 (epoch 49), train_loss = 2.285, time/batch = 0.205\n",
            "15578/15750 (epoch 49), train_loss = 2.258, time/batch = 0.200\n",
            "15579/15750 (epoch 49), train_loss = 2.174, time/batch = 0.202\n",
            "15580/15750 (epoch 49), train_loss = 2.172, time/batch = 0.201\n",
            "15581/15750 (epoch 49), train_loss = 2.138, time/batch = 0.202\n",
            "15582/15750 (epoch 49), train_loss = 2.229, time/batch = 0.209\n",
            "15583/15750 (epoch 49), train_loss = 2.257, time/batch = 0.202\n",
            "15584/15750 (epoch 49), train_loss = 2.209, time/batch = 0.199\n",
            "15585/15750 (epoch 49), train_loss = 2.193, time/batch = 0.203\n",
            "15586/15750 (epoch 49), train_loss = 2.237, time/batch = 0.203\n",
            "15587/15750 (epoch 49), train_loss = 2.264, time/batch = 0.207\n",
            "15588/15750 (epoch 49), train_loss = 2.218, time/batch = 0.201\n",
            "15589/15750 (epoch 49), train_loss = 2.232, time/batch = 0.193\n",
            "15590/15750 (epoch 49), train_loss = 2.230, time/batch = 0.201\n",
            "15591/15750 (epoch 49), train_loss = 2.229, time/batch = 0.199\n",
            "15592/15750 (epoch 49), train_loss = 2.226, time/batch = 0.201\n",
            "15593/15750 (epoch 49), train_loss = 2.303, time/batch = 0.198\n",
            "15594/15750 (epoch 49), train_loss = 2.170, time/batch = 0.207\n",
            "15595/15750 (epoch 49), train_loss = 2.250, time/batch = 0.198\n",
            "15596/15750 (epoch 49), train_loss = 2.231, time/batch = 0.200\n",
            "15597/15750 (epoch 49), train_loss = 2.256, time/batch = 0.201\n",
            "15598/15750 (epoch 49), train_loss = 2.321, time/batch = 0.199\n",
            "15599/15750 (epoch 49), train_loss = 2.243, time/batch = 0.199\n",
            "15600/15750 (epoch 49), train_loss = 2.245, time/batch = 0.199\n",
            "15601/15750 (epoch 49), train_loss = 2.230, time/batch = 0.200\n",
            "15602/15750 (epoch 49), train_loss = 2.202, time/batch = 0.200\n",
            "15603/15750 (epoch 49), train_loss = 2.166, time/batch = 0.212\n",
            "15604/15750 (epoch 49), train_loss = 2.161, time/batch = 0.201\n",
            "15605/15750 (epoch 49), train_loss = 2.200, time/batch = 0.200\n",
            "15606/15750 (epoch 49), train_loss = 2.231, time/batch = 0.200\n",
            "15607/15750 (epoch 49), train_loss = 2.209, time/batch = 0.199\n",
            "15608/15750 (epoch 49), train_loss = 2.285, time/batch = 0.212\n",
            "15609/15750 (epoch 49), train_loss = 2.210, time/batch = 0.204\n",
            "15610/15750 (epoch 49), train_loss = 2.144, time/batch = 0.195\n",
            "15611/15750 (epoch 49), train_loss = 2.175, time/batch = 0.205\n",
            "15612/15750 (epoch 49), train_loss = 2.234, time/batch = 0.201\n",
            "15613/15750 (epoch 49), train_loss = 2.168, time/batch = 0.209\n",
            "15614/15750 (epoch 49), train_loss = 2.127, time/batch = 0.201\n",
            "15615/15750 (epoch 49), train_loss = 2.165, time/batch = 0.199\n",
            "15616/15750 (epoch 49), train_loss = 2.237, time/batch = 0.198\n",
            "15617/15750 (epoch 49), train_loss = 2.217, time/batch = 0.204\n",
            "15618/15750 (epoch 49), train_loss = 2.279, time/batch = 0.207\n",
            "15619/15750 (epoch 49), train_loss = 2.251, time/batch = 0.201\n",
            "15620/15750 (epoch 49), train_loss = 2.219, time/batch = 0.197\n",
            "15621/15750 (epoch 49), train_loss = 2.174, time/batch = 0.202\n",
            "15622/15750 (epoch 49), train_loss = 2.237, time/batch = 0.205\n",
            "15623/15750 (epoch 49), train_loss = 2.262, time/batch = 0.206\n",
            "15624/15750 (epoch 49), train_loss = 2.318, time/batch = 0.200\n",
            "15625/15750 (epoch 49), train_loss = 2.311, time/batch = 0.200\n",
            "15626/15750 (epoch 49), train_loss = 2.215, time/batch = 0.200\n",
            "15627/15750 (epoch 49), train_loss = 2.232, time/batch = 0.202\n",
            "15628/15750 (epoch 49), train_loss = 2.165, time/batch = 0.206\n",
            "15629/15750 (epoch 49), train_loss = 2.291, time/batch = 0.202\n",
            "15630/15750 (epoch 49), train_loss = 2.253, time/batch = 0.200\n",
            "15631/15750 (epoch 49), train_loss = 2.213, time/batch = 0.201\n",
            "15632/15750 (epoch 49), train_loss = 2.162, time/batch = 0.198\n",
            "15633/15750 (epoch 49), train_loss = 2.270, time/batch = 0.208\n",
            "15634/15750 (epoch 49), train_loss = 2.053, time/batch = 0.203\n",
            "15635/15750 (epoch 49), train_loss = 2.167, time/batch = 0.202\n",
            "15636/15750 (epoch 49), train_loss = 2.133, time/batch = 0.204\n",
            "15637/15750 (epoch 49), train_loss = 2.209, time/batch = 0.201\n",
            "15638/15750 (epoch 49), train_loss = 2.175, time/batch = 0.209\n",
            "15639/15750 (epoch 49), train_loss = 2.246, time/batch = 0.202\n",
            "15640/15750 (epoch 49), train_loss = 2.185, time/batch = 0.197\n",
            "15641/15750 (epoch 49), train_loss = 2.079, time/batch = 0.204\n",
            "15642/15750 (epoch 49), train_loss = 2.139, time/batch = 0.196\n",
            "15643/15750 (epoch 49), train_loss = 2.146, time/batch = 0.206\n",
            "15644/15750 (epoch 49), train_loss = 2.211, time/batch = 0.201\n",
            "15645/15750 (epoch 49), train_loss = 2.106, time/batch = 0.199\n",
            "15646/15750 (epoch 49), train_loss = 2.176, time/batch = 0.203\n",
            "15647/15750 (epoch 49), train_loss = 2.069, time/batch = 0.198\n",
            "15648/15750 (epoch 49), train_loss = 2.139, time/batch = 0.204\n",
            "15649/15750 (epoch 49), train_loss = 2.128, time/batch = 0.203\n",
            "15650/15750 (epoch 49), train_loss = 2.107, time/batch = 0.202\n",
            "15651/15750 (epoch 49), train_loss = 2.271, time/batch = 0.203\n",
            "15652/15750 (epoch 49), train_loss = 2.097, time/batch = 0.199\n",
            "15653/15750 (epoch 49), train_loss = 2.332, time/batch = 0.207\n",
            "15654/15750 (epoch 49), train_loss = 2.207, time/batch = 0.200\n",
            "15655/15750 (epoch 49), train_loss = 2.092, time/batch = 0.204\n",
            "15656/15750 (epoch 49), train_loss = 2.116, time/batch = 0.199\n",
            "15657/15750 (epoch 49), train_loss = 2.180, time/batch = 0.201\n",
            "15658/15750 (epoch 49), train_loss = 2.165, time/batch = 0.206\n",
            "15659/15750 (epoch 49), train_loss = 2.145, time/batch = 0.203\n",
            "15660/15750 (epoch 49), train_loss = 2.160, time/batch = 0.201\n",
            "15661/15750 (epoch 49), train_loss = 2.225, time/batch = 0.205\n",
            "15662/15750 (epoch 49), train_loss = 2.145, time/batch = 0.200\n",
            "15663/15750 (epoch 49), train_loss = 2.193, time/batch = 0.206\n",
            "15664/15750 (epoch 49), train_loss = 2.281, time/batch = 0.197\n",
            "15665/15750 (epoch 49), train_loss = 2.136, time/batch = 0.201\n",
            "15666/15750 (epoch 49), train_loss = 2.148, time/batch = 0.202\n",
            "15667/15750 (epoch 49), train_loss = 2.185, time/batch = 0.200\n",
            "15668/15750 (epoch 49), train_loss = 2.189, time/batch = 0.209\n",
            "15669/15750 (epoch 49), train_loss = 2.142, time/batch = 0.198\n",
            "15670/15750 (epoch 49), train_loss = 2.128, time/batch = 0.196\n",
            "15671/15750 (epoch 49), train_loss = 2.101, time/batch = 0.203\n",
            "15672/15750 (epoch 49), train_loss = 2.144, time/batch = 0.202\n",
            "15673/15750 (epoch 49), train_loss = 2.341, time/batch = 0.207\n",
            "15674/15750 (epoch 49), train_loss = 2.183, time/batch = 0.201\n",
            "15675/15750 (epoch 49), train_loss = 2.236, time/batch = 0.201\n",
            "15676/15750 (epoch 49), train_loss = 2.117, time/batch = 0.199\n",
            "15677/15750 (epoch 49), train_loss = 2.164, time/batch = 0.202\n",
            "15678/15750 (epoch 49), train_loss = 2.189, time/batch = 0.200\n",
            "15679/15750 (epoch 49), train_loss = 2.200, time/batch = 0.197\n",
            "15680/15750 (epoch 49), train_loss = 2.253, time/batch = 0.202\n",
            "15681/15750 (epoch 49), train_loss = 2.208, time/batch = 0.203\n",
            "15682/15750 (epoch 49), train_loss = 2.210, time/batch = 0.194\n",
            "15683/15750 (epoch 49), train_loss = 2.184, time/batch = 0.204\n",
            "15684/15750 (epoch 49), train_loss = 2.201, time/batch = 0.214\n",
            "15685/15750 (epoch 49), train_loss = 2.115, time/batch = 0.200\n",
            "15686/15750 (epoch 49), train_loss = 2.104, time/batch = 0.199\n",
            "15687/15750 (epoch 49), train_loss = 2.196, time/batch = 0.203\n",
            "15688/15750 (epoch 49), train_loss = 2.215, time/batch = 0.199\n",
            "15689/15750 (epoch 49), train_loss = 2.182, time/batch = 0.213\n",
            "15690/15750 (epoch 49), train_loss = 2.146, time/batch = 0.202\n",
            "15691/15750 (epoch 49), train_loss = 2.098, time/batch = 0.200\n",
            "15692/15750 (epoch 49), train_loss = 2.130, time/batch = 0.199\n",
            "15693/15750 (epoch 49), train_loss = 2.272, time/batch = 0.200\n",
            "15694/15750 (epoch 49), train_loss = 2.250, time/batch = 0.212\n",
            "15695/15750 (epoch 49), train_loss = 2.226, time/batch = 0.199\n",
            "15696/15750 (epoch 49), train_loss = 2.170, time/batch = 0.198\n",
            "15697/15750 (epoch 49), train_loss = 2.192, time/batch = 0.200\n",
            "15698/15750 (epoch 49), train_loss = 2.185, time/batch = 0.204\n",
            "15699/15750 (epoch 49), train_loss = 2.195, time/batch = 0.207\n",
            "15700/15750 (epoch 49), train_loss = 2.245, time/batch = 0.196\n",
            "15701/15750 (epoch 49), train_loss = 2.243, time/batch = 0.204\n",
            "15702/15750 (epoch 49), train_loss = 2.180, time/batch = 0.202\n",
            "15703/15750 (epoch 49), train_loss = 2.205, time/batch = 0.204\n",
            "15704/15750 (epoch 49), train_loss = 2.244, time/batch = 0.206\n",
            "15705/15750 (epoch 49), train_loss = 2.230, time/batch = 0.197\n",
            "15706/15750 (epoch 49), train_loss = 2.148, time/batch = 0.203\n",
            "15707/15750 (epoch 49), train_loss = 2.187, time/batch = 0.204\n",
            "15708/15750 (epoch 49), train_loss = 2.243, time/batch = 0.202\n",
            "15709/15750 (epoch 49), train_loss = 2.253, time/batch = 0.209\n",
            "15710/15750 (epoch 49), train_loss = 2.194, time/batch = 0.199\n",
            "15711/15750 (epoch 49), train_loss = 2.259, time/batch = 0.198\n",
            "15712/15750 (epoch 49), train_loss = 2.199, time/batch = 0.203\n",
            "15713/15750 (epoch 49), train_loss = 2.177, time/batch = 0.205\n",
            "15714/15750 (epoch 49), train_loss = 2.125, time/batch = 0.208\n",
            "15715/15750 (epoch 49), train_loss = 2.327, time/batch = 0.199\n",
            "15716/15750 (epoch 49), train_loss = 2.161, time/batch = 0.200\n",
            "15717/15750 (epoch 49), train_loss = 2.139, time/batch = 0.204\n",
            "15718/15750 (epoch 49), train_loss = 2.240, time/batch = 0.201\n",
            "15719/15750 (epoch 49), train_loss = 2.154, time/batch = 0.206\n",
            "15720/15750 (epoch 49), train_loss = 2.277, time/batch = 0.202\n",
            "15721/15750 (epoch 49), train_loss = 2.199, time/batch = 0.199\n",
            "15722/15750 (epoch 49), train_loss = 2.201, time/batch = 0.203\n",
            "15723/15750 (epoch 49), train_loss = 2.122, time/batch = 0.201\n",
            "15724/15750 (epoch 49), train_loss = 2.220, time/batch = 0.210\n",
            "15725/15750 (epoch 49), train_loss = 2.143, time/batch = 0.199\n",
            "15726/15750 (epoch 49), train_loss = 2.204, time/batch = 0.200\n",
            "15727/15750 (epoch 49), train_loss = 2.216, time/batch = 0.203\n",
            "15728/15750 (epoch 49), train_loss = 2.164, time/batch = 0.199\n",
            "15729/15750 (epoch 49), train_loss = 2.219, time/batch = 0.204\n",
            "15730/15750 (epoch 49), train_loss = 2.292, time/batch = 0.202\n",
            "15731/15750 (epoch 49), train_loss = 2.239, time/batch = 0.200\n",
            "15732/15750 (epoch 49), train_loss = 2.270, time/batch = 0.200\n",
            "15733/15750 (epoch 49), train_loss = 2.152, time/batch = 0.204\n",
            "15734/15750 (epoch 49), train_loss = 2.218, time/batch = 0.206\n",
            "15735/15750 (epoch 49), train_loss = 2.201, time/batch = 0.203\n",
            "15736/15750 (epoch 49), train_loss = 2.148, time/batch = 0.198\n",
            "15737/15750 (epoch 49), train_loss = 2.274, time/batch = 0.200\n",
            "15738/15750 (epoch 49), train_loss = 2.122, time/batch = 0.199\n",
            "15739/15750 (epoch 49), train_loss = 2.244, time/batch = 0.204\n",
            "15740/15750 (epoch 49), train_loss = 2.205, time/batch = 0.200\n",
            "15741/15750 (epoch 49), train_loss = 2.165, time/batch = 0.200\n",
            "15742/15750 (epoch 49), train_loss = 2.111, time/batch = 0.202\n",
            "15743/15750 (epoch 49), train_loss = 2.151, time/batch = 0.199\n",
            "15744/15750 (epoch 49), train_loss = 2.257, time/batch = 0.205\n",
            "15745/15750 (epoch 49), train_loss = 2.141, time/batch = 0.200\n",
            "15746/15750 (epoch 49), train_loss = 2.113, time/batch = 0.202\n",
            "15747/15750 (epoch 49), train_loss = 2.151, time/batch = 0.201\n",
            "15748/15750 (epoch 49), train_loss = 2.170, time/batch = 0.198\n",
            "15749/15750 (epoch 49), train_loss = 2.255, time/batch = 0.207\n",
            "model saved to ./save_star/model.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIU3vBNtu-Ec",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cp input.txt /content/char-rnn-tensorflow/data/star"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiwQsoXgNbUQ",
        "colab_type": "code",
        "outputId": "37bb6c0a-9b1a-45e3-e4df-0d0b346e8b84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python sample.py --save_dir=./save_star"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0828 03:12:30.832082 140132896421760 deprecation.py:323] From /content/char-rnn-tensorflow/model.py:30: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "W0828 03:12:30.833436 140132896421760 deprecation.py:323] From /content/char-rnn-tensorflow/model.py:36: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
            "W0828 03:12:30.834038 140132896421760 deprecation_wrapper.py:119] From /content/char-rnn-tensorflow/model.py:39: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0828 03:12:30.859474 140132896421760 deprecation_wrapper.py:119] From /content/char-rnn-tensorflow/model.py:46: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0828 03:12:30.859923 140132896421760 deprecation_wrapper.py:119] From /content/char-rnn-tensorflow/model.py:47: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "W0828 03:12:30.860571 140132896421760 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0828 03:12:31.265022 140132896421760 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn_cell_impl.py:961: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0828 03:12:31.910497 140132896421760 deprecation_wrapper.py:119] From /content/char-rnn-tensorflow/model.py:86: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "W0828 03:12:32.030439 140132896421760 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/clip_ops.py:286: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0828 03:12:32.041883 140132896421760 deprecation_wrapper.py:119] From /content/char-rnn-tensorflow/model.py:92: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "W0828 03:12:32.171435 140132896421760 deprecation_wrapper.py:119] From /content/char-rnn-tensorflow/model.py:98: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n",
            "\n",
            "W0828 03:12:32.174329 140132896421760 deprecation_wrapper.py:119] From /content/char-rnn-tensorflow/model.py:100: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "W0828 03:12:32.175674 140132896421760 deprecation_wrapper.py:119] From sample.py:39: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2019-08-28 03:12:32.177009: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
            "2019-08-28 03:12:32.196519: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-28 03:12:32.200545: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-08-28 03:12:32.201053: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-08-28 03:12:32.203310: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-08-28 03:12:32.205285: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-08-28 03:12:32.205908: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-08-28 03:12:32.212839: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-08-28 03:12:32.214591: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-08-28 03:12:32.221166: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-08-28 03:12:32.221418: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-28 03:12:32.222448: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-28 03:12:32.223244: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-08-28 03:12:32.229262: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
            "2019-08-28 03:12:32.229536: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x164abc0 executing computations on platform Host. Devices:\n",
            "2019-08-28 03:12:32.229572: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-08-28 03:12:32.286098: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-28 03:12:32.287037: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x164aa00 executing computations on platform CUDA. Devices:\n",
            "2019-08-28 03:12:32.287083: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2019-08-28 03:12:32.287330: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-28 03:12:32.288042: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-08-28 03:12:32.288117: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-08-28 03:12:32.288147: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-08-28 03:12:32.288171: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-08-28 03:12:32.288207: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-08-28 03:12:32.288230: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-08-28 03:12:32.288261: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-08-28 03:12:32.288286: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-08-28 03:12:32.288346: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-28 03:12:32.289054: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-28 03:12:32.289713: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-08-28 03:12:32.289806: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-08-28 03:12:32.291269: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-08-28 03:12:32.291300: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2019-08-28 03:12:32.291313: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2019-08-28 03:12:32.291478: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-28 03:12:32.292171: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-28 03:12:32.292885: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:40] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-08-28 03:12:32.292935: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "W0828 03:12:32.759906 140132896421760 deprecation_wrapper.py:119] From sample.py:41: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "W0828 03:12:32.794989 140132896421760 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "2019-08-28 03:12:32.900624: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            " 무무리기 중해하는 일이 얼크거리서 비함을 더 고미해도 없었고 망주에 자기 요담하면 모든 과정이 아슬렁도 시작해야길 의례적으로 나타났다. 그리고 이론은 저게 빨리 보였다. 목성이다. 이는 꿈이 있었습니다. 그런 비행동절기자는 남은 종족이 의자를 보였다. 이는 돌사도’.”\n",
            "\n",
            "헌트는 그의 얼굴로 깔려물 불짝이라고 말할 겁니다, 쉽게 생각하고 일어났다. “우리가 전에 가지우니가 많아요. 단편은 모서고 만대로 행성의 실험감으로 전용 가능성이었는지는 모르겠습니다. 전 감시를 구했어, 더욱 그 내디질에 앞쪽으로 경험했을 것 같습니다.”\n",
            "\n",
            "헌트가 하루는 단어폰 허원준의 핵상임이 있었다. 브로귈리오가 울려고 살아 있었다. 섀넌 대장 가진 UN 우주군의 전체를 만든 시간을 걸었다. 비자르가 그 건지 조류에 지구에서 같은 규지의 일상이 일어나자 모두 혼잣부 번술을 기다리고 있는 타공생술 및 지구의 핵전체가 개 할 수 있습니다. 두 군압은 인간의 공초능선을 통하는 일이었다. 이는 우주선에서도 구비과 사령\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PT49nDXlNk8y",
        "colab_type": "code",
        "outputId": "34b85523-7a36-4036-9b46-3d2ec7604ab2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python sample.py --save_dir=./save_star"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0828 03:13:06.436845 140356636878720 deprecation.py:323] From /content/char-rnn-tensorflow/model.py:30: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "W0828 03:13:06.438036 140356636878720 deprecation.py:323] From /content/char-rnn-tensorflow/model.py:36: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
            "W0828 03:13:06.438627 140356636878720 deprecation_wrapper.py:119] From /content/char-rnn-tensorflow/model.py:39: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0828 03:13:06.461845 140356636878720 deprecation_wrapper.py:119] From /content/char-rnn-tensorflow/model.py:46: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0828 03:13:06.462194 140356636878720 deprecation_wrapper.py:119] From /content/char-rnn-tensorflow/model.py:47: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "W0828 03:13:06.462766 140356636878720 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0828 03:13:06.836856 140356636878720 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn_cell_impl.py:961: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0828 03:13:07.473809 140356636878720 deprecation_wrapper.py:119] From /content/char-rnn-tensorflow/model.py:86: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "W0828 03:13:07.593162 140356636878720 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/clip_ops.py:286: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0828 03:13:07.604793 140356636878720 deprecation_wrapper.py:119] From /content/char-rnn-tensorflow/model.py:92: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "W0828 03:13:07.733974 140356636878720 deprecation_wrapper.py:119] From /content/char-rnn-tensorflow/model.py:98: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n",
            "\n",
            "W0828 03:13:07.736660 140356636878720 deprecation_wrapper.py:119] From /content/char-rnn-tensorflow/model.py:100: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "W0828 03:13:07.737992 140356636878720 deprecation_wrapper.py:119] From sample.py:39: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2019-08-28 03:13:07.739152: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
            "2019-08-28 03:13:07.756507: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-28 03:13:07.757296: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-08-28 03:13:07.757574: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-08-28 03:13:07.758870: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-08-28 03:13:07.760135: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-08-28 03:13:07.760502: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-08-28 03:13:07.762491: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-08-28 03:13:07.763734: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-08-28 03:13:07.767432: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-08-28 03:13:07.767546: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-28 03:13:07.768390: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-28 03:13:07.769097: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-08-28 03:13:07.774563: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
            "2019-08-28 03:13:07.774827: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2994bc0 executing computations on platform Host. Devices:\n",
            "2019-08-28 03:13:07.774878: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-08-28 03:13:07.837974: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-28 03:13:07.838988: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2994a00 executing computations on platform CUDA. Devices:\n",
            "2019-08-28 03:13:07.839034: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2019-08-28 03:13:07.839188: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-28 03:13:07.840008: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-08-28 03:13:07.840092: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-08-28 03:13:07.840121: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-08-28 03:13:07.840147: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-08-28 03:13:07.840172: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-08-28 03:13:07.840198: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-08-28 03:13:07.840223: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-08-28 03:13:07.840264: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-08-28 03:13:07.840325: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-28 03:13:07.841130: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-28 03:13:07.841867: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-08-28 03:13:07.841924: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-08-28 03:13:07.843572: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-08-28 03:13:07.843604: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2019-08-28 03:13:07.843617: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2019-08-28 03:13:07.843758: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-28 03:13:07.844621: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-28 03:13:07.845317: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:40] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-08-28 03:13:07.845369: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "W0828 03:13:08.298489 140356636878720 deprecation_wrapper.py:119] From sample.py:41: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "W0828 03:13:08.331714 140356636878720 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "2019-08-28 03:13:08.436993: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            " 착원들을 안 됩니다. 활동을 감춰봤었다는 뜻인지 믿을 수 있도록 회신의 적이 지르러져 나왔다는 사실을 저류할 수 있을 겁니다. 그 게 아니라. 내가 저한테 동물 움직이며 사라졌습니다. 하나가 지구를 해주 도넛 둘에서 초공간 행성의 기술 나타씨륨의 독립하지만 이번에는 그 대표발 없은 친구들일지도 하겠습니다.” 단체커가 잠시 멈춰 근처가 멎었다. “일질은 투리엔 존재들이 들고, 심각하게 할 수 있습니다. 하지만 그 문명이 의중 방향으로 자리로 쌓았을지 본래 여긴 역사가 걸렸습니다. 우리는 발견되었지….” 단체커가 어울리듯 설명으로 닦고 소브로데도 바로 동료들을 드린 동의와 작은 자네의 스테레이트란 손위란 충학은 가니메데인 준비가 있는 사람들이 멍한 인류야, 최면을 믿기는 에너지(A 대형의 모든 것이― 일행 속에서 계속 내가의 숨았는지는 위로 만난 감명을 멸망해봐. 가니메데인은 지구 뭐죠?”\n",
            "\n",
            "“그들은 샤피에론호에 기타물와 다른 행체의 비추로면서 투장한 능력이 월인에게 말없이 비쳤는군요.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35-ESPylN0cG",
        "colab_type": "code",
        "outputId": "9e894f8c-c5d4-46ce-d7bd-0649720dc1c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python sample.py --save_dir=./save_star"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0828 03:14:25.711887 139945528301440 deprecation.py:323] From /content/char-rnn-tensorflow/model.py:30: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "W0828 03:14:25.713043 139945528301440 deprecation.py:323] From /content/char-rnn-tensorflow/model.py:36: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
            "W0828 03:14:25.713633 139945528301440 deprecation_wrapper.py:119] From /content/char-rnn-tensorflow/model.py:39: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0828 03:14:25.737417 139945528301440 deprecation_wrapper.py:119] From /content/char-rnn-tensorflow/model.py:46: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0828 03:14:25.737746 139945528301440 deprecation_wrapper.py:119] From /content/char-rnn-tensorflow/model.py:47: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "W0828 03:14:25.738279 139945528301440 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0828 03:14:26.122740 139945528301440 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn_cell_impl.py:961: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0828 03:14:26.764925 139945528301440 deprecation_wrapper.py:119] From /content/char-rnn-tensorflow/model.py:86: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "W0828 03:14:26.895271 139945528301440 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/clip_ops.py:286: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0828 03:14:26.906153 139945528301440 deprecation_wrapper.py:119] From /content/char-rnn-tensorflow/model.py:92: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "W0828 03:14:27.045245 139945528301440 deprecation_wrapper.py:119] From /content/char-rnn-tensorflow/model.py:98: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n",
            "\n",
            "W0828 03:14:27.048112 139945528301440 deprecation_wrapper.py:119] From /content/char-rnn-tensorflow/model.py:100: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "W0828 03:14:27.049734 139945528301440 deprecation_wrapper.py:119] From sample.py:39: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2019-08-28 03:14:27.050947: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
            "2019-08-28 03:14:27.068757: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-28 03:14:27.069527: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-08-28 03:14:27.069798: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-08-28 03:14:27.071032: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-08-28 03:14:27.072221: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-08-28 03:14:27.072589: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-08-28 03:14:27.074396: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-08-28 03:14:27.075698: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-08-28 03:14:27.079433: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-08-28 03:14:27.079544: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-28 03:14:27.080338: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-28 03:14:27.081044: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-08-28 03:14:27.086595: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
            "2019-08-28 03:14:27.086826: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1bcebc0 executing computations on platform Host. Devices:\n",
            "2019-08-28 03:14:27.086863: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-08-28 03:14:27.141425: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-28 03:14:27.142223: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1bcea00 executing computations on platform CUDA. Devices:\n",
            "2019-08-28 03:14:27.142255: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2019-08-28 03:14:27.142447: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-28 03:14:27.143129: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-08-28 03:14:27.143227: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-08-28 03:14:27.143257: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-08-28 03:14:27.143282: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-08-28 03:14:27.143306: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-08-28 03:14:27.143329: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-08-28 03:14:27.143353: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-08-28 03:14:27.143403: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-08-28 03:14:27.143475: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-28 03:14:27.144165: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-28 03:14:27.144843: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-08-28 03:14:27.144914: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-08-28 03:14:27.146369: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-08-28 03:14:27.146420: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2019-08-28 03:14:27.146434: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2019-08-28 03:14:27.146544: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-28 03:14:27.147285: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-28 03:14:27.147977: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:40] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-08-28 03:14:27.148025: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "W0828 03:14:27.601585 139945528301440 deprecation_wrapper.py:119] From sample.py:41: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "W0828 03:14:27.634931 139945528301440 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "2019-08-28 03:14:27.739939: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            " 당인 본부장은 착륙을 연결를 일으키고 됩니다!” 쉴로힌인 테니다.” 소브로스킨이 고개를 끄덕여 모르게 단손된 체름이 입니다만, 다시 다루고 지난 말을 잘섰다. 과정의 방사실로 돌아야 할 사람 같은 산소를 찾아모….” 무슨 헌트가 말했다. “내와 달걀의 날이었다는 이야기를 차지하기 위해 후, 에서 공기의 궤도를 통해 그 의문도 여기이?” 쉴로힌이 대답했다. “내성 의자에 달렸어. 인상과 선방에 전적이라는 생물들이었지만, 이쯤 가너웠다는 것 같으면 놓퉁자실 캡슐을 따라가를 알려 한팔 비했다시 말에 대한 빛들에 섰었다. 이건 원의 군사에 쏟은 것이 나타낼 수 있었다. 가니메데에 탐지기를 반복하지 않았을만?”\n",
            "\n",
            "“가지를 환지하고, 당신은 가니메데인들이 이것이 계산받을 물려받았고, 그리고 나오게 그들을 구의 파괴된 각도의 인간의 체준 연구소쪽으로 해결병을 보고 있는 작은 방장도 되고 제대로 모르기 때문에 우리의 공중적인 공학자의 고분 의미 시절됩니다. 논리가 많은데?” 비자르가 낮은 모니터에\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUQjsVyKN-QY",
        "colab_type": "code",
        "outputId": "ff0f5469-be09-4fb1-d29d-8fda22f56bcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cp -r /content/char-rnn-tensorflow /content/gdrive/My Drive/"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cp: target 'Drive/' is not a directory\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}